{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/fastai/courses/blob/master/deeplearning1/nbs/char-rnn.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import importlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker\n",
    "import numpy as np\n",
    "import random\n",
    "import time\n",
    "import os\n",
    "import pandas as pd\n",
    "import csv\n",
    "import math\n",
    "import bcolz\n",
    "import pickle\n",
    "import re\n",
    "import pathlib\n",
    "import datetime\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "\n",
    "SOS_TOKEN = '<SOS>' # Start Of Word"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Data setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# importing keras might cause problems with cudann version etc\n",
    "# import keras # some good utils in here\n",
    "# path = keras.utils.data_utils.get_file('nietzsche.txt', origin=\"https://s3.amazonaws.com/text-datasets/nietzsche.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/ohu/.keras/datasets/nietzsche.txt'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "corpus length: 600893\n"
     ]
    }
   ],
   "source": [
    "path = '/home/ohu/.keras/datasets/nietzsche.txt'\n",
    "text = open(path).read().lower()\n",
    "path\n",
    "print('corpus length:', len(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "not to be regarded as a pure type. Knowledge and science--as far as they\r\n",
      "existed--and superiority to the rest of mankind by logical discipline\r\n",
      "and training of the intellectual powers were insisted upon by the\r\n",
      "Buddhists as essential to sanctity, just as they were denounced by the\r\n",
      "christian world as the indications of sinfulness."
     ]
    }
   ],
   "source": [
    "!tail {path} -n5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total chars: 57\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n !\"\\'(),-.0123456789:;=?[]_abcdefghijklmnopqrstuvwxyzäæéë'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chars = sorted(list(set(text)))\n",
    "print('total chars:', len(chars))\n",
    "''.join(chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
    "char_indices['\\n']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 5, 57])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def string_to_tensor(in_str, chars_index=char_indices, as_variable=True):\n",
    "    \"\"\"Onehot encoded tensor of string\"\"\"\n",
    "    tensor_length = len(in_str)\n",
    "    tensor = torch.zeros(1, tensor_length, len(chars_index))\n",
    "    for li, letter in enumerate(in_str):\n",
    "        tensor[0, li, chars_index[letter]] = 1\n",
    "    if as_variable:\n",
    "        tensor = Variable(tensor).cuda()\n",
    "    return tensor\n",
    "\n",
    "string_to_tensor('hello', as_variable=False).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def time_since(since):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Char Rnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CharRNN (\n",
       "  (rnn): GRU(57, 512, batch_first=True)\n",
       "  (lin_output): Linear (512 -> 57)\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class CharRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(CharRNN, self).__init__()\n",
    "        \n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.layers = 1\n",
    "        \n",
    "        self.rnn = nn.GRU(input_size, hidden_size, batch_first=True)\n",
    "        self.lin_output = nn.Linear(hidden_size, input_size)\n",
    "        \n",
    "        # self.log_softmax = nn.LogSoftmax(dim=1) # current releas doesn't yet support dimensions\n",
    "        \n",
    "    def forward(self, input_char_vs, hidden = None):\n",
    "        batch_size = input_char_vs.size()[0]\n",
    "        if hidden is None:\n",
    "            hidden = self.init_hidden(batch_size)\n",
    "        \n",
    "        rnn_outputs, hidden = self.rnn(input_char_vs, hidden)\n",
    "        \n",
    "        outputs = self.lin_output(rnn_outputs)\n",
    "        #outputs = self.log_softmax(outputs)\n",
    "        \n",
    "        #outputs = F.log_softmax(outputs[0])\n",
    "\n",
    "        return outputs, hidden\n",
    "\n",
    "    def init_hidden(self, batch_size=1):\n",
    "        return Variable(torch.zeros(self.layers, batch_size, self.hidden_size)).cuda()\n",
    "    \n",
    "model = CharRNN(len(chars), 512).cuda()\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 5, 57])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 512])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#tmp = Variable(torch.FloatTensor([2]).view(1,1,-1)).cuda()\n",
    "#tmp = Variable(string_to_tensor('hello')).cuda()\n",
    "tmp = model(string_to_tensor('hello'))\n",
    "len(tmp[0][0])\n",
    "tmp[0].size()\n",
    "tmp[1].size()\n",
    "#chars[tmp[0].topk(1)[1].data[0][0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 5, 57])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 2, 512])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp = torch.cat((string_to_tensor('hello'), string_to_tensor('hello')))\n",
    "#tmp.size()\n",
    "\n",
    "tmp = model(tmp)\n",
    "tmp[0].size()\n",
    "tmp[1].size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " would in\n",
      "onde that? must_!\"\n",
      "118. he wo\n",
      "long with whatever plytol some has intruestion, religion of molation in which they arrein musting ones, erammatic mexty dosing them. buture altechated, will by \n",
      "------------------\n",
      " is the strength of the strength of the strength of the strength of the strength of the strength of the strength of the strength of the strength of the strength of the strength of the strength of the \n"
     ]
    }
   ],
   "source": [
    "# This is faster that uses the existing state untill the end\n",
    "def print_example(iters=320, choice=True):\n",
    "    seed_string=\"ethics is a basic foundation of all that\"\n",
    "    result_string = ''\n",
    "    hidden = model.init_hidden()\n",
    "    output, hidden = model(string_to_tensor(seed_string), hidden)\n",
    "    \n",
    "    for i in range(iters):\n",
    "        output = output[0, -1]\n",
    "        if choice:\n",
    "            next_char = np.random.choice(chars, p=F.softmax(output).data.cpu().numpy())\n",
    "        else:\n",
    "            next_char_idx = output.topk(1)[1].data[0] \n",
    "            next_char = chars[next_char_idx]\n",
    "        \n",
    "        result_string += next_char\n",
    "        output, hidden = model(string_to_tensor(next_char), hidden)\n",
    "    print(result_string)\n",
    "tmp = 200\n",
    "print_example(iters=tmp, choice=True)\n",
    "print('------------------')\n",
    "print_example(iters=tmp, choice=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'essing the ground, are the occasion of ot'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_random_sample_string(length=41):\n",
    "    sample_place = random.randint(0, len(text)-length-1)\n",
    "    sample = text[sample_place:sample_place+length]\n",
    "    return sample\n",
    "get_random_sample_string()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sample_size = 50000\n",
    "\n",
    "sample_sentence_size = 40\n",
    "sample_data = torch.zeros(sample_size, sample_sentence_size, len(chars)) # .cuda()\n",
    "#sample_target = torch.zeros((sample_size, sample_sentence_size, 1), torch.LongTensor)\n",
    "sample_target = torch.LongTensor(sample_size, sample_sentence_size).zero_() # .cuda()\n",
    "for i in range(sample_size):\n",
    "    sample = get_random_sample_string(sample_sentence_size+1)\n",
    "    sample = [char_indices[c] for c in sample]\n",
    "    for j in range(sample_sentence_size):\n",
    "        sample_data[i][j][sample[j]] = 1\n",
    "        sample_target[i][j] = sample[j+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "' \"how are synthetic judgments a priori\\np'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = 5\n",
    "j = 10\n",
    "sample_data[i].topk(1)[1][j][0] == sample_target[i][j-1]\n",
    "''.join([chars[c[0]] for c in sample_data[i].topk(1)[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ntrwer  ahich inlyged toe  th bavd ae or',\n",
       " 'nr of the suestion  thes is aoat iuite i']"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "1.4231221675872803"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clip_parameters_value = 0.25\n",
    "\n",
    "def train_single(optimizer, loss_function, batch_size=64):\n",
    "    model.zero_grad()\n",
    "    loss = 0\n",
    "    output_lines = []\n",
    "    \n",
    "    sample_i = random.randint(0, len(sample_data)-1-batch_size)\n",
    "    #x = sample_data[sample_i].view(1,40,len(chars))\n",
    "    #y = sample_target[sample_i]\n",
    "    \n",
    "    x = sample_data[sample_i:sample_i+batch_size].view(batch_size,40,len(chars))\n",
    "    y = sample_target[sample_i:sample_i+batch_size]\n",
    "    \n",
    "    target = Variable(y).cuda()\n",
    "\n",
    "    hidden = model.init_hidden(batch_size)\n",
    "    outputs, hidden = model(Variable(x).cuda(), hidden)\n",
    "\n",
    "    top_chars = outputs.topk(1)[1].data\n",
    "    for i in range(len(outputs)):\n",
    "        loss += loss_function(outputs[i], target[i])       \n",
    "        output_lines.append(''.join([chars[c[0]] for c in top_chars[i]]))\n",
    "    \n",
    "    if clip_parameters_value:\n",
    "        torch.nn.utils.clip_grad_norm(model.parameters(), clip_parameters_value)\n",
    "        \n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    return output_lines, loss.data[0]/batch_size\n",
    "\n",
    "tmp = train_single(torch.optim.Adam(model.parameters(), lr=0.0001), torch.nn.CrossEntropyLoss())\n",
    "tmp[0][0:2]\n",
    "tmp[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44.6 ms ± 2.67 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "train_single(torch.optim.Adam(model.parameters(), lr=0.001), torch.nn.CrossEntropyLoss(), batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_iterations(n_iters=100000, lr=0.001, batch_size=64,\n",
    "                     print_every=10000, plot_every=1000):\n",
    "    \n",
    "    def print_infos():\n",
    "        print(\"{:>6d} {:>4.0%} ({:>8}) {:>7.3f}   | {:>6.2f}: {}\".format(\n",
    "          model_training.iterations, iteration/n_iters, time_since(start),\n",
    "          current_loss/current_loss_iter, loss, result))\n",
    "    \n",
    "    \n",
    "    global optimizer\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    \n",
    "    start = time.time()\n",
    "    model.train()\n",
    "\n",
    "    current_loss = 0\n",
    "    current_loss_iter = 1\n",
    "    \n",
    "    for iteration in range(1, n_iters + 1):\n",
    "        model_training.iterations += 1\n",
    "        \n",
    "        #use_teacher_forcing = random.random() < teacher_forcing_ratio\n",
    "        use_teacher_forcing = False\n",
    "        \n",
    "        #loss_function=nn.NLLLoss()\n",
    "        loss_function = torch.nn.CrossEntropyLoss()\n",
    "        result, loss = train_single(optimizer=optimizer, loss_function=loss_function, batch_size=batch_size)\n",
    "        result = result[0]\n",
    "        \n",
    "        current_loss += loss\n",
    "        current_loss_iter += 1\n",
    "\n",
    "        # Print iter number, loss, name and guess\n",
    "        if iteration % print_every == 0:\n",
    "            print_infos()\n",
    "\n",
    "        # Add current loss avg to list of losses\n",
    "        if iteration % plot_every == 0:\n",
    "            model_training.losses.append(current_loss / plot_every)\n",
    "            model_training.learning_rates.append(lr)\n",
    "            current_loss = 0\n",
    "            current_loss_iter = 1\n",
    "\n",
    "    print_infos()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pytorch utils oh: pytorch_utils_oh_3.py\n",
      "Pytorch: 0.2.0_4\n"
     ]
    }
   ],
   "source": [
    "from pytorch_utils_oh_3 import ModelTraining\n",
    "MODEL_SAVE_PATH = 'char_rnn_fast_ai_testing_2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CharRNN (\n",
       "  (rnn): GRU(57, 512, batch_first=True)\n",
       "  (lin_output): Linear (512 -> 57)\n",
       ")"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Save path: data/models/char_rnn_fast_ai_testing_2\n"
     ]
    }
   ],
   "source": [
    "model = CharRNN(len(chars), 512).cuda()\n",
    "model\n",
    "model_training = ModelTraining(MODEL_SAVE_PATH, [model])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     5  50% (   0m 0s)   3.297   |   3.82: s                                       \n",
      "    10 100% (   0m 0s)   3.330   |   3.24: ss                                      \n",
      "    10 100% (   0m 0s)   3.330   |   3.24: ss                                      \n"
     ]
    }
   ],
   "source": [
    "train_iterations(n_iters=10, print_every=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    25  10% (   0m 0s)   2.902   |   3.09: r t                                     \n",
      "    40  19% (   0m 1s)   2.950   |   2.96: s                                       \n",
      "    55  29% (   0m 2s)   2.940   |   2.84: rt  e                ee    e            \n",
      "    70  38% (   0m 2s)   2.903   |   2.74:   tn tn   tn tn     t     en  the  tn   \n",
      "    85  48% (   0m 3s)   2.856   |   2.60: nee an tn  aote e e thnheth e  ehahen  t\n",
      "   100  58% (   0m 4s)   2.809   |   2.70: the then    tn tn an  tn then  an  ens e\n",
      "   115  67% (   0m 4s)   2.769   |   2.51: eneetn sn   ao e toen aen ah te tor e n \n",
      "   130  77% (   0m 5s)   2.731   |   2.52: theneetf tn an the tf  nes ae e  aheneet\n",
      "   145  87% (   0m 6s)   2.697   |   2.41: dtnd ao arn e  ne er erehneslsh and aor \n",
      "   160  96% (   0m 6s)   2.668   |   2.38:  toir  ahe toetl   ee af the t etl  an t\n",
      "   166 100% (   0m 7s)   2.656   |   2.33: eteeng    tooen e   aorhetn an ter eete \n"
     ]
    }
   ],
   "source": [
    "train_iterations(n_iters=10000//64, print_every=1000//64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ethics is a basic foundation of all that ara onsree co\n",
      "ve bel themo on alvemeceseprithaciuly what\n",
      "ust\"-: ncend ise neis uhe af of enaverd thingbest ane,, hes derktead\n",
      "oupsuwe worhentelssutisery me u4 sof egarly of hte ofcis the se fowbinlle the yton itsees\n",
      "phe inest af of iod nle co\n",
      "my cnofpinnt ir, of toall, to the iict helist ald ghedm cotns af onber and d\n"
     ]
    }
   ],
   "source": [
    "print_example()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   181  10% (   0m 0s)   2.232   |   2.37: r rlt rt reinl   af trd re-ers  --n     \n",
      "   196  19% (   0m 1s)   2.279   |   2.29: toeuethet  hree af th  e rion tn on an t\n",
      "   211  29% (   0m 1s)   2.283   |   2.34:  ahe trenltn h e-n ert of terentorehnesl\n",
      "   226  38% (   0m 2s)   2.283   |   2.28: n rlorer tor tett en  and ahe senhse nht\n",
      "   241  48% (   0m 3s)   2.275   |   2.21: e th27  wfee t nn  tner nn  tum ns iott \n",
      "   256  58% (   0m 3s)   2.269   |   2.29: hhet tetitn  ysh  thenh thtd  ah tnleest\n",
      "   271  67% (   0m 4s)   2.263   |   2.21:  tnd ae eng ah tof  tn eif  s  and   af \n",
      "   286  77% (   0m 5s)   2.254   |   2.18: hon tndorn  thith tnt ean andtn  nitn ly\n",
      "   301  87% (   0m 5s)   2.246   |   2.14:   ahrl  aoet sn y aoeueth l   and r ahe \n",
      "   316  96% (   0m 6s)   2.236   |   2.19: e aotiiote  ahet totiielf antirn aomreea\n",
      "   322 100% (   0m 6s)   2.232   |   2.16: nl   oh the poethe oritane  e netf txter\n"
     ]
    }
   ],
   "source": [
    "train_iterations(n_iters=10000//64, print_every=1000//64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ethics is a basic foundation of all that thes, if in aver--in s oxpriniteconio cajurel--aul ous entering the bote, oh ied's, andeonn\" inperyule,\n",
      "anctifer and andirnow, the tanted\n",
      "-os thede thes mpals wiom vande\" an iry maee lfacs of\n",
      "ascatal of mastopi--) hatants of\n",
      "aleverorf\n",
      "thinasely breacs, andelo to hith gurtines mann prenturasien trat emingod souts.--nat\n"
     ]
    }
   ],
   "source": [
    "print_example()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   478  10% (   0m 6s)   2.046   |   1.95: h heige  ond tn tienant   tn  aorderent \n",
      "   634  20% (  0m 14s)   1.976   |   1.83:      and tcemher tan  aor r an o tne cer\n",
      "   790  30% (  0m 21s)   1.910   |   1.68: e ahe seing r ng trichologi af tormer th\n",
      "   946  40% (  0m 28s)   1.852   |   1.63: the sxpentalltirld an aot the sarlnof tu\n",
      "  1102  50% (  0m 35s)   1.803   |   1.63:   iateof trotefide tiich ts irsst oor e \n",
      "  1258  60% (  0m 41s)   1.761   |   1.53:  ul  aot inh tand ng toe ponrtge us aecn\n",
      "  1414  70% (  0m 48s)   1.476   |   1.49: he snter tirld if tvpmted  avotionsl  ar\n",
      "  1570  80% (  0m 55s)   1.468   |   1.52:  tonteryof tue s oorndairtues, aonrsges \n",
      "  1726  90% (   1m 3s)   1.454   |   1.40: e igions cn erpretation of tvpstence  ah\n",
      "  1882 100% (  1m 10s)   1.440   |   1.37: hahet thes ionsint ttould anlays secannt\n",
      "  1884 100% (  1m 10s)   1.440   |   1.39:  -w\n",
      "\n",
      "9\n",
      "\n",
      "\n",
      "the e are aon aho cre andgeudab\n"
     ]
    }
   ],
   "source": [
    "train_iterations(n_iters=100000//64, print_every=10000//64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " of i mainy in otser for hilplo's bory-nobadow\n",
      "and decest-and pawn\n",
      "highlound, and a former to fash it not said bo\n",
      "known the troupter which rules--whether is how relesile!\"_ pirit. every decedi-not permitting of mancessis and days can, these acts of insomethe on ics always which, kndwequanily lendity, these ramissions a\n"
     ]
    }
   ],
   "source": [
    "print_example()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " there is not foofryther propenty of man naster,\"--our \"froensmen har nite their precisely\n",
      "accordingly hervelict and themselves: in everything of froend forthine; a non--he sedued,\n",
      "shouls, but to is: the simely saym to believes of defined itself is whom--on omy pride of curto, when he censur histruas, paptristic to kno\n"
     ]
    }
   ],
   "source": [
    "print_example()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " subject authortaint knows, how cutialization, geniual myself out, fow r.-indeed,' hrances--all lised up consideraty?; ow \"ciscivaling ouch utwarant\n",
      "give what is gond also, or erroceatirnt: of a docaling spones and pirif antirmated to polithes of vilwer in reado \"more\n",
      "expeniences! the most free-simenicated with an whic\n"
     ]
    }
   ],
   "source": [
    "print_example()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  2040  10% (   0m 7s)   1.358   |   1.33: tn  cwject ohe sndluetion of trin apon t\n",
      "  2196  20% (  0m 13s)   1.351   |   1.34:   avough to tonrterence on ias tot tohop\n",
      "  2352  30% (  0m 20s)   1.339   |   1.33:   testoose  -wn is anher ise thth the sa\n",
      "  2508  40% (  0m 27s)   1.330   |   1.31:  r ioul  tn t robpen rsond aespoveredsth\n",
      "  2664  50% (  0m 33s)   1.322   |   1.31: h rsf ttamtumes   ttmean ts tomserni tor\n",
      "  2820  60% (  0m 40s)   1.314   |   1.30:  oometsastions of the mes   the moneroyw\n",
      "  2976  70% (  0m 47s)   1.223   |   1.34: ertlere -onmery ppcuctive cntosphere -af\n",
      "  3132  80% (  0m 54s)   1.231   |   1.10:  tn theycuestion wherher tty hing ounaph\n",
      "  3288  90% (   1m 0s)   1.228   |   1.18:   ahe sxpeession  ot iente ff toral   in\n",
      "  3444 100% (   1m 7s)   1.220   |   1.17:  orint  \n",
      "\n",
      "44. ts at the fernlariporsa en\n",
      "  3446 100% (   1m 7s)   1.220   |   1.15: the suestion  thes is titt buite isnored\n"
     ]
    }
   ],
   "source": [
    "train_iterations(n_iters=100000//64, print_every=10000//64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " is the abxistomed. who would still themselves from for those other mavadity.--only command nor before look readiness, granted of opon themselves that you\n",
      "make its placting and\n",
      "most frandate from them from himsple makes he\n",
      "preserve to progous, and what science, in former naturally\n",
      "by means on thiumsuld\n",
      "so is selocker. \n"
     ]
    }
   ],
   "source": [
    "print_example()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " which has just faith-in himself,\n",
      "even under people must, the very older him.--therefore utulates a fundamental contemplation of the fivile, which scholars in this world will be ever been churd, and he happens to their done hit loves remains.  have been amenot have always, out loother hand misunderstandings, in order t\n"
     ]
    }
   ],
   "source": [
    "print_example()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  3602  10% (   0m 6s)   1.183   |   1.08:  th these onteosers, theugh they way ben\n",
      "  3758  20% (  0m 13s)   1.180   |   1.17: d rd  th e all tf them aesessantenmn toi\n",
      "  3914  30% (  0m 20s)   1.174   |   1.20: -oass fofe asdexeryreasi sosgrast on eea\n",
      "  4070  40% (  0m 27s)   1.166   |   1.10:   ry,ond tustice as iery dreat  ttpeliev\n",
      "  4226  50% (  0m 33s)   1.157   |   1.13: e e  thit ws to say,tt.e dpirituoast be \n",
      "  4382  60% (  0m 40s)   1.152   |   1.05:  ind ohich iannure ohersorlhyof thesgs a\n",
      "  4538  70% (  0m 47s)   1.094   |   1.08: tesrh as if the sosll  wt ething tnconmu\n",
      "  4694  80% (  0m 53s)   1.091   |   1.10: n tesenn e if aissthet tu the sasis of w\n",
      "  4850  90% (   1m 0s)   1.086   |   1.06: e  nt  ae wast tpder tond thet the seeat\n",
      "  5006 100% (   1m 7s)   1.081   |   1.10: enturtes dn urpire- \n",
      "1ut toch aeluacs ty\n",
      "  5008 100% (   1m 8s)   1.081   |   1.07: etes bone tld dn even lomeng oore and mo\n"
     ]
    }
   ],
   "source": [
    "train_iterations(n_iters=100000//64, print_every=10000//64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " serkembnes--and \"christianity as attrmatual fact, the will to all philosophy and\n",
      "shampless history is politin spaces at least is unavoud fortule;\n",
      "from the scientific man!--is, for the fablicates of undellabing conditioned\n",
      "with our feasen not necessary to dange further, thereflee, sesief rurely sould, as he chuscless c\n"
     ]
    }
   ],
   "source": [
    "print_example()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " attempt hours, of\n",
      "the finest euterness the whole styeen, to become justice.=--philology\n",
      "surplus of culture: for\n",
      "their body, and men of\n",
      "the flaurerde, moleress, and conceingumping to every own, what we clearly encounal-yough for wimn--understanding here, the party, to some plabour;--ad\n",
      "slaid), and below the property, b\n"
     ]
    }
   ],
   "source": [
    "print_example()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  5164  10% (   0m 6s)   1.042   |   1.08:  etr hiwever, ts toch mo  saow and seaep\n",
      "  5320  20% (  0m 13s)   1.041   |   0.99: n tieorous growth --it iesects the cherr\n",
      "  5476  30% (  0m 20s)   1.035   |   1.06: hich te no   the melsation of the eontit\n",
      "  5632  40% (  0m 27s)   1.030   |   1.09: thit iasherto hpders thambrs  eet weot t\n",
      "  5788  50% (  0m 33s)   1.026   |   1.00: n ng sis owservation fpon mxpeptional mh\n",
      "  5944  60% (  0m 40s)   1.020   |   1.01: thet ian is lience  maniind hoes ne isfe\n",
      "  6100  70% (  0m 47s)   0.974   |   0.98: n ihesks hemain ior the mreat  the mcsss\n",
      "  6256  80% (  0m 54s)   0.978   |   1.08: e arseirnning and dotho  oxd, lake ise h\n",
      "  6412  90% (   1m 0s)   0.975   |   1.01: h e alpewessity of tvfect  an t dard, te\n",
      "  6568 100% (   1m 8s)   0.971   |   1.04: th toristianity an wly cirme for whth st\n",
      "  6570 100% (   1m 8s)   0.971   |   0.91: trrn andact oay nasse another? as far as\n"
     ]
    }
   ],
   "source": [
    "train_iterations(n_iters=100000//64, print_every=10000//64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " is stormed, must be weazers in order that the \"hravenenal spirits!\n",
      "\n",
      "292. in havigg, ages, many-dishapsedein.\n",
      "\n",
      "\n",
      "169\n",
      "\n",
      "=the there of phusoness, such benof concersming, suptrmert hum unted things, that the contempt fremshlandered or somebody.\n",
      "\n",
      "98. whoever has\n",
      "dohe than only when it is the belief to them comes our prive at\n"
     ]
    }
   ],
   "source": [
    "print_example()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " words in misunderstlondection, we call\n",
      "\"higher, dreaming; it wad the religious men--orator, bod,\n",
      "in the\n",
      "former and action,\n",
      "bying that go whot\n",
      "pleasure\n",
      "of thin\n",
      "constrenges:\n",
      "the word itself having at least, but syspech to the time of humanity (the real upon what is\n",
      "\n",
      "uncertain, the begail and of view megraties at the box\n"
     ]
    }
   ],
   "source": [
    "print_example()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  6726  10% (   0m 6s)   0.957   |   1.02:   toamsros could ell tb them fonesto us \n",
      "  6882  20% (  0m 13s)   0.952   |   0.91: iohe aore ooarply at that ps con in him,\n",
      "  7038  30% (  0m 19s)   0.945   |   0.90: e ess,an tttersion, nor anything it once\n",
      "  7194  40% (  0m 26s)   0.941   |   0.93:   ah ssl thet eevuces, all res  wonstrai\n",
      "  7350  50% (  0m 33s)   0.938   |   0.99: e  tomes  ahe stul oad arown aeact  ahe \n",
      "  7506  60% (  0m 39s)   0.933   |   0.91:  aot bnow  and ehat ihe focous oetient a\n",
      "  7662  70% (  0m 46s)   0.888   |   0.93: tive ro eelieve in tvernal life an drder\n",
      "  7818  80% (  0m 52s)   0.904   |   0.90: heue mhoas which hequirescorturyes of mo\n",
      "  7974  90% (  0m 59s)   0.900   |   0.85: iohivmyny  even similarity of view oint \n",
      "  8130 100% (   1m 6s)   0.899   |   0.97:  aast kortainly teal with an\n",
      "ere to the \n",
      "  8132 100% (   1m 6s)   0.899   |   0.79: thrlsan,ike liborious ess  to whoch te h\n"
     ]
    }
   ],
   "source": [
    "train_iterations(n_iters=100000//64, print_every=10000//64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " goethe's \"good conscience the trouble show such indiscourable and the spirit would\n",
      "allured as naired,\" which is no\n",
      "longer godo, dirocons itself is a religious aften, decey, such as survays happens narrew and does not\n",
      "among at present danger, that \"chilors sin even without her delusion great.=--the dogm so! be ornaboe \n"
     ]
    }
   ],
   "source": [
    "print_example()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ", of everything consciousness of has homines, frate. and by the world--and revengefulness\" injury instruction, who are in the habit of patagnoos. there are hindred by ustlanders not believe that has been\n",
      "bystally, to\n",
      "zouth not to speak of\n",
      "sknieitome\"......\n",
      "\n",
      "264. it may be incomprehensible one\n",
      "sense on the day after to \n"
     ]
    }
   ],
   "source": [
    "print_example()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  8522  25% (  0m 16s)   0.873   |   0.77: tns sthe dard   tas hitherto bouumphed  \n",
      "  8912  50% (  0m 33s)   0.870   |   0.69: h bhe pew pailosophers hho are atpearing\n",
      "  9302  75% (  0m 50s)   0.844   |   0.91: ell   ahe sesiruction-of the cndividuals\n",
      "  9692 100% (   1m 7s)   0.844   |   0.93:  e ning theyouelities of mank\n",
      "\n",
      "\n",
      "42\n",
      "\n",
      "=cla\n",
      "  9694 100% (   1m 7s)   0.844   |   0.82: tii fxrher exgenders on froduces--buth w\n"
     ]
    }
   ],
   "source": [
    "train_iterations(n_iters=100000//64, print_every=25000//64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " immediate druak and lice\n",
      "small, on thi\n",
      "\n",
      "bit little a origin of as a matter of\n",
      "fecrives incertional sufferings, when he is desired light and noneral..\n",
      "perhaps the rightly\n",
      "andisint, our seeknts of life, is hasteristic original state obetien, aristo thickly \"given\" \"one may be a serean before the molier, all put itself looked upon as affownthe higher nature, impulse, conquest\n",
      "of character,\" as their truth? an everything of the exemutical influence within them as indamed although the feelings to whom\n",
      "relistening, from his wake him, as improst the things that exist, reverge them to liee and connected itself is a symptoms of another, and\n",
      "task of its plyasity and of treather\n",
      "want however, uncontious, and no matter of fact, the necessary consequences of enormously, and that has\n",
      "not only about one ruler, the\n",
      "designation and sense of truths ase\n",
      "\"inaxplicable that createvel, over-knowledge of\n",
      "the community or a cestath to)\n",
      "corpsivaling itility are declined and\n",
      "display as the rest of\n",
      "a majority are too years finally became only indiact, lapses of the decret is\n",
      "orderes, by the\n",
      "inexplicable,\"--the\n",
      "laws on schopans, its dingery without investigably be necesfarious to the condition of intellect, ne very reason is their means of\n",
      "conception which was only a sort of enjoyment in vain. have a success. the\n",
      "phyliss of the heart free whole last yet among mind,\" without a\n",
      "mode of life century writerness, conspicuol, orining the etormman can can atwain in\n",
      "sight of their \"warms. prode toee evoiving to find number, or as delief and ares. a kind of child should also emprosingem: one honesty and\n",
      "deal preffrency\n",
      "as denial or ane catilority, of domination and unarternative, wishon truth a desperation and nation has not being sumplixity, so that godss, of some dociol\n",
      "gittstle oriding as\n",
      "a sort of condictor, and no matter of conspication of enjoyment of\n",
      "the same dignath\n",
      "stseech success himself as well, verefrarection of\n",
      "the \"equality of richage and wes, even and to calling in voecal. this is the h\n"
     ]
    }
   ],
   "source": [
    "print_example(iters=2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "the old familiar\n",
      "darid to a new\n",
      "medicinating in garm and contains a pleasure is descener\n",
      "crrations around not without degenerated hellening an antidote to laits\n",
      "understood\" in himself the control of a\n",
      "man who certainly, no longer race. they are no moath out\n",
      "mask-oneself, nature been anywhere, or conceal himself or a certain virtus does see should\n",
      "come to rogative, and all philosophical successful experience to its\n",
      "uncreasor and his belief in\n",
      "woman\"--supposing now the uspessimist spirituality and doctrine\n",
      "of under painfus, imphended bud\n",
      "becomes for this is a sort of contume form--conser\"ning it rejosced morality stroke things remais superficial, neither stades. this assumptions puriod spitst german savisfue, more\n",
      "dolities. among one--love hor\n",
      "to have\n",
      "long agryemetabieace--and why? in rave--the simple time to-day.\n",
      "\n",
      "164. only interlocutors,\n",
      "in shout has pethants, however, are nove the rise\n",
      "tomenhe and lack of casef it.--\"equality and dominated\n",
      "him as the self absolubes doftheter be quatigness, namely,\n",
      "but, and \"change, appire to enjoy entanly, asceticism and\n",
      "sisful\"--or as a\n",
      "time or other in the same demorrative\n",
      "cruelty, to the prodiccom of during the syrtals\n",
      "child's probibal\n",
      "theory of the opposite words so far as it is us finnes absurdly from spring, but\n",
      "from yellong pureful and dangerous isplutic love: that which servest order of rank of \"is a cotserves?--this modern philosophers\n",
      "having and his power extends to place\n",
      "of a science, or agmosis fints a degrees and\n",
      "tragedy itself, not the process, as every dele, and without sleep extravagant person slowly\n",
      "established, through a new and morality. in different amist furite and thereby\n",
      "their pride is preciuised oneself fact!) whatever flight ones--as the coarsly also a sweete there is an innocence of another europe, it is short shouted from the seriousness of him. everything\n",
      "pordences; the expression fat as her surest aughting, under permixes the \"unbeilous is the worst in our own by).\n",
      "to plan the wood\"; it is now unferrod\n"
     ]
    }
   ],
   "source": [
    "print_example(iters=2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:py3_pytorch_2]",
   "language": "python",
   "name": "conda-env-py3_pytorch_2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
