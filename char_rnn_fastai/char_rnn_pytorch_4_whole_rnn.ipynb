{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/fastai/courses/blob/master/deeplearning1/nbs/char-rnn.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import importlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker\n",
    "import numpy as np\n",
    "import random\n",
    "import time\n",
    "import os\n",
    "import pandas as pd\n",
    "import csv\n",
    "import math\n",
    "import bcolz\n",
    "import pickle\n",
    "import re\n",
    "import pathlib\n",
    "import datetime\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "\n",
    "SOS_TOKEN = '<SOS>' # Start Of Word"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Data setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# importing keras might cause problems with cudann version etc\n",
    "# import keras # some good utils in here\n",
    "# path = keras.utils.data_utils.get_file('nietzsche.txt', origin=\"https://s3.amazonaws.com/text-datasets/nietzsche.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/ohu/.keras/datasets/nietzsche.txt'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "corpus length: 600893\n"
     ]
    }
   ],
   "source": [
    "path = '/home/ohu/.keras/datasets/nietzsche.txt'\n",
    "text = open(path).read().lower()\n",
    "path\n",
    "print('corpus length:', len(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "not to be regarded as a pure type. Knowledge and science--as far as they\r\n",
      "existed--and superiority to the rest of mankind by logical discipline\r\n",
      "and training of the intellectual powers were insisted upon by the\r\n",
      "Buddhists as essential to sanctity, just as they were denounced by the\r\n",
      "christian world as the indications of sinfulness."
     ]
    }
   ],
   "source": [
    "!tail {path} -n5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total chars: 57\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n !\"\\'(),-.0123456789:;=?[]_abcdefghijklmnopqrstuvwxyzäæéë'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chars = sorted(list(set(text)))\n",
    "print('total chars:', len(chars))\n",
    "''.join(chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
    "char_indices['\\n']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 5, 57])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def string_to_tensor(in_str, chars_index=char_indices, as_variable=True):\n",
    "    \"\"\"Onehot encoded tensor of string\"\"\"\n",
    "    tensor_length = len(in_str)\n",
    "    tensor = torch.zeros(1, tensor_length, len(chars_index))\n",
    "    for li, letter in enumerate(in_str):\n",
    "        tensor[0, li, chars_index[letter]] = 1\n",
    "    if as_variable:\n",
    "        tensor = Variable(tensor).cuda()\n",
    "    return tensor\n",
    "\n",
    "string_to_tensor('hello', as_variable=False).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def time_since(since):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Char Rnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CharRNN (\n",
       "  (rnn): GRU(57, 512, batch_first=True)\n",
       "  (lin_output): Linear (512 -> 57)\n",
       ")"
      ]
     },
     "execution_count": 290,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class CharRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(CharRNN, self).__init__()\n",
    "        \n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.layers = 1\n",
    "        \n",
    "        self.rnn = nn.GRU(input_size, hidden_size, batch_first=True)\n",
    "        self.lin_output = nn.Linear(hidden_size, input_size)\n",
    "        \n",
    "        \n",
    "    def forward(self, input_char_vs, hidden = None):\n",
    "        if hidden is None:\n",
    "            hidden = self.init_hidden()\n",
    "        \n",
    "        rnn_outputs, hidden = self.rnn(input_char_vs, hidden)\n",
    "        \n",
    "        outputs = self.lin_output(rnn_outputs[0])\n",
    "        outputs = F.log_softmax(outputs)\n",
    "\n",
    "        return outputs, hidden\n",
    "\n",
    "    def init_hidden(self):\n",
    "        return Variable(torch.zeros(self.layers, 1, self.hidden_size)).cuda()\n",
    "    \n",
    "model = CharRNN(len(chars), 512).cuda()\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "57"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 57])"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 512])"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#tmp = Variable(torch.FloatTensor([2]).view(1,1,-1)).cuda()\n",
    "#tmp = Variable(string_to_tensor('hello')).cuda()\n",
    "tmp = model(string_to_tensor('hello'))\n",
    "len(tmp[0][0])\n",
    "tmp[0].size()\n",
    "tmp[1].size()\n",
    "#chars[tmp[0].topk(1)[1].data[0][0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp[0][0].topk(1)[1].data[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ethics is a basic foundation of all thatgwyj50q2c9b qgt656643\n",
      ";cs9w(3?6(0ën]8f ,\n",
      "ethics is a basic foundation of all that----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "def print_example(iters=320, choice=True):\n",
    "    seed_string=\"ethics is a basic foundation of all that\"\n",
    "    for i in range(iters):\n",
    "        #x=np.array([char_indices[c] for c in seed_string[-40:]])[np.newaxis,:]\n",
    "        x = string_to_tensor(seed_string)\n",
    "        output, hidden = model(x)\n",
    "        output = output[-1]\n",
    "        if choice:\n",
    "            #next_char = np.random.choice(chars, p=F.softmax(output)[0].data.cpu().numpy())\n",
    "            next_char = np.random.choice(chars, p=F.softmax(output).data.cpu().numpy())\n",
    "        else:\n",
    "            next_char_idx = output.topk(1)[1].data[0] # [0]\n",
    "            next_char = chars[next_char_idx]\n",
    "        # return next_char\n",
    "        seed_string = seed_string + next_char\n",
    "    print(seed_string)\n",
    "#tmp = print_example(choice=False)\n",
    "print_example(iters=40, choice=True)\n",
    "print_example(iters=40, choice=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "', and mean to\\nguard and protect it from e'"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_random_sample_string(length=41):\n",
    "    sample_place = random.randint(0, len(text)-length-1)\n",
    "    sample = text[sample_place:sample_place+length]\n",
    "    return sample\n",
    "get_random_sample_string()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sample_size = 50000\n",
    "\n",
    "sample_sentence_size = 40\n",
    "sample_data = torch.zeros(sample_size, sample_sentence_size, len(chars)) # .cuda()\n",
    "#sample_target = torch.zeros((sample_size, sample_sentence_size, 1), torch.LongTensor)\n",
    "sample_target = torch.LongTensor(sample_size, sample_sentence_size).zero_() # .cuda()\n",
    "for i in range(sample_size):\n",
    "    sample = get_random_sample_string(sample_sentence_size+1)\n",
    "    sample = [char_indices[c] for c in sample]\n",
    "    for j in range(sample_sentence_size):\n",
    "        sample_data[i][j][sample[j]] = 1\n",
    "        sample_target[i][j] = sample[j+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'it was locke of whom schelling rightly s'"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = 5\n",
    "j = 10\n",
    "sample_data[i].topk(1)[1][j][0] == sample_target[i][j-1]\n",
    "''.join([chars[c[0]] for c in sample_data[i].topk(1)[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('                                        ', 3.9262466430664062)"
      ]
     },
     "execution_count": 320,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clip_parameters_value = 0.25\n",
    "\n",
    "def train_single(optimizer, loss_function, use_teacher_forcing):\n",
    "    model.zero_grad()\n",
    "    loss = 0\n",
    "    \n",
    "    sample_i = random.randint(0, len(sample_data)-1)\n",
    "    #x = sample_data[sample_i].view(1,40,len(chars))\n",
    "    #y = sample_target[sample_i]\n",
    "    \n",
    "    x = sample_data[sample_i].view(1,40,len(chars))\n",
    "    y = sample_target[sample_i]\n",
    "    \n",
    "    target = Variable(y).cuda()\n",
    "\n",
    "    hidden = model.init_hidden()\n",
    "    outputs, hidden = model(Variable(x).cuda(), hidden)\n",
    "    \n",
    "    loss += loss_function(outputs, target)\n",
    "\n",
    "    if clip_parameters_value:\n",
    "        torch.nn.utils.clip_grad_norm(model.parameters(), clip_parameters_value)\n",
    "    \n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    output_line = []\n",
    "    for output in outputs:\n",
    "        char_idx = output.topk(1)[1].data[0]\n",
    "        output_line.append(chars[char_idx])\n",
    "\n",
    "    return ''.join(output_line), loss.data[0]\n",
    "\n",
    "tmp = train_single(torch.optim.Adam(model.parameters(), lr=0.0001), nn.NLLLoss(), use_teacher_forcing=False)\n",
    "tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([40, 57])"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([40])"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp[0].size()\n",
    "tmp[1].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_iterations(n_iters=100000, lr=0.001, teacher_forcing_ratio=0,\n",
    "                     print_every=10000, plot_every=1000):\n",
    "    global optimizer\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    \n",
    "    start = time.time()\n",
    "    model.train()\n",
    "\n",
    "    current_loss = 0\n",
    "    current_loss_iter = 0\n",
    "    \n",
    "    for iteration in range(1, n_iters + 1):\n",
    "        model_training.iterations += 1\n",
    "        \n",
    "        #use_teacher_forcing = random.random() < teacher_forcing_ratio\n",
    "        use_teacher_forcing = False\n",
    "        \n",
    "        result, loss = train_single(optimizer=optimizer, loss_function=nn.NLLLoss(),\n",
    "                                    use_teacher_forcing=use_teacher_forcing)\n",
    "        \n",
    "        current_loss += loss\n",
    "        current_loss_iter += 1\n",
    "\n",
    "        # Print iter number, loss, name and guess\n",
    "        if iteration % print_every == 0:\n",
    "            teacher_forcing_str = \"\"\n",
    "            if use_teacher_forcing:\n",
    "                teacher_forcing_str = \"(forcing)\"\n",
    "            \n",
    "            print(\"{:>6d} {:>4.0%} ({:>8}) {:>7.3f}   | {:>6.2f}: {} {}\".format(\n",
    "                      model_training.iterations, iteration/n_iters, time_since(start),\n",
    "                      current_loss/current_loss_iter, loss, result, teacher_forcing_str))\n",
    "\n",
    "        # Add current loss avg to list of losses\n",
    "        if iteration % plot_every == 0:\n",
    "            model_training.losses.append(current_loss / plot_every)\n",
    "            model_training.learning_rates.append(lr)\n",
    "            current_loss = 0\n",
    "            current_loss_iter = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_utils_oh_3 import ModelTraining\n",
    "MODEL_SAVE_PATH = 'char_rnn_fast_ai_testing_2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Save path: data/models/char_rnn_fast_ai_testing_2\n"
     ]
    }
   ],
   "source": [
    "model_training = ModelTraining(MODEL_SAVE_PATH, [model])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     5  50% (   0m 0s)   3.957   |   3.86: s                                        \n",
      "    10 100% (   0m 0s)   3.704   |   3.33: t                                        \n"
     ]
    }
   ],
   "source": [
    "train_iterations(n_iters=10, print_every=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  1010  10% (   0m 4s)   2.469   |   2.06:  ahrl     af thtl aonee uld  y  an the w \n",
      "  2010  20% (   0m 9s)   2.142   |   1.94:   elidtnd seaslct ohth ushthe mne of tot \n",
      "  3010  30% (  0m 13s)   1.979   |   2.03: n ng   ior txplpee  ahet  ahlh y afeahll \n",
      "  4010  40% (  0m 17s)   1.884   |   1.58: ireton ooctinn tn elf aiinett is tegeess \n",
      "  5010  50% (  0m 22s)   1.799   |   1.14: nttomething thet the statd nd tnd the so \n",
      "  6010  60% (  0m 26s)   1.738   |   2.09: hen  t10 ooosouedtoe hrrsose  tnd the pa \n",
      "  7010  70% (  0m 31s)   1.698   |   1.25: thet thes worne of tunf toutenpli of ton \n",
      "  8010  80% (  0m 36s)   1.653   |   1.81: h hn tot days torled bfrovieat  inl tfer \n",
      "  9010  90% (  0m 40s)   1.634   |   1.69:   oesl  and done tncasst ine anowl an ae \n",
      " 10010 100% (  0m 45s)   1.599   |   1.90: n irly tlsh d  and cictiuaid thy foperii \n"
     ]
    }
   ],
   "source": [
    "train_iterations(n_iters=10000, print_every=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ethics is a basic foundation of all that they knowse!\"\n",
      "\n",
      "\"40\n",
      "\n",
      "=dect,s which has aid semptaticipal hos infucquinest, however\n",
      "extradicarice as this want for this factly anwicchy from sugsifeclizes,\n",
      "itsil\n",
      "duponitions\n",
      "of any tratth, tham only neighing which make to lece, ar way their\n",
      "practed by this freeconical sciences if the osay, always\n",
      "way is the retort of re\n"
     ]
    }
   ],
   "source": [
    "print_example()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 11010  10% (   0m 4s)   1.577   |   1.50:   oh t seldly txot eealiog trilosophecal \n",
      " 12010  20% (   0m 8s)   1.558   |   1.57: h ootmonger df eree  \n",
      "10. th hive aan in \n",
      " 13010  30% (  0m 13s)   1.551   |   1.68: i atnlhough  an an t praceatte on thmnh  \n",
      " 14010  40% (  0m 17s)   1.520   |   1.67: e tt ioos totdot her dhat thes fawg ng   \n",
      " 15010  50% (  0m 22s)   1.508   |   1.19:  stonning tfl fusht avrily tecardstimsel \n",
      " 16010  60% (  0m 26s)   1.499   |   1.30: hltr y tith ttcvtance,ond tilh tieedom o \n",
      " 17010  70% (  0m 31s)   1.486   |   1.32: af the srrn and txocarion ahas axpersed  \n",
      " 18010  80% (  0m 35s)   1.500   |   1.43:  l al anserpourse whtl tonsesahe snpgena \n",
      " 19010  90% (  0m 40s)   1.460   |   1.61: ee ng oh tnher   wn ias alpeaan  tnd tlp \n",
      " 20010 100% (  0m 44s)   1.449   |   2.41:  rlng onei-theough aed aaein dionrs -the \n"
     ]
    }
   ],
   "source": [
    "train_iterations(n_iters=10000, print_every=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ethics is a basic foundation of all that\n",
      "will despritte. there is some onesfluness, consequently coula sees of wive id a than he who eaviless one would partic lofty sttent one's basig we, and the belief that which he say and such an act far as under the word about the\n",
      "more standardance of \"geats, and thes succe! which were would be accustome theme the consti\n"
     ]
    }
   ],
   "source": [
    "print_example()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 25010  50% (  0m 22s)   1.440   |   1.76: hdt d iite aseem  to  th   wnsonmanity t \n",
      " 30010 100% (  0m 46s)   1.403   |   1.22: aoearerto anr own iirtues  aot ae ome a  \n"
     ]
    }
   ],
   "source": [
    "train_iterations(n_iters=10000, print_every=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ethics is a basic foundation of all that all rato one is all that he is abruth!\n",
      "\n",
      "\n",
      "1 110\n",
      "\n",
      "been that there is ewhicatantimis and hadgenerto inspieses age, in a partically, and in a performous moralic and it is whenner, has value\n",
      "of conduct has the liverdly, threed, and not be \"ture,\" and beants\" man's to guise\" and shill, seems a string at\n",
      "allated the powerful\n"
     ]
    }
   ],
   "source": [
    "print_example()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 35010  50% (  0m 23s)   1.380   |   1.41: aart dasdoess arr eof tttlience on aesig \n",
      " 40010 100% (  0m 46s)   1.353   |   1.11: n o ae ahe diart and rtul if thesks  \n",
      "\n",
      "1 \n"
     ]
    }
   ],
   "source": [
    "train_iterations(n_iters=10000, print_every=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ethics is a basic foundation of all that and inquired about a hindities, as\n",
      "trouble, thas the pessame tual act in the law of their laid, in keep some genius, which namuated, first, to de uniteding as circumstancle, its delusales, despicabld. hitherto sociated some vivius of himself so near the fuith as \"fututions\"--this mind,\n",
      "in it. i unand, in the last cutt\n"
     ]
    }
   ],
   "source": [
    "print_example()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 45010  50% (  0m 22s)   1.338   |   1.74: nlesrua  and aon be d  time and tol nemm \n",
      " 50010 100% (  0m 44s)   1.318   |   1.01:  toffecient  an iauld bave teen t w tn t \n"
     ]
    }
   ],
   "source": [
    "train_iterations(n_iters=10000, print_every=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ethics is a basic foundation of all that wese most yet agreea,\n",
      "terrible attitations which these of all these scale, if the most business of the head altherner of life, in fact, the world over religion in\n",
      "mytorous appirable than the \"bid hence\n",
      "feels prospesses oneself, has do not\n",
      "science, with the soul of secret distress and deplictful and's falient, is clain\n"
     ]
    }
   ],
   "source": [
    "print_example()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 60010  20% (  0m 46s)   1.307   |   1.69:  teoegsdam pwn sike,-irl oo dl ant;tust  \n",
      " 70010  40% (  1m 32s)   1.289   |   1.62:  tn  lf aart dntavse there  tnmeml  trne \n",
      " 80010  60% (  2m 17s)   1.284   |   1.17:  ttfe ms aesposid to thkk ond siught and \n",
      " 90010  80% (   3m 1s)   1.274   |   1.28: ns ond snsis norkh ahece bo ng tom tven  \n",
      "100010 100% (  3m 46s)   1.260   |   1.13:  ttimself ia dosdsttvery ooelings aveny  \n"
     ]
    }
   ],
   "source": [
    "train_iterations(n_iters=50000, print_every=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ethics is a basic foundation of all that wisfined\n",
      "good nor hand, from show, that makes than ne virtue; for the reason, among impolencusance and the like origin, and therefore, the wisfy of nature\n",
      "and our!\" everywheres.--everythingmands conduce interpreted, prolistic, and unsertionally originated\n",
      "understand understanding--or cratics,-and superiority and hardl\n"
     ]
    }
   ],
   "source": [
    "print_example()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ethics is a basic foundation of all that we\n",
      "have been a remarnative, and enchaning and art fallited in tormely of france. the inclination of the deportmanity inso our\n",
      "condictly as well an oldners, of sphinx-like\n",
      "priparanisms.--but it is the genuine saint, he is prularieve,\n",
      "already neither freedoms, certaintiap regarding\n",
      "things, but understand overwhradies ar\n"
     ]
    }
   ],
   "source": [
    "print_example()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "110010  10% (  0m 44s)   1.265   |   1.59: ers ng y sorl aoth tis wrisicil serensan \n",
      "120010  20% (  1m 30s)   1.260   |   1.11:  ess of dsdelfishnborives ahth tod, lt i \n",
      "130010  30% (  2m 15s)   1.259   |   1.52: t    eur soul ahlh t seofocsess setdensi \n",
      "140010  40% (   3m 1s)   1.249   |   1.13:   and ahe potter oion te wsserpretsd in  \n",
      "150010  50% (  3m 47s)   1.259   |   1.06: i tt tot teecehibed ty the wertrrs of th \n",
      "160010  60% (  4m 31s)   1.261   |   0.93: he dosel ty of the r pxgironment  the r  \n",
      "170010  70% (  5m 15s)   1.255   |   1.74: hred tnl the  aave totherto oioes  tnstb \n",
      "180010  80% (  5m 58s)   1.256   |   1.30: ton il drwerf th tuercome tarhphysica  o \n",
      "190010  90% (  6m 42s)   1.269   |   1.32:  r tg tsen the sest snd selpest tave on  \n",
      "200010 100% (  7m 26s)   1.284   |   1.10: athe mesinning  tn ttirificedthe mamrifi \n"
     ]
    }
   ],
   "source": [
    "train_iterations(n_iters=100000, print_every=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ethics is a basic foundation of all that hypocrity art the feelings of much\n",
      "and is--what as show the sedisating as perhaps after long agar most singly; and is that for the awe operates his \"war,\n",
      "much mirror, \"de\" his \"latter,\" would yet to be levilesing the emergaus proper any, the most power: it has there is no health, to which we more evil.\" the mestly con\n"
     ]
    }
   ],
   "source": [
    "print_example()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ethics is a basic foundation of all that the\n",
      "first still tipet and obvicable convalial haraffelly developed and friendly, to faist, ntilled on the \"monstrous\"--and \"the\" in the order of\n",
      "habliaring and experienced them, most science, one, there\n",
      "are mellow betrayed, arises what extent really the europeoning for mirds apartous case or that the sounce has made a\n"
     ]
    }
   ],
   "source": [
    "print_example()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.00446"
      ]
     },
     "execution_count": 289,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# seconds per iteration\n",
    "(7*60+26)/100000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:py3_pytorch_2]",
   "language": "python",
   "name": "conda-env-py3_pytorch_2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
