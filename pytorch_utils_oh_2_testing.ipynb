{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pytorch utils oh: pytorch_utils_oh_2.py\n",
      "Pytorch: 0.2.0_4\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "# import pytorch_utils_oh_1; from pytorch_utils_oh_1 import *;\n",
    "from pytorch_utils_oh_2 import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pytorch utils oh: pytorch_utils_oh_2.py\n",
      "Pytorch: 0.2.0_4\n"
     ]
    }
   ],
   "source": [
    "import pytorch_utils_oh_2; importlib.reload(pytorch_utils_oh_2); from pytorch_utils_oh_2 import *;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utils testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['asdf', \"'s\", 'asdf', '-', 'test']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simple_tokeniser(\"asdf's   ASDF   -test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(400000, 50)\n",
      "400000\n",
      "400000\n",
      "0 2772\n"
     ]
    }
   ],
   "source": [
    "wv_vecs, wv_words, wv_idx = load_glove('/home/ohu/koodi/data/glove_wordvec/glove.6B.50d.txt')\n",
    "print(wv_vecs.shape)\n",
    "print(len(wv_words))\n",
    "print(len(wv_idx))\n",
    "print(wv_idx['the'], wv_idx['yes'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<EOS>'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'<SOS>'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'<SAMPLE>'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EOS_TOKEN\n",
    "SOS_TOKEN\n",
    "SAMPLE_WORD_TOKEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "common_words, common_words_index = load_common_words_100()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yes\n",
      "☒\n",
      "<UNK>\n",
      "<SAMPLE>\n",
      "<0000>\n",
      "12\n",
      "<EOS>\n"
     ]
    }
   ],
   "source": [
    "tmp = ['yes', VERBATIM_CHAR, 'not_found', SAMPLE_WORD_TOKEN, '123321123321123', '12']\n",
    "for t in words_to_tensor(tmp, common_words_index)[0].topk(1)[1]:\n",
    "    print(common_words[t[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<SOS><EOS>☒ !\"#$%&'(),-./0123456789:;ABCDEFGHIJKLMNOPQRSTUVWXYZ_abcdefghijklmnopqrstuvwxyz~£¥ª²³µº¼½¾éɒʻˈΩμ—€⅓⅔⅛\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 104])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 104])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chars_normal, chars_normal_index = load_characters_pkl('data/en_features/chars_normal.pkl')\n",
    "print(''.join(chars_normal))\n",
    "\n",
    "char_to_tensor('<EOS>', chars_normal_index)[0][1] == 1\n",
    "char_to_tensor('<EOS>', chars_normal_index).shape\n",
    "char_to_tensor('0', chars_normal_index).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 6, 104])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 7, 104])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 8, 104])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string_to_tensor('wordup', chars_normal_index, include_eos=False).size()\n",
    "string_to_tensor('wordup', chars_normal_index, include_eos=True).size()\n",
    "string_to_tensor('wordup', chars_normal_index, include_eos=True)[0, -1, chars_normal_index['<EOS>']] == 1\n",
    "string_to_tensor('wordup⅞', chars_normal_index, include_eos=True).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 4, 50)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(1, 5, 50)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True], dtype=bool)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp = ['and', 'here', 'she', SAMPLE_WORD_TOKEN]\n",
    "sentence_word_vectorize(tmp, wv_vecs=wv_vecs, wv_idx=wv_idx).shape\n",
    "\n",
    "tmp = sentence_word_vectorize(simple_tokeniser(\"Here is my <SAMPLE> sentence\"),\n",
    "                              wv_vecs=wv_vecs, wv_idx=wv_idx)\n",
    "tmp.shape\n",
    "tmp[0, -1] == wv_vecs[wv_idx['sentence']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1, 50)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_word_vectorize(['the']).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pytorch utils oh: pytorch_utils_oh_1.py\n",
      "Pytorch: 0.2.0_4\n"
     ]
    }
   ],
   "source": [
    "import pytorch_utils_oh_1; importlib.reload(pytorch_utils_oh_1); from pytorch_utils_oh_1 import *;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "(0 ,.,.) = \n",
       "   0   0   0   0   0   0   1   0   0   0\n",
       "   0   0   0   0   0   0   0   1   0   0\n",
       "   1   0   0   0   0   0   0   0   0   0\n",
       "[torch.FloatTensor of size 1x3x10]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp_words = [EOS_TOKEN, SOS_TOKEN, UNKNOWN_WORD_TOKEN, NUMBER_WORD_TOKEN\n",
    "            ] + ['you', 'are', 'the', 'hundred', 'man', 'woman']\n",
    "tmp_index = dict((c, i) for i, c in enumerate(tmp_words))\n",
    "tmp = ['the', 'hundred']\n",
    "\n",
    "words_to_tensor(tmp, words_lookup_index=tmp_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "(0 ,.,.) = \n",
       "   0   0   0   0   0   0   1   0   0   0\n",
       "   0   0   0   1   0   0   0   0   0   0\n",
       "   0   0   1   0   0   0   0   0   0   0\n",
       "   1   0   0   0   0   0   0   0   0   0\n",
       "[torch.FloatTensor of size 1x4x10]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_to_tensor(['the', '123', 'unknown'], words_lookup_index=tmp_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Works ok'"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "try:\n",
    "    words_to_tensor(['the', '123', 'unkown'], words_lookup_index=tmp_index, unknown_replace=False)\n",
    "except:\n",
    "    \"Works ok\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0m 1s'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start = time.time()\n",
    "time.sleep(1.2)\n",
    "time_since(start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pytorch utils oh: pytorch_utils_oh_1.py\n",
      "Pytorch: 0.2.0_4\n"
     ]
    }
   ],
   "source": [
    "import pytorch_utils_oh_1; importlib.reload(pytorch_utils_oh_1); from pytorch_utils_oh_1 import *;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test.training_iterations += 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class TestModule(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(TestModule, self).__init__()\n",
    "\n",
    "        self.rnn = nn.LSTM(128, 64 // 2, 1, batch_first=True, bidirectional=True)\n",
    "        self.lin = nn.Linear(2, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tmp = TestModule()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving to path: data/models/testing_2\n"
     ]
    }
   ],
   "source": [
    "test = ModelTraining('testing_2', [tmp, tmp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to data/models/testing_2/1000_(TestModule/TestModule_1)\n"
     ]
    }
   ],
   "source": [
    "test.save_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_data_org = pd.read_csv('data/en_train_org.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>token_id</th>\n",
       "      <th>class</th>\n",
       "      <th>before</th>\n",
       "      <th>after</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>616107</th>\n",
       "      <td>49226</td>\n",
       "      <td>17</td>\n",
       "      <td>LETTERS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>n a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>684691</th>\n",
       "      <td>54634</td>\n",
       "      <td>1</td>\n",
       "      <td>PLAIN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>965529</th>\n",
       "      <td>76612</td>\n",
       "      <td>7</td>\n",
       "      <td>PLAIN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        sentence_id  token_id    class before after\n",
       "616107        49226        17  LETTERS    NaN   n a\n",
       "684691        54634         1    PLAIN    NaN   NaN\n",
       "965529        76612         7    PLAIN    NaN   NaN"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data rows: 9918390,  (dropped none rows: 51)\n"
     ]
    }
   ],
   "source": [
    "all_data_org[pd.isnull(all_data_org['before'])][:3]\n",
    "all_data = all_data_org.dropna()\n",
    "print(\"Data rows: {},  (dropped none rows: {})\".format(len(all_data), len(all_data_org)-len(all_data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data rows: 9840282,  (dropped (verbatim) rows: 78159)\n"
     ]
    }
   ],
   "source": [
    "all_data = all_data[all_data['class'] != 'VERBATIM']\n",
    "print(\"Data rows: {},  (dropped (verbatim) rows: {})\".format(len(all_data), len(all_data_org)-len(all_data)))\n",
    "all_data = all_data.reset_index(drop=True)\n",
    "# Note we dropped VERBATIM class. Thats because it had so many weird characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_data_sentence_index = all_data.set_index('sentence_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "number_classes = ['DATE','CARDINAL','MEASURE','ORDINAL','DECIMAL','MONEY', 'DIGIT', 'TELEPHONE', 'TIME', 'FRACTION', 'ADDRESS']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data rows: 448176,  (dropped rows: 9470265)\n"
     ]
    }
   ],
   "source": [
    "number_data = all_data[all_data['class'].isin(number_classes)]\n",
    "print(\"Data rows: {},  (dropped rows: {})\".format(len(number_data), len(all_data_org)-len(number_data)))\n",
    "number_data = number_data.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### More balanced sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "balanced_data_classes_select = list(number_data.groupby('class'))\n",
    "def balanced_data_randomize(max_len=10000):\n",
    "    global balanced_data\n",
    "    balanced_data = pd.concat([v.sample(min(max_len, len(v))) for k, v in balanced_data_classes_select])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Letters all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<EOS><SOS> \"$%'(),-./0123456789:ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz£¥ª²³µº¼½¾Ωμ€⅓⅔⅛⅝⅞\n",
      "94\n"
     ]
    }
   ],
   "source": [
    "tmp = sorted(list(set(''.join(number_data['before']))))\n",
    "letters_all = ['<EOS>', '<SOS>'] + sorted(list(set(tmp)))\n",
    "letters_all_index = dict((c, i) for i, c in enumerate(letters_all))\n",
    "print(''.join(letters_all))\n",
    "print(len(letters_all))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "546"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr = list(set(list(number_data['after'])))\n",
    "arr = [s.split(' ') for s in arr]\n",
    "arr = np.concatenate(arr)\n",
    "arr = list(set(arr))\n",
    "number_words = ['<EOS>', '<SOS>'] + arr\n",
    "number_words_index = dict((c, i) for i, c in enumerate(number_words))\n",
    "len(number_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 3, 546)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def number_words_to_tensor(words, include_eos=True):\n",
    "    return words_to_tensor(words, words_lookup_index=number_words_index, include_eos=include_eos)\n",
    "number_words_to_tensor(['one', 'first']).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 546])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "number_words_onehot_sos = number_words_to_tensor([SOS_TOKEN], include_eos=False)\n",
    "number_words_onehot_sos = Variable(torch.from_numpy(number_words_onehot_sos)).cuda()\n",
    "number_words_onehot_sos.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ORDINAL : 5th -> fifth\n",
      "Saint Cyngar was a <SAMPLE> century Catholic Pre congregational saint .\n",
      "(1, 11, 50)\n",
      "(1, 2, 546)\n"
     ]
    }
   ],
   "source": [
    "def get_random_sample():\n",
    "    sample_row = balanced_data.iloc[random.randint(1, len(balanced_data)-1)]\n",
    "    sentence_id = sample_row['class']\n",
    "\n",
    "    rows = all_data_sentence_index.loc[sample_row['sentence_id']]\n",
    "    befores = rows.before.values\n",
    "        \n",
    "    token_id_idx = list(rows['token_id']).index(sample_row['token_id'])\n",
    "    befores[token_id_idx] = SAMPLE_WORD_TOKEN\n",
    "\n",
    "    return sample_row['before'], sample_row['after'], sample_row['class'], befores\n",
    "            \n",
    "def tmp():\n",
    "    s_bef, s_aft, s_class, s_sentence = get_random_sample()\n",
    "    print(s_class, ':', s_bef, '->', s_aft)\n",
    "    print(' '.join(s_sentence))\n",
    "    print(sentence_word_vectorize(s_sentence).shape)\n",
    "    print(number_words_to_tensor(s_aft.split(' ')).shape)\n",
    "tmp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "417 µs ± 19.9 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "get_random_sample()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "use_cuda = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, wordvect_size, chars_input_size, words_hidden_size, chars_hidden_size,\n",
    "                 words_layers=1, chars_layers=1):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        \n",
    "        self.words_layers = words_layers\n",
    "        self.chars_layers = chars_layers\n",
    "        self.words_hidden_size = words_hidden_size\n",
    "        self.chars_hidden_size = chars_hidden_size\n",
    "\n",
    "        self.rnn_words = nn.LSTM(wordvect_size, words_hidden_size // 2, words_layers,\n",
    "                                 batch_first=True, bidirectional=True)\n",
    "\n",
    "        self.rnn_chars = nn.LSTM(chars_input_size, chars_hidden_size // 2, chars_layers,\n",
    "                                batch_first=True, bidirectional=True)\n",
    "        \n",
    "    def forward(self, word_vectors, string_tensor, hidden = None, init_hidden = True):\n",
    "        if init_hidden:\n",
    "            hidden_words, hidden_chars = self.init_hidden()\n",
    "        \n",
    "        all_outputs_words, hidden_words = self.rnn_words(word_vectors, hidden_words)\n",
    "        output_words = all_outputs_words[:, -1]\n",
    "        \n",
    "        all_outputs_chars, hidden_chars = self.rnn_chars(string_tensor, hidden_chars)\n",
    "        output_chars = all_outputs_chars[:, -1]\n",
    "        \n",
    "        output = torch.cat((output_words, output_chars), 1)\n",
    "        \n",
    "        return output\n",
    "\n",
    "    def init_hidden(self):\n",
    "        var1_1 = Variable(torch.zeros(2 * self.words_layers, 1, self.words_hidden_size // 2))\n",
    "        var1_2 = Variable(torch.zeros(2 * self.words_layers, 1, self.words_hidden_size // 2))\n",
    "        var2_1 = Variable(torch.zeros(2 * self.chars_layers, 1, self.chars_hidden_size // 2))\n",
    "        var2_2 = Variable(torch.zeros(2 * self.chars_layers, 1, self.chars_hidden_size // 2))\n",
    "        if use_cuda:\n",
    "            var1_1 = var1_1.cuda(); var1_2 = var1_2.cuda()\n",
    "            var2_1 = var2_1.cuda(); var2_2 = var2_2.cuda()\n",
    "        return ((var1_1, var1_2), (var2_1, var2_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word vect size: (1, 20, 50) . String vector size: torch.Size([1, 5, 94])\n",
      "Output: torch.Size([1, 192])\n"
     ]
    }
   ],
   "source": [
    "def get_encoder(debug=False):\n",
    "    # s_bef, s_aft, s_class, s_word_vs = get_random_sample()\n",
    "    s_bef, s_aft, s_class, s_sentence = get_random_sample()\n",
    "    \n",
    "    s_word_vs = sentence_word_vectorize(s_sentence)\n",
    "    s_string = string_to_tensor(s_bef, letters_all_index)\n",
    "    target = number_words_to_tensor(s_aft.split(' '))\n",
    "    \n",
    "    encoder_rnn = EncoderRNN(wordvect_size=s_word_vs.shape[-1], chars_input_size=len(letters_all),\n",
    "                                      words_hidden_size=64, chars_hidden_size=128,\n",
    "                                      words_layers=1, chars_layers=1).cuda()\n",
    "    output_encoded = encoder_rnn(Variable(torch.from_numpy(s_word_vs)).cuda(), Variable(s_string).cuda())\n",
    "    if debug:\n",
    "        print('Word vect size:', s_word_vs.shape, '. String vector size:', s_string.size())\n",
    "        print('Output:', output_encoded.size())\n",
    "    return encoder_rnn, output_encoded;\n",
    "encoder_rnn, output_encoded = get_encoder(debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'EncoderRNN (\\n  (rnn_words): LSTM(50, 32, batch_first=True, bidirectional=True)\\n  (rnn_chars): LSTM(94, 64, batch_first=True, bidirectional=True)\\n)'"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class DecoderRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, n_layers=1):\n",
    "        super(DecoderRNN, self).__init__()\n",
    "        self.n_layers = n_layers\n",
    "        self.hidden_size = hidden_size\n",
    "        \n",
    "        self.rnn = nn.GRU(input_size, hidden_size, n_layers,\n",
    "                                 batch_first=True, bidirectional=False)\n",
    "                         # LSTM would require own hidden included\n",
    "        \n",
    "        self.lin_out = nn.Linear(hidden_size, input_size)\n",
    "        #self.softmax = nn.LogSoftmax()\n",
    "\n",
    "    def forward(self, char, hidden):\n",
    "        #char = char.view(1,1,-1)\n",
    "        #hidden = hidden.view(1,1,-1)\n",
    "        output, hidden = self.rnn(char, hidden)\n",
    "        output = output[:, -1] # view(1,-1)\n",
    "        output = self.lin_out(output)\n",
    "        output = F.log_softmax(output)\n",
    "        return output, hidden\n",
    "\n",
    "decoder_rnn = DecoderRNN(input_size=len(number_words), hidden_size=output_encoded.size()[-1])\n",
    "decoder_rnn = decoder_rnn.cuda()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 546])\n",
      "Variable containing:\n",
      "-6.1721\n",
      "[torch.cuda.FloatTensor of size 1x1 (GPU 0)]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tmp_a, tmp_b = decoder_rnn(number_words_onehot_sos, output_encoded.view(1,1,-1))\n",
    "print(tmp_a.size())\n",
    "print(tmp_a.topk(1)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[torch.Size([1, 546]), torch.Size([1, 1, 192])]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp_input = number_words_to_tensor([number_words[tmp_a.topk(1)[1].data[0][0]]])\n",
    "tmp_input = Variable(torch.from_numpy(tmp_input)).cuda()\n",
    "tmp = decoder_rnn(tmp_input, tmp_b)\n",
    "[t.size() for t in tmp]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training etc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluate(encoder, decoder, s_bef, s_sentence, max_length=20):\n",
    "    encoder.eval()\n",
    "    decoder.eval()\n",
    "    s_word_vs = sentence_word_vectorize(s_sentence)\n",
    "    s_bef_string = string_to_tensor(s_bef, include_eos=True)\n",
    "\n",
    "    encoder_output = encoder(Variable(torch.from_numpy(s_word_vs)).cuda(), Variable(s_bef_string).cuda())\n",
    "    encoder_output = encoder_output.view(1,1,-1)\n",
    "    \n",
    "    decoder_hidden = encoder_output\n",
    "    decoder_input = number_words_onehot_sos\n",
    "\n",
    "    decoded_output = []\n",
    "    for _ in range(max_length):\n",
    "        decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden)\n",
    "\n",
    "        topv, topi = decoder_output.data.topk(1)\n",
    "        word_index = topi[0][0]\n",
    "        word = number_words[word_index] # Use own prediction as next input\n",
    "                \n",
    "        if word == '<EOS>':\n",
    "            break\n",
    "\n",
    "        decoded_output.append(word)\n",
    "        \n",
    "        decoder_input = number_words_to_tensor([word], include_eos=False)\n",
    "        decoder_input = Variable(torch.from_numpy(decoder_input)).cuda()\n",
    "\n",
    "    return ' '.join(decoded_output)\n",
    "\n",
    "evaluate(encoder_rnn, decoder_rnn, '12th', 'he was <SAMPLE>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test_model_accuracy(n_sample=10000, print_wrongs=False):\n",
    "    balanced_data_randomize()\n",
    "    n_correct = 0\n",
    "    for iteration in range(n_sample):\n",
    "        s_bef, s_aft, s_class, s_sentence = get_random_sample()\n",
    "        output = evaluate(encoder_rnn, decoder_rnn, s_bef, s_sentence)\n",
    "        if s_aft == output:\n",
    "            n_correct += 1\n",
    "        else:\n",
    "            if print_wrongs:\n",
    "                print(\"{:<20} -> {} \\n{:<20} != {}\".format(s_bef, output, '', s_aft))\n",
    "                \n",
    "\n",
    "    print(\"Accuracy: {:>4.2%} ({:>8d}/{:>8d})\".format(\n",
    "            n_correct/n_sample, n_correct, n_sample))\n",
    "\n",
    "test_model_accuracy(10, print_wrongs=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train(s_bef, s_aft, s_sentence, encoder, decoder, encoder_optimizer, decoder_optimizer, loss_function,\n",
    "          use_teacher_forcing, max_length=20):\n",
    "\n",
    "    s_word_vs = sentence_word_vectorize(s_sentence)\n",
    "    s_bef_string = string_to_tensor(s_bef, include_eos=True)\n",
    "    target_arr = s_aft.split(' ') + ['<EOS>']\n",
    "    \n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "    loss = 0\n",
    "\n",
    "    encoder_output = encoder(Variable(torch.from_numpy(s_word_vs)).cuda(), Variable(s_bef_string).cuda())\n",
    "    encoder_output = encoder_output.view(1,1,-1)\n",
    "    decoder_hidden = encoder_output\n",
    "\n",
    "    decoder_input = number_words_onehot_sos\n",
    "\n",
    "    decoded_output = []\n",
    "    for i in range(len(target_arr)):\n",
    "        decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden)\n",
    "\n",
    "        decoder_target = number_words_index[target_arr[i]]\n",
    "        #print(decoder_target)\n",
    "        decoder_target = Variable(torch.LongTensor([decoder_target])).cuda()\n",
    "        \n",
    "        # import IPython; IPython.core.debugger.set_trace()\n",
    "        \n",
    "        loss += loss_function(decoder_output, decoder_target)\n",
    "\n",
    "        topv, topi = decoder_output.data.topk(1)\n",
    "        word_index = topi[0][0]\n",
    "        word = number_words[word_index] # Use own prediction as next input\n",
    "        decoded_output.append(word)\n",
    "        \n",
    "        if use_teacher_forcing:\n",
    "            word = target_arr[i] # replace input with right target\n",
    "        else:\n",
    "            # use output normally as input \n",
    "            if word == '<EOS>':\n",
    "                break\n",
    "\n",
    "        decoder_input = number_words_to_tensor([word], include_eos=False)\n",
    "        decoder_input = Variable(torch.from_numpy(decoder_input)).cuda()\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "\n",
    "    return((loss.data[0] / len(target_arr)), ' '.join(decoded_output))\n",
    "#print(train())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_iterations(n_iters=100000, lr=0.001, teacher_forcing_ratio=0.5,\n",
    "                     print_every=5000, plot_every=1000):\n",
    "    global model_train_iterations\n",
    "    global model_train_history\n",
    "    start = time.time()\n",
    "    decoder_rnn.train()\n",
    "    encoder_rnn.train()\n",
    "\n",
    "    current_loss = 0\n",
    "    current_loss_iter = 0\n",
    "\n",
    "    encoder_optimizer = torch.optim.Adam(encoder_rnn.parameters(), lr=lr)\n",
    "    decoder_optimizer = torch.optim.Adam(decoder_rnn.parameters(), lr=lr)\n",
    "    loss_function = nn.NLLLoss()\n",
    "    \n",
    "    for iteration in range(1, n_iters + 1):\n",
    "        model_train_iterations += 1\n",
    "\n",
    "        use_teacher_forcing = random.random() < teacher_forcing_ratio\n",
    "        \n",
    "        s_bef, s_aft, s_class, s_sentence = get_random_sample()\n",
    "        \n",
    "        loss, result = train(s_bef=s_bef, s_aft=s_aft, s_sentence=s_sentence,\n",
    "                             encoder=encoder_rnn, decoder=decoder_rnn,\n",
    "                             encoder_optimizer=encoder_optimizer, decoder_optimizer=decoder_optimizer,\n",
    "                             loss_function=nn.NLLLoss(), use_teacher_forcing=use_teacher_forcing,\n",
    "                             max_length=40 )\n",
    "\n",
    "        current_loss += loss\n",
    "        current_loss_iter += 1\n",
    "\n",
    "        # Print iter number, loss, name and guess\n",
    "        if iteration % print_every == 0:\n",
    "            teacher_forcing_str = \"\"\n",
    "            if use_teacher_forcing:\n",
    "                teacher_forcing_str = \"(forcing)\"\n",
    "            print(\"{:>6d} {:>4.0%} ({:>8}) {:>7.3f}   | {:>6.2f}: {} -> {} {} ({})\".format(\n",
    "                      model_train_iterations, iteration/n_iters, timeSince(start),\n",
    "                      current_loss/current_loss_iter, loss,\n",
    "                      s_bef, teacher_forcing_str, result, s_aft))\n",
    "\n",
    "        # Add current loss avg to list of losses\n",
    "        if iteration % plot_every == 0:\n",
    "            model_train_history.append((current_loss / plot_every, lr))\n",
    "            current_loss = 0\n",
    "            current_loss_iter = 0\n",
    "            \n",
    "        if model_train_iterations % 10000 == 0:\n",
    "            balanced_data_randomize()\n",
    "            \n",
    "        if model_train_iterations % 50000 == 0:\n",
    "            save_model()\n",
    "    \n",
    "    # test_model_accuracy(model, n_sample=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_iterations(n_iters=1000, print_every=100, teacher_forcing_ratio=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:py3_pytorch_2]",
   "language": "python",
   "name": "conda-env-py3_pytorch_2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
