{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pytorch utils oh: pytorch_utils_oh_2.py\n",
      "Pytorch: 0.2.0_4\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import importlib\n",
    "from pytorch_utils_oh_2 import *\n",
    "import IPython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MODEL_SAVE_PATH = 'whole_gen_10_after_words_attention'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pytorch utils oh: pytorch_utils_oh_2.py\n",
      "Pytorch: 0.2.0_4\n"
     ]
    }
   ],
   "source": [
    "import pytorch_utils_oh_2; importlib.reload(pytorch_utils_oh_2); from pytorch_utils_oh_2 import *;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# all_data = pickle.load(open(\"data/en_train_fixed_4_sentences.pkl\", \"rb\" ))\n",
    "all_data = pickle.load(open(\"data/en_train_fixed_5_manual.pkl\", \"rb\" ))\n",
    "# all_data_sentence_index = all_data.set_index('sentence_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data rows: 654333,  (dropped rows: 9263859)\n"
     ]
    }
   ],
   "source": [
    "sample_data = all_data.copy()\n",
    "sample_data = sample_data[sample_data['class'] != 'NOT_CHANGED']\n",
    "sample_data = sample_data[sample_data['class'] != 'MANUAL']\n",
    "print(\"Data rows: {},  (dropped rows: {})\".format(len(sample_data), len(all_data)-len(sample_data)))\n",
    "sample_data = sample_data.reset_index(drop=True)\n",
    "del(all_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ELECTRONIC', 'LETTERS', 'NUMBERS', 'PLAIN', 'VERBATIM']\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "categories_all = sorted(sample_data[\"class\"].unique())\n",
    "print(categories_all)\n",
    "print(len(categories_all))\n",
    "categories_index = dict((c, i) for i, c in enumerate(categories_all))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utils stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<SOS><EOS>☒ !\"#$%&'(),-./0123456789:;ABCDEFGHIJKLMNOPQRSTUVWXYZ_abcdefghijklmnopqrstuvwxyz~£¥ª²³µº¼½¾éɒʻˈΩμ—€⅓⅔⅛\n"
     ]
    }
   ],
   "source": [
    "chars_normal, chars_normal_index = load_characters_pkl('data/en_features/chars_normal.pkl')\n",
    "print(''.join(chars_normal))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "common_words, common_words_index = load_common_words_10k()\n",
    "len(common_words)\n",
    "common_words[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wv_vecs, wv_words, wv_idx = load_glove('/home/ohu/koodi/data/glove_wordvec/glove.6B.50d.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### After words handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<EOS>', '<SOS>', '<UNK>', '<0000>', '<SAMPLE>', 'two', 'twenty']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "1351"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_after_common = pickle.load(open(\"data/en_features/words_after_ext.pkl\", 'rb'))\n",
    "words_after_index = dict((c, i) for i, c in enumerate(words_after_common))\n",
    "words_after_common[0:7]\n",
    "len(words_after_common)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#onehot_sos = torch.zeros(1, 1, len(words_after_index))\n",
    "#onehot_sos[0, 0, words_after_index[SOS_TOKEN]] = 1\n",
    "#onehot_sos.size()\n",
    "#del(onehot_sos)\n",
    "\n",
    "sos_tensor = torch.LongTensor([words_after_index[SOS_TOKEN]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### More balanced sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sample_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-31737bdfc577>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mbalanced_data_classes_select\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'class'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mbalanced_data_accessed_counter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mbalanced_data_randomize_freq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mbalanced_data_length\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'sample_data' is not defined"
     ]
    }
   ],
   "source": [
    "balanced_data_classes_select = list(sample_data.groupby('class'))\n",
    "\n",
    "balanced_data_accessed_counter = 0 \n",
    "balanced_data_randomize_freq = False\n",
    "balanced_data_length = 0\n",
    "\n",
    "def balanced_data_randomize(max_len=20000):\n",
    "    global balanced_data, balanced_data_length, balanced_data_accessed_counter\n",
    "    balanced_data = pd.concat([v.sample(min(max_len, len(v))) for k, v in balanced_data_classes_select])\n",
    "    balanced_data_length = len(balanced_data)\n",
    "    balanced_data_randomize_freq = balanced_data_length * 0.2\n",
    "    balanced_data_accessed_counter = 0\n",
    "\n",
    "def balanced_data_sample_row():\n",
    "    global balanced_data_accessed_counter\n",
    "    global balanced_data_last_sample\n",
    "    balanced_data_accessed_counter += 1\n",
    "    if balanced_data_randomize_setting and balanced_data_accessed_counter > balanced_data_randomize_setting:\n",
    "        balanced_data_randomize()\n",
    "    balanced_data_last_sample = balanced_data.iloc[random.randint(1, balanced_data_length-1)]\n",
    "    return balanced_data_last_sample\n",
    "    \n",
    "balanced_data_randomize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "class\n",
       "ELECTRONIC     4964\n",
       "LETTERS       20000\n",
       "NUMBERS       20000\n",
       "PLAIN         20000\n",
       "VERBATIM      11741\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#all_data.groupby('class')['class'].count()\n",
    "#sample_data.groupby('class')['class'].count()\n",
    "balanced_data.groupby('class')['class'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentence_id                                         159847\n",
       "token_id                                                 8\n",
       "class                                                PLAIN\n",
       "before                                                   -\n",
       "after                                                   to\n",
       "class_org                                            PLAIN\n",
       "a_word_ind                                         [57, 0]\n",
       "sentence       human ecology 32 ( 2 ) : 137 <SAMPLE> 162 .\n",
       "Name: 139022, dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " balanced_data_sample_row()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VERBATIM : & -> and <EOS> [55, 0]\n",
      "the barnes <SAMPLE> noble review .\n",
      "torch.Size([1, 2, 104])\n"
     ]
    }
   ],
   "source": [
    "def get_random_sample():\n",
    "    sample_row = balanced_data_sample_row()\n",
    "    sentence_id = sample_row['class']\n",
    "    \n",
    "    return sample_row['before'], sample_row['a_word_ind'], sample_row['class'], sample_row['sentence']\n",
    "            \n",
    "def tmp():\n",
    "    s_bef, s_aft, s_class, s_sentence = get_random_sample()\n",
    "    s_aft_str = ' '.join([words_after_common[i] for i in s_aft])\n",
    "    print(s_class, ':', s_bef, '->', s_aft_str, s_aft)\n",
    "    print(s_sentence)\n",
    "    print(string_to_tensor(s_bef, chars_normal_index).shape)\n",
    "tmp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "158 µs ± 4.78 µs per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "get_random_sample()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "use_cuda = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = sample_data[sample_data['before'].str.len()>50]\n",
    "len(tmp)\n",
    "tmp.sample(2)\n",
    "tmp[~tmp['before'].str.contains('/')].sample(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MAX_ATTENTION_LENGTH = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EncoderRNN (\n",
       "  (rnn_words): LSTM(50, 64, batch_first=True, bidirectional=True)\n",
       "  (rnn_chars): LSTM(104, 128, batch_first=True, bidirectional=True)\n",
       ")"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, words_input_size, chars_input_size, words_hidden_size, chars_hidden_size,\n",
    "                 words_layers=1, chars_layers=1):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        \n",
    "        self.words_layers = words_layers\n",
    "        self.chars_layers = chars_layers\n",
    "        self.words_hidden_size = words_hidden_size\n",
    "        self.chars_hidden_size = chars_hidden_size\n",
    "        self.hidden_size = words_hidden_size + chars_hidden_size\n",
    "\n",
    "        self.rnn_words = nn.LSTM(words_input_size, words_hidden_size // 2, words_layers,\n",
    "                                 batch_first=True, bidirectional=True)\n",
    "\n",
    "        self.rnn_chars = nn.LSTM(chars_input_size, chars_hidden_size // 2, chars_layers,\n",
    "                                batch_first=True, bidirectional=True)\n",
    "        \n",
    "    def forward(self, word_vectors, string_tensor, hidden = None, init_hidden = True):\n",
    "        if init_hidden:\n",
    "            hidden_words, hidden_chars = self.init_hidden()\n",
    "        \n",
    "        all_outputs_words, hidden_words = self.rnn_words(word_vectors, hidden_words)\n",
    "        output_words = all_outputs_words[:, -1]\n",
    "        \n",
    "        all_outputs_chars, hidden_chars = self.rnn_chars(string_tensor, hidden_chars)\n",
    "        output_chars = all_outputs_chars[:, -1]\n",
    "        \n",
    "        hidden_states_cat = Variable(torch.zeros(MAX_ATTENTION_LENGTH, self.hidden_size)).cuda()\n",
    "        for ei in range(min(MAX_ATTENTION_LENGTH, len(string_tensor[0]))):\n",
    "            hidden_states_cat[ei] = torch.cat((output_words, all_outputs_chars[0, ei].view(1,-1)), 1)\n",
    "                \n",
    "        output = torch.cat((output_words[0], output_chars[0]), 0)\n",
    "\n",
    "        #output = torch.cat((output_words, output_chars), 1)\n",
    "        \n",
    "        #return output, all_outputs_chars\n",
    "        return output, hidden_states_cat\n",
    "\n",
    "    def init_hidden(self):\n",
    "        var1_1 = Variable(torch.zeros(2 * self.words_layers, 1, self.words_hidden_size // 2))\n",
    "        var1_2 = Variable(torch.zeros(2 * self.words_layers, 1, self.words_hidden_size // 2))\n",
    "        var2_1 = Variable(torch.zeros(2 * self.chars_layers, 1, self.chars_hidden_size // 2))\n",
    "        var2_2 = Variable(torch.zeros(2 * self.chars_layers, 1, self.chars_hidden_size // 2))\n",
    "        \n",
    "        var1_1 = var1_1.cuda(); var1_2 = var1_2.cuda()\n",
    "        var2_1 = var2_1.cuda(); var2_2 = var2_2.cuda()\n",
    "        return ((var1_1, var1_2), (var2_1, var2_2))\n",
    "    \n",
    "    \n",
    "encoder_rnn = EncoderRNN(words_input_size=wv_vecs.shape[-1], chars_input_size=len(chars_normal),\n",
    "                         words_hidden_size=128, chars_hidden_size=256,\n",
    "                         words_layers=1, chars_layers=1).cuda()\n",
    "encoder_rnn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "&\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'&'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([384])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([50, 384])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def test_encoder_single_sample():\n",
    "    s_bef, s_aft, s_class, s_sentence = get_random_sample()\n",
    "    print(s_bef)\n",
    "    \n",
    "    words_t = Variable(words_to_word_vectors_tensor(list(s_sentence), wv_vecs, wv_idx)).cuda()\n",
    "    \n",
    "    string_t = string_to_tensor(s_bef, chars_normal_index)\n",
    "    string_t = Variable(string_t).cuda()\n",
    "    \n",
    "    return encoder_rnn(words_t, string_t), s_bef\n",
    "    \n",
    "(encoder_output, encoder_outputs), tmp = test_encoder_single_sample()\n",
    "tmp\n",
    "encoder_output.size()\n",
    "encoder_outputs.size()\n",
    "torch.eq(encoder_output, encoder_outputs[len(tmp)]).data.all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecoderRNN (\n",
       "  (rnn): GRU(384, 384, batch_first=True)\n",
       "  (lin_out): Linear (384 -> 1351)\n",
       "  (embedding): Embedding(1351, 384)\n",
       "  (attn): Linear (768 -> 50)\n",
       "  (attn_combine): Linear (768 -> 384)\n",
       "  (dropout): Dropout (p = 0.1)\n",
       ")"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[torch.Size([1, 1351]), torch.Size([1, 1, 384]), torch.Size([1, 50])]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class DecoderRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, n_layers=1, dropout_p=0.1, max_length=MAX_ATTENTION_LENGTH):\n",
    "        super(DecoderRNN, self).__init__()\n",
    "        self.n_layers = n_layers\n",
    "        self.hidden_size = hidden_size\n",
    "        \n",
    "        #self.rnn = nn.GRU(input_size, hidden_size, n_layers,\n",
    "        self.rnn = nn.GRU(hidden_size, hidden_size, n_layers,\n",
    "                                 batch_first=True, bidirectional=False)\n",
    "        \n",
    "        self.lin_out = nn.Linear(hidden_size, input_size)\n",
    "        #self.softmax = nn.LogSoftmax()\n",
    "        \n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        self.max_length = max_length\n",
    "        self.attn = nn.Linear(hidden_size*2, self.max_length)\n",
    "        self.attn_combine = nn.Linear(self.hidden_size * 2, self.hidden_size)\n",
    "        self.dropout = nn.Dropout(dropout_p)\n",
    "        \n",
    "    #def forward(self, char, hidden):\n",
    "    def forward(self, last_input, hidden, encoder_outputs):\n",
    "        embedded = self.embedding(last_input).view(1, 1, -1)\n",
    "        embedded = self.dropout(embedded)\n",
    "        #IPython.core.debugger.Pdb().set_trace()\n",
    "        #attn_weights = F.softmax(self.attn(torch.cat((char[0], hidden[0]), 1)))\n",
    "        attn_weights = F.softmax(self.attn(torch.cat((embedded[0], hidden[0]), 1)))\n",
    "        attn_applied = torch.bmm(attn_weights.unsqueeze(0), encoder_outputs.unsqueeze(0))\n",
    "        \n",
    "        output = torch.cat((embedded[0], attn_applied[0]), 1)\n",
    "        output = self.attn_combine(output).unsqueeze(0)\n",
    "\n",
    "        \n",
    "        output = F.relu(output)\n",
    "        output, hidden = self.rnn(output, hidden)\n",
    "\n",
    "        output = F.log_softmax(self.lin_out(output[0]))\n",
    "        return output, hidden, attn_weights\n",
    "    \n",
    "    def init_rest_hidden(self, input_var):\n",
    "        if self.n_layers > 1:\n",
    "            hid_var = Variable(torch.zeros(self.n_layers - 1, 1, self.hidden_size)).cuda()\n",
    "            res = torch.cat((input_var, hid_var), 0)\n",
    "            return res\n",
    "        else:\n",
    "            return input_var\n",
    "        \n",
    "\n",
    "decoder_rnn = DecoderRNN(input_size=len(words_after_common), hidden_size=encoder_output.size()[0], n_layers=1)\n",
    "decoder_rnn = decoder_rnn.cuda()\n",
    "decoder_rnn\n",
    "\n",
    "tmp_outputs = Variable(torch.zeros(MAX_ATTENTION_LENGTH, encoder_output.size()[0])).cuda()\n",
    "tmp_hiddens = decoder_rnn.init_rest_hidden(encoder_output.view(1,1,-1))\n",
    "tmp = decoder_rnn(Variable(sos_tensor).cuda(), tmp_hiddens, tmp_outputs)\n",
    "[v.size() for v in tmp]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "(0 ,.,.) = \n",
       "  1.2000  2.4000  3.6000  4.8000\n",
       "[torch.FloatTensor of size 1x1x4]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.bmm(torch.FloatTensor([1,0.1,0.1]).view(1,1,-1), torch.arange(0, 12).view(1,3,-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[torch.Size([1, 1351]), torch.Size([1, 1, 384]), torch.Size([1, 50])]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      " 477\n",
      "[torch.cuda.LongTensor of size 1x1 (GPU 0)]\n",
      "\n",
      "francs\n"
     ]
    }
   ],
   "source": [
    "tmp_outputs = Variable(torch.zeros(MAX_ATTENTION_LENGTH, encoder_output.size()[0])).cuda()\n",
    "tmp_hiddens = decoder_rnn.init_rest_hidden(encoder_output.view(1,1,-1))\n",
    "tmp = decoder_rnn(Variable(sos_tensor).cuda(), tmp_hiddens, tmp_outputs)\n",
    "[v.size() for v in tmp]\n",
    "print(tmp[0].topk(1)[1])\n",
    "print(words_after_common[tmp[0].topk(1)[1].data[0][0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training etc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('ii killallmuslims killallmuslims month cafe cafe cafe cafe cafe cafe cafe cafe cafe cafe cafe cafe cafe cafe cafe cafe',\n",
       " 'ii killallmuslims killallmuslims month cafe cafe cafe cafe cafe cafe cafe cafe cafe cafe cafe cafe cafe cafe cafe cafe',\n",
       " 'and',\n",
       " ('&', [55, 0], 'VERBATIM', 'baskin <SAMPLE> battey .'))"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def test_model_single_sample(model=None, return_more=False):\n",
    "    decoder_rnn.eval()\n",
    "    encoder_rnn.eval()\n",
    "    \n",
    "    s_bef, s_aft, s_class, s_sentence = sample = get_random_sample()\n",
    "        \n",
    "    words_t = Variable(words_to_word_vectors_tensor(list(s_sentence), wv_vecs, wv_idx)).cuda()\n",
    "    \n",
    "    string_t = string_to_tensor(s_bef, chars_normal_index)\n",
    "    string_t = Variable(string_t).cuda()\n",
    "    \n",
    "    encoder_output, encoder_outputs = encoder_rnn(words_t, string_t)\n",
    "    \n",
    "    #encoder_output = encoder_output.view(1,1,-1)\n",
    "    \n",
    "    decoder_hidden = decoder_rnn.init_rest_hidden(encoder_outputs[0].view(1,1,-1))\n",
    "    decoder_input = Variable(sos_tensor).cuda()\n",
    "\n",
    "    decoded_output = []\n",
    "    decoder_attns_arr = []\n",
    "    max_length = 20\n",
    "    for _ in range(max_length):\n",
    "        decoder_output, decoder_hidden, decoder_attns = decoder_rnn(decoder_input, decoder_hidden, encoder_outputs)\n",
    "        decoder_attns_arr.append(decoder_attns)\n",
    "        #return decoder_output\n",
    "\n",
    "        topv, topi = decoder_output.data.topk(1)\n",
    "        word_index = topi[0][0]\n",
    "        word = words_after_common[word_index] # Use own prediction as next input\n",
    "                \n",
    "        if word == EOS_TOKEN:\n",
    "            break\n",
    "\n",
    "        decoded_output.append(word)\n",
    "        \n",
    "        decoder_input = Variable(torch.LongTensor([word_index])).cuda()\n",
    "        \n",
    "        #decoder_input = torch.zeros(1, 1, len(words_after_index))\n",
    "        #decoder_input[0, 0, word_index] = 1\n",
    "        #decoder_input = Variable(decoder_input).cuda()\n",
    "    \n",
    "    output = ' '.join(decoded_output)\n",
    "    sample_target = ' '.join([words_after_common[w] for w in s_aft][:-1])\n",
    "    \n",
    "    decoder_rnn.train()\n",
    "    encoder_rnn.train()\n",
    "    \n",
    "    if return_more:\n",
    "        return output, decoded_output, decoder_attns_arr, sample\n",
    "    \n",
    "    return output, output, sample_target, sample\n",
    "    \n",
    "tmp = test_model_single_sample(None)\n",
    "tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no             => ii ii ii ii ii hundred german german german german german german german german german german german german german german || [109, 0] \n",
      "                  florida historical quarterly <SAMPLE> 16 ( october 1937 ) .\n",
      "-              => hundred hundred hundred hundred hundred hundred german german german german german german german german german german german german german german || [57, 0] \n",
      "                  91 , issue 342 <SAMPLE> 342 , pp .\n"
     ]
    }
   ],
   "source": [
    "def print_local_wrong_predictions(max_results=10):\n",
    "    arr = get_some_wrong_predictions(None, test_model_single_sample, max_iterations=10000, max_results=max_results)\n",
    "    for sample, predict, output in arr:\n",
    "        s_bef, s_aft, s_class, s_sentence = sample\n",
    "        print(\"{:<14} => {:<14} || {} \\n{:>17} {}\".format(s_bef, predict, s_aft, '', s_sentence, ))\n",
    "print_local_wrong_predictions(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.00% (       0/     100)\n",
      "CPU times: user 2.35 s, sys: 56 ms, total: 2.41 s\n",
      "Wall time: 2.41 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "test_model_accuracy(encoder_rnn, test_model_single_sample, n_sample=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train(s_bef, s_aft, s_sentence, encoder_optimizer, decoder_optimizer, loss_function,\n",
    "          use_teacher_forcing, max_length=20):\n",
    "    \n",
    "    words_t = Variable(words_to_word_vectors_tensor(list(s_sentence), wv_vecs, wv_idx)).cuda()\n",
    "    \n",
    "    string_t = string_to_tensor(s_bef, chars_normal_index)\n",
    "    string_t = Variable(string_t).cuda()\n",
    "    \n",
    "    encoder_output, encoder_outputs = encoder_rnn(words_t, string_t)\n",
    "    \n",
    "    #encoder_output = encoder_output.view(1,1,-1)\n",
    "    \n",
    "    decoder_hidden = decoder_rnn.init_rest_hidden(encoder_outputs[0].view(1,1,-1))\n",
    "    decoder_input = Variable(sos_tensor).cuda()\n",
    "    \n",
    "    ###\n",
    "    target_arr = s_aft\n",
    "    #target_arr = after_sentence_to_word_indexes(s_aft, include_eos=True)\n",
    "    \n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "    loss = 0\n",
    "    \n",
    "    decoded_output = []\n",
    "    for i in range(len(target_arr)):\n",
    "        decoder_output, decoder_hidden, decoder_attns = decoder_rnn(decoder_input, decoder_hidden, encoder_outputs)\n",
    "\n",
    "        #decoder_target_i = chars_after_index[target_arr[i]]\n",
    "        decoder_target_i = target_arr[i]\n",
    "        decoder_target_i = Variable(torch.LongTensor([decoder_target_i])).cuda()\n",
    "        loss += loss_function(decoder_output, decoder_target_i)\n",
    "        \n",
    "        topv, topi = decoder_output.data.topk(1)\n",
    "        word_index = topi[0][0]\n",
    "        word = words_after_common[word_index] # Use own prediction as next input\n",
    "        decoded_output.append(word)\n",
    "        \n",
    "        if use_teacher_forcing:\n",
    "            word_index = target_arr[i] # replace input with right target\n",
    "        else:\n",
    "            # use output normally as input \n",
    "            if word == EOS_TOKEN:\n",
    "                break\n",
    "                \n",
    "        decoder_input = Variable(torch.LongTensor([word_index])).cuda()\n",
    "        \n",
    "    if decoded_output[-1] == EOS_TOKEN:\n",
    "        decoded_output = decoded_output[:-1]\n",
    "        \n",
    "    loss.backward()\n",
    "\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "\n",
    "    return ' '.join(decoded_output), (loss.data[0] / len(target_arr))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_iterations(n_iters=100000, lr=0.001, teacher_forcing_ratio=0.5,\n",
    "                     print_every=10000, plot_every=1000):\n",
    "\n",
    "    start = time.time()\n",
    "    \n",
    "    decoder_rnn.train()\n",
    "    encoder_rnn.train()\n",
    "\n",
    "    current_loss = 0\n",
    "    current_loss_iter = 0\n",
    "\n",
    "    encoder_optimizer = torch.optim.Adam(encoder_rnn.parameters(), lr=lr)\n",
    "    decoder_optimizer = torch.optim.Adam(decoder_rnn.parameters(), lr=lr)\n",
    "    loss_function = nn.NLLLoss()\n",
    "    \n",
    "    for iteration in range(1, n_iters + 1):\n",
    "        model_training.iterations += 1\n",
    "        \n",
    "        use_teacher_forcing = random.random() < teacher_forcing_ratio\n",
    "        \n",
    "        s_bef, s_aft, s_class, s_sentence = get_random_sample()\n",
    "        \n",
    "        result, loss = train(s_bef=s_bef, s_aft=s_aft, s_sentence=s_sentence,\n",
    "                             encoder_optimizer=encoder_optimizer, decoder_optimizer=decoder_optimizer,\n",
    "                             loss_function=nn.NLLLoss(), use_teacher_forcing=use_teacher_forcing,\n",
    "                             max_length=40 )\n",
    "        \n",
    "        current_loss += loss\n",
    "        current_loss_iter += 1\n",
    "\n",
    "        # Print iter number, loss, name and guess\n",
    "        if iteration % print_every == 0:\n",
    "            teacher_forcing_str = \"\"\n",
    "            if use_teacher_forcing:\n",
    "                teacher_forcing_str = \"(forcing)\"\n",
    "            s_aft_sentence = ' '.join([words_after_common[w] for w in s_aft][:-1])\n",
    "            correct = '✓' if result == s_aft_sentence else \"✗: {}\".format(s_aft)\n",
    "            \n",
    "            print(\"{:>6d} {:>4.0%} ({:>8}) {:>7.3f}   | {:>6.2f}: {} -> {} ({}) {}\".format(\n",
    "                      model_training.iterations, iteration/n_iters, time_since(start),\n",
    "                      current_loss/current_loss_iter, loss,\n",
    "                      s_bef, result, correct, teacher_forcing_str))\n",
    "\n",
    "        # Add current loss avg to list of losses\n",
    "        if iteration % plot_every == 0:\n",
    "            model_training.losses.append(current_loss / plot_every)\n",
    "            model_training.learning_rates.append(lr)\n",
    "            current_loss = 0\n",
    "            current_loss_iter = 0\n",
    "            \n",
    "        if model_training.iterations % 50000 == 0 or model_training.iterations == 10:\n",
    "            model_training.save_models()\n",
    "            acc = test_model_accuracy(encoder_rnn, test_model_single_sample)\n",
    "            model_training.accuracy.append(acc)\n",
    "    \n",
    "    # test_model_accuracy(model, n_sample=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Save path: data/models/whole_gen_10_after_words_attention\n"
     ]
    }
   ],
   "source": [
    "model_training = ModelTraining(MODEL_SAVE_PATH, [encoder_rnn, decoder_rnn])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     9  18% (   0m 0s)   6.749   |   3.59: 1853 -> e (✗: [40, 38, 13, 0]) \n",
      "Saved model to data/models/whole_gen_10_after_words_attention/10_(EncoderRNN/DecoderRNN)\n",
      "Accuracy: 0.00% (       0/   10000)\n",
      "    18  36% (  0m 47s)   5.805   |   1.44: November 4, 2014 ->  (✗: [69, 77, 6, 50, 0]) \n",
      "    27  54% (  0m 47s)   5.209   |   1.76: 1964 ->  (✗: [7, 39, 19, 0]) \n",
      "    36  72% (  0m 47s)   5.228   |   6.53: 2 -> <EOS> (✗: [5, 0]) (forcing)\n",
      "    45  90% (  0m 47s)   4.856   |   3.59: 11 ->  (✗: [48, 0]) \n"
     ]
    }
   ],
   "source": [
    "train_iterations(n_iters=50, print_every=9, lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   550  53% (   0m 9s)   3.082   |   5.10: #VII -> and (✗: [175, 247, 1100, 0]) \n"
     ]
    }
   ],
   "source": [
    "train_iterations(n_iters=(1000-model_training.iterations), print_every=500, lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  2000  11% (  0m 18s)   2.562   |   2.78: 10 -> to (✗: [44, 0]) (forcing)\n",
      "  3000  22% (  0m 42s)   2.322   |   1.81: centre -> nineteen (✗: [110, 0]) (forcing)\n",
      "  4000  33% (   1m 4s)   2.283   |   2.18: DC -> u <EOS> (✗: [26, 21, 0]) (forcing)\n",
      "  5000  44% (  1m 26s)   2.223   |   3.18: Dialogue -> the (✗: [200, 0]) \n",
      "  6000  56% (  1m 48s)   2.080   |   1.75: Sp -> p p (✗: [17, 24, 0]) (forcing)\n",
      "  7000  67% (  2m 10s)   1.983   |   1.55: 2005 -> nineteen seventy eight (✗: [5, 8, 14, 0]) \n",
      "  8000  78% (  2m 33s)   1.987   |   2.24: 4 -> number (✗: [19, 0]) (forcing)\n",
      "  9000  89% (  2m 55s)   1.898   |   0.02: & -> and (✓) \n",
      " 10000 100% (  3m 16s)   1.944   |   1.67: metres -> center (✗: [108, 0]) \n"
     ]
    }
   ],
   "source": [
    "train_iterations(n_iters=9000, lr=0.0001, print_every=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 20000  11% (  3m 39s)   1.122   |   3.49: lawsociety.ie -> b e s l a s h e s l a s h e (✗: [42, 22, 52, 17, 25, 21, 31, 28, 30, 86, 74, 31, 28, 0]) \n",
      " 30000  22% (  7m 35s)   0.855   |   0.00: & -> and (✓) \n",
      " 40000  33% ( 11m 18s)   0.737   |   0.55: PhD -> p d d (✗: [24, 45, 26, 0]) (forcing)\n",
      " 50000  44% ( 14m 59s)   0.673   |   0.00: - -> to (✓) (forcing)\n",
      "Saved model to data/models/whole_gen_10_after_words_attention/50000_(EncoderRNN/DecoderRNN)\n",
      "Accuracy: 67.36% (    6736/   10000)\n",
      " 60000  56% (  20m 9s)   0.657   |   0.00: & -> and (✓) (forcing)\n",
      " 70000  67% ( 23m 56s)   0.675   |   0.00: - -> to (✓) (forcing)\n",
      " 80000  78% ( 27m 50s)   0.631   |   1.15: ISEE- -> i e e <EOS> (✗: [31, 17, 28, 28, 0]) (forcing)\n",
      " 90000  89% ( 31m 37s)   0.572   |   0.02: # -> number (✓) (forcing)\n",
      "100000 100% ( 35m 18s)   0.627   |   0.12: F.C. -> f c (✓) \n",
      "Saved model to data/models/whole_gen_10_after_words_attention/100000_(EncoderRNN/DecoderRNN)\n",
      "Accuracy: 71.84% (    7184/   10000)\n"
     ]
    }
   ],
   "source": [
    "train_iterations(n_iters=90000, print_every=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "110095   5% (  3m 42s)   0.588   |   0.96: NLRB -> n b r <EOS> (✗: [29, 42, 35, 36, 0]) (forcing)\n",
      "120095  10% (  7m 23s)   0.591   |   0.00: & -> and (✓) \n",
      "130095  15% (  11m 5s)   0.520   |   0.31: JDL -> j d l (✓) \n",
      "140095  20% ( 14m 56s)   0.594   |   0.00: & -> and (✓) \n",
      "Saved model to data/models/whole_gen_10_after_words_attention/150000_(EncoderRNN/DecoderRNN)\n",
      "Accuracy: 74.33% (    7433/   10000)\n",
      "150095  25% (  20m 2s)   0.522   |   0.00: - -> to (✓) \n",
      "160095  30% ( 23m 39s)   0.510   |   0.00: Centre -> center (✓) \n",
      "170095  35% ( 27m 35s)   0.472   |   3.14: 55.93% -> fifty seven point three percent (✗: [38, 14, 46, 15, 13, 83, 0]) \n",
      "180095  40% ( 31m 23s)   0.506   |   0.00: Organisation -> organization (✓) \n",
      "190095  45% ( 35m 18s)   0.543   |   0.00: - -> to (✓) (forcing)\n",
      "Saved model to data/models/whole_gen_10_after_words_attention/200000_(EncoderRNN/DecoderRNN)\n",
      "Accuracy: 74.77% (    7477/   10000)\n",
      "200095  50% ( 40m 50s)   0.541   |   0.00: mr -> mister (✓) \n",
      "210095  55% ( 44m 48s)   0.517   |   0.68: Iro -> i r <EOS> (✗: [31, 35, 25, 0]) (forcing)\n",
      "220095  60% ( 48m 20s)   0.491   |   0.01: 151 -> one hundred fifty one (✓) (forcing)\n",
      "230095  65% ( 51m 39s)   0.464   |   0.00: vs -> versus (✓) \n",
      "240095  70% (  55m 1s)   0.421   |   0.00: - -> to (✓) (forcing)\n",
      "Saved model to data/models/whole_gen_10_after_words_attention/250000_(EncoderRNN/DecoderRNN)\n",
      "Accuracy: 76.50% (    7650/   10000)\n",
      "250095  75% ( 59m 36s)   0.498   |   0.01: # -> number (✓) \n",
      "260095  80% (  63m 9s)   0.536   |   0.00: Subsidised -> subsidized (✓) (forcing)\n",
      "270095  85% ( 66m 40s)   0.463   |   0.72: RGH- -> r h <EOS> (✗: [35, 53, 45, 0]) (forcing)\n",
      "280095  90% ( 70m 29s)   0.429   |   2.43: telegraph.co.uk -> t h h h h h a m <EOS> o u o m u k (✗: [30, 28, 42, 28, 53, 35, 22, 24, 45, 74, 21, 25, 74, 43, 59, 0]) (forcing)\n",
      "290095  95% ( 74m 12s)   0.416   |   1.96: www.youtube.com -> w w w w w s <EOS> s <EOS> s dot dot c o u (✗: [52, 52, 52, 74, 86, 25, 43, 30, 43, 36, 28, 74, 21, 25, 32, 0]) (forcing)\n",
      "Saved model to data/models/whole_gen_10_after_words_attention/300000_(EncoderRNN/DecoderRNN)\n",
      "Accuracy: 78.32% (    7832/   10000)\n",
      "300095 100% ( 79m 11s)   0.449   |   0.00: & -> and (✓) \n"
     ]
    }
   ],
   "source": [
    "train_iterations(n_iters=200000, print_every=10000, teacher_forcing_ratio=0.5, lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OldRacingCars.com => o d i n s dot c o m || [25, 42, 26, 35, 22, 21, 31, 29, 53, 21, 22, 35, 17, 74, 21, 25, 32, 0] \n",
      "                  \" thruxton , 31 mar 1975 « british formula 3 « <SAMPLE> \" .\n",
      "TCTapes.net    => t p s a n d p a s p p p p p p p p p p p || [30, 21, 30, 22, 24, 28, 17, 74, 29, 28, 30, 0] \n",
      "                  united states : <SAMPLE> .\n",
      "EGC            => e c g          || [28, 53, 21, 0] \n",
      "                  one of the best known <SAMPLE> graduates is queen sofia of spain .\n",
      "BentleyPublishers.com => b l e s q s p s c o s q y n y s p n s p || [36, 28, 29, 30, 42, 28, 86, 24, 43, 36, 42, 31, 17, 45, 28, 35, 17, 74, 21, 25, 32, 0] \n",
      "                  cambridge massachusetts : <SAMPLE> .\n",
      "fictionalised  => october k      || [576, 0] \n",
      "                  in 2010 , he appeared as a <SAMPLE> version of himself in the controversial movie killer bitch .\n",
      "Elzén          => e acute acute acute acute acute acute acute acute acute acute acute acute acute acute acute acute acute acute acute || [28, 42, 105, 28, 121, 29, 0] \n",
      "                  <SAMPLE> was born in sweden in 1972 and currently lives and works in berlin .\n",
      "2008-09-23     => the twenty eighth of october two thousand eight || [11, 6, 76, 12, 64, 5, 8, 16, 0] \n",
      "                  nord , liz ( <SAMPLE> ) .\n",
      "MITNJEK        => m i n k j k k k k k k k k k k k k k k k || [32, 31, 30, 29, 60, 28, 59, 0] \n",
      "                  \" <SAMPLE> vesna s . p . carna bauta \" ( in slovenian ) .\n",
      "1946           => one thousand nine hundred forty six || [7, 41, 20, 0] \n",
      "                  this was followed by stranger at home in <SAMPLE> .\n",
      "2008-01-30     => the eighth of october two eight || [11, 103, 12, 63, 5, 8, 16, 0] \n",
      "                  mickey furfari ( <SAMPLE> ) .\n"
     ]
    }
   ],
   "source": [
    "print_local_wrong_predictions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "310095   5% (  3m 40s)   0.480   |   0.19: 2nd -> second (✓) \n",
      "320095  10% (  7m 21s)   0.419   |   0.00: Vol -> volume (✓) (forcing)\n",
      "330095  15% (  11m 3s)   0.429   |   0.00: centre -> center (✓) \n",
      "340095  20% ( 14m 44s)   0.520   |   0.03: # -> number (✓) \n",
      "Saved model to data/models/whole_gen_10_after_words_attention/350000_(EncoderRNN/DecoderRNN)\n",
      "Accuracy: 78.88% (    7888/   10000)\n",
      "350095  25% ( 19m 51s)   0.399   |   0.00: _ -> underscore (✓) \n",
      "360095  30% ( 23m 30s)   0.419   |   0.00: & -> and (✓) \n",
      "370095  35% (  27m 9s)   0.516   |   0.00: J- -> j (✓) \n",
      "380095  40% ( 30m 46s)   0.501   |   0.05: ISBN -> i s b n (✓) \n",
      "390095  45% ( 34m 22s)   0.467   |   0.00: & -> and (✓) \n",
      "Saved model to data/models/whole_gen_10_after_words_attention/400000_(EncoderRNN/DecoderRNN)\n",
      "Accuracy: 76.44% (    7644/   10000)\n",
      "400095  50% ( 39m 19s)   0.401   |   0.01: 29 -> twenty nine (✓) \n",
      "410095  55% (  43m 6s)   0.469   |   2.24: Defense.gov -> d e s f o n e s e n s e (✗: [26, 28, 37, 28, 29, 17, 28, 74, 53, 25, 54, 0]) \n",
      "420095  60% ( 46m 43s)   0.440   |   0.41: RHS -> r h s h (✗: [35, 45, 17, 0]) (forcing)\n",
      "430095  65% ( 50m 15s)   0.432   |   0.04: 1979 -> nineteen seventy nine (✓) \n",
      "440095  70% ( 53m 49s)   0.446   |   0.00: metres -> meters (✓) \n",
      "Saved model to data/models/whole_gen_10_after_words_attention/450000_(EncoderRNN/DecoderRNN)\n",
      "Accuracy: 78.01% (    7801/   10000)\n",
      "450095  75% ( 58m 45s)   0.435   |   0.00: - -> to (✓) \n",
      "460095  80% ( 62m 26s)   0.390   |   0.01: st -> saint (✓) \n",
      "470095  85% (  66m 6s)   0.433   |   0.13: ZJ -> z j (✓) \n",
      "480095  90% ( 69m 44s)   0.424   |   0.00: metres -> meters (✓) \n",
      "490095  95% ( 73m 26s)   0.472   |   0.00: st -> saint (✓) \n",
      "Saved model to data/models/whole_gen_10_after_words_attention/500000_(EncoderRNN/DecoderRNN)\n",
      "Accuracy: 76.68% (    7668/   10000)\n",
      "500095 100% ( 78m 39s)   0.472   |   1.34: Twitter.com -> t w dot c o m (✗: [30, 52, 31, 30, 30, 28, 35, 74, 21, 25, 32, 0]) \n"
     ]
    }
   ],
   "source": [
    "train_iterations(n_iters=200000, print_every=10000, teacher_forcing_ratio=0.3, lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NCA            => n a c          || [29, 21, 22, 0] \n",
      "                  with tiebout 's support , she founded the national council on alcoholism ( <SAMPLE> ) .\n",
      "R.A.F.         => r f a          || [35, 22, 37, 0] \n",
      "                  \" shindig at n . y . airport opens fund drive for <SAMPLE> \" .\n",
      "DVD            => d v            || [26, 54, 26, 0] \n",
      "                  sleeve notes from <SAMPLE> .\n",
      "12.1           => twelve point one point one point one point one point one point one point one point one point one point || [47, 46, 9, 0] \n",
      "                  das heilige und die kultformen , grundriss der germanischen philologie <SAMPLE> , 2nd ed .\n",
      "RNAs           => r v's a n a t a n a n a n a n a n a n a n || [35, 29, 142, 0] \n",
      "                  these short double stranded fragments are called small interfering <SAMPLE> ( sirnas ) .\n",
      "http://www.kuvataiteilijamatrikkeli.fi/fi/taiteilijat/1449 => h t j p colon o v i o v i o v i o v i o v i || [45, 30, 30, 24, 129, 101, 101, 52, 52, 52, 74, 59, 43, 54, 22, 30, 22, 31, 30, 28, 31, 42, 31, 60, 22, 32, 22, 30, 35, 31, 59, 59, 28, 42, 31, 74, 37, 31, 101, 37, 31, 101, 30, 22, 31, 30, 28, 31, 42, 31, 60, 22, 30, 101, 25, 29, 28, 37, 25, 43, 35, 37, 25, 43, 35, 29, 31, 29, 28, 0] \n",
      "                  url : <SAMPLE> ( referred 1 august 2013 ) , in finnish .\n",
      "recognises     => recognize      || [432, 0] \n",
      "                  macmurrough conforms to some degree but <SAMPLE> his homosexuality as a permanent character trait .\n",
      "20             => twenty         || [5, 25, 0] \n",
      "                  the treasury books contain about 133 puzzles and 25 of which are the larger 20 x <SAMPLE> size .\n",
      "May 3, 1997    => may third nineteen seven seven seven seven seven seven seven seven seven seven seven seven seven seven seven seven seven || [66, 76, 7, 23, 18, 0] \n",
      "                  billboard , <SAMPLE> \" top rpm country tracks : issue 3479 . \"\n",
      "TWEB           => t w b w        || [30, 52, 28, 36, 0] \n",
      "                  acm transactions on the web ( <SAMPLE> ) .\n"
     ]
    }
   ],
   "source": [
    "print_local_wrong_predictions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "510095  10% (  3m 40s)   0.375   |   0.56: JBEI -> j b e i (✓) \n",
      "520095  20% (  7m 17s)   0.300   |   2.04: TheCelebrityCafe.com -> t h e e e e e e e e e e e e h e e c o m e (✗: [30, 45, 28, 21, 28, 42, 28, 36, 35, 31, 30, 86, 21, 22, 37, 28, 74, 21, 25, 32, 0]) (forcing)\n",
      "530095  30% ( 10m 56s)   0.296   |   0.01: st -> saint (✓) (forcing)\n",
      "540095  40% ( 14m 35s)   0.325   |   0.02: st -> saint (✓) (forcing)\n",
      "Saved model to data/models/whole_gen_10_after_words_attention/550000_(EncoderRNN/DecoderRNN)\n",
      "Accuracy: 83.38% (    8338/   10000)\n",
      "550095  50% ( 19m 43s)   0.307   |   0.01: 1960 -> nineteen sixty (✓) \n",
      "560095  60% ( 23m 29s)   0.277   |   0.00: Theatre -> theater (✓) (forcing)\n",
      "570095  70% ( 27m 13s)   0.303   |   0.01: st -> saint (✓) (forcing)\n",
      "580095  80% ( 30m 53s)   0.313   |   0.00: criticised -> criticized (✓) \n",
      "590095  90% ( 34m 30s)   0.311   |   0.01: 1978 -> nineteen seventy eight (✓) (forcing)\n",
      "Saved model to data/models/whole_gen_10_after_words_attention/600000_(EncoderRNN/DecoderRNN)\n",
      "Accuracy: 84.42% (    8442/   10000)\n",
      "600095 100% ( 39m 29s)   0.243   |   0.00: 2003 -> two thousand three (✓) \n"
     ]
    }
   ],
   "source": [
    "train_iterations(n_iters=100000, print_every=10000, teacher_forcing_ratio=0.5, lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "USPACOM        => u s p o m      || [43, 17, 24, 22, 21, 25, 32, 0] \n",
      "                  the us army contingent is from the us army pacific ( usarpac ) , part of the united states pacific command ( <SAMPLE> ) .\n",
      "Brisbanetimes.com.au => b r b a s i n dot c o m || [36, 35, 31, 17, 36, 22, 29, 28, 30, 31, 32, 28, 17, 74, 21, 25, 32, 74, 22, 43, 0] \n",
      "                  <SAMPLE> ( 19 august 2010 ) .\n",
      "PKM            => p k            || [24, 59, 32, 0] \n",
      "                  it can also accept all standard <SAMPLE> accessories , including tripod mount , and 100 - round clip on belt boxes .\n",
      "CatholicCulture.org => c a t t t t t t t t t t t t t t t t t t || [21, 22, 30, 45, 25, 42, 31, 21, 21, 43, 42, 30, 43, 35, 28, 74, 25, 35, 53, 0] \n",
      "                  <SAMPLE> ( trinity communications ) .\n",
      ".254           => point two five || [46, 5, 14, 19, 0] \n",
      "                  isbn 978 - 1 - 86969 - 366 - 4 , p <SAMPLE> .\n",
      "Egm            => e g g g g g g g g g g g g g g g g g g g || [28, 53, 32, 0] \n",
      "                  \" <SAMPLE> review : batman : arkham city \" .\n",
      "X1.net         => x dot o n e t  || [97, 25, 29, 28, 74, 29, 28, 30, 0] \n",
      "                  \" test for echo tourbook — cygnus <SAMPLE> \" .\n",
      "//www.spamlaws.com => s l a s h w a s h s s s s s s s s s s s || [17, 42, 22, 17, 45, 17, 42, 22, 17, 45, 52, 52, 52, 74, 17, 24, 22, 32, 42, 22, 52, 17, 74, 21, 25, 32, 0] \n",
      "                  netspot wifi site survey appwardrivewlanpollutionh ttp : <SAMPLE> / war - driving - attack . htmltsow , alex .\n",
      "2007-08 AHL    => the twenty eighth of july two thousand || [5, 25, 25, 18, 58, 25, 16, 58, 656, 0] \n",
      "                  \" <SAMPLE> playoff results \" .\n",
      "#              => number         || [175, 0] \n",
      "                  comics buyer 's guide <SAMPLE> 1650 ; february 2009 ; page 107 jennings , dana .\n"
     ]
    }
   ],
   "source": [
    "print_local_wrong_predictions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "610095  10% (  3m 41s)   0.526   |   1.57: ECTRIMS -> e r s c (✗: [28, 21, 30, 35, 31, 32, 17, 0]) \n",
      "620095  20% (  7m 19s)   0.469   |   0.33: 385 -> three hundred eighty five eighty (✗: [13, 10, 27, 14, 0]) \n",
      "630095  30% ( 10m 47s)   0.449   |   0.02: F. -> f (✓) \n",
      "640095  40% ( 14m 18s)   0.503   |   0.02: 1961 -> nineteen sixty one (✓) \n",
      "Saved model to data/models/whole_gen_10_after_words_attention/650000_(EncoderRNN/DecoderRNN)\n",
      "Accuracy: 79.42% (    7942/   10000)\n",
      "650095  50% ( 19m 14s)   0.379   |   0.00: 1994 -> nineteen ninety four (✓) \n",
      "660095  60% ( 22m 57s)   0.482   |   2.46: 978-1-57912-313-0 -> nine seven sil sil sil sil sil sil sil sil sil sil sil sil sil sil sil sil (✗: [15, 18, 16, 58, 9, 58, 14, 18, 15, 9, 5, 58, 13, 9, 13, 58, 25, 0]) \n",
      "670095  70% ( 26m 34s)   0.485   |   0.00: metres -> meters (✓) \n",
      "680095  80% ( 30m 16s)   0.444   |   0.02: 360 -> three hundred sixty (✓) \n",
      "690095  90% ( 33m 52s)   0.407   |   0.03: PDF -> p d f (✓) \n",
      "Saved model to data/models/whole_gen_10_after_words_attention/700000_(EncoderRNN/DecoderRNN)\n",
      "Accuracy: 78.58% (    7858/   10000)\n",
      "700095 100% ( 38m 53s)   0.394   |   0.00: A. -> a (✓) \n"
     ]
    }
   ],
   "source": [
    "train_iterations(n_iters=100000, print_every=10000, teacher_forcing_ratio=0.1, lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M. A. C.       => m c            || [32, 22, 21, 0] \n",
      "                  perryman , <SAMPLE> et al .\n",
      "2500           => two thousand five || [5, 8, 14, 10, 0] \n",
      "                  total number of population in this village is close to <SAMPLE> .\n",
      "Catholic.org   => c a o t h r dot o g || [21, 22, 30, 45, 25, 42, 31, 21, 74, 25, 35, 53, 0] \n",
      "                  \" <SAMPLE> information web site for hong kong \" .\n",
      "1980           => nineteen eighty || [9, 8, 15, 10, 27, 0] \n",
      "                  two day ( 15 ) : 1927 / 28 , 1928 / 29 , 1935 / 36 , 1939 / 40 , 1957 / 58 , <SAMPLE> / 81 , 1982 / 83 , 1985 / 86 , 1986 / 87 , 1987 / 88 , 1990 / 91 , 1991 / 92 , 2009 / 10 , 2010 / 11 and 2011 / 12 .\n",
      "M.C.C.         => m c            || [32, 21, 21, 0] \n",
      "                  his first class debut came ten years later when he played for the <SAMPLE> against lancashire .\n",
      "1718           => seventeen eighteen seventeen || [81, 40, 0] \n",
      "                  they returned to power with the election of manuel ii following the death of pedro iv in <SAMPLE> .\n",
      "ArnaudTsamere.com => a r m s r a m t o r a m || [22, 35, 29, 22, 43, 26, 30, 17, 22, 32, 28, 35, 28, 74, 21, 25, 32, 0] \n",
      "                  <SAMPLE> ( in french ) .\n",
      "VOC            => v o            || [54, 25, 21, 0] \n",
      "                  le maire applied for shares for the sum of 85 , 000 guilders and he became the largest shareholder in the <SAMPLE> .\n",
      "Balweg         => weg            || [1313, 315, 0] \n",
      "                  for them , it affect their families , livelihoods and cause terrorism due to conrado <SAMPLE> and the new people 's army ( npa ) .\n",
      ".com           => dot o m        || [74, 21, 25, 32, 0] \n",
      "                  london hotels <SAMPLE> .\n"
     ]
    }
   ],
   "source": [
    "print_local_wrong_predictions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "710095   5% (  3m 45s)   0.384   |   0.00: Centre -> center (✓) \n",
      "720095  10% (  7m 27s)   0.379   |   0.00: Organisation -> organization (✓) \n",
      "730095  15% (  11m 9s)   0.390   |   2.47: 3-17-003263-1 -> three sil o one sil one one one one one one one one one (✗: [13, 58, 9, 18, 58, 25, 25, 13, 5, 20, 13, 58, 9, 0]) \n",
      "740095  20% ( 14m 49s)   0.368   |   0.00: W. -> w (✓) \n",
      "Saved model to data/models/whole_gen_10_after_words_attention/750000_(EncoderRNN/DecoderRNN)\n",
      "Accuracy: 82.80% (    8280/   10000)\n",
      "750095  25% ( 19m 51s)   0.386   |   0.00: 3 -> three (✓) (forcing)\n",
      "760095  30% ( 23m 28s)   0.325   |   0.03: 221 -> two hundred twenty one (✓) \n",
      "770095  35% ( 27m 12s)   0.292   |   0.01: AJ -> a j (✓) \n",
      "780095  40% ( 30m 58s)   0.399   |   0.00: 2008 -> two thousand eight (✓) \n",
      "790095  45% ( 34m 37s)   0.343   |   0.02: 1963 -> nineteen sixty three (✓) \n",
      "Saved model to data/models/whole_gen_10_after_words_attention/800000_(EncoderRNN/DecoderRNN)\n",
      "Accuracy: 82.18% (    8218/   10000)\n",
      "800095  50% ( 39m 39s)   0.379   |   1.30: Mapquest.com -> m a u s m c (✗: [32, 22, 24, 111, 43, 28, 17, 30, 74, 21, 25, 32, 0]) \n",
      "810095  55% ( 43m 20s)   0.294   |   0.00: D. -> d (✓) \n",
      "820095  60% ( 46m 53s)   0.347   |   1.03: nit.org -> n i t g o dot (✗: [29, 31, 30, 74, 25, 35, 53, 0]) \n",
      "830095  65% ( 50m 37s)   0.320   |   0.00: theatre -> theater (✓) \n",
      "840095  70% ( 54m 14s)   0.324   |   2.90: talkinbroadway.com -> t a n o a a a a a a a a a a a a a a a (✗: [30, 22, 42, 59, 31, 29, 36, 35, 25, 22, 26, 52, 22, 86, 74, 21, 25, 32, 0]) \n",
      "Saved model to data/models/whole_gen_10_after_words_attention/850000_(EncoderRNN/DecoderRNN)\n",
      "Accuracy: 82.87% (    8287/   10000)\n",
      "850095  75% ( 59m 19s)   0.350   |   1.17: .com -> dot o m (✗: [74, 21, 25, 32, 0]) \n",
      "860095  80% (  63m 8s)   0.347   |   2.36: AsthmaMeds.ca -> a s m a s m t dot c m m m m m (✗: [22, 17, 30, 45, 32, 22, 32, 28, 26, 17, 74, 21, 22, 0]) \n",
      "870095  85% ( 66m 49s)   0.353   |   0.69: DLGR -> d l r (✗: [26, 42, 53, 35, 0]) \n",
      "880095  90% ( 70m 24s)   0.329   |   0.00: realised -> realized (✓) \n",
      "890095  95% (  74m 3s)   0.335   |   0.00: - -> to (✓) \n",
      "Saved model to data/models/whole_gen_10_after_words_attention/900000_(EncoderRNN/DecoderRNN)\n",
      "Accuracy: 83.33% (    8333/   10000)\n",
      "900095 100% (  79m 4s)   0.357   |   0.00: pvt -> private (✓) \n"
     ]
    }
   ],
   "source": [
    "train_iterations(n_iters=200000, print_every=10000, teacher_forcing_ratio=0.1, lr=0.0005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MGNREGA        => m g n g e g g g g g g g g g g g g g g g || [32, 53, 29, 35, 28, 53, 22, 0] \n",
      "                  \" mihir shah committee proposes new guidelines on <SAMPLE> : some highlights \" .\n",
      "12/03/07       => the third of march o || [11, 76, 12, 65, 25, 18, 0] \n",
      "                  \" weekly list of actions taken on properties <SAMPLE> through 12 / 07 / 07 \" , national register of historic places , national park service .\n",
      "Amazon.com     => a m a z o n dot c o || [22, 32, 22, 105, 25, 29, 74, 21, 25, 32, 0] \n",
      "                  <SAMPLE> ( us ) amazon . com inc retrieved 2013 - 01 - 25 .\n",
      "38.6           => thirty point six || [34, 16, 46, 20, 0] \n",
      "                  the median age was <SAMPLE> years .\n",
      "talkfootball.co.uk => t a l k dot c o dot c o dot c o dot c o dot c o dot || [30, 22, 42, 59, 37, 25, 25, 30, 36, 22, 42, 42, 74, 21, 25, 74, 43, 59, 0] \n",
      "                  positions in football : sweeper / libero <SAMPLE> , accessed 11 july 2010 ramesh , priya .\n",
      "AACo           => a c a a a a a a a a a a a a a a a a a a || [22, 22, 21, 25, 0] \n",
      "                  in 2009 , elders sold 75 per cent of elders insurance to qbe , and ceased its stake in <SAMPLE> .\n",
      "J.R.R.         => j r r r r r r r r r r r r r r r r r r r || [60, 35, 35, 0] \n",
      "                  \" an interview with <SAMPLE> tolkien \" .\n",
      "Donnasummer.it => d o n e u n s n dot c o m || [26, 25, 29, 29, 22, 17, 43, 32, 32, 28, 35, 74, 31, 30, 0] \n",
      "                  <SAMPLE> \" dutchcharts . nl — discografie donna summer \" .\n",
      "BMW-           => b m            || [36, 32, 52, 0] \n",
      "                  <SAMPLE> powered sidecars have won numerous world championships , notable competitors being rolf steinhausen , klaus enders and max deubel .\n",
      "1500m          => one thousand five hundred fifteen meters || [9, 8, 14, 10, 108, 0] \n",
      "                  in 1987 ivan won golds at both <SAMPLE> and 3000m at the universiade in zagreb .\n"
     ]
    }
   ],
   "source": [
    "print_local_wrong_predictions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "910095   3% (  3m 39s)   0.274   |   0.00: & -> and (✓) (forcing)\n",
      "920095   7% (  7m 22s)   0.347   |   0.00: - -> to (✓) \n",
      "930095  10% ( 10m 58s)   0.305   |   6.40: fertilises -> third (✗: [1122, 0]) \n",
      "940095  13% ( 14m 41s)   0.220   |   0.00: 24 October 2008 -> the twenty fourth of october two thousand eight (✓) (forcing)\n",
      "Saved model to data/models/whole_gen_10_after_words_attention/950000_(EncoderRNN/DecoderRNN)\n",
      "Accuracy: 85.96% (    8596/   10000)\n",
      "950095  17% ( 19m 37s)   0.283   |   0.01: st -> saint (✓) \n",
      "960095  20% ( 23m 21s)   0.280   |   1.91: 33.9% -> thirty point three percent percent percent (✗: [34, 13, 46, 15, 83, 0]) \n",
      "970095  23% (  27m 3s)   0.297   |   0.50: GMAD -> g m a d d (✗: [53, 32, 22, 26, 0]) \n",
      "980095  27% ( 30m 42s)   0.305   |   0.00: US -> u s (✓) \n",
      "990095  30% ( 34m 16s)   0.257   |   0.00: G. -> g (✓) \n",
      "Saved model to data/models/whole_gen_10_after_words_attention/1000000_(EncoderRNN/DecoderRNN)\n",
      "Accuracy: 85.35% (    8535/   10000)\n",
      "1000095  33% ( 39m 12s)   0.250   |   0.00: & -> and (✓) \n",
      "1010095  37% ( 42m 57s)   0.308   |   0.00: : -> to (✓) \n",
      "1020095  40% ( 46m 40s)   0.230   |   0.00: US -> u s (✓) \n",
      "1030095  43% ( 50m 23s)   0.255   |   0.04: J.L. -> j l (✓) \n",
      "1040095  47% (  54m 3s)   0.300   |   1.10: Uboat.net -> u b o a t e t dot t (✗: [43, 36, 25, 22, 30, 74, 29, 28, 30, 0]) \n",
      "Saved model to data/models/whole_gen_10_after_words_attention/1050000_(EncoderRNN/DecoderRNN)\n",
      "Accuracy: 85.89% (    8589/   10000)\n",
      "1050095  50% (  59m 3s)   0.279   |   0.32: AOC -> a o c (✓) \n",
      "1060095  53% ( 62m 47s)   0.285   |   0.01: 7th -> seventh (✓) \n",
      "1070095  57% ( 66m 29s)   0.307   |   0.02: 175 -> one hundred seventy five (✓) \n",
      "1080095  60% ( 70m 21s)   0.261   |   0.00: & -> and (✓) \n",
      "1090095  63% (  74m 8s)   0.289   |   0.00: N. -> n (✓) \n",
      "Saved model to data/models/whole_gen_10_after_words_attention/1100000_(EncoderRNN/DecoderRNN)\n",
      "Accuracy: 85.65% (    8565/   10000)\n",
      "1100095  67% (  79m 5s)   0.226   |   0.02: BP -> b p (✓) \n",
      "1110095  70% ( 82m 49s)   0.299   |   7.60: 1910 -> nineteen ten (✗: [9, 15, 9, 25, 0]) \n",
      "1120095  73% ( 86m 32s)   0.270   |   0.06: HF -> h f (✓) \n",
      "1130095  77% ( 90m 30s)   0.238   |   0.01: C. L. -> c l (✓) \n",
      "1140095  80% ( 94m 12s)   0.273   |   0.14: 101 -> one hundred one (✓) \n",
      "Saved model to data/models/whole_gen_10_after_words_attention/1150000_(EncoderRNN/DecoderRNN)\n",
      "Accuracy: 86.20% (    8620/   10000)\n",
      "1150095  83% ( 99m 15s)   0.241   |   0.01: January 25, 1956 -> january twenty fifth nineteen fifty six (✓) \n",
      "1160095  87% (102m 55s)   0.290   |   0.00: & -> and (✓) \n",
      "1170095  90% (106m 36s)   0.249   |   0.00: - -> to (✓) \n",
      "1180095  93% (110m 28s)   0.257   |   0.00: - -> to (✓) \n",
      "1190095  97% ( 114m 3s)   0.265   |   0.01: 1994 -> nineteen ninety four (✓) \n",
      "Saved model to data/models/whole_gen_10_after_words_attention/1200000_(EncoderRNN/DecoderRNN)\n",
      "Accuracy: 86.74% (    8674/   10000)\n",
      "1200095 100% (119m 10s)   0.306   |   0.00: & -> and (✓) \n"
     ]
    }
   ],
   "source": [
    "train_iterations(n_iters=300000, print_every=10000, teacher_forcing_ratio=0.1, lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ndek           => n d k          || [29, 26, 28, 59, 0] \n",
      "                  irondequoit / ᵻ ˈ r ɒ <SAMPLE> ɔ ɪ t / is a town ( and census designated place ) in monroe county new york , usa .\n",
      "420.9          => four hundred twenty nine point nine || [19, 10, 6, 46, 15, 0] \n",
      "                  the population density was <SAMPLE> people per square mile ( 162 . 3 / km² ) .\n",
      "www.avalancheinc.co.uk/finalbio.htmlhttp://www.doommantia.com/2010/05/interview-with-andy-swan-from-iroha.htmlStrong => w w w w w w w w w w w w w w w w w w w w || [52, 52, 52, 74, 22, 54, 22, 42, 22, 29, 21, 45, 28, 31, 29, 21, 74, 21, 25, 74, 43, 59, 17, 42, 22, 17, 45, 37, 31, 29, 22, 42, 36, 31, 25, 74, 45, 30, 32, 42, 45, 30, 30, 24, 21, 25, 42, 25, 29, 17, 42, 22, 17, 45, 17, 42, 22, 17, 45, 52, 52, 52, 74, 26, 25, 25, 32, 32, 22, 29, 30, 31, 22, 74, 21, 25, 32, 17, 42, 22, 17, 45, 30, 52, 28, 29, 30, 86, 30, 28, 29, 17, 42, 22, 17, 45, 25, 37, 31, 54, 28, 17, 42, 22, 17, 45, 31, 29, 30, 28, 35, 54, 31, 28, 52, 26, 22, 17, 45, 52, 31, 30, 45, 26, 22, 17, 45, 22, 29, 26, 86, 26, 22, 17, 45, 17, 52, 22, 29, 26, 22, 17, 45, 37, 35, 25, 32, 26, 22, 17, 45, 31, 35, 25, 45, 22, 74, 45, 30, 32, 42, 17, 30, 35, 25, 29, 53, 0] \n",
      "                  los angeles california : feral house http : / / <SAMPLE> , martin c . ( 2003 ) the great indie discography , canongate , isbn 1 - 84195 - 335 - 0 , p . 489 lazell , barry ( 1997 ) .\n",
      "lala.com       => l a a a a a a a a a a a a a a a a a a a || [42, 22, 42, 22, 74, 21, 25, 32, 0] \n",
      "                  it was released via itunes and <SAMPLE> on october 29 , 2007 , in conjunction with a live webchat from the band .\n",
      "Grid.dk        => g r d i        || [53, 35, 31, 26, 74, 26, 59, 0] \n",
      "                  <SAMPLE> is the national danish grid , slated to run the migrid software , mixed with other grid middelware , such as nordugrid .\n",
      "dane.gov.co    => d a e n g dot c o v e dot c o || [26, 22, 29, 28, 74, 53, 25, 54, 74, 21, 25, 0] \n",
      "                  dane : 2005 census of colombia — total area <SAMPLE> accessed 23 august 2007 .\n",
      "http://cfpub.epa.gov/ncea/iris/index.cfm => h t p colon slash slash slash slash slash slash slash slash slash slash slash slash slash slash slash slash || [45, 30, 30, 24, 129, 101, 101, 21, 37, 24, 43, 36, 74, 28, 24, 22, 74, 53, 25, 54, 101, 29, 21, 28, 22, 101, 31, 35, 31, 17, 101, 31, 29, 26, 28, 97, 74, 21, 37, 32, 0] \n",
      "                  available at : <SAMPLE> .\n",
      "INSAS          => i n s a s s s s s s s s s s s s s s s s || [31, 29, 17, 22, 17, 0] \n",
      "                  cyprus india replaced by the <SAMPLE> .\n",
      "NFL's          => n f l          || [29, 37, 204, 0] \n",
      "                  the <SAMPLE> oakland raiders played their second game of the 1973 regular season at memorial stadium .\n",
      "rden           => r e d          || [35, 26, 28, 29, 0] \n",
      "                  cloughjordan , officially cloghjordan ( / kl ɒ k ˈ d ʒ ɔ ː <SAMPLE> / klok jor den , irish : cloch shiurdain , meaning \" siurdan 's stone \" ) , is a town in county tipperary in ireland .\n"
     ]
    }
   ],
   "source": [
    "print_local_wrong_predictions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1210095   3% (  3m 45s)   0.351   |   0.06: 1934 -> nineteen thirty four (✓) \n",
      "1220095   7% (  7m 33s)   0.361   |   0.00: & -> and (✓) \n",
      "1230095  10% ( 11m 18s)   0.319   |   0.00: Vol -> volume (✓) \n",
      "1240095  13% ( 14m 57s)   0.308   |   0.03: NZ -> n z (✓) \n",
      "Saved model to data/models/whole_gen_10_after_words_attention/1250000_(EncoderRNN/DecoderRNN)\n",
      "Accuracy: 82.60% (    8260/   10000)\n",
      "1250095  17% (  20m 2s)   0.393   |   0.00: programmes -> programs (✓) \n",
      "1260095  20% ( 23m 41s)   0.311   |   0.00: vol -> volume (✓) \n",
      "1270095  23% ( 27m 23s)   0.353   |   0.00: & -> and (✓) \n",
      "1280095  27% ( 31m 11s)   0.347   |   0.00: organisation -> organization (✓) \n",
      "1290095  30% ( 34m 50s)   0.294   |   0.00: & -> and (✓) \n",
      "Saved model to data/models/whole_gen_10_after_words_attention/1300000_(EncoderRNN/DecoderRNN)\n",
      "Accuracy: 83.46% (    8346/   10000)\n",
      "1300095  33% ( 39m 55s)   0.319   |   0.13: October 18, 2009 -> october eighteenth two thousand nine (✓) \n",
      "1310095  37% ( 43m 32s)   0.307   |   2.02: nishina-mf.or.jp -> n i j h s a dot a f r f s a f (✗: [29, 31, 17, 45, 31, 29, 22, 26, 22, 17, 45, 32, 37, 74, 25, 35, 74, 60, 24, 0]) \n",
      "1320095  40% ( 47m 16s)   0.320   |   0.00: vol -> volume (✓) \n",
      "1330095  43% ( 50m 55s)   0.350   |   0.02: W. H. -> w h (✓) \n",
      "1340095  47% ( 54m 29s)   0.279   |   3.86: 114762 -> one hundred sixty two hundred four hundred seven (✗: [9, 10, 50, 8, 18, 10, 39, 5, 0]) \n",
      "Saved model to data/models/whole_gen_10_after_words_attention/1350000_(EncoderRNN/DecoderRNN)\n",
      "Accuracy: 83.66% (    8366/   10000)\n",
      "1350095  50% ( 59m 27s)   0.284   |   0.00: & -> and (✓) \n",
      "1360095  53% (  63m 6s)   0.316   |   0.06: RT -> r t (✓) \n",
      "1370095  57% ( 66m 50s)   0.250   |   0.01: 1994 -> nineteen ninety four (✓) \n",
      "1380095  60% ( 70m 30s)   0.354   |   0.00: Centre -> center (✓) \n",
      "1390095  63% ( 74m 12s)   0.343   |   0.00: programme -> program (✓) \n",
      "Saved model to data/models/whole_gen_10_after_words_attention/1400000_(EncoderRNN/DecoderRNN)\n",
      "Accuracy: 83.12% (    8312/   10000)\n",
      "1400095  67% ( 79m 13s)   0.332   |   0.01: 1998 -> nineteen ninety eight (✓) \n",
      "1410095  70% ( 82m 55s)   0.345   |   5.91: V -> five (✗: [11, 78, 0]) \n",
      "1420095  73% ( 86m 31s)   0.373   |   0.07: BBC -> b b c (✓) \n",
      "1430095  77% (  90m 9s)   0.303   |   0.00: PDF -> p d f (✓) \n",
      "1440095  80% ( 93m 41s)   0.264   |   1.85: 0.23% -> zero point two percent (✗: [104, 46, 5, 13, 83, 0]) \n",
      "Saved model to data/models/whole_gen_10_after_words_attention/1450000_(EncoderRNN/DecoderRNN)\n",
      "Accuracy: 84.42% (    8442/   10000)\n",
      "1450095  83% ( 98m 34s)   0.276   |   0.29: RSA -> r s a (✓) \n",
      "1460095  87% (102m 18s)   0.306   |   0.04: Ph -> p h (✓) \n",
      "1470095  90% ( 106m 3s)   0.322   |   0.00: 1920s -> nineteen twenties (✓) \n",
      "1480095  93% (109m 47s)   0.356   |   0.00: - -> to (✓) \n",
      "1490095  97% (113m 24s)   0.293   |   0.00: - -> to (✓) \n",
      "Saved model to data/models/whole_gen_10_after_words_attention/1500000_(EncoderRNN/DecoderRNN)\n",
      "Accuracy: 84.04% (    8404/   10000)\n",
      "1500095 100% (118m 31s)   0.312   |   0.02: 1999 -> nineteen ninety nine (✓) \n"
     ]
    }
   ],
   "source": [
    "train_iterations(n_iters=300000, print_every=10000, teacher_forcing_ratio=0, lr=0.0005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0-86356-520-4  => o sil eight sil sil sil sil sil sil sil sil sil sil sil sil sil sil sil sil sil || [25, 58, 16, 20, 13, 14, 20, 58, 14, 5, 25, 58, 19, 0] \n",
      "                  isbn <SAMPLE> salucci , ilario .\n",
      "110 m          => one hundred meters || [9, 10, 44, 108, 0] \n",
      "                  its elevation is <SAMPLE> . it is located west of the state capital of porto alegre and northeast of alegrete .\n",
      "NPIAS          => n p i s        || [29, 24, 31, 22, 17, 0] \n",
      "                  alkali lake state airport is categorized as a level 5 , non <SAMPLE> airport .\n",
      "Euroleague.net => e u r e e e e e e e e e e e e e e e e e || [28, 43, 35, 25, 42, 28, 22, 53, 43, 28, 74, 29, 28, 30, 0] \n",
      "                  <SAMPLE> spanoulis named bwin mvp of 2013 final four .\n",
      "Area-Codes.com => a r d e a o d c o d a c h a o d c o d c || [22, 35, 28, 22, 26, 22, 17, 45, 21, 25, 26, 28, 17, 74, 21, 25, 32, 0] \n",
      "                  area code lookup — npa nxx for long beach , nj , <SAMPLE> .\n",
      "cshpm          => c s p m        || [21, 17, 45, 24, 32, 0] \n",
      "                  glen van brummelen at the mathematics genealogy project <SAMPLE> council , retrieved 2013 - 12 - 26 .\n",
      "LocationWorks.com => l o a c o o o o o o o o o o o o o o o o || [42, 25, 21, 22, 30, 31, 25, 29, 52, 25, 35, 59, 17, 74, 21, 25, 32, 0] \n",
      "                  \" pictures of the farmiloe building at <SAMPLE> \" .\n",
      "Devant-soi.com => d e t a v o m  || [26, 28, 54, 22, 29, 30, 26, 22, 17, 45, 17, 25, 31, 74, 21, 25, 32, 0] \n",
      "                  f . devant - soi . com ( retrieved march 22 , 2008 ) fleches cool , march 2 , 2002 , \" les mots \" <SAMPLE> ( retrieved march 22 , 2008 ) t é l é star , no\n",
      "RIAJ           => r i a          || [35, 31, 22, 60, 0] \n",
      "                  <SAMPLE> ( in japanese ) .\n",
      "http://0-www.oxforddnb.com.librarycatalog.vts.edu/view/article/3848 => h t t t t t t t t t t t t t t t t t t t || [45, 30, 30, 24, 129, 101, 101, 25, 115, 52, 52, 52, 74, 25, 97, 37, 25, 35, 26, 26, 29, 36, 74, 156, 74, 42, 31, 36, 35, 22, 35, 86, 21, 22, 30, 22, 42, 25, 53, 74, 54, 30, 17, 74, 28, 26, 43, 101, 54, 31, 28, 52, 101, 22, 35, 30, 31, 21, 42, 28, 101, 30, 45, 35, 28, 28, 28, 31, 53, 45, 30, 37, 25, 43, 35, 28, 31, 53, 45, 30, 0] \n",
      "                  lawrence goldman , 2004 , <SAMPLE> ( accessed november 8 , 2015 ) .\n"
     ]
    }
   ],
   "source": [
    "print_local_wrong_predictions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1510095   5% (  3m 43s)   0.299   |   0.00: E. -> e (✓) \n",
      "1520095  10% (  7m 25s)   0.277   |   0.01: 11 -> eleven (✓) \n",
      "1530095  15% ( 11m 14s)   0.265   |   0.01: 145 -> one hundred forty five (✓) \n",
      "1540095  20% (  15m 0s)   0.273   |   0.04: L.J. -> l j (✓) \n",
      "Saved model to data/models/whole_gen_10_after_words_attention/1550000_(EncoderRNN/DecoderRNN)\n",
      "Accuracy: 85.81% (    8581/   10000)\n",
      "1550095  25% (  20m 2s)   0.268   |   2.28: CollegeInsdier.com -> c o l d i e e e e e e e e e e e e e e (✗: [21, 25, 42, 42, 28, 53, 28, 31, 29, 17, 26, 31, 28, 35, 74, 21, 25, 32, 0]) \n",
      "1560095  30% ( 23m 46s)   0.282   |   0.00: vol -> volume (✓) \n",
      "1570095  35% ( 27m 32s)   0.262   |   0.00: pp -> p p (✓) \n",
      "1580095  40% ( 31m 12s)   0.257   |   0.00: & -> and (✓) \n",
      "1590095  45% ( 34m 49s)   0.238   |   0.00: st -> saint (✓) \n",
      "Saved model to data/models/whole_gen_10_after_words_attention/1600000_(EncoderRNN/DecoderRNN)\n",
      "Accuracy: 86.15% (    8615/   10000)\n",
      "1600095  50% ( 39m 48s)   0.283   |   0.37: GXG -> g x (✗: [53, 97, 53, 0]) \n",
      "1610095  55% ( 43m 28s)   0.278   |   0.00: & -> and (✓) \n",
      "1620095  60% ( 47m 17s)   0.243   |   0.00: Theatre -> theater (✓) \n",
      "1630095  65% ( 50m 55s)   0.281   |   0.00: dr -> doctor (✓) \n",
      "1640095  70% ( 54m 31s)   0.254   |   0.00: G. -> g (✓) \n",
      "Saved model to data/models/whole_gen_10_after_words_attention/1650000_(EncoderRNN/DecoderRNN)\n",
      "Accuracy: 86.12% (    8612/   10000)\n",
      "1650095  75% ( 59m 32s)   0.258   |   0.00: vol -> volume (✓) \n",
      "1660095  80% (  63m 2s)   0.300   |   0.00: & -> and (✓) \n",
      "1670095  85% ( 66m 54s)   0.322   |   0.00: PDF -> p d f (✓) \n",
      "1680095  90% ( 70m 33s)   0.247   |   0.21: UFOs -> u f o's (✓) \n",
      "1690095  95% ( 74m 14s)   0.280   |   0.06: GMA -> g m a (✓) \n",
      "Saved model to data/models/whole_gen_10_after_words_attention/1700000_(EncoderRNN/DecoderRNN)\n",
      "Accuracy: 86.52% (    8652/   10000)\n",
      "1700095 100% ( 79m 20s)   0.308   |   0.00: No -> number (✓) \n"
     ]
    }
   ],
   "source": [
    "train_iterations(n_iters=200000, print_every=10000, teacher_forcing_ratio=0, lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuesday 11 March 1845 => tuesday eighteen forty five o five || [223, 11, 92, 12, 62, 40, 41, 14, 0] \n",
      "                  it first appeared on <SAMPLE> .\n",
      "KROQ           => k o q r        || [59, 35, 25, 111, 0] \n",
      "                  \" <SAMPLE> top 106 . 7 artists of all time ( may 2007 ) \" .\n",
      "TULOMSAS       => t l o u a s    || [30, 43, 42, 25, 32, 17, 22, 17, 0] \n",
      "                  the remaining devrim is open for visit at <SAMPLE> factory in eskisehir everyday between 08 : 00 - 17 : 00 .\n",
      "falkirkfchistorian.blogspot.com => f a t i l s i c i o c dot k o c o m || [37, 22, 42, 59, 31, 35, 59, 37, 21, 45, 31, 17, 30, 25, 35, 31, 22, 29, 74, 36, 42, 25, 53, 17, 24, 25, 30, 74, 21, 25, 32, 0] \n",
      "                  falkirk fc managers , <SAMPLE> ; accessed 6 september 2015 .\n",
      "Officialcharts.com/ => o f i c a s f c a c c c c c c c c c c c || [25, 37, 37, 31, 21, 31, 22, 42, 21, 45, 22, 35, 30, 17, 74, 21, 25, 32, 17, 42, 22, 17, 45, 0] \n",
      "                  <SAMPLE> official charts company .\n",
      "VCC            => v c c c c c c c c c c c c c c c c c c c || [54, 21, 21, 0] \n",
      "                  an offshoot of sll , the voluntary census committee ( <SAMPLE> ) gathered census forms from protesters across the nation in 1980 .\n",
      "NRDC           => n d r c        || [29, 35, 26, 21, 0] \n",
      "                  la onda verde de <SAMPLE> : pagina principal .\n",
      "2.26           => two point six  || [5, 46, 5, 20, 0] \n",
      "                  the average household size was <SAMPLE> .\n",
      "10.1126        => one point one one one one one one one one one one one one one one one one one one || [44, 46, 9, 9, 5, 20, 0] \n",
      "                  6269 ( 2016 ) doi : <SAMPLE> / science . aad 2622 .\n",
      "2010           => twenty ten     || [5, 8, 44, 0] \n",
      "                  state - 85% <SAMPLE> - 84% , 48% adv ( 5% below basic ) .\n"
     ]
    }
   ],
   "source": [
    "print_local_wrong_predictions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1710095   2% (  3m 50s)   0.306   |   2.27: tribune.com.pk -> t r n b i o c e p o c o c o c (✗: [30, 35, 31, 36, 43, 29, 28, 74, 21, 25, 32, 74, 24, 59, 0]) \n",
      "1720095   4% (  7m 27s)   0.303   |   0.02: st -> saint (✓) \n",
      "1730095   6% ( 11m 15s)   0.249   |   0.03: 2003-05-13 -> the thirteenth of may two thousand three (✓) \n",
      "1740095   8% (  15m 5s)   0.283   |   0.26: 5,405 -> five thousand four hundred five (✓) \n",
      "Saved model to data/models/whole_gen_10_after_words_attention/1750000_(EncoderRNN/DecoderRNN)\n",
      "Accuracy: 86.67% (    8667/   10000)\n",
      "1750095  10% (  20m 9s)   0.269   |   0.01: AC -> a c (✓) \n",
      "1760095  12% ( 23m 53s)   0.264   |   0.00: metres -> meters (✓) \n",
      "1770095  14% ( 27m 36s)   0.280   |   0.00: & -> and (✓) \n",
      "1780095  16% ( 31m 11s)   0.233   |   0.01: CD -> c d (✓) \n",
      "1790095  18% ( 34m 52s)   0.224   |   0.00: & -> and (✓) \n",
      "Saved model to data/models/whole_gen_10_after_words_attention/1800000_(EncoderRNN/DecoderRNN)\n",
      "Accuracy: 86.15% (    8615/   10000)\n",
      "1800095  20% ( 39m 53s)   0.259   |   0.00: & -> and (✓) \n",
      "1810095  22% ( 43m 35s)   0.219   |   0.01: 1969 -> nineteen sixty nine (✓) \n",
      "1820095  24% ( 47m 26s)   0.275   |   0.00: 15th -> fifteenth (✓) \n",
      "1830095  26% ( 51m 13s)   0.253   |   0.00: 9 -> nine (✓) \n",
      "1840095  28% ( 54m 54s)   0.251   |   0.00: # -> number (✓) \n",
      "Saved model to data/models/whole_gen_10_after_words_attention/1850000_(EncoderRNN/DecoderRNN)\n",
      "Accuracy: 86.12% (    8612/   10000)\n",
      "1850095  30% ( 59m 58s)   0.279   |   0.08: IEC -> i e c (✓) \n",
      "1860095  32% ( 63m 39s)   0.268   |   0.00: - -> to (✓) \n",
      "1870095  34% ( 67m 32s)   0.385   |   0.00: - -> to (✓) \n",
      "1880095  36% ( 71m 29s)   0.242   |   0.00: 2006 -> two thousand six (✓) \n",
      "1890095  38% ( 75m 19s)   0.241   |   0.00: Centre -> center (✓) \n",
      "Saved model to data/models/whole_gen_10_after_words_attention/1900000_(EncoderRNN/DecoderRNN)\n",
      "Accuracy: 86.86% (    8686/   10000)\n",
      "1900095  40% ( 80m 25s)   0.281   |   0.25: DR -> doctor (✓) \n",
      "1910095  42% (  84m 7s)   0.247   |   0.00: vs -> versus (✓) \n",
      "1920095  44% ( 87m 53s)   0.243   |   0.00: 14 -> fourteen (✓) \n",
      "1930095  46% ( 91m 39s)   0.225   |   0.02: HD -> h d (✓) \n",
      "1940095  48% ( 95m 22s)   0.277   |   0.00: & -> and (✓) \n",
      "Saved model to data/models/whole_gen_10_after_words_attention/1950000_(EncoderRNN/DecoderRNN)\n",
      "Accuracy: 86.59% (    8659/   10000)\n",
      "1950095  50% (100m 30s)   0.234   |   0.00: & -> and (✓) \n",
      "1960095  52% (104m 13s)   0.297   |   0.00: franchise -> franchize (✓) \n",
      "1970095  54% (107m 56s)   0.249   |   0.00: - -> to (✓) \n",
      "1980095  56% (111m 51s)   0.269   |   0.00: - -> to (✓) \n",
      "1990095  58% (115m 40s)   0.269   |   0.00: & -> and (✓) \n",
      "Saved model to data/models/whole_gen_10_after_words_attention/2000000_(EncoderRNN/DecoderRNN)\n",
      "Accuracy: 86.81% (    8681/   10000)\n",
      "2000095  60% (120m 45s)   0.250   |   0.00: : -> to (✓) \n",
      "2010095  62% (124m 33s)   0.225   |   0.00: May 19, 2010 -> may nineteenth twenty ten (✓) \n",
      "2020095  64% (128m 23s)   0.268   |   0.00: Etc -> etcetera (✓) \n",
      "2030095  66% ( 132m 8s)   0.246   |   0.00: NJ -> n j (✓) \n",
      "2040095  68% (135m 56s)   0.274   |   0.00: - -> to (✓) \n",
      "Saved model to data/models/whole_gen_10_after_words_attention/2050000_(EncoderRNN/DecoderRNN)\n",
      "Accuracy: 86.73% (    8673/   10000)\n",
      "2050095  70% (140m 59s)   0.237   |   0.00: & -> and (✓) \n",
      "2060095  72% (144m 49s)   0.246   |   0.00: st -> saint (✓) \n",
      "2070095  74% (148m 43s)   0.270   |   0.00: S- -> s (✓) \n",
      "2080095  76% (152m 35s)   0.240   |   0.00: coloured -> colored (✓) \n",
      "2090095  78% (156m 22s)   0.265   |   0.00: pp -> p p (✓) \n",
      "Saved model to data/models/whole_gen_10_after_words_attention/2100000_(EncoderRNN/DecoderRNN)\n",
      "Accuracy: 87.25% (    8725/   10000)\n",
      "2100095  80% (161m 39s)   0.272   |   0.01: 1940 -> nineteen forty (✓) \n",
      "2110095  82% (165m 23s)   0.291   |   0.00: & -> and (✓) \n",
      "2120095  84% ( 169m 4s)   0.205   |   0.00: - -> to (✓) \n",
      "2130095  86% (172m 48s)   0.229   |   0.84: Al2O3 -> aluminium (✗: [511, 512, 0]) \n",
      "2140095  88% (176m 35s)   0.227   |   2.35: OVCSports.com -> o s p c o s o s o s o s o s (✗: [25, 54, 21, 17, 24, 25, 35, 30, 17, 74, 21, 25, 32, 0]) \n",
      "Saved model to data/models/whole_gen_10_after_words_attention/2150000_(EncoderRNN/DecoderRNN)\n",
      "Accuracy: 86.92% (    8692/   10000)\n",
      "2150095  90% (181m 38s)   0.227   |   0.04: A.A. -> a a (✓) \n",
      "2160095  92% (185m 21s)   0.229   |   0.00: pp -> p p (✓) \n",
      "2170095  94% ( 189m 5s)   0.243   |   0.02: December 6, 1925 -> december sixth nineteen twenty five (✓) \n",
      "2180095  96% ( 193m 3s)   0.269   |   0.00: 9 -> nine (✓) \n",
      "2190095  98% (196m 40s)   0.262   |   0.00: P. -> p (✓) \n",
      "Saved model to data/models/whole_gen_10_after_words_attention/2200000_(EncoderRNN/DecoderRNN)\n",
      "Accuracy: 87.43% (    8743/   10000)\n",
      "2200095 100% (201m 52s)   0.209   |   0.00: - -> to (✓) \n"
     ]
    }
   ],
   "source": [
    "train_iterations(n_iters=500000, print_every=10000, teacher_forcing_ratio=0, lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTML           => h t l m        || [45, 30, 32, 42, 0] \n",
      "                  i . j . good , \" speculations concerning the first ultraintelligent machine \" ( <SAMPLE> ) , advances in computers , vol\n",
      "2010           => twenty ten     || [5, 8, 44, 0] \n",
      "                  he coached skiing and taught chemistry at the berkshire school in massachusetts during the 2009 - <SAMPLE> school year .\n",
      "maemo.org      => m a e o o o o o o o o o o o o o o o o o || [32, 22, 28, 32, 25, 74, 25, 35, 53, 0] \n",
      "                  \" n 900 hardware usb host — <SAMPLE> wiki \" .\n",
      "Stafl          => s a t f l f l f l f l f l f l f l f l f || [17, 30, 22, 37, 42, 0] \n",
      "                  <SAMPLE> a . cervicography : a new method for cervical cancer detection .\n",
      "WFFI           => w f i          || [52, 37, 37, 31, 0] \n",
      "                  <SAMPLE> was previously operated under the callsign wyyb .\n",
      "OhioJCL.org    => o i c h i o o o o o o o o o o o o o o o || [25, 45, 31, 25, 60, 21, 42, 74, 25, 35, 53, 0] \n",
      "                  <SAMPLE> — june 2007 .\n",
      "1,241          => one thousand one hundred forty two || [9, 8, 5, 10, 41, 9, 0] \n",
      "                  there were <SAMPLE> housing units at an average density of 390 . 8 per square mile ( 150 . 7 / km² ) .\n",
      "TheRecordHerald.com => t h e r d e o c e o c e o c e o c e o c || [30, 45, 28, 35, 28, 21, 25, 35, 26, 45, 28, 35, 22, 42, 26, 74, 21, 25, 32, 0] \n",
      "                  \" dr francis achampong returns to penn state mont alto as chancellor , \" <SAMPLE> .\n",
      "Gipf           => g i f          || [53, 31, 24, 37, 0] \n",
      "                  it consists of the villages of <SAMPLE> and oberfrick .\n",
      "125AU          => one five a i dash || [9, 10, 6, 14, 385, 393, 0] \n",
      "                  \" voyager at <SAMPLE> \" .\n"
     ]
    }
   ],
   "source": [
    "print_local_wrong_predictions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2210095   2% (  3m 59s)   0.204   |   0.00: & -> and (✓) \n",
      "2220095   4% (  7m 47s)   0.283   |   0.01: May 6 -> may sixth (✓) \n",
      "2230095   6% ( 11m 55s)   0.230   |   0.18: FCC -> f c c (✓) \n",
      "2240095   8% ( 15m 46s)   0.232   |   0.00: 2001 -> two thousand one (✓) \n",
      "Saved model to data/models/whole_gen_10_after_words_attention/2250000_(EncoderRNN/DecoderRNN)\n",
      "Accuracy: 87.55% (    8755/   10000)\n",
      "2250095  10% (  21m 9s)   0.254   |   0.52: O.F.M. -> o f m (✓) \n",
      "2260095  12% (  25m 4s)   0.202   |   0.00: & -> and (✓) \n",
      "2270095  14% ( 28m 53s)   0.278   |   0.06: aka -> a k a (✓) \n",
      "2280095  16% ( 32m 58s)   0.226   |   0.00: Centres -> centers (✓) \n",
      "2290095  18% ( 36m 54s)   0.228   |   0.78: EWG.orgBaltimore -> e w dot r g o g (✗: [28, 52, 53, 74, 25, 35, 53, 36, 22, 42, 30, 31, 32, 25, 35, 28, 0]) \n",
      "Saved model to data/models/whole_gen_10_after_words_attention/2300000_(EncoderRNN/DecoderRNN)\n",
      "Accuracy: 87.08% (    8708/   10000)\n",
      "2300095  20% ( 42m 16s)   0.278   |   0.00: - -> to (✓) \n",
      "2310095  22% (  46m 8s)   0.275   |   0.00: Advertisers -> advertizers (✓) \n",
      "2320095  24% (  50m 0s)   0.250   |   0.00: 1 -> one (✓) \n",
      "2330095  26% ( 53m 59s)   0.251   |   0.01: R.F. -> r f (✓) \n",
      "2340095  28% ( 57m 54s)   0.214   |   0.01: NBA -> n b a (✓) \n",
      "Saved model to data/models/whole_gen_10_after_words_attention/2350000_(EncoderRNN/DecoderRNN)\n",
      "Accuracy: 87.84% (    8784/   10000)\n",
      "2350095  30% ( 63m 24s)   0.241   |   0.00: & -> and (✓) \n",
      "2360095  32% ( 67m 35s)   0.232   |   0.01: Tg -> t g (✓) \n",
      "2370095  34% ( 71m 41s)   0.223   |   0.00: pp -> p p (✓) \n",
      "2380095  36% ( 75m 48s)   0.210   |   0.00: CA -> c a (✓) \n",
      "2390095  38% ( 79m 51s)   0.232   |   0.00: dr -> doctor (✓) \n",
      "Saved model to data/models/whole_gen_10_after_words_attention/2400000_(EncoderRNN/DecoderRNN)\n",
      "Accuracy: 86.97% (    8697/   10000)\n",
      "2400095  40% ( 85m 16s)   0.273   |   0.20: MLB.com -> m l b dot c o m (✓) \n",
      "2410095  42% ( 89m 23s)   0.286   |   0.00: mt -> mount (✓) \n",
      "2420095  44% ( 93m 24s)   0.277   |   0.04: 2013 -> twenty thirteen (✓) \n",
      "2430095  46% ( 97m 30s)   0.216   |   6.16: aliʻi -> b (✗: [807, 0]) \n",
      "2440095  48% (101m 39s)   0.260   |   0.00: pp -> p p (✓) \n",
      "Saved model to data/models/whole_gen_10_after_words_attention/2450000_(EncoderRNN/DecoderRNN)\n",
      "Accuracy: 87.52% (    8752/   10000)\n",
      "2450095  50% (107m 12s)   0.247   |   0.00: H. -> h (✓) \n",
      "2460095  52% (111m 26s)   0.246   |   0.00: 2006 -> two thousand six (✓) \n",
      "2470095  54% (115m 28s)   0.227   |   0.01: Bd -> b d (✓) \n",
      "2480095  56% (119m 49s)   0.246   |   0.01: 2012 -> twenty twelve (✓) \n",
      "2490095  58% ( 124m 9s)   0.206   |   0.00: & -> and (✓) \n",
      "Saved model to data/models/whole_gen_10_after_words_attention/2500000_(EncoderRNN/DecoderRNN)\n",
      "Accuracy: 86.48% (    8648/   10000)\n",
      "2500095  60% (129m 49s)   0.267   |   0.46: PIMS -> p i m s s (✗: [24, 31, 32, 17, 0]) \n",
      "2510095  62% (134m 30s)   0.273   |   0.00: metres -> meters (✓) \n",
      "2520095  64% (138m 42s)   0.231   |   2.32: foot-national.com -> f o t a a a a a a a a a a a a a a a a a a (✗: [37, 25, 25, 30, 26, 22, 17, 45, 29, 22, 30, 31, 25, 29, 22, 42, 74, 21, 25, 32, 0]) \n",
      "2530095  66% ( 143m 8s)   0.275   |   0.51: FIDE's -> f i d (✗: [37, 31, 26, 173, 0]) \n",
      "2540095  68% (147m 41s)   0.216   |   0.00: U.N. -> u n (✓) \n",
      "Saved model to data/models/whole_gen_10_after_words_attention/2550000_(EncoderRNN/DecoderRNN)\n",
      "Accuracy: 87.01% (    8701/   10000)\n",
      "2550095  70% (153m 25s)   0.230   |   0.00: & -> and (✓) \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-97-84861d645bfb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_iterations\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_iters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m500000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprint_every\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mteacher_forcing_ratio\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0001\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-36-fc5438e8eb84>\u001b[0m in \u001b[0;36mtrain_iterations\u001b[0;34m(n_iters, lr, teacher_forcing_ratio, print_every, plot_every)\u001b[0m\n\u001b[1;32m     24\u001b[0m                              \u001b[0mencoder_optimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoder_optimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder_optimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdecoder_optimizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m                              \u001b[0mloss_function\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNLLLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_teacher_forcing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_teacher_forcing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m                              max_length=40 )\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0mcurrent_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-35-f95435b96447>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(s_bef, s_aft, s_sentence, encoder_optimizer, decoder_optimizer, loss_function, use_teacher_forcing, max_length)\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;31m#target_arr = after_sentence_to_word_indexes(s_aft, include_eos=True)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m     \u001b[0mencoder_optimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m     \u001b[0mdecoder_optimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py3_pytorch_2/lib/python3.6/site-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mzero_grad\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    138\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvolatile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 140\u001b[0;31m                         \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    141\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m                         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_iterations(n_iters=500000, print_every=10000, teacher_forcing_ratio=0, lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print_local_wrong_predictions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_iterations(n_iters=500000, print_every=10000, teacher_forcing_ratio=0, lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print_local_wrong_predictions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_iterations(n_iters=500000, print_every=10000, teacher_forcing_ratio=0, lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print_local_wrong_predictions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input:   Arabicalistapart.com\n",
      "output:  ['a', 'r', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a']\n",
      "target:    a r a b i c a l i s t a p a r t dot c o m\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAwoAAAFpCAYAAAA8x9/8AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSZKkNf4/XKI9cuaASaQAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fd7a1e03d68>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def debug_show_attention(input_sentence, output_words, attentions):\n",
    "    # Set up figure with colorbar\n",
    "    fig = plt.figure(figsize=(15,6))\n",
    "    ax = fig.add_subplot(111)\n",
    "    #cax = ax.matshow(attentions.numpy(), cmap='bone')\n",
    "    cax = ax.matshow(attentions, cmap='bone')\n",
    "    fig.colorbar(cax)\n",
    "    # Set up axes\n",
    "    #ax.set_xticklabels([''] + input_sentence.split(' ') + ['<EOS>'], rotation=90)\n",
    "    ax.set_xticklabels([''] + input_sentence + ['<EOS>'], rotation=90)\n",
    "    ax.set_yticklabels([''] + output_words)\n",
    "\n",
    "    # Show label at every tick\n",
    "    ax.xaxis.set_major_locator(matplotlib.ticker.MultipleLocator(1))\n",
    "    ax.yaxis.set_major_locator(matplotlib.ticker.MultipleLocator(1))\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "def debug_eval_sample_show_attention():\n",
    "    output, decoded_output, decoder_attns_arr, sample = test_model_single_sample(None, return_more=True)\n",
    "    print('input:  ', sample[0])\n",
    "    print('output: ', decoded_output)\n",
    "    print('target:   ', ' '.join([words_after_common[w] for w in sample[1][:-1]]))\n",
    "\n",
    "    attns = np.array([arr.data[0].cpu().numpy() for arr in decoder_attns_arr])\n",
    "\n",
    "    debug_show_attention(list(sample[0]), decoded_output, attns)\n",
    "    #plt.matshow(attns)\n",
    "    \n",
    "debug_eval_sample_show_attention()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tmp = [r/sum(r) for r in attns]\n",
    "plt.matshow(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.argmax(attns, 1)\n",
    "[attns[k,v] for k, v in enumerate(np.argmax(attns, 1))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:py3_pytorch_2]",
   "language": "python",
   "name": "conda-env-py3_pytorch_2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
