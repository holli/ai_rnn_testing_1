{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import importlib\n",
    "from pytorch_utils_oh_2 import *\n",
    "import IPython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MODEL_SAVE_PATH = 'electronic_gen_6_testing_attn'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pytorch utils oh: pytorch_utils_oh_2.py\n",
      "Pytorch: 0.2.0_4\n"
     ]
    }
   ],
   "source": [
    "import pytorch_utils_oh_2; importlib.reload(pytorch_utils_oh_2); from pytorch_utils_oh_2 import *;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# all_data = pickle.load(open(\"data/en_train_fixed_4_sentences.pkl\", \"rb\" ))\n",
    "all_data = pickle.load(open(\"data/en_train_fixed_5_manual.pkl\", \"rb\" ))\n",
    "# all_data_sentence_index = all_data.set_index('sentence_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>token_id</th>\n",
       "      <th>class</th>\n",
       "      <th>before</th>\n",
       "      <th>after</th>\n",
       "      <th>class_org</th>\n",
       "      <th>a_word_ind</th>\n",
       "      <th>sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6474792</th>\n",
       "      <td>492378</td>\n",
       "      <td>1</td>\n",
       "      <td>LETTERS</td>\n",
       "      <td>Oper</td>\n",
       "      <td>o p e r</td>\n",
       "      <td>LETTERS</td>\n",
       "      <td>[25, 24, 28, 35, 0]</td>\n",
       "      <td>stiftung &lt;SAMPLE&gt; in berlin .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6166880</th>\n",
       "      <td>469644</td>\n",
       "      <td>1</td>\n",
       "      <td>LETTERS</td>\n",
       "      <td>Hver</td>\n",
       "      <td>h v e r</td>\n",
       "      <td>LETTERS</td>\n",
       "      <td>[45, 54, 28, 35, 0]</td>\n",
       "      <td>\" &lt;SAMPLE&gt; er samraethisaldur a islandi ? \"</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         sentence_id  token_id    class before    after class_org  \\\n",
       "6474792       492378         1  LETTERS   Oper  o p e r   LETTERS   \n",
       "6166880       469644         1  LETTERS   Hver  h v e r   LETTERS   \n",
       "\n",
       "                  a_word_ind                                     sentence  \n",
       "6474792  [25, 24, 28, 35, 0]                stiftung <SAMPLE> in berlin .  \n",
       "6166880  [45, 54, 28, 35, 0]  \" <SAMPLE> er samraethisaldur a islandi ? \"  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "32992"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data = all_data[(all_data['class'] == 'LETTERS') | (all_data['class'] == 'ELECTRONIC')]\n",
    "all_data = all_data[all_data['after'].str.len() > 5]\n",
    "all_data.sample(2)\n",
    "len(all_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sample_data = all_data.copy()\n",
    "sample_data = sample_data.reset_index(drop=True)\n",
    "del(all_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sample_data = all_data.copy()\n",
    "sample_data = sample_data[sample_data['class'] == 'ELECTRONIC']\n",
    "print(\"Data rows: {},  (dropped rows: {})\".format(len(sample_data), len(all_data)-len(sample_data)))\n",
    "sample_data = sample_data.reset_index(drop=True)\n",
    "del(all_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ELECTRONIC', 'LETTERS']\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "categories_all = sorted(sample_data[\"class\"].unique())\n",
    "print(categories_all)\n",
    "print(len(categories_all))\n",
    "categories_index = dict((c, i) for i, c in enumerate(categories_all))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>token_id</th>\n",
       "      <th>class</th>\n",
       "      <th>before</th>\n",
       "      <th>after</th>\n",
       "      <th>class_org</th>\n",
       "      <th>a_word_ind</th>\n",
       "      <th>sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>27118</th>\n",
       "      <td>612098</td>\n",
       "      <td>4</td>\n",
       "      <td>LETTERS</td>\n",
       "      <td>A&amp;M</td>\n",
       "      <td>a and m</td>\n",
       "      <td>LETTERS</td>\n",
       "      <td>[22, 55, 32, 0]</td>\n",
       "      <td>college station : texas &lt;SAMPLE&gt; university pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4646</th>\n",
       "      <td>112672</td>\n",
       "      <td>3</td>\n",
       "      <td>LETTERS</td>\n",
       "      <td>Ngay</td>\n",
       "      <td>n g a y</td>\n",
       "      <td>LETTERS</td>\n",
       "      <td>[29, 53, 22, 86, 0]</td>\n",
       "      <td>vi trai tim &lt;SAMPLE&gt; tho thanh quynh 3 .</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       sentence_id  token_id    class before    after class_org  \\\n",
       "27118       612098         4  LETTERS    A&M  a and m   LETTERS   \n",
       "4646        112672         3  LETTERS   Ngay  n g a y   LETTERS   \n",
       "\n",
       "                a_word_ind                                           sentence  \n",
       "27118      [22, 55, 32, 0]  college station : texas <SAMPLE> university pr...  \n",
       "4646   [29, 53, 22, 86, 0]           vi trai tim <SAMPLE> tho thanh quynh 3 .  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_data.sample(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utils stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<SOS><EOS>☒ !\"#$%&'(),-./0123456789:;ABCDEFGHIJKLMNOPQRSTUVWXYZ_abcdefghijklmnopqrstuvwxyz~£¥ª²³µº¼½¾éɒʻˈΩμ—€⅓⅔⅛\n"
     ]
    }
   ],
   "source": [
    "chars_normal, chars_normal_index = load_characters_pkl('data/en_features/chars_normal.pkl')\n",
    "print(''.join(chars_normal))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wv_vecs, wv_words, wv_idx = load_glove('/home/ohu/koodi/data/glove_wordvec/glove.6B.50d.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "arr = list(sample_data['after'])\n",
    "arr = [s.split(' ') for s in arr]\n",
    "words_after = [EOS_TOKEN, SOS_TOKEN, UNKNOWN_WORD_TOKEN, NUMBER_WORD_TOKEN, SAMPLE_WORD_TOKEN]\n",
    "words_after = words_after + sorted(list(set(np.concatenate(arr))))\n",
    "words_after_index = dict((c, i) for i, c in enumerate(words_after))\n",
    "words_after_by_length = sorted(words_after, key=len, reverse=True)\n",
    "words_after_regex = re.compile('(' + ')|('.join(words_after_by_length) + ')')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "152"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(words_after)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "chars_after = [EOS_TOKEN, SOS_TOKEN] + sorted(list(set(list(''.join(list(sample_data['after']))))))\n",
    "chars_after_index = dict((c, i) for i, c in enumerate(chars_after))\n",
    "''.join(chars_after)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[32, 26, 92, 19, 0]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "['dot', 'd', 'o', 'c', '<EOS>']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def after_sentence_to_word_indexes(sentence, include_eos=True):\n",
    "    reg = re.finditer(words_after_regex, sentence)\n",
    "    arr = [words_after_index[s[0]] for s in reg]\n",
    "    if include_eos:\n",
    "        arr += [words_after_index[EOS_TOKEN]]\n",
    "    return arr\n",
    "tmp = after_sentence_to_word_indexes('dot d o c')\n",
    "tmp\n",
    "[words_after[t] for t in tmp]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 152])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sos_tensor = torch.zeros(1, 1, len(words_after_index))\n",
    "sos_tensor[0, 0, words_after_index[SOS_TOKEN]] = 1\n",
    "sos_tensor.size()\n",
    "#del(onehot_sos)\n",
    "\n",
    "# sos_tensor = torch.LongTensor([words_after_index[SOS_TOKEN]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "balanced_data_length = len(sample_data)\n",
    "def get_random_sample(return_last = False):\n",
    "    global sample_row_last\n",
    "    sample_row = balanced_data_last_sample = sample_data.iloc[random.randint(1, balanced_data_length-1)]\n",
    "    if return_last:\n",
    "        sample_row = sample_row_last\n",
    "    else:\n",
    "        sample_row_last = sample_row\n",
    "    \n",
    "    a_words_ind = after_sentence_to_word_indexes(sample_row['after'], include_eos=True)\n",
    "    return sample_row['before'], a_words_ind, sample_row['class'], sample_row['sentence'].split(' ')\n",
    "            \n",
    "def tmp():\n",
    "    s_bef, s_aft, s_class, s_sentence = get_random_sample()\n",
    "    s_aft_str = ' '.join([words_after[i] for i in s_aft])\n",
    "    print(s_class, s_bef, '->', s_aft_str, s_aft)\n",
    "    print(string_to_tensor(s_bef, chars_normal_index).shape)\n",
    "    \n",
    "    print(s_sentence)\n",
    "    words_t = words_to_word_vectors_tensor(s_sentence, wv_vecs, wv_idx)\n",
    "    print(words_t.size())\n",
    "\n",
    "tmp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%timeit\n",
    "get_random_sample()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "use_cuda = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MAX_ATTENTION_LENGTH = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "498"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>token_id</th>\n",
       "      <th>class</th>\n",
       "      <th>before</th>\n",
       "      <th>after</th>\n",
       "      <th>class_org</th>\n",
       "      <th>a_word_ind</th>\n",
       "      <th>sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>27339</th>\n",
       "      <td>616779</td>\n",
       "      <td>7</td>\n",
       "      <td>ELECTRONIC</td>\n",
       "      <td>http://www.upi.com/Audio/Year_in_Review/Events...</td>\n",
       "      <td>h t t p colon slash slash w w w dot u p i dot ...</td>\n",
       "      <td>ELECTRONIC</td>\n",
       "      <td>[45, 30, 30, 24, 129, 101, 101, 52, 52, 52, 74...</td>\n",
       "      <td>isbn 0 - 471 - 13340 - x . upi . com , year in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5497</th>\n",
       "      <td>133089</td>\n",
       "      <td>8</td>\n",
       "      <td>ELECTRONIC</td>\n",
       "      <td>http://www.natchezontheriver.com/news/2008/oct...</td>\n",
       "      <td>h t t p colon slash slash w w w dot n a t c h ...</td>\n",
       "      <td>ELECTRONIC</td>\n",
       "      <td>[45, 30, 30, 24, 129, 101, 101, 52, 52, 52, 74...</td>\n",
       "      <td>natchez on the river staff : dunleith , &lt;SAMPL...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       sentence_id  token_id       class  \\\n",
       "27339       616779         7  ELECTRONIC   \n",
       "5497        133089         8  ELECTRONIC   \n",
       "\n",
       "                                                  before  \\\n",
       "27339  http://www.upi.com/Audio/Year_in_Review/Events...   \n",
       "5497   http://www.natchezontheriver.com/news/2008/oct...   \n",
       "\n",
       "                                                   after   class_org  \\\n",
       "27339  h t t p colon slash slash w w w dot u p i dot ...  ELECTRONIC   \n",
       "5497   h t t p colon slash slash w w w dot n a t c h ...  ELECTRONIC   \n",
       "\n",
       "                                              a_word_ind  \\\n",
       "27339  [45, 30, 30, 24, 129, 101, 101, 52, 52, 52, 74...   \n",
       "5497   [45, 30, 30, 24, 129, 101, 101, 52, 52, 52, 74...   \n",
       "\n",
       "                                                sentence  \n",
       "27339  isbn 0 - 471 - 13340 - x . upi . com , year in...  \n",
       "5497   natchez on the river staff : dunleith , <SAMPL...  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp = sample_data[sample_data['before'].str.len()>MAX_ATTENTION_LENGTH]\n",
    "len(tmp)\n",
    "tmp.sample(2)\n",
    "# tmp[~tmp['before'].str.contains('/')].sample(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EncoderRNN (\n",
       "  (rnn_words): GRU(50, 64, batch_first=True, bidirectional=True)\n",
       "  (rnn_chars): GRU(104, 128, batch_first=True, bidirectional=True)\n",
       ")"
      ]
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, words_input_size, chars_input_size, words_hidden_size, chars_hidden_size,\n",
    "                 words_layers=1, chars_layers=1):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        \n",
    "        self.words_layers = words_layers\n",
    "        self.chars_layers = chars_layers\n",
    "        self.words_hidden_size = words_hidden_size\n",
    "        self.chars_hidden_size = chars_hidden_size\n",
    "        self.hidden_size = words_hidden_size + chars_hidden_size\n",
    "\n",
    "        self.rnn_words = nn.GRU(words_input_size, words_hidden_size // 2, words_layers,\n",
    "                                 batch_first=True, bidirectional=True)\n",
    "\n",
    "        self.rnn_chars = nn.GRU(chars_input_size, chars_hidden_size // 2, chars_layers,\n",
    "                                 batch_first=True, bidirectional=True)\n",
    "        \n",
    "    def forward(self, word_vectors, string_tensor, hidden = None, init_hidden = True):\n",
    "        if init_hidden:\n",
    "            hidden_words, hidden_chars = self.init_hidden()\n",
    "        \n",
    "        all_outputs_words, hidden_words = self.rnn_words(word_vectors, hidden_words)\n",
    "        output_words = hidden_words.view(1, -1)\n",
    "        \n",
    "        all_outputs_chars, hidden_chars = self.rnn_chars(string_tensor, hidden_chars)\n",
    "        output_chars = hidden_chars.view(1, -1)\n",
    "        \n",
    "        #hidden_states_cat = Variable(torch.zeros(MAX_ATTENTION_LENGTH, self.hidden_size)).cuda()\n",
    "        #for ei in range(min(MAX_ATTENTION_LENGTH, len(string_tensor[0]))):\n",
    "        #    hidden_states_cat[ei] = torch.cat((output_words, all_outputs_chars[0, ei].view(1,-1)), 1)\n",
    "\n",
    "        all_outputs_chars_padded = Variable(torch.zeros(MAX_ATTENTION_LENGTH, self.chars_hidden_size)).cuda()\n",
    "        att_length = min(len(all_outputs_chars[0]), MAX_ATTENTION_LENGTH-1)\n",
    "        all_outputs_chars_padded[0:att_length] = all_outputs_chars[0][0:att_length]\n",
    "        \n",
    "        output = torch.cat((output_words, output_chars), 1)\n",
    "\n",
    "        #output = torch.cat((output_words, output_chars), 1)\n",
    "        \n",
    "        #return output, all_outputs_chars\n",
    "        return output, all_outputs_chars_padded\n",
    "\n",
    "    def init_hidden(self):\n",
    "        var1 = Variable(torch.zeros(2 * self.words_layers, 1, self.words_hidden_size // 2))\n",
    "        var2 = Variable(torch.zeros(2 * self.chars_layers, 1, self.chars_hidden_size // 2))\n",
    "        \n",
    "        var1 = var1.cuda(); var2 = var2.cuda()\n",
    "        return (var1, var2)\n",
    "    \n",
    "    \n",
    "encoder_rnn = EncoderRNN(words_input_size=wv_vecs.shape[-1], chars_input_size=len(chars_normal),\n",
    "                         words_hidden_size=128, chars_hidden_size=256,\n",
    "                         words_layers=1, chars_layers=1).cuda()\n",
    "encoder_rnn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ISBN\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'ISBN'"
      ]
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 384])"
      ]
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([50, 256])"
      ]
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def test_encoder_single_sample():\n",
    "    s_bef, s_aft, s_class, s_sentence = get_random_sample()\n",
    "    #s_bef, s_aft, s_class, s_sentence = get_random_sample(True)\n",
    "    print(s_bef)\n",
    "    \n",
    "    words_t = Variable(words_to_word_vectors_tensor(s_sentence, wv_vecs, wv_idx)).cuda()\n",
    "    \n",
    "    string_t = string_to_tensor(s_bef, chars_normal_index)\n",
    "    string_t = Variable(string_t).cuda()\n",
    "    \n",
    "    return encoder_rnn(words_t, string_t), s_bef\n",
    "    \n",
    "(tmp_encoder_output, tmp_encoder_outputs), tmp = test_encoder_single_sample()\n",
    "tmp\n",
    "tmp_encoder_output.size()\n",
    "tmp_encoder_outputs.size()\n",
    "#torch.eq(encoder_output, encoder_outputs[len(tmp)]).data.all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecoderRNN (\n",
       "  (emb_lin): Linear (152 -> 384)\n",
       "  (dropout): Dropout (p = 0.1)\n",
       "  (attn): Linear (768 -> 50)\n",
       "  (attn_combine): Linear (640 -> 384)\n",
       "  (rnn): GRU(384, 384, batch_first=True)\n",
       "  (lin_out): Linear (384 -> 152)\n",
       ")"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[torch.Size([1, 152]), torch.Size([1, 384]), torch.Size([1, 50])]"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class DecoderRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, chars_encoded_size,\n",
    "                 n_layers=1, dropout_p=0.1, max_length=MAX_ATTENTION_LENGTH):\n",
    "        super(DecoderRNN, self).__init__()\n",
    "        \n",
    "        self.n_layers = n_layers\n",
    "        self.hidden_size = hidden_size\n",
    "        self.max_length = max_length\n",
    "        \n",
    "        self.emb_lin = nn.Linear(input_size, hidden_size)\n",
    "        self.dropout = nn.Dropout(dropout_p)\n",
    "                \n",
    "        self.attn = nn.Linear(self.hidden_size+self.hidden_size, self.max_length)\n",
    "        self.attn_combine = nn.Linear(self.hidden_size+chars_encoded_size, self.hidden_size)\n",
    "        \n",
    "        self.rnn = nn.GRU(hidden_size, hidden_size, n_layers, batch_first=True, bidirectional=False)\n",
    "        self.lin_out = nn.Linear(hidden_size, input_size)\n",
    "\n",
    "    def forward(self, last_input, hidden, encoder_outputs):\n",
    "        embedded = self.emb_lin(last_input).view(1, 1, -1)\n",
    "        embedded = self.dropout(embedded)\n",
    "        embedded = embedded[0]\n",
    "                \n",
    "        attn_weights = F.softmax(self.attn(torch.cat((embedded, hidden), 1)))\n",
    "        attn_applied = torch.bmm(attn_weights.unsqueeze(0), encoder_outputs.unsqueeze(0))\n",
    "        #return embedded, attn_applied\n",
    "        rnn_input = torch.cat((embedded, attn_applied[0]), 1)\n",
    "        \n",
    "        rnn_input = self.attn_combine(rnn_input).unsqueeze(0)\n",
    "        \n",
    "        rnn_input = F.relu(rnn_input)\n",
    "    \n",
    "        \n",
    "        output, hidden = self.rnn(rnn_input, hidden.unsqueeze(0))\n",
    "        output = F.log_softmax(self.lin_out(output[0]))\n",
    "        \n",
    "        return output, hidden[0], attn_weights\n",
    "    \n",
    "    def init_rest_hidden(self, input_var):\n",
    "        if self.n_layers > 1:\n",
    "            hid_var = Variable(torch.zeros(self.n_layers - 1, 1, self.hidden_size)).cuda()\n",
    "            res = torch.cat((input_var, hid_var), 0)\n",
    "            return res\n",
    "        else:\n",
    "            return input_var\n",
    "        \n",
    "\n",
    "decoder_rnn = DecoderRNN(input_size=len(words_after), hidden_size=tmp_encoder_output.size()[1],\n",
    "                         chars_encoded_size=tmp_encoder_outputs.size()[1], n_layers=1)\n",
    "decoder_rnn = decoder_rnn.cuda()\n",
    "decoder_rnn\n",
    "\n",
    "tmp = decoder_rnn(Variable(sos_tensor).cuda(), tmp_encoder_output, tmp_encoder_outputs)\n",
    "#tmp\n",
    "[v.size() for v in tmp]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      " 132\n",
      "[torch.cuda.LongTensor of size 1x1 (GPU 0)]\n",
      "\n",
      "twerkit\n"
     ]
    }
   ],
   "source": [
    "print(tmp[0].topk(1)[1])\n",
    "print(words_after[tmp[0].topk(1)[1].data[0][0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training etc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('a o s l o',\n",
       " 'a o s l o',\n",
       " 'a o s l o',\n",
       " ('AOSLO',\n",
       "  [5, 92, 113, 76, 92, 0],\n",
       "  'LETTERS',\n",
       "  ['<SAMPLE>',\n",
       "   'compares',\n",
       "   'favorably',\n",
       "   'with',\n",
       "   'other',\n",
       "   'retinal',\n",
       "   'imaging',\n",
       "   'techniques',\n",
       "   'as',\n",
       "   'well',\n",
       "   '.']))"
      ]
     },
     "execution_count": 376,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def test_model_single_sample(model=None, return_more=False, sample=False):\n",
    "    decoder_rnn.eval()\n",
    "    encoder_rnn.eval()\n",
    "    \n",
    "    if not sample:\n",
    "        sample = get_random_sample()\n",
    "    s_bef, s_aft, s_class, s_sentence = sample\n",
    "        \n",
    "    words_t = Variable(words_to_word_vectors_tensor(s_sentence, wv_vecs, wv_idx)).cuda()\n",
    "    \n",
    "    string_t = string_to_tensor(s_bef, chars_normal_index)\n",
    "    string_t = Variable(string_t).cuda()\n",
    "    \n",
    "    encoder_output, encoder_outputs = encoder_rnn(words_t, string_t)\n",
    "\n",
    "    decoder_input = Variable(sos_tensor).cuda()\n",
    "    decoder_hidden = encoder_output\n",
    "\n",
    "    decoded_output = []\n",
    "    decoder_attns_arr = []\n",
    "    max_length = 30\n",
    "    for _ in range(max_length):\n",
    "        decoder_output, decoder_hidden, decoder_attns = decoder_rnn(decoder_input, decoder_hidden, encoder_outputs)\n",
    "        decoder_attns_arr.append(decoder_attns)\n",
    "        #return decoder_output\n",
    "\n",
    "        topv, topi = decoder_output.data.topk(1)\n",
    "        word_index = topi[0][0]\n",
    "        word = words_after[word_index] # Use own prediction as next input\n",
    "                \n",
    "        if word == EOS_TOKEN:\n",
    "            break\n",
    "\n",
    "        decoded_output.append(word)\n",
    "        \n",
    "        decoder_input = torch.zeros(1, 1, len(words_after_index))\n",
    "        decoder_input[0, 0, word_index] = 1\n",
    "        decoder_input = Variable(decoder_input).cuda()\n",
    "    \n",
    "    output = ' '.join(decoded_output)\n",
    "    sample_target = ' '.join([words_after[w] for w in s_aft][:-1])\n",
    "    \n",
    "    decoder_rnn.train()\n",
    "    encoder_rnn.train()\n",
    "    \n",
    "    if return_more:\n",
    "        return output, decoded_output, decoder_attns_arr, sample\n",
    "    \n",
    "    return output, output, sample_target, sample\n",
    "    \n",
    "tmp = test_model_single_sample()\n",
    "tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ESPN           => w w w one one one one one one one one one one one one one one one one one one one one one one one one one one one || [33, 113, 100, 87, 0] \n",
      "                  ['<SAMPLE>', 'fc', '(', 'entertainment', 'and', 'sports', 'programming', 'network', '(', 'espn', ')', ')', '.']\n",
      "NORAD          => w w one one one one one one one one one one one one one one one one one one one one one one one one one one one one || [87, 92, 109, 5, 26, 0] \n",
      "                  ['\"', 'jb', '-', '3', 'c', 'satellite', 'details', '2004', '-', '044', 'a', '<SAMPLE>', '28470', '\"', '.']\n"
     ]
    }
   ],
   "source": [
    "def print_local_wrong_predictions(max_results=10):\n",
    "    arr = get_some_wrong_predictions(None, test_model_single_sample, max_iterations=10000, max_results=max_results)\n",
    "    for sample, predict, output in arr:\n",
    "        s_bef, s_aft, s_class, s_sentence = sample\n",
    "        print(\"{:<14} => {:<14} || {} \\n{:>17} {}\".format(s_bef, predict, s_aft, '', s_sentence, ))\n",
    "print_local_wrong_predictions(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.00% (       0/     100)\n",
      "CPU times: user 3.3 s, sys: 28 ms, total: 3.32 s\n",
      "Wall time: 3.32 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 287,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "test_model_accuracy(decoder_rnn, test_model_single_sample, n_sample=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train(s_bef, s_aft, s_sentence, encoder_optimizer, decoder_optimizer, loss_function,\n",
    "          use_teacher_forcing, max_length=20):\n",
    "    \n",
    "    words_t = Variable(words_to_word_vectors_tensor(s_sentence, wv_vecs, wv_idx)).cuda()\n",
    "    \n",
    "    string_t = string_to_tensor(s_bef, chars_normal_index)\n",
    "    string_t = Variable(string_t).cuda()\n",
    "    \n",
    "    encoder_output, encoder_outputs = encoder_rnn(words_t, string_t)\n",
    "    \n",
    "   \n",
    "    decoder_hidden = encoder_output\n",
    "    decoder_input = Variable(sos_tensor).cuda()\n",
    "    \n",
    "    ###\n",
    "    target_arr = s_aft\n",
    "    #target_arr = after_sentence_to_word_indexes(s_aft, include_eos=True)\n",
    "    \n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "    loss = 0\n",
    "    \n",
    "    decoded_output = []\n",
    "    for i in range(len(target_arr)):\n",
    "        decoder_output, decoder_hidden, decoder_attns = decoder_rnn(decoder_input, decoder_hidden, encoder_outputs)\n",
    "\n",
    "        #decoder_target_i = chars_after_index[target_arr[i]]\n",
    "        decoder_target_i = target_arr[i]\n",
    "        decoder_target_i = Variable(torch.LongTensor([decoder_target_i])).cuda()\n",
    "        loss += loss_function(decoder_output, decoder_target_i)\n",
    "        \n",
    "        topv, topi = decoder_output.data.topk(1)\n",
    "        word_index = topi[0][0]\n",
    "        word = words_after[word_index] # Use own prediction as next input\n",
    "        decoded_output.append(word)\n",
    "        \n",
    "        if use_teacher_forcing:\n",
    "            word_index = target_arr[i] # replace input with right target\n",
    "        else:\n",
    "            # use output normally as input \n",
    "            if word == EOS_TOKEN:\n",
    "                break\n",
    "                \n",
    "        decoder_input = torch.zeros(1, 1, len(words_after_index))\n",
    "        decoder_input[0, 0, word_index] = 1\n",
    "        decoder_input = Variable(decoder_input).cuda()\n",
    "        #decoder_input = Variable(torch.LongTensor([word_index])).cuda()\n",
    "        \n",
    "    if decoded_output[-1] == EOS_TOKEN:\n",
    "        decoded_output = decoded_output[:-1]\n",
    "        \n",
    "    loss.backward()\n",
    "\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "\n",
    "    return ' '.join(decoded_output), (loss.data[0] / len(target_arr))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_iterations(n_iters=100000, lr=0.001, teacher_forcing_ratio=0.5,\n",
    "                     print_every=10000, plot_every=1000):\n",
    "\n",
    "    start = time.time()\n",
    "    \n",
    "    decoder_rnn.train()\n",
    "    encoder_rnn.train()\n",
    "\n",
    "    current_loss = 0\n",
    "    current_loss_iter = 0\n",
    "\n",
    "    encoder_optimizer = torch.optim.Adam(encoder_rnn.parameters(), lr=lr)\n",
    "    decoder_optimizer = torch.optim.Adam(decoder_rnn.parameters(), lr=lr)\n",
    "    loss_function = nn.NLLLoss()\n",
    "    \n",
    "    for iteration in range(1, n_iters + 1):\n",
    "        model_training.iterations += 1\n",
    "        \n",
    "        use_teacher_forcing = random.random() < teacher_forcing_ratio\n",
    "        \n",
    "        s_bef, s_aft, s_class, s_sentence = get_random_sample()\n",
    "        \n",
    "        result, loss = train(s_bef=s_bef, s_aft=s_aft, s_sentence=s_sentence,\n",
    "                             encoder_optimizer=encoder_optimizer, decoder_optimizer=decoder_optimizer,\n",
    "                             loss_function=nn.NLLLoss(), use_teacher_forcing=use_teacher_forcing,\n",
    "                             max_length=40 )\n",
    "        \n",
    "        current_loss += loss\n",
    "        current_loss_iter += 1\n",
    "\n",
    "        # Print iter number, loss, name and guess\n",
    "        if iteration % print_every == 0:\n",
    "            teacher_forcing_str = \"\"\n",
    "            if use_teacher_forcing:\n",
    "                teacher_forcing_str = \"(forcing)\"\n",
    "            s_aft_sentence = ' '.join([words_after[w] for w in s_aft][:-1])\n",
    "            correct = '✓' if result == s_aft_sentence else \"✗: {}\".format(s_aft_sentence)\n",
    "            \n",
    "            print(\"{:>6d} {:>4.0%} ({:>8}) {:>7.3f}   | {:>6.2f}: {} -> {} ({}) {}\".format(\n",
    "                      model_training.iterations, iteration/n_iters, time_since(start),\n",
    "                      current_loss/current_loss_iter, loss,\n",
    "                      s_bef, result, correct, teacher_forcing_str))\n",
    "\n",
    "        # Add current loss avg to list of losses\n",
    "        if iteration % plot_every == 0:\n",
    "            model_training.losses.append(current_loss / plot_every)\n",
    "            model_training.learning_rates.append(lr)\n",
    "            current_loss = 0\n",
    "            current_loss_iter = 0\n",
    "            \n",
    "        if model_training.iterations % 50000 == 0 or model_training.iterations == 10:\n",
    "            model_training.save_models()\n",
    "            acc = test_model_accuracy(encoder_rnn, test_model_single_sample)\n",
    "            model_training.accuracy.append(acc)\n",
    "    \n",
    "    # test_model_accuracy(model, n_sample=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Save path: data/models/electronic_gen_6_testing_attn\n"
     ]
    }
   ],
   "source": [
    "model_training = ModelTraining(MODEL_SAVE_PATH, [encoder_rnn, decoder_rnn])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    19  18% (   0m 0s)   4.053   |   0.25: http://www.flightglobal.com/pdfarchive/view/1953/1953%20-%201102.html -> s s s s s (✗: h t t p colon slash slash w w w dot f l i g h t g l o b a l dot com slash p d f a r c h i v e slash v i e w slash n i n e t e e n f i f t y t h r e e slash n i n e t e e n f i f t y t h r e e p e r c e n t t w e n t y dash p e r c e n t t w o o o n e o n e o t w o dot h t m l) \n",
      "    28  36% (   0m 0s)   4.395   |   4.89: é -> s s s (✗: e acute) \n",
      "    37  54% (   0m 0s)   4.164   |   0.09: www.avalancheinc.co.uk/finalbio.htmlhttp://www.doommantia.com/2010/05/interview-with-andy-swan-from-iroha.htmlStrong -> s s (✗: w w w dot a v a l a n c h e i n c dot c o dot u k s l a s h f i n a l b i o dot h t m l h t t p c o l o n s l a s h s l a s h w w w dot d o o m m a n t i a dot c o m s l a s h t w e n t y t e n s l a s h o f i v e s l a s h i n t e r v i e w d a s h w i t h d a s h a n d y d a s h s w a n d a s h f r o m d a s h i r o h a dot h t m l s t r o n g) \n",
      "    46  72% (   0m 0s)   4.147   |   4.68: UCSB -> s s <EOS> <EOS> (✗: u c s b) (forcing)\n",
      "    55  90% (   0m 0s)   4.046   |   4.48: ISBN -> s <EOS> <EOS> <EOS> (✗: i s b n) (forcing)\n"
     ]
    }
   ],
   "source": [
    "train_iterations(n_iters=50, print_every=9, lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iterations(n_iters=(1000-model_training.iterations), print_every=500, lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 11000  11% (  4m 51s)   0.172   |   0.00: CEOs -> c e o's (✓) \n",
      " 21000  22% (  9m 36s)   0.240   |   0.01: APA's -> a p a's (✓) \n",
      " 31000  33% ( 14m 36s)   0.293   |   0.01: é -> e acute (✓) \n",
      " 41000  44% ( 19m 40s)   0.307   |   0.01: ALTn -> a l t n (✓) \n",
      "Saved model to data/models/electronic_gen_6_testing_attn/50000_(EncoderRNN/DecoderRNN)\n",
      "Accuracy: 84.02% (    8402/   10000)\n",
      " 51000  56% ( 26m 15s)   0.259   |   2.99: Pro-Football-Reference.com -> p r o d a s h a a s s a a s a a a s a i a a h a d a a a s s e e a (✗: p r o d a s h f o o t b a l l d a s h r e f e r e n c e dot c o m) (forcing)\n",
      " 61000  67% ( 31m 13s)   0.357   |   0.01: ICBM -> i c b m (✓) (forcing)\n",
      " 71000  78% ( 36m 12s)   0.279   |   0.01: Quoy -> q u o y (✓) \n",
      " 81000  89% ( 41m 23s)   0.431   |   2.61: OpenSecrets.orgLindsay -> o p e n n e e e e n dot e o dot e e e e e i e n dot (✗: o p e n s e c r e t s dot o r g l i n d s a y) (forcing)\n",
      " 91000 100% ( 46m 32s)   0.260   |   0.01: Nahj -> n a h j (✓) (forcing)\n"
     ]
    }
   ],
   "source": [
    "train_iterations(n_iters=90000, print_every=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 96000  56% (  2m 23s)   0.557   |   1.31: atrophin- -> a t s o p <EOS> i <EOS> (✗: a t r o p h i n) (forcing)\n",
      "Saved model to data/models/electronic_gen_6_testing_attn/100000_(EncoderRNN/DecoderRNN)\n",
      "Accuracy: 73.32% (    7332/   10000)\n"
     ]
    }
   ],
   "source": [
    "train_iterations(n_iters=9000, print_every=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "110000  20% (  4m 45s)   0.279   |   0.01: OROV -> o r o v (✓) \n",
      "120000  40% (  9m 43s)   0.261   |   0.13: Ilhwa -> i l h w a (✓) \n",
      "130000  60% ( 14m 41s)   0.320   |   0.11: amazon.com -> a m a z o n dot c o m (✓) \n",
      "140000  80% ( 19m 48s)   0.489   |   0.02: mRNAs -> m r n a's (✓) (forcing)\n",
      "150000 100% ( 24m 46s)   0.425   |   0.21: ICTMN.com -> i c t m n dot c o m (✓) (forcing)\n",
      "Saved model to data/models/electronic_gen_6_testing_attn/150000_(EncoderRNN/DecoderRNN)\n",
      "Accuracy: 76.26% (    7626/   10000)\n"
     ]
    }
   ],
   "source": [
    "train_iterations(n_iters=50000, print_every=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160000  20% (  4m 56s)   0.353   |   2.63: http://www.espnscrum.com/scrum/rugby/story/96890.html -> h t t p colon slash slash w w dot dot c dot slash slash slash dot slash e n slash c slash slash c i i n slash c e e slash dot c c c dot n e c c e c e c slash c e dot c slash slash e e e slash c n c dot i slash a (✗: h t t p colon slash slash w w w dot e s p n s c r u m dot com slash s c r u m slash r u g b y slash s t o r y slash n i n e s i x e i g h t n i n e o dot h t m l) (forcing)\n",
      "170000  40% (  9m 38s)   0.393   |   0.02: MNLUAT -> m n l u a t (✓) \n",
      "180000  60% ( 14m 27s)   0.294   |   0.00: ISBN -> i s b n (✓) (forcing)\n",
      "190000  80% ( 19m 27s)   0.317   |   0.01: DOCG -> d o c g (✓) \n",
      "200000 100% ( 24m 19s)   0.390   |   0.00: ISBN -> i s b n (✓) \n",
      "Saved model to data/models/electronic_gen_6_testing_attn/200000_(EncoderRNN/DecoderRNN)\n",
      "Accuracy: 73.65% (    7365/   10000)\n"
     ]
    }
   ],
   "source": [
    "train_iterations(n_iters=50000, print_every=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "state_dict_path = 'data/models/electronic_gen_6_testing_attn/100000_'\n",
    "#state_dict_path = 'data/models/electronic_gen_6_testing_attn/50000_'\n",
    "decoder_rnn.load_state_dict(torch.load(state_dict_path + 'DecoderRNN'))\n",
    "encoder_rnn.load_state_dict(torch.load(state_dict_path + 'EncoderRNN'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input:   GodVine.com\n",
      "output:  g o d i i c o m\n",
      "target:    godvinedotcom\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAw0AAAFeCAYAAADHZPOQAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nkKQBAAAYJGkAAAAGSRoAAIBB/w9E3GMJ9Vgc5wAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f659b29ef98>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def debug_show_attention(input_sentence, output_words, attentions):\n",
    "    # Set up figure with colorbar\n",
    "    fig = plt.figure(figsize=(15,6))\n",
    "    ax = fig.add_subplot(111)\n",
    "    #cax = ax.matshow(attentions.numpy(), cmap='bone')\n",
    "    cax = ax.matshow(attentions, cmap='bone')\n",
    "    fig.colorbar(cax)\n",
    "    # Set up axes\n",
    "    #ax.set_xticklabels([''] + input_sentence.split(' ') + ['<EOS>'], rotation=90)\n",
    "    #ax.set_xticklabels([''] + input_sentence + ['<EOS>'], rotation=90)\n",
    "    ax.set_yticklabels([''] + output_words)\n",
    "    \n",
    "    input_sentence = input_sentence + ['<EOS>']\n",
    "    #inp_arr = [\"{}\\n{}\".format(input_sentence[i], input_sentence[-1-i]) for i in range(len(input_sentence))]\n",
    "    inp_arr = input_sentence\n",
    "    ax.set_xticklabels([''] + inp_arr, rotation=0)\n",
    "\n",
    "    # Show label at every tick\n",
    "    ax.xaxis.set_major_locator(matplotlib.ticker.MultipleLocator(1))\n",
    "    ax.yaxis.set_major_locator(matplotlib.ticker.MultipleLocator(1))\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "def debug_eval_sample_show_attention():\n",
    "    global sample_row_last\n",
    "    #sample_row = balanced_data_sample_row()\n",
    "    sample_row = sample_data[sample_data['before'].str.len()>10].sample(1).iloc[0]\n",
    "    sample_row_last = sample_row\n",
    "       \n",
    "    a_words_ind = after_sentence_to_word_indexes(sample_row['after'], include_eos=True)\n",
    "    sample = sample_row['before'], a_words_ind, sample_row['class'], sample_row['sentence'].split(' ')\n",
    "\n",
    "    output, decoded_output, decoder_attns_arr, sample = test_model_single_sample(None, \n",
    "                                                            return_more=True, sample=sample)\n",
    "    print('input:  ', sample[0])\n",
    "    print('output: ', ' '.join(decoded_output))\n",
    "    print('target:   ', ''.join([words_after[w] for w in a_words_ind[:-1]]))\n",
    "\n",
    "    attns = np.array([arr.data[0].cpu().numpy() for arr in decoder_attns_arr])\n",
    "\n",
    "    debug_show_attention(list(sample[0]), decoded_output, attns)\n",
    "    #plt.matshow(attns)\n",
    "\n",
    "debug_eval_sample_show_attention()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentence_id                                               360158\n",
       "token_id                                                       3\n",
       "class                                                 ELECTRONIC\n",
       "before         https://www.gov.uk/government/organisations/te...\n",
       "after          h t t p s colon slash slash w w w dot g o v do...\n",
       "class_org                                             ELECTRONIC\n",
       "a_word_ind     [45, 30, 30, 24, 17, 129, 101, 101, 52, 52, 52...\n",
       "sentence                             available from : <SAMPLE> .\n",
       "Name: 15512, dtype: object"
      ]
     },
     "execution_count": 329,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_row_last"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentence_id                                               360158\n",
       "token_id                                                       3\n",
       "class                                                 ELECTRONIC\n",
       "before         https://www.gov.uk/government/organisations/te...\n",
       "after          h t t p s colon slash slash w w w dot g o v do...\n",
       "class_org                                             ELECTRONIC\n",
       "a_word_ind     [45, 30, 30, 24, 17, 129, 101, 101, 52, 52, 52...\n",
       "sentence                             available from : <SAMPLE> .\n",
       "Name: 15512, dtype: object"
      ]
     },
     "execution_count": 370,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_row_last = sample_data.loc[15512]\n",
    "sample_row_last"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:py3_pytorch_2]",
   "language": "python",
   "name": "conda-env-py3_pytorch_2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
