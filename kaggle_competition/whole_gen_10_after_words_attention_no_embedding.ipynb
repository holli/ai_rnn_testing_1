{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pytorch utils oh: pytorch_utils_oh_2.py\n",
      "Pytorch: 0.2.0_4\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import importlib\n",
    "from pytorch_utils_oh_2 import *\n",
    "import IPython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MODEL_SAVE_PATH = 'whole_gen_10_after_words_attention_no_embd'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pytorch utils oh: pytorch_utils_oh_2.py\n",
      "Pytorch: 0.2.0_4\n"
     ]
    }
   ],
   "source": [
    "import pytorch_utils_oh_2; importlib.reload(pytorch_utils_oh_2); from pytorch_utils_oh_2 import *;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# all_data = pickle.load(open(\"data/en_train_fixed_4_sentences.pkl\", \"rb\" ))\n",
    "all_data = pickle.load(open(\"data/en_train_fixed_5_manual.pkl\", \"rb\" ))\n",
    "# all_data_sentence_index = all_data.set_index('sentence_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data rows: 654333,  (dropped rows: 9263859)\n"
     ]
    }
   ],
   "source": [
    "sample_data = all_data.copy()\n",
    "sample_data = sample_data[sample_data['class'] != 'NOT_CHANGED']\n",
    "sample_data = sample_data[sample_data['class'] != 'MANUAL']\n",
    "print(\"Data rows: {},  (dropped rows: {})\".format(len(sample_data), len(all_data)-len(sample_data)))\n",
    "sample_data = sample_data.reset_index(drop=True)\n",
    "del(all_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ELECTRONIC', 'LETTERS', 'NUMBERS', 'PLAIN', 'VERBATIM']\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "categories_all = sorted(sample_data[\"class\"].unique())\n",
    "print(categories_all)\n",
    "print(len(categories_all))\n",
    "categories_index = dict((c, i) for i, c in enumerate(categories_all))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utils stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<SOS><EOS>☒ !\"#$%&'(),-./0123456789:;ABCDEFGHIJKLMNOPQRSTUVWXYZ_abcdefghijklmnopqrstuvwxyz~£¥ª²³µº¼½¾éɒʻˈΩμ—€⅓⅔⅛\n"
     ]
    }
   ],
   "source": [
    "chars_normal, chars_normal_index = load_characters_pkl('data/en_features/chars_normal.pkl')\n",
    "print(''.join(chars_normal))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "common_words, common_words_index = load_common_words_10k()\n",
    "len(common_words)\n",
    "common_words[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wv_vecs, wv_words, wv_idx = load_glove('/home/ohu/koodi/data/glove_wordvec/glove.6B.50d.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### After words handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<EOS>', '<SOS>', '<UNK>', '<0000>', '<SAMPLE>', 'two', 'twenty']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "1351"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_after_common = pickle.load(open(\"data/en_features/words_after_ext.pkl\", 'rb'))\n",
    "words_after_index = dict((c, i) for i, c in enumerate(words_after_common))\n",
    "words_after_common[0:7]\n",
    "len(words_after_common)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 1351])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sos_tensor = torch.zeros(1, 1, len(words_after_index))\n",
    "sos_tensor[0, 0, words_after_index[SOS_TOKEN]] = 1\n",
    "sos_tensor.size()\n",
    "#del(onehot_sos)\n",
    "\n",
    "# sos_tensor = torch.LongTensor([words_after_index[SOS_TOKEN]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### More balanced sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "balanced_data_classes_select = list(sample_data.groupby('class'))\n",
    "\n",
    "balanced_data_accessed_counter = 0 \n",
    "balanced_data_randomize_freq = False\n",
    "balanced_data_length = 0\n",
    "\n",
    "def balanced_data_randomize_org(max_len=20000):\n",
    "    global balanced_data, balanced_data_length, balanced_data_accessed_counter, balanced_data_randomize_freq\n",
    "    balanced_data = pd.concat([v.sample(min(max_len, len(v))) for k, v in balanced_data_classes_select])\n",
    "    balanced_data_length = len(balanced_data)\n",
    "    balanced_data_randomize_freq = balanced_data_length * 0.2\n",
    "    balanced_data_accessed_counter = 0\n",
    "balanced_data_randomize = balanced_data_randomize_org\n",
    "\n",
    "def balanced_data_sample_row():\n",
    "    global balanced_data_accessed_counter\n",
    "    global balanced_data_last_sample\n",
    "    balanced_data_accessed_counter += 1\n",
    "    if balanced_data_randomize_freq and balanced_data_accessed_counter > balanced_data_randomize_freq:\n",
    "        balanced_data_randomize()\n",
    "    balanced_data_last_sample = balanced_data.iloc[random.randint(1, balanced_data_length-1)]\n",
    "    return balanced_data_last_sample\n",
    "    \n",
    "balanced_data_randomize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "class\n",
       "ELECTRONIC     4964\n",
       "LETTERS       20000\n",
       "NUMBERS       20000\n",
       "PLAIN         20000\n",
       "VERBATIM      11741\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#all_data.groupby('class')['class'].count()\n",
    "#sample_data.groupby('class')['class'].count()\n",
    "balanced_data.groupby('class')['class'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentence_id                                                66440\n",
       "token_id                                                      12\n",
       "class                                                      PLAIN\n",
       "before                                                        sq\n",
       "after                                                     square\n",
       "class_org                                                  PLAIN\n",
       "a_word_ind                                              [106, 0]\n",
       "sentence       there were 3 , 942 housing units at an average...\n",
       "Name: 57557, dtype: object"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "balanced_data_sample_row()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LETTERS : NOTCH -> n o t c h <EOS> [29, 25, 30, 21, 45, 0]\n",
      "lck has been shown to interact with : adam 15 , cd 2 , cd 44 , cd 4 , coup tfii , dlg 1 , <SAMPLE> 1 , pik 3 ca , ptpn 6 , ptprc , unc 119 , syk , ube 3 a , andzap 70 .\n",
      "torch.Size([1, 6, 104])\n"
     ]
    }
   ],
   "source": [
    "def get_random_sample():\n",
    "    sample_row = balanced_data_sample_row()   \n",
    "    return sample_row['before'], sample_row['a_word_ind'], sample_row['class'], sample_row['sentence']\n",
    "            \n",
    "def tmp():\n",
    "    s_bef, s_aft, s_class, s_sentence = get_random_sample()\n",
    "    s_aft_str = ' '.join([words_after_common[i] for i in s_aft])\n",
    "    print(s_class, ':', s_bef, '->', s_aft_str, s_aft)\n",
    "    print(s_sentence)\n",
    "    print(string_to_tensor(s_bef, chars_normal_index).shape)\n",
    "tmp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "163 µs ± 2.04 µs per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "get_random_sample()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "use_cuda = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "499"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>token_id</th>\n",
       "      <th>class</th>\n",
       "      <th>before</th>\n",
       "      <th>after</th>\n",
       "      <th>class_org</th>\n",
       "      <th>a_word_ind</th>\n",
       "      <th>sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>240278</th>\n",
       "      <td>276093</td>\n",
       "      <td>2</td>\n",
       "      <td>ELECTRONIC</td>\n",
       "      <td>http://www.rollingstone.com/music/albumreviews...</td>\n",
       "      <td>h t t p colon slash slash w w w dot r o l l i ...</td>\n",
       "      <td>ELECTRONIC</td>\n",
       "      <td>[45, 30, 30, 24, 129, 101, 101, 52, 52, 52, 74...</td>\n",
       "      <td>rolling stone &lt;SAMPLE&gt; .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340543</th>\n",
       "      <td>392314</td>\n",
       "      <td>17</td>\n",
       "      <td>ELECTRONIC</td>\n",
       "      <td>https://diva.sfsu.edu/collections/sfbatv/bundl...</td>\n",
       "      <td>h t t p s colon slash slash d i v a dot s f s ...</td>\n",
       "      <td>ELECTRONIC</td>\n",
       "      <td>[45, 30, 30, 24, 17, 129, 101, 101, 26, 31, 54...</td>\n",
       "      <td>watch the full 60 minute version of this 1973 ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        sentence_id  token_id       class  \\\n",
       "240278       276093         2  ELECTRONIC   \n",
       "340543       392314        17  ELECTRONIC   \n",
       "\n",
       "                                                   before  \\\n",
       "240278  http://www.rollingstone.com/music/albumreviews...   \n",
       "340543  https://diva.sfsu.edu/collections/sfbatv/bundl...   \n",
       "\n",
       "                                                    after   class_org  \\\n",
       "240278  h t t p colon slash slash w w w dot r o l l i ...  ELECTRONIC   \n",
       "340543  h t t p s colon slash slash d i v a dot s f s ...  ELECTRONIC   \n",
       "\n",
       "                                               a_word_ind  \\\n",
       "240278  [45, 30, 30, 24, 129, 101, 101, 52, 52, 52, 74...   \n",
       "340543  [45, 30, 30, 24, 17, 129, 101, 101, 26, 31, 54...   \n",
       "\n",
       "                                                 sentence  \n",
       "240278                           rolling stone <SAMPLE> .  \n",
       "340543  watch the full 60 minute version of this 1973 ...  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>token_id</th>\n",
       "      <th>class</th>\n",
       "      <th>before</th>\n",
       "      <th>after</th>\n",
       "      <th>class_org</th>\n",
       "      <th>a_word_ind</th>\n",
       "      <th>sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>593100</th>\n",
       "      <td>678277</td>\n",
       "      <td>4</td>\n",
       "      <td>NUMBERS</td>\n",
       "      <td>06-09-05 GEN RE EXECUTIVE JOHN HOULDSWORTH PLE...</td>\n",
       "      <td>o six sil o nine sil o five sil gen sil re sil...</td>\n",
       "      <td>TELEPHONE</td>\n",
       "      <td>[25, 20, 58, 25, 15, 58, 25, 14, 58, 1303, 58,...</td>\n",
       "      <td>\" # 314 : &lt;SAMPLE&gt; , agrees to cooperate with ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279519</th>\n",
       "      <td>321586</td>\n",
       "      <td>1</td>\n",
       "      <td>ELECTRONIC</td>\n",
       "      <td>0-253-34237-6wpamurals.comlibrary.wustl.eduAdr...</td>\n",
       "      <td>o d a s h t w o f i v e t h r e e d a s h t h ...</td>\n",
       "      <td>ELECTRONIC</td>\n",
       "      <td>[25, 26, 22, 17, 45, 30, 52, 25, 37, 31, 54, 2...</td>\n",
       "      <td>isbn &lt;SAMPLE&gt; drell , chicago sun times , 21 j...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        sentence_id  token_id       class  \\\n",
       "593100       678277         4     NUMBERS   \n",
       "279519       321586         1  ELECTRONIC   \n",
       "\n",
       "                                                   before  \\\n",
       "593100  06-09-05 GEN RE EXECUTIVE JOHN HOULDSWORTH PLE...   \n",
       "279519  0-253-34237-6wpamurals.comlibrary.wustl.eduAdr...   \n",
       "\n",
       "                                                    after   class_org  \\\n",
       "593100  o six sil o nine sil o five sil gen sil re sil...   TELEPHONE   \n",
       "279519  o d a s h t w o f i v e t h r e e d a s h t h ...  ELECTRONIC   \n",
       "\n",
       "                                               a_word_ind  \\\n",
       "593100  [25, 20, 58, 25, 15, 58, 25, 14, 58, 1303, 58,...   \n",
       "279519  [25, 26, 22, 17, 45, 30, 52, 25, 37, 31, 54, 2...   \n",
       "\n",
       "                                                 sentence  \n",
       "593100  \" # 314 : <SAMPLE> , agrees to cooperate with ...  \n",
       "279519  isbn <SAMPLE> drell , chicago sun times , 21 j...  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp = sample_data[sample_data['before'].str.len()>50]\n",
    "len(tmp)\n",
    "tmp.sample(2)\n",
    "tmp[~tmp['before'].str.contains('/')].sample(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MAX_ATTENTION_LENGTH = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EncoderRNN (\n",
       "  (rnn_words): LSTM(50, 64, batch_first=True, bidirectional=True)\n",
       "  (rnn_chars): LSTM(104, 128, batch_first=True, bidirectional=True)\n",
       ")"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, words_input_size, chars_input_size, words_hidden_size, chars_hidden_size,\n",
    "                 words_layers=1, chars_layers=1):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        \n",
    "        self.words_layers = words_layers\n",
    "        self.chars_layers = chars_layers\n",
    "        self.words_hidden_size = words_hidden_size\n",
    "        self.chars_hidden_size = chars_hidden_size\n",
    "        self.hidden_size = words_hidden_size + chars_hidden_size\n",
    "\n",
    "        self.rnn_words = nn.LSTM(words_input_size, words_hidden_size // 2, words_layers,\n",
    "                                 batch_first=True, bidirectional=True)\n",
    "\n",
    "        self.rnn_chars = nn.LSTM(chars_input_size, chars_hidden_size // 2, chars_layers,\n",
    "                                batch_first=True, bidirectional=True)\n",
    "        \n",
    "    def forward(self, word_vectors, string_tensor, hidden = None, init_hidden = True):\n",
    "        if init_hidden:\n",
    "            hidden_words, hidden_chars = self.init_hidden()\n",
    "        \n",
    "        all_outputs_words, hidden_words = self.rnn_words(word_vectors, hidden_words)\n",
    "        output_words = all_outputs_words[:, -1]\n",
    "        \n",
    "        all_outputs_chars, hidden_chars = self.rnn_chars(string_tensor, hidden_chars)\n",
    "        output_chars = all_outputs_chars[:, -1]\n",
    "        \n",
    "        hidden_states_cat = Variable(torch.zeros(MAX_ATTENTION_LENGTH, self.hidden_size)).cuda()\n",
    "        for ei in range(min(MAX_ATTENTION_LENGTH, len(string_tensor[0]))):\n",
    "            hidden_states_cat[ei] = torch.cat((output_words, all_outputs_chars[0, ei].view(1,-1)), 1)\n",
    "                \n",
    "        output = torch.cat((output_words[0], output_chars[0]), 0)\n",
    "\n",
    "        #output = torch.cat((output_words, output_chars), 1)\n",
    "        \n",
    "        #return output, all_outputs_chars\n",
    "        return output, hidden_states_cat\n",
    "\n",
    "    def init_hidden(self):\n",
    "        var1_1 = Variable(torch.zeros(2 * self.words_layers, 1, self.words_hidden_size // 2))\n",
    "        var1_2 = Variable(torch.zeros(2 * self.words_layers, 1, self.words_hidden_size // 2))\n",
    "        var2_1 = Variable(torch.zeros(2 * self.chars_layers, 1, self.chars_hidden_size // 2))\n",
    "        var2_2 = Variable(torch.zeros(2 * self.chars_layers, 1, self.chars_hidden_size // 2))\n",
    "        \n",
    "        var1_1 = var1_1.cuda(); var1_2 = var1_2.cuda()\n",
    "        var2_1 = var2_1.cuda(); var2_2 = var2_2.cuda()\n",
    "        return ((var1_1, var1_2), (var2_1, var2_2))\n",
    "    \n",
    "    \n",
    "encoder_rnn = EncoderRNN(words_input_size=wv_vecs.shape[-1], chars_input_size=len(chars_normal),\n",
    "                         words_hidden_size=128, chars_hidden_size=256,\n",
    "                         words_layers=1, chars_layers=1).cuda()\n",
    "encoder_rnn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T-\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'T-'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([384])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([50, 384])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def test_encoder_single_sample():\n",
    "    s_bef, s_aft, s_class, s_sentence = get_random_sample()\n",
    "    print(s_bef)\n",
    "    \n",
    "    words_t = Variable(words_to_word_vectors_tensor(list(s_sentence), wv_vecs, wv_idx)).cuda()\n",
    "    \n",
    "    string_t = string_to_tensor(s_bef, chars_normal_index)\n",
    "    string_t = Variable(string_t).cuda()\n",
    "    \n",
    "    return encoder_rnn(words_t, string_t), s_bef\n",
    "    \n",
    "(encoder_output, encoder_outputs), tmp = test_encoder_single_sample()\n",
    "tmp\n",
    "encoder_output.size()\n",
    "encoder_outputs.size()\n",
    "torch.eq(encoder_output, encoder_outputs[len(tmp)]).data.all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecoderRNN (\n",
       "  (rnn): GRU(384, 384, batch_first=True)\n",
       "  (lin_out): Linear (384 -> 1351)\n",
       "  (emb_lin): Linear (1351 -> 384)\n",
       "  (attn): Linear (768 -> 50)\n",
       "  (attn_combine): Linear (768 -> 384)\n",
       "  (dropout): Dropout (p = 0.1)\n",
       ")"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[torch.Size([1, 1351]), torch.Size([1, 1, 384]), torch.Size([1, 50])]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class DecoderRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, n_layers=1, dropout_p=0.1, max_length=MAX_ATTENTION_LENGTH):\n",
    "        super(DecoderRNN, self).__init__()\n",
    "        self.n_layers = n_layers\n",
    "        self.hidden_size = hidden_size\n",
    "        \n",
    "        #self.rnn = nn.GRU(input_size, hidden_size, n_layers,\n",
    "        self.rnn = nn.GRU(hidden_size, hidden_size, n_layers,\n",
    "                                 batch_first=True, bidirectional=False)\n",
    "        \n",
    "        self.lin_out = nn.Linear(hidden_size, input_size)\n",
    "        #self.softmax = nn.LogSoftmax()\n",
    "        \n",
    "        #self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        self.emb_lin = nn.Linear(input_size, hidden_size)\n",
    "        self.max_length = max_length\n",
    "        self.attn = nn.Linear(hidden_size*2, self.max_length)\n",
    "        self.attn_combine = nn.Linear(self.hidden_size * 2, self.hidden_size)\n",
    "        self.dropout = nn.Dropout(dropout_p)\n",
    "        \n",
    "    #def forward(self, char, hidden):\n",
    "    def forward(self, last_input, hidden, encoder_outputs):\n",
    "        #embedded = self.embedding(last_input).view(1, 1, -1)\n",
    "        embedded = self.emb_lin(last_input).view(1, 1, -1)\n",
    "        embedded = self.dropout(embedded)\n",
    "        #IPython.core.debugger.Pdb().set_trace()\n",
    "        #attn_weights = F.softmax(self.attn(torch.cat((char[0], hidden[0]), 1)))\n",
    "        attn_weights = F.softmax(self.attn(torch.cat((embedded[0], hidden[0]), 1)))\n",
    "        attn_applied = torch.bmm(attn_weights.unsqueeze(0), encoder_outputs.unsqueeze(0))\n",
    "        \n",
    "        output = torch.cat((embedded[0], attn_applied[0]), 1)\n",
    "        output = self.attn_combine(output).unsqueeze(0)\n",
    "\n",
    "        \n",
    "        output = F.relu(output)\n",
    "        output, hidden = self.rnn(output, hidden)\n",
    "\n",
    "        output = F.log_softmax(self.lin_out(output[0]))\n",
    "        return output, hidden, attn_weights\n",
    "    \n",
    "    def init_rest_hidden(self, input_var):\n",
    "        if self.n_layers > 1:\n",
    "            hid_var = Variable(torch.zeros(self.n_layers - 1, 1, self.hidden_size)).cuda()\n",
    "            res = torch.cat((input_var, hid_var), 0)\n",
    "            return res\n",
    "        else:\n",
    "            return input_var\n",
    "        \n",
    "\n",
    "decoder_rnn = DecoderRNN(input_size=len(words_after_common), hidden_size=encoder_output.size()[0], n_layers=1)\n",
    "decoder_rnn = decoder_rnn.cuda()\n",
    "decoder_rnn\n",
    "\n",
    "tmp_outputs = Variable(torch.zeros(MAX_ATTENTION_LENGTH, encoder_output.size()[0])).cuda()\n",
    "tmp_hiddens = decoder_rnn.init_rest_hidden(encoder_output.view(1,1,-1))\n",
    "tmp = decoder_rnn(Variable(sos_tensor).cuda(), tmp_hiddens, tmp_outputs)\n",
    "[v.size() for v in tmp]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "(0 ,.,.) = \n",
       "  1.2000  2.4000  3.6000  4.8000\n",
       "[torch.FloatTensor of size 1x1x4]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.bmm(torch.FloatTensor([1,0.1,0.1]).view(1,1,-1), torch.arange(0, 12).view(1,3,-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[torch.Size([1, 1351]), torch.Size([1, 1, 384]), torch.Size([1, 50])]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      " 434\n",
      "[torch.cuda.LongTensor of size 1x1 (GPU 0)]\n",
      "\n",
      "pence\n"
     ]
    }
   ],
   "source": [
    "tmp_outputs = Variable(torch.zeros(MAX_ATTENTION_LENGTH, encoder_output.size()[0])).cuda()\n",
    "tmp_hiddens = decoder_rnn.init_rest_hidden(encoder_output.view(1,1,-1))\n",
    "tmp = decoder_rnn(Variable(sos_tensor).cuda(), tmp_hiddens, tmp_outputs)\n",
    "[v.size() for v in tmp]\n",
    "print(tmp[0].topk(1)[1])\n",
    "print(words_after_common[tmp[0].topk(1)[1].data[0][0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training etc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('december twenty eleven',\n",
       " 'december twenty eleven',\n",
       " 'december twenty eleven',\n",
       " ('December 2011',\n",
       "  [65, 6, 48, 0],\n",
       "  'NUMBERS',\n",
       "  'beting , gianfranco ( <SAMPLE> ) , \" pantanal : o ultimo voo do tuiuiu \" , flap internacional ( in portuguese ) ( 472 ) : 46 .'))"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def test_model_single_sample(model=None, return_more=False, sample=False):\n",
    "    decoder_rnn.eval()\n",
    "    encoder_rnn.eval()\n",
    "    \n",
    "    if not sample:\n",
    "        sample = get_random_sample()\n",
    "    s_bef, s_aft, s_class, s_sentence = sample\n",
    "        \n",
    "    words_t = Variable(words_to_word_vectors_tensor(list(s_sentence), wv_vecs, wv_idx)).cuda()\n",
    "    \n",
    "    string_t = string_to_tensor(s_bef, chars_normal_index)\n",
    "    string_t = Variable(string_t).cuda()\n",
    "    \n",
    "    encoder_output, encoder_outputs = encoder_rnn(words_t, string_t)\n",
    "    \n",
    "    #encoder_output = encoder_output.view(1,1,-1)\n",
    "    \n",
    "    decoder_hidden = decoder_rnn.init_rest_hidden(encoder_outputs[0].view(1,1,-1))\n",
    "    decoder_input = Variable(sos_tensor).cuda()\n",
    "\n",
    "    decoded_output = []\n",
    "    decoder_attns_arr = []\n",
    "    max_length = 20\n",
    "    for _ in range(max_length):\n",
    "        decoder_output, decoder_hidden, decoder_attns = decoder_rnn(decoder_input, decoder_hidden, encoder_outputs)\n",
    "        decoder_attns_arr.append(decoder_attns)\n",
    "        #return decoder_output\n",
    "\n",
    "        topv, topi = decoder_output.data.topk(1)\n",
    "        word_index = topi[0][0]\n",
    "        word = words_after_common[word_index] # Use own prediction as next input\n",
    "                \n",
    "        if word == EOS_TOKEN:\n",
    "            break\n",
    "\n",
    "        decoded_output.append(word)\n",
    "        \n",
    "        #decoder_input = Variable(torch.LongTensor([word_index])).cuda()\n",
    "        \n",
    "        decoder_input = torch.zeros(1, 1, len(words_after_index))\n",
    "        decoder_input[0, 0, word_index] = 1\n",
    "        decoder_input = Variable(decoder_input).cuda()\n",
    "    \n",
    "    output = ' '.join(decoded_output)\n",
    "    sample_target = ' '.join([words_after_common[w] for w in s_aft][:-1])\n",
    "    \n",
    "    decoder_rnn.train()\n",
    "    encoder_rnn.train()\n",
    "    \n",
    "    if return_more:\n",
    "        return output, decoded_output, decoder_attns_arr, sample\n",
    "    \n",
    "    return output, output, sample_target, sample\n",
    "    \n",
    "tmp = test_model_single_sample(None)\n",
    "tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25 January 2010 => visualized categorization categorization categorization categorization categorization categorization categorization categorization categorization categorization categorization categorization categorization categorization categorization categorization categorization categorization categorization || [11, 6, 78, 12, 63, 6, 44, 0] \n",
      "                  <SAMPLE> .\n",
      "labour         => pence categorization categorization categorization categorization categorization categorization categorization categorization categorization categorization categorization categorization categorization categorization categorization categorization categorization categorization categorization || [137, 0] \n",
      "                  some new prisoners were selected to work as slave <SAMPLE> , but most went straight to the gas chamber .\n"
     ]
    }
   ],
   "source": [
    "def print_local_wrong_predictions(max_results=10):\n",
    "    arr = get_some_wrong_predictions(None, test_model_single_sample, max_iterations=10000, max_results=max_results)\n",
    "    for sample, predict, output in arr:\n",
    "        s_bef, s_aft, s_class, s_sentence = sample\n",
    "        print(\"{:<14} => {:<14} || {} \\n{:>17} {}\".format(s_bef, predict, s_aft, '', s_sentence, ))\n",
    "print_local_wrong_predictions(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.00% (       0/     100)\n",
      "CPU times: user 2.48 s, sys: 40 ms, total: 2.52 s\n",
      "Wall time: 2.52 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "test_model_accuracy(encoder_rnn, test_model_single_sample, n_sample=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train(s_bef, s_aft, s_sentence, encoder_optimizer, decoder_optimizer, loss_function,\n",
    "          use_teacher_forcing, max_length=20):\n",
    "    \n",
    "    words_t = Variable(words_to_word_vectors_tensor(list(s_sentence), wv_vecs, wv_idx)).cuda()\n",
    "    \n",
    "    string_t = string_to_tensor(s_bef, chars_normal_index)\n",
    "    string_t = Variable(string_t).cuda()\n",
    "    \n",
    "    encoder_output, encoder_outputs = encoder_rnn(words_t, string_t)\n",
    "    \n",
    "    #encoder_output = encoder_output.view(1,1,-1)\n",
    "    \n",
    "    decoder_hidden = decoder_rnn.init_rest_hidden(encoder_outputs[0].view(1,1,-1))\n",
    "    decoder_input = Variable(sos_tensor).cuda()\n",
    "    \n",
    "    ###\n",
    "    target_arr = s_aft\n",
    "    #target_arr = after_sentence_to_word_indexes(s_aft, include_eos=True)\n",
    "    \n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "    loss = 0\n",
    "    \n",
    "    decoded_output = []\n",
    "    for i in range(len(target_arr)):\n",
    "        decoder_output, decoder_hidden, decoder_attns = decoder_rnn(decoder_input, decoder_hidden, encoder_outputs)\n",
    "\n",
    "        #decoder_target_i = chars_after_index[target_arr[i]]\n",
    "        decoder_target_i = target_arr[i]\n",
    "        decoder_target_i = Variable(torch.LongTensor([decoder_target_i])).cuda()\n",
    "        loss += loss_function(decoder_output, decoder_target_i)\n",
    "        \n",
    "        topv, topi = decoder_output.data.topk(1)\n",
    "        word_index = topi[0][0]\n",
    "        word = words_after_common[word_index] # Use own prediction as next input\n",
    "        decoded_output.append(word)\n",
    "        \n",
    "        if use_teacher_forcing:\n",
    "            word_index = target_arr[i] # replace input with right target\n",
    "        else:\n",
    "            # use output normally as input \n",
    "            if word == EOS_TOKEN:\n",
    "                break\n",
    "                \n",
    "        decoder_input = torch.zeros(1, 1, len(words_after_index))\n",
    "        decoder_input[0, 0, word_index] = 1\n",
    "        decoder_input = Variable(decoder_input).cuda()\n",
    "        #decoder_input = Variable(torch.LongTensor([word_index])).cuda()\n",
    "        \n",
    "    if decoded_output[-1] == EOS_TOKEN:\n",
    "        decoded_output = decoded_output[:-1]\n",
    "        \n",
    "    loss.backward()\n",
    "\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "\n",
    "    return ' '.join(decoded_output), (loss.data[0] / len(target_arr))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_iterations(n_iters=100000, lr=0.001, teacher_forcing_ratio=0.5,\n",
    "                     print_every=10000, plot_every=1000):\n",
    "\n",
    "    start = time.time()\n",
    "    \n",
    "    decoder_rnn.train()\n",
    "    encoder_rnn.train()\n",
    "\n",
    "    current_loss = 0\n",
    "    current_loss_iter = 0\n",
    "\n",
    "    encoder_optimizer = torch.optim.Adam(encoder_rnn.parameters(), lr=lr)\n",
    "    decoder_optimizer = torch.optim.Adam(decoder_rnn.parameters(), lr=lr)\n",
    "    loss_function = nn.NLLLoss()\n",
    "    \n",
    "    for iteration in range(1, n_iters + 1):\n",
    "        model_training.iterations += 1\n",
    "        \n",
    "        use_teacher_forcing = random.random() < teacher_forcing_ratio\n",
    "        \n",
    "        s_bef, s_aft, s_class, s_sentence = get_random_sample()\n",
    "        \n",
    "        result, loss = train(s_bef=s_bef, s_aft=s_aft, s_sentence=s_sentence,\n",
    "                             encoder_optimizer=encoder_optimizer, decoder_optimizer=decoder_optimizer,\n",
    "                             loss_function=nn.NLLLoss(), use_teacher_forcing=use_teacher_forcing,\n",
    "                             max_length=40 )\n",
    "        \n",
    "        current_loss += loss\n",
    "        current_loss_iter += 1\n",
    "\n",
    "        # Print iter number, loss, name and guess\n",
    "        if iteration % print_every == 0:\n",
    "            teacher_forcing_str = \"\"\n",
    "            if use_teacher_forcing:\n",
    "                teacher_forcing_str = \"(forcing)\"\n",
    "            s_aft_sentence = ' '.join([words_after_common[w] for w in s_aft][:-1])\n",
    "            correct = '✓' if result == s_aft_sentence else \"✗: {}\".format(s_aft_sentence)\n",
    "            \n",
    "            print(\"{:>6d} {:>4.0%} ({:>8}) {:>7.3f}   | {:>6.2f}: {} -> {} ({}) {}\".format(\n",
    "                      model_training.iterations, iteration/n_iters, time_since(start),\n",
    "                      current_loss/current_loss_iter, loss,\n",
    "                      s_bef, result, correct, teacher_forcing_str))\n",
    "\n",
    "        # Add current loss avg to list of losses\n",
    "        if iteration % plot_every == 0:\n",
    "            model_training.losses.append(current_loss / plot_every)\n",
    "            model_training.learning_rates.append(lr)\n",
    "            current_loss = 0\n",
    "            current_loss_iter = 0\n",
    "            \n",
    "        if model_training.iterations % 50000 == 0 or model_training.iterations == 10:\n",
    "            model_training.save_models()\n",
    "            acc = test_model_accuracy(encoder_rnn, test_model_single_sample)\n",
    "            model_training.accuracy.append(acc)\n",
    "    \n",
    "    # test_model_accuracy(model, n_sample=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Save path: data/models/whole_gen_10_after_words_attention_no_embd\n"
     ]
    }
   ],
   "source": [
    "model_training = ModelTraining(MODEL_SAVE_PATH, [encoder_rnn, decoder_rnn])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     9  18% (   0m 0s)   7.178   |   7.16: 10 -> visualized (✗: [44, 0]) \n",
      "Saved model to data/models/whole_gen_10_after_words_attention_no_embd/10_(EncoderRNN/DecoderRNN)\n",
      "Accuracy: 0.00% (       0/   10000)\n",
      "    18  36% (   1m 2s)   5.897   |   1.80: MCC ->  (✗: [32, 21, 21, 0]) \n",
      "    27  54% (   1m 3s)   5.220   |   7.07: vol -> <EOS> (✗: [107, 0]) (forcing)\n",
      "    36  72% (   1m 3s)   4.725   |   7.12: FGF -> <EOS> <EOS> <EOS> (✗: [37, 53, 37, 0]) (forcing)\n",
      "    45  90% (   1m 3s)   4.734   |   7.08: FC -> <EOS> <EOS> (✗: [37, 21, 0]) (forcing)\n"
     ]
    }
   ],
   "source": [
    "train_iterations(n_iters=50, print_every=9, lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   550  53% (   0m 8s)   3.357   |   4.56: mobilisation ->  (✗: [574, 0]) \n"
     ]
    }
   ],
   "source": [
    "train_iterations(n_iters=(1000-model_training.iterations), print_every=500, lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  2000  11% (  0m 21s)   2.669   |   1.20: 19 November 2003 -> the (✗: [11, 87, 12, 69, 5, 8, 13, 0]) \n",
      "  3000  22% (  0m 41s)   2.473   |   2.99: AK -> nineteen <EOS> (✗: [22, 59, 0]) (forcing)\n",
      "  4000  33% (   1m 0s)   2.374   |   2.05: st -> nineteen (✗: [102, 0]) \n",
      "  5000  44% (  1m 22s)   2.402   |   2.89: Overstock.com -> s s a a c c c c c <EOS> c c c (✗: [25, 54, 28, 35, 17, 30, 25, 21, 59, 74, 21, 25, 32, 0]) (forcing)\n",
      "  6000  56% (  1m 43s)   2.194   |   0.23: & -> and (✓) \n",
      "  7000  67% (   2m 3s)   2.038   |   1.86: 1987 -> nineteen thousand (✗: [7, 27, 18, 0]) \n",
      "  8000  78% (  2m 27s)   1.982   |   1.09: # -> to (✗: [109, 0]) \n",
      "  9000  89% (  2m 50s)   1.919   |   3.01: 525 -> nineteen hundred six (✗: [14, 10, 6, 14, 0]) \n",
      " 10000 100% (  3m 15s)   1.855   |   2.35: pci -> m s (✗: [24, 21, 31, 0]) \n"
     ]
    }
   ],
   "source": [
    "train_iterations(n_iters=9000, lr=0.0001, print_every=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 20000  11% (  3m 30s)   1.154   |   0.00: & -> and (✓) (forcing)\n",
      " 30000  22% (  7m 18s)   0.680   |   0.13: 1973 -> nineteen seventy three (✓) (forcing)\n",
      " 40000  33% (  11m 1s)   0.652   |   0.92: E&M -> e m m (✗: [28, 55, 32, 0]) (forcing)\n",
      " 50000  44% ( 14m 41s)   0.537   |   0.00: J. -> j (✓) \n",
      "Saved model to data/models/whole_gen_10_after_words_attention_no_embd/50000_(EncoderRNN/DecoderRNN)\n",
      "Accuracy: 72.18% (    7218/   10000)\n",
      " 60000  56% ( 19m 46s)   0.565   |   0.00: 5 -> five (✓) (forcing)\n",
      " 70000  67% ( 23m 24s)   0.517   |   0.03: st -> saint (✓) \n",
      " 80000  78% ( 27m 13s)   0.406   |   0.05: 29 -> twenty nine (✓) (forcing)\n",
      " 90000  89% ( 30m 54s)   0.389   |   0.00: pp -> p p (✓) (forcing)\n",
      "100000 100% ( 34m 42s)   0.435   |   0.00: - -> to (✓) \n",
      "Saved model to data/models/whole_gen_10_after_words_attention_no_embd/100000_(EncoderRNN/DecoderRNN)\n",
      "Accuracy: 76.11% (    7611/   10000)\n"
     ]
    }
   ],
   "source": [
    "train_iterations(n_iters=90000, print_every=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "110000   5% (  3m 48s)   0.463   |   0.01: st -> saint (✓) \n",
      "120000  10% (  7m 32s)   0.409   |   0.01: franchise -> franchize (✓) (forcing)\n",
      "130000  15% ( 11m 21s)   0.342   |   0.00: & -> and (✓) \n",
      "140000  20% ( 15m 10s)   0.398   |   1.59: 200852 -> twenty hundred fifty two <EOS> fifty two (✗: [5, 10, 8, 16, 10, 38, 5, 0]) (forcing)\n",
      "150000  25% ( 18m 53s)   0.419   |   0.00: centre -> center (✓) \n",
      "Saved model to data/models/whole_gen_10_after_words_attention_no_embd/150000_(EncoderRNN/DecoderRNN)\n",
      "Accuracy: 81.72% (    8172/   10000)\n",
      "160000  30% ( 23m 58s)   0.374   |   1.60: CMYK -> c y y <EOS> (✗: [21, 32, 86, 59, 0]) (forcing)\n",
      "170000  35% ( 27m 51s)   0.357   |   1.37: Kordia.co.nz -> k o n n a n dot c o dot o z (✗: [59, 25, 35, 26, 31, 22, 74, 21, 25, 74, 29, 105, 0]) (forcing)\n",
      "180000  40% ( 31m 33s)   0.410   |   0.00: 1960 -> nineteen sixty (✓) (forcing)\n",
      "190000  45% ( 35m 16s)   0.417   |   0.01: theatre -> theater (✓) (forcing)\n",
      "200000  50% ( 38m 59s)   0.333   |   3.06: stabilised -> subsidized (✗: [496, 0]) \n",
      "Saved model to data/models/whole_gen_10_after_words_attention_no_embd/200000_(EncoderRNN/DecoderRNN)\n",
      "Accuracy: 82.25% (    8225/   10000)\n",
      "210000  55% ( 44m 10s)   0.334   |   0.00: & -> and (✓) \n",
      "220000  60% ( 47m 57s)   0.324   |   0.00: & -> and (✓) \n",
      "230000  65% ( 51m 39s)   0.351   |   0.00: & -> and (✓) (forcing)\n",
      "240000  70% ( 55m 36s)   0.352   |   0.00: pp -> p p (✓) \n",
      "250000  75% ( 59m 26s)   0.332   |   0.10: January 28, 1905 -> january twenty eighth nineteen o five (✓) (forcing)\n",
      "Saved model to data/models/whole_gen_10_after_words_attention_no_embd/250000_(EncoderRNN/DecoderRNN)\n",
      "Accuracy: 84.66% (    8466/   10000)\n",
      "260000  80% ( 64m 28s)   0.276   |   0.00: 3 -> three (✓) (forcing)\n",
      "270000  85% ( 68m 10s)   0.394   |   0.01: 100 -> one hundred (✓) (forcing)\n",
      "280000  90% ( 71m 53s)   0.298   |   0.00: - -> to (✓) \n",
      "290000  95% ( 75m 45s)   0.299   |   0.00: μ -> mu (✓) (forcing)\n",
      "300000 100% ( 79m 27s)   0.345   |   0.00: J. C. -> j c (✓) \n",
      "Saved model to data/models/whole_gen_10_after_words_attention_no_embd/300000_(EncoderRNN/DecoderRNN)\n",
      "Accuracy: 85.26% (    8526/   10000)\n"
     ]
    }
   ],
   "source": [
    "train_iterations(n_iters=200000, print_every=10000, teacher_forcing_ratio=0.5, lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Billboard.biz  => b i l l b i b b dot dot i b || [36, 31, 42, 42, 36, 25, 22, 35, 26, 74, 36, 31, 105, 0] \n",
      "                  <SAMPLE> ( april 19 , 2014 ) .\n",
      "obec           => o b e e        || [25, 36, 28, 21, 0] \n",
      "                  chvalnov lisky is a village and municipality ( <SAMPLE> ) in kromeriz district in the zlin region of the czech republic .\n",
      "January 13, 1973 => january thirteenth nineteen seventy three three || [63, 100, 7, 33, 13, 0] \n",
      "                  cristian heyne ( born <SAMPLE> in santiago ) is a chilean composer and producer , and formally a journalist .\n",
      "mineralisation => modernization  || [864, 0] \n",
      "                  the ore therefore belongs to the <SAMPLE> type sphalerite pyrite galena chalcopyrite .\n",
      "Fotbolls-em.nu => f o l b b b e s s dot s t || [37, 25, 30, 36, 25, 42, 42, 17, 26, 22, 17, 45, 28, 32, 74, 29, 43, 0] \n",
      "                  <SAMPLE> ( in swedish ) .\n",
      "67th           => sixty seven    || [39, 82, 0] \n",
      "                  the <SAMPLE> je khenpo , ngawang thinley lhundup , died at the age of 84 on 10 june 2005 .\n",
      "UBCP           => u c p c        || [43, 36, 21, 24, 0] \n",
      "                  tockar was nominated for the 2012 <SAMPLE> / actra best voice award .\n",
      "Rémy           => m e acute m m y || [35, 28, 121, 32, 86, 0] \n",
      "                  lothaire bluteau ( daniel ) catherine wilkening ( mireille ) johanne marie tremblay ( constance ) <SAMPLE> girard ( martin ) robert lepage ( rené ) gilles pelletier ( fr .\n",
      "www.cerambyx.uochb.cz => w w w dot h u dot c dot h m dot h dot b z dot h u b || [52, 52, 52, 74, 21, 28, 35, 22, 32, 36, 86, 97, 74, 43, 25, 21, 45, 36, 74, 21, 105, 0] \n",
      "                  acanthocinus henschi at <SAMPLE> .\n",
      "1413           => nineteen thirteen || [50, 49, 0] \n",
      "                  av 18 de juliotangueria el farolito : montevideo — juncal <SAMPLE> esq .\n"
     ]
    }
   ],
   "source": [
    "print_local_wrong_predictions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "310000   5% (  3m 51s)   0.376   |   0.04: FX -> f x (✓) (forcing)\n",
      "320000  10% (  7m 33s)   0.324   |   0.00: NFL -> n f l (✓) \n",
      "330000  15% ( 11m 19s)   0.332   |   0.00: Prologue -> prolog (✓) \n",
      "340000  20% (  15m 7s)   0.347   |   0.00: Theatre -> theater (✓) (forcing)\n",
      "350000  25% (  19m 2s)   0.340   |   0.00: 5 -> five (✓) (forcing)\n",
      "Saved model to data/models/whole_gen_10_after_words_attention_no_embd/350000_(EncoderRNN/DecoderRNN)\n",
      "Accuracy: 85.02% (    8502/   10000)\n",
      "360000  30% (  24m 1s)   0.302   |   0.00: FG -> f g (✓) \n",
      "370000  35% ( 27m 51s)   0.319   |   0.01: specialising -> specializing (✓) \n",
      "380000  40% ( 31m 41s)   0.349   |   1.04: Billboard.com -> b i o l b dot dot a (✗: [36, 31, 42, 42, 36, 25, 22, 35, 26, 74, 21, 25, 32, 0]) \n",
      "390000  45% ( 35m 20s)   0.266   |   1.56: lahistory.org -> l a s a t h y r g dot dot r g g (✗: [42, 22, 45, 31, 17, 30, 25, 35, 86, 74, 25, 35, 53, 0]) (forcing)\n",
      "400000  50% ( 39m 17s)   0.300   |   0.00: 1992 -> nineteen ninety two (✓) \n",
      "Saved model to data/models/whole_gen_10_after_words_attention_no_embd/400000_(EncoderRNN/DecoderRNN)\n",
      "Accuracy: 83.27% (    8327/   10000)\n",
      "410000  55% ( 44m 25s)   0.297   |   0.00: Authorised -> authorized (✓) \n",
      "420000  60% ( 48m 10s)   0.401   |   0.00: BC -> b c (✓) \n",
      "430000  65% ( 51m 58s)   0.320   |   0.17: TIV- -> t i v (✓) (forcing)\n",
      "440000  70% ( 55m 38s)   0.316   |   0.00: - -> to (✓) (forcing)\n",
      "450000  75% ( 59m 28s)   0.319   |   0.00: US -> u s (✓) \n",
      "Saved model to data/models/whole_gen_10_after_words_attention_no_embd/450000_(EncoderRNN/DecoderRNN)\n",
      "Accuracy: 84.14% (    8414/   10000)\n",
      "460000  80% ( 64m 41s)   0.337   |   0.00: & -> and (✓) \n",
      "470000  85% ( 68m 26s)   0.329   |   0.00: - -> to (✓) \n",
      "480000  90% ( 72m 19s)   0.348   |   0.98: BioLib.cz -> b i o l i b b dot c (✗: [36, 31, 25, 42, 31, 36, 74, 21, 105, 0]) \n",
      "490000  95% (  76m 6s)   0.363   |   0.17: CNF- -> c n f (✓) \n",
      "500000 100% ( 79m 53s)   0.333   |   0.32: SBB -> b b b (✗: [17, 36, 36, 0]) \n",
      "Saved model to data/models/whole_gen_10_after_words_attention_no_embd/500000_(EncoderRNN/DecoderRNN)\n",
      "Accuracy: 84.66% (    8466/   10000)\n"
     ]
    }
   ],
   "source": [
    "train_iterations(n_iters=200000, print_every=10000, teacher_forcing_ratio=0.3, lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2009-04-08     => the eighth of april two thousand eight || [11, 80, 12, 71, 5, 8, 15, 0] \n",
      "                  untalan , catherine ( <SAMPLE> ) .\n",
      "www.theinquirer.net/inquirer/news/2331280/nokia-imaging-sdk-set-for-android-nokia-x-platform => w w w dot s s s s s s s s s s s s s s s s || [52, 52, 52, 74, 30, 45, 28, 31, 29, 111, 43, 31, 35, 28, 35, 74, 29, 28, 30, 17, 42, 22, 17, 45, 31, 29, 111, 43, 31, 35, 28, 35, 17, 42, 22, 17, 45, 29, 28, 52, 17, 17, 42, 22, 17, 45, 30, 52, 25, 30, 45, 35, 28, 28, 30, 45, 35, 28, 28, 25, 29, 28, 30, 52, 25, 28, 31, 53, 45, 30, 25, 17, 42, 22, 17, 45, 29, 25, 59, 31, 22, 26, 22, 17, 45, 31, 32, 22, 53, 31, 29, 53, 26, 22, 17, 45, 17, 26, 59, 26, 22, 17, 45, 17, 28, 30, 26, 22, 17, 45, 37, 25, 35, 26, 22, 17, 45, 22, 29, 26, 35, 25, 31, 26, 26, 22, 17, 45, 29, 25, 59, 31, 22, 26, 22, 17, 45, 97, 26, 22, 17, 45, 24, 42, 22, 30, 37, 25, 35, 32, 0] \n",
      "                  ux checklist — nokia x design guidelines http : / / <SAMPLE> \" announcement of software update v . 1 . 2 . 4 . 1 / 1 . 2 . 4 . 21 \" .\n",
      "BobDylanRoots.com => b o l b a o t o s t s t dot c o m o m o o || [36, 25, 36, 26, 86, 42, 22, 29, 35, 25, 25, 30, 17, 74, 21, 25, 32, 0] \n",
      "                  retrieved 3 april 2014 john bauldie , wanted man : in search of bob dylan , london , 1990 , p . 37 , quoted at <SAMPLE> .\n",
      "Toutelatele.com => t o l l l l t e t e t dot c o m || [30, 25, 43, 30, 28, 42, 22, 30, 28, 42, 28, 74, 21, 25, 32, 0] \n",
      "                  neoranga , sur <SAMPLE> .\n",
      "Baseball-Reference.com => b a s b a l e e e e e e e e e e e e e e || [36, 22, 17, 28, 36, 22, 42, 42, 26, 22, 17, 45, 35, 28, 37, 28, 35, 28, 29, 21, 28, 74, 21, 25, 32, 0] \n",
      "                  <SAMPLE> — major league statistics and information .\n",
      "XIII           => the twenty     || [49, 0] \n",
      "                  estado linguistico da galiza e do noroeste de portugal desde o século <SAMPLE> ao século xvi .\n",
      "PKWARE         => p k k a r      || [24, 59, 52, 22, 35, 28, 0] \n",
      "                  header ids 0 - 31 are reserved for use by <SAMPLE> .\n",
      "$24,167        => two thousand seven hundred dollars || [6, 19, 8, 9, 10, 39, 18, 85, 0] \n",
      "                  the median income for a household in the cdp was <SAMPLE> , and the median income for a family was $23 , 958 .\n",
      "Ngobe          => n g o b e e    || [29, 53, 25, 36, 28, 0] \n",
      "                  noncomala was the main and creative deity of the ngabe of the <SAMPLE> buglé comarca in panama .\n",
      "http://stan4j.com/ => h t t p colon slash slash w w a n t com com com com com com com com || [45, 30, 30, 24, 129, 101, 101, 17, 30, 22, 29, 37, 25, 43, 35, 60, 74, 156, 101, 0] \n",
      "                  available at : <SAMPLE> .\n"
     ]
    }
   ],
   "source": [
    "print_local_wrong_predictions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "510000  10% (  3m 50s)   0.250   |   0.00: LPs -> l p's (✓) \n",
      "520000  20% (  7m 35s)   0.256   |   0.00: _ -> underscore (✓) \n",
      "530000  30% ( 11m 20s)   0.249   |   0.00: 350 -> three hundred fifty (✓) \n",
      "540000  40% ( 15m 19s)   0.251   |   0.00: - -> to (✓) (forcing)\n",
      "550000  50% (  19m 7s)   0.245   |   0.02: Chr -> c h r (✓) \n",
      "Saved model to data/models/whole_gen_10_after_words_attention_no_embd/550000_(EncoderRNN/DecoderRNN)\n",
      "Accuracy: 88.27% (    8827/   10000)\n",
      "560000  60% ( 24m 11s)   0.212   |   0.00: ltd -> limited (✓) (forcing)\n",
      "570000  70% ( 27m 56s)   0.254   |   0.00: LLC -> l l c (✓) \n",
      "580000  80% ( 31m 53s)   0.208   |   0.01: February 23, 2003 -> february twenty third two thousand three (✓) (forcing)\n",
      "590000  90% ( 35m 34s)   0.221   |   0.00: U.S. -> u s (✓) \n",
      "600000 100% ( 39m 24s)   0.209   |   0.00: November 18, 2014 -> november eighteenth twenty fourteen (✓) \n",
      "Saved model to data/models/whole_gen_10_after_words_attention_no_embd/600000_(EncoderRNN/DecoderRNN)\n",
      "Accuracy: 88.75% (    8875/   10000)\n"
     ]
    }
   ],
   "source": [
    "train_iterations(n_iters=100000, print_every=10000, teacher_forcing_ratio=0.5, lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "st             => saint          || [195, 0] \n",
      "                  new york : <SAMPLE> martin 's griffin , 1999 .\n",
      "Brno           => b r n n        || [36, 35, 29, 25, 0] \n",
      "                  in 2006 sor introduced in <SAMPLE> on autotec a completely new range of low floor buses .\n",
      "6.8 lbs        => six point eight nine || [20, 46, 16, 124, 0] \n",
      "                  released online on july 16 , 2009 , the inspiron 1750 is dell 's 17 . 3 \" budget laptop that weighs <SAMPLE> .\n",
      "Sports-Reference.com => s p o r t s d e s s e e e e e e e e dot c || [17, 24, 25, 35, 30, 17, 26, 22, 17, 45, 35, 28, 37, 28, 35, 28, 29, 21, 28, 74, 21, 25, 32, 0] \n",
      "                  <SAMPLE> , olympic sports , swimming at the 1948 london summer games , men 's 100 metres backstroke semi finals .\n",
      "art.thewalters.org/detail/26104/portrait-of-maria-salviati-de-medici-with-giulia-de-medici/http://www.artnews.com/2012/10/25/image-of-africans-in-western-art/http://www.neh.gov/humanities/2013/januaryfebruary/feature/faces-the-renaissanceLangdon => a a h h a s h a s h a s h a s h a s h a || [22, 35, 30, 74, 30, 45, 28, 52, 22, 42, 30, 28, 35, 17, 74, 25, 35, 53, 17, 42, 22, 17, 45, 26, 28, 30, 22, 31, 42, 17, 42, 22, 17, 45, 30, 52, 25, 17, 31, 97, 25, 29, 28, 25, 37, 25, 43, 35, 17, 42, 22, 17, 45, 24, 25, 35, 30, 35, 22, 31, 30, 26, 22, 17, 45, 25, 37, 26, 22, 17, 45, 32, 22, 35, 31, 22, 26, 22, 17, 45, 17, 22, 42, 54, 31, 22, 30, 31, 26, 22, 17, 45, 26, 28, 26, 22, 17, 45, 32, 28, 26, 31, 21, 31, 26, 22, 17, 45, 52, 31, 30, 45, 26, 22, 17, 45, 53, 31, 43, 42, 31, 22, 26, 22, 17, 45, 26, 28, 26, 22, 17, 45, 32, 28, 26, 31, 21, 31, 17, 42, 22, 17, 45, 45, 30, 30, 24, 21, 25, 42, 25, 29, 17, 42, 22, 17, 45, 17, 42, 22, 17, 45, 52, 52, 52, 74, 22, 35, 30, 29, 28, 52, 17, 74, 21, 25, 32, 17, 42, 22, 17, 45, 30, 52, 28, 29, 30, 86, 30, 52, 28, 42, 54, 28, 17, 42, 22, 17, 45, 30, 28, 29, 17, 42, 22, 17, 45, 30, 52, 28, 29, 30, 86, 37, 31, 54, 28, 17, 42, 22, 17, 45, 31, 32, 22, 53, 28, 26, 22, 17, 45, 25, 37, 26, 22, 17, 45, 22, 37, 35, 31, 21, 22, 29, 17, 26, 22, 17, 45, 31, 29, 26, 22, 17, 45, 52, 28, 17, 30, 28, 35, 29, 26, 22, 17, 45, 22, 35, 30, 17, 42, 22, 17, 45, 45, 30, 30, 24, 21, 25, 42, 25, 29, 17, 42, 22, 17, 45, 17, 42, 22, 17, 45, 52, 52, 52, 74, 29, 28, 45, 74, 53, 25, 54, 17, 42, 22, 17, 45, 45, 43, 32, 22, 29, 31, 30, 31, 28, 17, 17, 42, 22, 17, 45, 30, 52, 28, 29, 30, 86, 30, 45, 31, 35, 30, 28, 28, 29, 17, 42, 22, 17, 45, 60, 22, 29, 43, 22, 35, 86, 37, 28, 36, 35, 43, 22, 35, 86, 17, 42, 22, 17, 45, 37, 28, 22, 30, 43, 35, 28, 17, 42, 22, 17, 45, 37, 22, 21, 28, 17, 26, 22, 17, 45, 30, 45, 28, 26, 22, 17, 45, 35, 28, 29, 22, 31, 17, 17, 22, 29, 21, 28, 42, 22, 29, 53, 26, 25, 29, 0] \n",
      "                  uffizi gallery http : / / <SAMPLE> ( 2006 ) , p . 40 http : / / www . kleio . org / de / buecher / true _ faces _ medici . htmlhttp : / / www . kleio . org / de / buecher / true _ faces _ medici . htmlmurphy ( 2008 ) , p . 32 .\n",
      "http://www.smp.uq.edu.au/people/YoniNazarathy/teaching_projects/studentWork/EricOrjebin_TruncatedNormalMoments.pdf => h t t p colon slash slash w w w dot c o dot p r c o r a || [45, 30, 30, 24, 129, 101, 101, 52, 52, 52, 74, 17, 32, 24, 74, 43, 111, 74, 28, 26, 43, 74, 22, 43, 101, 24, 28, 25, 24, 42, 28, 101, 86, 25, 29, 31, 29, 22, 105, 22, 35, 22, 30, 45, 86, 101, 30, 28, 22, 21, 45, 31, 29, 53, 43, 29, 26, 28, 35, 17, 21, 25, 35, 28, 24, 35, 25, 60, 28, 21, 30, 17, 101, 17, 30, 43, 26, 28, 29, 30, 52, 25, 35, 59, 101, 28, 35, 31, 21, 25, 35, 60, 28, 36, 31, 29, 43, 29, 26, 28, 35, 17, 21, 25, 35, 28, 30, 35, 43, 29, 21, 22, 30, 28, 26, 29, 25, 35, 32, 22, 42, 32, 25, 32, 28, 29, 30, 17, 74, 24, 26, 37, 0] \n",
      "                  document by eric orjebin , \" <SAMPLE> \" kroese , d . p . ; taimre , t . ; botev , z . i . ( 2011 ) .\n",
      "http://online.vitalsource.com/books/978-1-58426-377-7/id/P2-206Marmor => h t t p colon slash slash w w w o o o o o o o o o o || [45, 30, 30, 24, 129, 101, 101, 25, 29, 42, 31, 29, 28, 74, 54, 31, 30, 22, 42, 17, 25, 43, 35, 21, 28, 74, 156, 101, 36, 25, 25, 59, 17, 101, 29, 31, 29, 28, 17, 28, 54, 28, 29, 28, 31, 53, 45, 30, 115, 25, 29, 28, 115, 37, 31, 54, 28, 28, 31, 53, 45, 30, 37, 25, 43, 35, 30, 52, 25, 17, 31, 97, 115, 30, 45, 35, 28, 28, 17, 28, 54, 28, 29, 17, 28, 54, 28, 29, 115, 17, 28, 54, 28, 29, 101, 31, 26, 101, 24, 30, 52, 25, 115, 30, 52, 25, 25, 17, 31, 97, 32, 22, 35, 32, 25, 35, 0] \n",
      "                  retrieved from <SAMPLE> , t . r . ( 2000 ) .\n",
      "Thecanadianencyclopedia.com => t e e a n d i n a d a c a n a n a p a dot || [30, 45, 28, 21, 22, 29, 22, 26, 31, 22, 29, 28, 29, 21, 86, 21, 42, 25, 24, 28, 26, 31, 22, 74, 21, 25, 32, 0] \n",
      "                  <SAMPLE> re ukrainian musical life in canada .\n",
      "EmersonKent.com => e m e k e r n n n n n dot c o m || [28, 32, 28, 35, 17, 25, 29, 59, 28, 29, 30, 74, 21, 25, 32, 0] \n",
      "                  \" timeline of the mexican revolution \" , <SAMPLE> .\n",
      "Amazon.de      => a m a z o n dot c o m || [22, 32, 22, 105, 25, 29, 74, 26, 28, 0] \n",
      "                  \" plastic beach : gorillaz : <SAMPLE> : musik \" .\n"
     ]
    }
   ],
   "source": [
    "print_local_wrong_predictions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "610000  10% (  3m 51s)   0.315   |   0.12: MR -> mister (✓) \n",
      "620000  20% (  7m 39s)   0.332   |   0.00: UK -> u k (✓) \n",
      "630000  30% ( 11m 22s)   0.367   |   0.04: MSF -> m s f (✓) \n",
      "640000  40% (  15m 6s)   0.305   |   0.00: - -> to (✓) \n",
      "650000  50% ( 18m 52s)   0.298   |   0.00: - -> to (✓) \n",
      "Saved model to data/models/whole_gen_10_after_words_attention_no_embd/650000_(EncoderRNN/DecoderRNN)\n",
      "Accuracy: 85.50% (    8550/   10000)\n",
      "660000  60% ( 23m 51s)   0.325   |   0.00: mr -> mister (✓) \n",
      "670000  70% ( 27m 43s)   0.305   |   0.83: I -> the (✗: [9, 0]) \n",
      "680000  80% ( 31m 23s)   0.331   |   0.28: 17 February 2014 -> the seventeenth of july twenty fourteen (✗: [11, 99, 12, 72, 6, 50, 0]) \n",
      "690000  90% ( 35m 10s)   0.300   |   0.00: TV -> t v (✓) \n",
      "700000 100% ( 38m 52s)   0.434   |   0.00: MP -> m p (✓) \n",
      "Saved model to data/models/whole_gen_10_after_words_attention_no_embd/700000_(EncoderRNN/DecoderRNN)\n",
      "Accuracy: 82.80% (    8280/   10000)\n"
     ]
    }
   ],
   "source": [
    "train_iterations(n_iters=100000, print_every=10000, teacher_forcing_ratio=0.1, lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://www.fishingworks.com/lakes/florida/polk/winter-haven/lake-connie/ => h t p colon dot slash dot dot dot dot w n n n n n n n n n || [45, 30, 30, 24, 129, 101, 101, 52, 52, 52, 74, 37, 31, 17, 45, 31, 29, 53, 52, 25, 35, 59, 17, 74, 156, 101, 42, 22, 59, 28, 17, 101, 37, 42, 25, 35, 31, 26, 22, 101, 24, 25, 42, 59, 101, 52, 31, 29, 30, 28, 35, 115, 45, 22, 54, 28, 29, 101, 42, 22, 59, 28, 115, 21, 25, 29, 29, 31, 28, 101, 0] \n",
      "                  fishing works website , http : / / www . fishingworks . com / lakes / florida / polk / winter - haven / lake - conine / and <SAMPLE> .\n",
      "LankaPage.com  => l a a a a a a a a a a a a a a a m a m a || [42, 22, 29, 59, 22, 24, 22, 53, 28, 74, 21, 25, 32, 0] \n",
      "                  gamini gunaratna , sri lanka news paper by <SAMPLE> ( llc ) - latest hot news from sri lanka ( 2009 - 09 - 06 ) .\n",
      "I/O            => one o          || [31, 25, 0] \n",
      "                  io . js , javascript <SAMPLE> , \" io . js has merged with the node . js project again .\n",
      "Reuters.com    => r e r e r e e e e e e e e e e e e e e e || [35, 28, 43, 30, 28, 35, 17, 74, 21, 25, 32, 0] \n",
      "                  \" newpark resources inc ( nr . n ) quote <SAMPLE> \" .\n",
      "1999-06-03     => the thirteenth nineteen ninety nine || [11, 76, 12, 68, 7, 23, 15, 0] \n",
      "                  mcclellan , jim ( <SAMPLE> ) .\n",
      "98.7           => ninety eight seven || [23, 16, 46, 18, 0] \n",
      "                  american journal of botany <SAMPLE> ( 2011 ) : 1164 - 1172 truswell , e . m . , and m . k . macphail .\n",
      "favoured       => r              || [297, 0] \n",
      "                  the british , with a strained economy and global commitments , <SAMPLE> unlimited cruiser tonnage but strict limits on the individual ships .\n",
      "Shefa          => s c e a        || [17, 45, 28, 37, 22, 0] \n",
      "                  an impressive synagogue was built , roads were constructed , and jewish agricultural settlements were founded at pekiin , <SAMPLE> ' amr , and kafr yasif .\n",
      "Absolutepunk.net => a l b e u e t e e e e e e e e e e e e e || [22, 36, 17, 25, 42, 43, 30, 28, 24, 43, 29, 59, 74, 29, 28, 30, 0] \n",
      "                  album review , the album projectalbum review , <SAMPLE> , may 7 , 2008 .\n",
      "IRT            => i r r          || [31, 35, 30, 0] \n",
      "                  34th street was a station on the demolished <SAMPLE> ninth avenue line .\n"
     ]
    }
   ],
   "source": [
    "print_local_wrong_predictions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "710000   5% (  3m 51s)   0.304   |   0.53: SKOT- -> s o o (✗: [17, 59, 25, 30, 0]) \n",
      "720000  10% (  7m 42s)   0.234   |   0.01: 1946 -> nineteen forty six (✓) \n",
      "730000  15% ( 11m 33s)   0.282   |   0.00: - -> to (✓) \n",
      "740000  20% ( 15m 21s)   0.223   |   0.08: # -> number (✓) \n",
      "750000  25% (  19m 9s)   0.237   |   0.00: H. -> h (✓) (forcing)\n",
      "Saved model to data/models/whole_gen_10_after_words_attention_no_embd/750000_(EncoderRNN/DecoderRNN)\n",
      "Accuracy: 87.40% (    8740/   10000)\n",
      "760000  30% ( 24m 11s)   0.256   |   0.00: 9 -> nine (✓) \n",
      "770000  35% (  28m 6s)   0.238   |   0.00: - -> to (✓) \n",
      "780000  40% ( 31m 51s)   0.285   |   2.77: http://www.fastcocreate.com/1679900/a-creative-movement-grows-in-brooklyn-mason-jar-brings-the-art-back-to-musicBrown -> h t t p colon slash slash w w w dot a a a a a a a dash a dash a dash a dash a dash a dash a dash a dash a dash a dash a dash dash a dash dash a dash dash a dash dash a dash dash a dash a dash dash a dash dash a dash dash dash a dash dash a dash dash a dash dash a dash dash a dash dash a dash dash a dash dash a dash dash a dash dash a dash dash a dash dash a dash dash a dash dash a dash dash a dash dash a dash dash a dash dash a dash dash a dash dash a dash dash a dash dash a dash dash (✗: [45, 30, 30, 24, 129, 101, 101, 52, 52, 52, 74, 37, 22, 17, 30, 21, 25, 21, 35, 28, 22, 30, 28, 74, 156, 101, 25, 29, 28, 17, 31, 97, 17, 28, 54, 28, 29, 29, 31, 29, 28, 29, 31, 29, 28, 25, 25, 101, 22, 115, 21, 35, 28, 22, 30, 31, 54, 28, 115, 32, 25, 54, 28, 32, 28, 29, 30, 115, 53, 35, 25, 52, 17, 115, 31, 29, 115, 36, 35, 25, 25, 59, 42, 86, 29, 115, 32, 22, 17, 25, 29, 115, 60, 22, 35, 115, 36, 35, 31, 29, 53, 17, 115, 30, 45, 28, 115, 22, 35, 30, 115, 36, 22, 21, 59, 115, 30, 25, 115, 32, 43, 17, 31, 21, 36, 35, 25, 52, 29, 0]) \n",
      "790000  45% ( 35m 38s)   0.285   |   0.05: Amazon.com -> a m a z o n dot c o m (✓) \n",
      "800000  50% ( 39m 22s)   0.328   |   0.03: SSAB -> s s a b (✓) \n",
      "Saved model to data/models/whole_gen_10_after_words_attention_no_embd/800000_(EncoderRNN/DecoderRNN)\n",
      "Accuracy: 87.96% (    8796/   10000)\n",
      "810000  55% ( 44m 25s)   0.226   |   0.02: 86 -> eighty six (✓) \n",
      "820000  60% (  48m 7s)   0.267   |   0.38: Forbes.com -> f o r e e s dot c o m (✗: [37, 25, 35, 36, 28, 17, 74, 21, 25, 32, 0]) \n",
      "830000  65% ( 51m 58s)   0.279   |   0.00: - -> to (✓) \n",
      "840000  70% ( 55m 45s)   0.180   |   0.00: NM -> n m (✓) \n",
      "850000  75% ( 59m 44s)   0.289   |   0.00: Oct 9, 2013 -> october ninth twenty thirteen (✓) \n",
      "Saved model to data/models/whole_gen_10_after_words_attention_no_embd/850000_(EncoderRNN/DecoderRNN)\n",
      "Accuracy: 88.47% (    8847/   10000)\n",
      "860000  80% ( 64m 47s)   0.276   |   0.00: etc -> etcetera (✓) \n",
      "870000  85% ( 68m 33s)   0.237   |   0.00: - -> to (✓) \n",
      "880000  90% ( 72m 23s)   0.287   |   0.00: & -> and (✓) (forcing)\n",
      "890000  95% ( 76m 14s)   0.235   |   0.00: RTL -> r t l (✓) \n",
      "900000 100% ( 79m 59s)   0.273   |   0.00: LJ -> l j (✓) \n",
      "Saved model to data/models/whole_gen_10_after_words_attention_no_embd/900000_(EncoderRNN/DecoderRNN)\n",
      "Accuracy: 88.46% (    8846/   10000)\n"
     ]
    }
   ],
   "source": [
    "train_iterations(n_iters=200000, print_every=10000, teacher_forcing_ratio=0.1, lr=0.0005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VII            => the            || [11, 82, 0] \n",
      "                  he was knighted at the coronation of edward <SAMPLE> .\n",
      "MPTW           => m p w w        || [32, 24, 30, 52, 0] \n",
      "                  following his death , there were several marks used to indicate that a tile had originated at <SAMPLE> .\n",
      "personalised   => r              || [592, 0] \n",
      "                  both plots contain standardised gravestones and do not allow <SAMPLE> memorials .\n",
      "DR             => drive          || [113, 0] \n",
      "                  \" lualua recalled to <SAMPLE> congo squad \" .\n",
      "d'Erf          => d e e r        || [26, 28, 35, 37, 0] \n",
      "                  \" dr percy charles edward <SAMPLE> wheeler ( 1859 - 1944 ) : a notable medical missionary of the holy land \" .\n",
      "bi.edu         => b i s e e u    || [36, 31, 74, 28, 26, 43, 0] \n",
      "                  randi lunnan appointed professor of strategy at <SAMPLE> , nv / 6 , 2008 .\n",
      "ustravelweather.com => u h u h a l a r r e e e e dot c o c o m || [43, 17, 30, 35, 22, 54, 28, 42, 52, 28, 22, 30, 45, 28, 35, 74, 21, 25, 32, 0] \n",
      "                  \" average weather for cairo , il \" , weather . com \" chicago weather \" , ustravelweather . com \" \" , weather . com \" moline weather \" , ustravelweather . com \" peoria weather \" , <SAMPLE> \" rockford weather \" , ustravelweather . com \" springfield weather \" , ustravelweather . comtammy webber ( the associated press ) ( 2002 - 01 - 13 ) .\n",
      "GFW's          => g f s's        || [53, 37, 290, 0] \n",
      "                  it was unveiled on october 23 , 2015 at the taping of <SAMPLE> television program amped .\n",
      "Antonovich.com => a n v o n n n n n c c o o || [22, 29, 30, 25, 29, 25, 54, 31, 21, 45, 74, 21, 25, 32, 0] \n",
      "                  <SAMPLE> : los angeles county fifth district ; supervisor michael d . antonovich .\n",
      "$26            => twenty twenty six || [6, 20, 85, 0] \n",
      "                  shares sharply rose 19% by the end of the trading day to $35 . 01 a share , up from <SAMPLE> .\n"
     ]
    }
   ],
   "source": [
    "print_local_wrong_predictions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "910000   3% (  3m 44s)   0.249   |   0.00: : -> to (✓) \n",
      "920000   7% (  7m 31s)   0.198   |   2.32: $40,929 -> twenty nine thousand nine nine nine nine dollars (✗: [41, 8, 15, 10, 6, 15, 85, 0]) \n",
      "930000  10% ( 11m 23s)   0.215   |   0.00: ave -> avenue (✓) (forcing)\n",
      "940000  13% ( 15m 11s)   0.223   |   0.15: Huo -> h u o (✓) \n",
      "950000  17% ( 18m 57s)   0.188   |   0.00: CRA -> c r a (✓) (forcing)\n",
      "Saved model to data/models/whole_gen_10_after_words_attention_no_embd/950000_(EncoderRNN/DecoderRNN)\n",
      "Accuracy: 88.82% (    8882/   10000)\n",
      "960000  20% (  24m 9s)   0.226   |   0.08: 1231 -> twelve thirty one (✓) \n",
      "970000  23% (  28m 3s)   0.234   |   8.87: ctr -> circle (✗: [110, 0]) \n",
      "980000  27% ( 31m 46s)   0.165   |   0.01: MAcc -> m a c c (✓) \n",
      "990000  30% ( 35m 48s)   0.183   |   0.00: AOL -> a o l (✓) \n",
      "1000000  33% ( 39m 33s)   0.206   |   0.00: 1 -> one (✓) \n",
      "Saved model to data/models/whole_gen_10_after_words_attention_no_embd/1000000_(EncoderRNN/DecoderRNN)\n",
      "Accuracy: 89.60% (    8960/   10000)\n",
      "1010000  37% ( 44m 57s)   0.244   |   0.00: & -> and (✓) (forcing)\n",
      "1020000  40% ( 48m 48s)   0.237   |   0.00: & -> and (✓) \n",
      "1030000  43% ( 52m 32s)   0.192   |   0.00: - -> to (✓) \n",
      "1040000  47% ( 56m 18s)   0.163   |   0.00: Centre -> center (✓) \n",
      "1050000  50% (  60m 8s)   0.190   |   0.05: 135th -> one hundred thirty fifth (✓) \n",
      "Saved model to data/models/whole_gen_10_after_words_attention_no_embd/1050000_(EncoderRNN/DecoderRNN)\n",
      "Accuracy: 89.44% (    8944/   10000)\n",
      "1060000  53% (  65m 9s)   0.182   |   0.03: 1988 -> nineteen eighty eight (✓) (forcing)\n",
      "1070000  57% ( 68m 51s)   0.165   |   0.00: & -> and (✓) \n",
      "1080000  60% ( 72m 46s)   0.146   |   0.00: & -> and (✓) \n",
      "1090000  63% ( 76m 29s)   0.228   |   0.00: O- -> o (✓) \n",
      "1100000  67% ( 80m 20s)   0.229   |   0.00: Bhd -> b h d (✓) \n",
      "Saved model to data/models/whole_gen_10_after_words_attention_no_embd/1100000_(EncoderRNN/DecoderRNN)\n",
      "Accuracy: 89.80% (    8980/   10000)\n",
      "1110000  70% ( 85m 24s)   0.178   |   0.00: PDF -> p d f (✓) \n",
      "1120000  73% ( 89m 13s)   0.150   |   0.00: A. -> a (✓) \n",
      "1130000  77% (  93m 2s)   0.235   |   0.00: & -> and (✓) \n",
      "1140000  80% ( 96m 55s)   0.211   |   0.00: L.P. -> l p (✓) \n",
      "1150000  83% (100m 50s)   0.224   |   0.00: recognised -> recognized (✓) (forcing)\n",
      "Saved model to data/models/whole_gen_10_after_words_attention_no_embd/1150000_(EncoderRNN/DecoderRNN)\n",
      "Accuracy: 90.09% (    9009/   10000)\n",
      "1160000  87% (105m 58s)   0.225   |   0.00: - -> to (✓) \n",
      "1170000  90% (109m 46s)   0.176   |   0.00: July 1873 -> july eighteen seventy three (✓) (forcing)\n",
      "1180000  93% (113m 26s)   0.191   |   0.00: & -> and (✓) (forcing)\n",
      "1190000  97% (117m 17s)   0.216   |   0.00: June 15, 2011 -> june fifteenth twenty eleven (✓) \n",
      "1200000 100% ( 121m 7s)   0.191   |   0.00: mr -> mister (✓) \n",
      "Saved model to data/models/whole_gen_10_after_words_attention_no_embd/1200000_(EncoderRNN/DecoderRNN)\n",
      "Accuracy: 89.89% (    8989/   10000)\n"
     ]
    }
   ],
   "source": [
    "train_iterations(n_iters=300000, print_every=10000, teacher_forcing_ratio=0.1, lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1-4.pmd        => o t n e e e e e a p e p d p p p d p || [25, 29, 28, 26, 22, 17, 45, 37, 25, 43, 35, 74, 24, 32, 26, 0] \n",
      "                  \" chapter <SAMPLE> \" ( pdf ) .\n",
      "97.5m          => ninety seven point five million || [23, 18, 46, 14, 108, 0] \n",
      "                  at the time of its completion , the jfk tower , at 320 feet ( <SAMPLE> ) , was the world 's tallest control tower .\n",
      "Saltdean.info  => s a d e d a n i n n n dot n || [17, 22, 42, 30, 26, 28, 22, 29, 74, 31, 29, 37, 25, 0] \n",
      "                  <SAMPLE> retrieved 17 august 2012 .\n",
      "ScotlandCT.org => s c o t t a d d t t dot o t g || [17, 21, 25, 30, 42, 22, 29, 26, 21, 30, 74, 25, 35, 53, 0] \n",
      "                  about scotland , ct , <SAMPLE> .\n",
      "reorganising   => neighboring    || [741, 0] \n",
      "                  they embarked on an unprecedented and aggressive revenue drive by restructuring , <SAMPLE> and re engineering the board of inland revenue .\n",
      "http://www.ticotimes.net/dailyarchive/2004_07/Week5/07_29_04.htm#story4 => h t t p colon slash slash w w w dot e e e e e e e e e || [45, 30, 30, 24, 129, 101, 101, 52, 52, 52, 74, 30, 31, 21, 25, 30, 31, 32, 28, 17, 74, 29, 28, 30, 101, 26, 22, 31, 42, 86, 22, 35, 21, 45, 31, 54, 28, 101, 30, 52, 25, 25, 25, 37, 25, 43, 35, 43, 29, 26, 28, 35, 17, 21, 25, 35, 28, 25, 17, 28, 54, 28, 29, 101, 52, 28, 28, 59, 37, 31, 54, 28, 101, 25, 17, 28, 54, 28, 29, 43, 29, 26, 28, 35, 17, 21, 25, 35, 28, 30, 52, 28, 29, 30, 86, 29, 31, 29, 28, 43, 29, 26, 28, 35, 17, 21, 25, 35, 28, 25, 37, 25, 43, 35, 74, 45, 30, 32, 175, 17, 30, 25, 35, 86, 37, 25, 43, 35, 0] \n",
      "                  tico times online daily <SAMPLE> .\n",
      "86.2%          => eighty six point six percent || [27, 20, 46, 5, 83, 0] \n",
      "                  it makes up <SAMPLE> of hong kong 's territory , and contains around half of the population of hong kong .\n",
      "Fsumonitor.com => f h u s o s i r t r dot c o m || [37, 17, 43, 32, 25, 29, 31, 30, 25, 35, 74, 21, 25, 32, 0] \n",
      "                  <SAMPLE> ( 15 january 2014 ) .\n",
      "https://familysearch.org/pal:/MM9.1.1/FGN1-Q53 => h t t p colon slash slash m e e e e e e e e e e e e || [45, 30, 30, 24, 17, 129, 101, 101, 37, 22, 32, 31, 42, 86, 17, 28, 22, 35, 21, 45, 74, 25, 35, 53, 101, 24, 22, 42, 129, 101, 32, 32, 29, 31, 29, 28, 74, 25, 29, 28, 74, 25, 29, 28, 101, 37, 53, 29, 25, 29, 28, 115, 111, 37, 31, 37, 30, 86, 30, 45, 35, 28, 28, 0] \n",
      "                  retrieved 8 november 2012 ; familysearch . org , india , marriages , 1792 - 1948 , at <SAMPLE> .\n",
      "Audimated.com  => a u d i a d d a e dot c o m || [22, 43, 26, 31, 32, 22, 30, 28, 26, 74, 21, 25, 32, 0] \n",
      "                  <SAMPLE> simply offers a platform to increase awareness and interest in independent music .\n"
     ]
    }
   ],
   "source": [
    "print_local_wrong_predictions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1210000   3% (  3m 51s)   0.222   |   1.41: icloud.com -> i l l o c c dot dot c o m (✗: [31, 21, 42, 25, 43, 26, 74, 21, 25, 32, 0]) \n",
      "1220000   7% (  7m 43s)   0.254   |   0.00: & -> and (✓) \n",
      "1230000  10% ( 11m 27s)   0.232   |   0.00: March 3, 1909 -> march third nineteen o nine (✓) \n",
      "1240000  13% ( 15m 11s)   0.200   |   1.14: RnR -> r r r (✗: [35, 29, 35, 0]) \n",
      "1250000  17% ( 18m 59s)   0.218   |   0.00: USA -> u s a (✓) \n",
      "Saved model to data/models/whole_gen_10_after_words_attention_no_embd/1250000_(EncoderRNN/DecoderRNN)\n",
      "Accuracy: 88.31% (    8831/   10000)\n",
      "1260000  20% (  24m 2s)   0.224   |   0.00: 1909 -> nineteen o nine (✓) \n",
      "1270000  23% ( 27m 41s)   0.311   |   0.00: 1995 -> nineteen ninety five (✓) \n",
      "1280000  27% ( 31m 23s)   0.246   |   0.00: vol -> volume (✓) \n",
      "1290000  30% ( 35m 12s)   0.236   |   0.00: CA -> c a (✓) \n",
      "1300000  33% ( 38m 57s)   0.240   |   1.76: (1995) 29 -> nine nine nine nine nine nine nine (✗: [9, 15, 15, 14, 58, 5, 15, 0]) \n",
      "Saved model to data/models/whole_gen_10_after_words_attention_no_embd/1300000_(EncoderRNN/DecoderRNN)\n",
      "Accuracy: 88.47% (    8847/   10000)\n",
      "1310000  37% (  44m 0s)   0.230   |   1.66: HamptonRoads.com -> h a a p o p o a a s s s dot dot c m m (✗: [45, 22, 32, 24, 30, 25, 29, 35, 25, 22, 26, 17, 74, 21, 25, 32, 0]) \n",
      "1320000  40% ( 47m 48s)   0.248   |   0.00: etc -> etcetera (✓) \n",
      "1330000  43% ( 51m 33s)   0.267   |   0.00: - -> to (✓) \n",
      "1340000  47% ( 55m 24s)   0.225   |   0.00: CBS -> c b s (✓) \n",
      "1350000  50% (  59m 6s)   0.220   |   0.00: 38th -> thirty eighth (✓) \n",
      "Saved model to data/models/whole_gen_10_after_words_attention_no_embd/1350000_(EncoderRNN/DecoderRNN)\n",
      "Accuracy: 88.61% (    8861/   10000)\n",
      "1360000  53% ( 64m 22s)   0.233   |   0.00: behaviour -> behavior (✓) \n",
      "1370000  57% (  68m 7s)   0.241   |   0.00: C.T. -> c t (✓) \n",
      "1380000  60% ( 71m 49s)   0.240   |   0.00: nr -> n r (✓) \n",
      "1390000  63% ( 75m 33s)   0.212   |   0.02: 616 -> six hundred sixteen (✓) \n",
      "1400000  67% ( 79m 23s)   0.247   |   0.00: 2008 -> two thousand eight (✓) \n",
      "Saved model to data/models/whole_gen_10_after_words_attention_no_embd/1400000_(EncoderRNN/DecoderRNN)\n",
      "Accuracy: 88.33% (    8833/   10000)\n",
      "1410000  70% ( 84m 26s)   0.258   |   1.13: 1402 -> fourteen hundred two (✗: [50, 25, 5, 0]) \n",
      "1420000  73% (  88m 9s)   0.224   |   0.00: & -> and (✓) \n",
      "1430000  77% (  92m 0s)   0.206   |   0.01: 2002 -> two thousand two (✓) \n",
      "1440000  80% ( 95m 41s)   0.241   |   0.00: sr -> senior (✓) \n",
      "1450000  83% ( 99m 26s)   0.229   |   0.00: US -> u s (✓) \n",
      "Saved model to data/models/whole_gen_10_after_words_attention_no_embd/1450000_(EncoderRNN/DecoderRNN)\n",
      "Accuracy: 89.80% (    8980/   10000)\n",
      "1460000  87% (104m 34s)   0.201   |   0.00: 1709 -> seventeen o nine (✓) \n",
      "1470000  90% (108m 25s)   0.256   |   0.00: x  -> by (✓) \n",
      "1480000  93% (112m 16s)   0.272   |   0.00: Honourable -> honorable (✓) \n",
      "1490000  97% (116m 12s)   0.225   |   0.00: 1919 -> nineteen nineteen (✓) \n",
      "1500000 100% ( 120m 0s)   0.216   |   0.00: theatre -> theater (✓) \n",
      "Saved model to data/models/whole_gen_10_after_words_attention_no_embd/1500000_(EncoderRNN/DecoderRNN)\n",
      "Accuracy: 89.73% (    8973/   10000)\n"
     ]
    }
   ],
   "source": [
    "train_iterations(n_iters=300000, print_every=10000, teacher_forcing_ratio=0, lr=0.0005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1989           => nineteen eighty nine || [9, 8, 15, 10, 27, 15, 0] \n",
      "                  \" estadisticas liga acb 1988 - <SAMPLE> : cai zaragoza \" .\n",
      "musicalsaustralia.com => m u s a a a a a a a a a a a a a a a a c || [32, 43, 17, 31, 21, 22, 42, 17, 22, 43, 17, 30, 35, 22, 42, 31, 22, 74, 21, 25, 32, 0] \n",
      "                  carousel has a new billy bigelow — david campbell <SAMPLE> ; accessed 31 may 2015 .\n",
      "soccerbase.comDavid => s o c c c c c c c c c a a a a a a a a a || [17, 25, 21, 21, 28, 35, 36, 22, 17, 28, 74, 21, 25, 32, 26, 22, 54, 31, 26, 0] \n",
      "                  peter jones referee statistics at <SAMPLE> elleray describes peter jones as one of his ' biggest influences' .\n",
      "Visualiser     => c's            || [1026, 0] \n",
      "                  time space <SAMPLE> issue 3 .\n",
      "NostalgieDom.fr => n o s t s f a a a d r r r r || [29, 25, 17, 30, 22, 42, 53, 31, 28, 26, 25, 32, 74, 37, 35, 0] \n",
      "                  \" <SAMPLE> : le site radio des années de légende — tubes , stars cultes , années 80 , biographies artistes \" .\n",
      "NYPress.com    => n y y r e s s s c o o || [29, 86, 24, 35, 28, 17, 17, 74, 21, 25, 32, 0] \n",
      "                  \" pressed for time : molly davies' traditions , inventions , exchange \" , <SAMPLE> .\n",
      "linkedin.com   => l i n n i e i n dot o o || [42, 31, 29, 59, 28, 26, 31, 29, 74, 21, 25, 32, 0] \n",
      "                  senior researcher \" at <SAMPLE> , 2015 euro mini conference graz 2013 , at eurominiconferencegraz2013 . wordpress . com .\n",
      "GlobalSecurity.org => g l o b o b l l r r r r r r r r dot o r || [53, 42, 25, 36, 22, 42, 17, 28, 21, 43, 35, 31, 30, 86, 74, 25, 35, 53, 0] \n",
      "                  \" <SAMPLE> : m 830 a 1 high explosive anti tank multi purpose — tracer ( heat mp - t ) \" .\n",
      "Deadline.com   => d e a d a a a n dot c o m || [26, 28, 22, 26, 42, 31, 29, 28, 74, 21, 25, 32, 0] \n",
      "                  in january 2016 , <SAMPLE> reported that lourd would return for season 2 of scream queens .\n",
      "soapoperadigest.com => s o a p a a a a d d e e e dot dot c o o || [17, 25, 22, 24, 25, 24, 28, 35, 22, 26, 31, 53, 28, 17, 30, 74, 21, 25, 32, 0] \n",
      "                  soap opera digest ( <SAMPLE> .\n"
     ]
    }
   ],
   "source": [
    "print_local_wrong_predictions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1510000   5% (  3m 53s)   0.211   |   0.00: - -> to (✓) \n",
      "1520000  10% (  7m 46s)   0.216   |   0.02: 24.1 -> twenty four point one (✓) \n",
      "1530000  15% ( 11m 36s)   0.206   |   0.00: LP -> l p (✓) \n",
      "1540000  20% ( 15m 21s)   0.195   |   0.00: - -> to (✓) \n",
      "1550000  25% ( 19m 10s)   0.206   |   0.00: SZ -> s z (✓) \n",
      "Saved model to data/models/whole_gen_10_after_words_attention_no_embd/1550000_(EncoderRNN/DecoderRNN)\n",
      "Accuracy: 88.93% (    8893/   10000)\n",
      "1560000  30% ( 24m 21s)   0.216   |   0.02: 2010 -> twenty ten (✓) \n",
      "1570000  35% ( 28m 14s)   0.162   |   0.00: & -> and (✓) \n",
      "1580000  40% (  32m 1s)   0.167   |   0.00: & -> and (✓) \n",
      "1590000  45% ( 35m 54s)   0.207   |   0.95: Britannica.com -> b r i n a n a a a a dot c c m (✗: [36, 35, 31, 30, 22, 29, 29, 31, 21, 22, 74, 21, 25, 32, 0]) \n",
      "1600000  50% ( 39m 41s)   0.172   |   0.00: MTS -> m t s (✓) \n",
      "Saved model to data/models/whole_gen_10_after_words_attention_no_embd/1600000_(EncoderRNN/DecoderRNN)\n",
      "Accuracy: 89.97% (    8997/   10000)\n",
      "1610000  55% ( 44m 50s)   0.202   |   0.00: UPO -> u p o (✓) \n",
      "1620000  60% ( 48m 41s)   0.164   |   0.00: Theatre -> theater (✓) \n",
      "1630000  65% ( 52m 30s)   0.205   |   0.00: U.N.C.L.E. -> uncle (✓) \n",
      "1640000  70% ( 56m 20s)   0.227   |   0.01: 66 -> sixty six (✓) \n",
      "1650000  75% ( 60m 22s)   0.204   |   0.00: honours -> honors (✓) \n",
      "Saved model to data/models/whole_gen_10_after_words_attention_no_embd/1650000_(EncoderRNN/DecoderRNN)\n",
      "Accuracy: 90.69% (    9069/   10000)\n",
      "1660000  80% ( 65m 29s)   0.266   |   1.57: TheDenverChannel.com -> t h e d e n n n n n n n n n n n dot dot c (✗: [30, 45, 28, 26, 28, 29, 54, 28, 35, 21, 45, 22, 29, 29, 28, 42, 74, 21, 25, 32, 0]) \n",
      "1670000  85% ( 69m 19s)   0.189   |   0.00: 1997 -> nineteen ninety seven (✓) \n",
      "1680000  90% (  73m 9s)   0.227   |   0.00: ltd -> limited (✓) \n",
      "1690000  95% (  77m 5s)   0.179   |   0.00: jr -> junior (✓) \n",
      "1700000 100% ( 80m 50s)   0.223   |   0.00: favour -> favor (✓) \n",
      "Saved model to data/models/whole_gen_10_after_words_attention_no_embd/1700000_(EncoderRNN/DecoderRNN)\n",
      "Accuracy: 90.09% (    9009/   10000)\n"
     ]
    }
   ],
   "source": [
    "train_iterations(n_iters=200000, print_every=10000, teacher_forcing_ratio=0, lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "II             => two            || [11, 73, 0] \n",
      "                  once a grand duchess : xenia , sister of nicholas <SAMPLE> .\n",
      "e1.ru          => e e e dot e r  || [28, 25, 29, 28, 74, 35, 43, 0] \n",
      "                  \" <SAMPLE> site info \" .\n",
      "nazw           => z a z e        || [29, 22, 105, 52, 0] \n",
      "                  wykaz urzedowych <SAMPLE> miejscowosci w polsce .\n",
      "News.Ops.gov.ph => n e s s dot s dot dot dot p p dot p || [29, 28, 52, 17, 74, 25, 24, 17, 74, 53, 25, 54, 74, 24, 45, 0] \n",
      "                  \" the thomasites : an army like no other \" , <SAMPLE> october 12 , 2003 counts , george ( october 1925 ) .\n",
      "Amazon.co.uk   => a m a z o n dot c dot dot u k k || [22, 32, 22, 105, 25, 29, 74, 21, 25, 74, 43, 59, 0] \n",
      "                  silent thunder at amazon \" a game of two halves : the autobiography : <SAMPLE> : archie macpherson : books \" .\n",
      "Année          => a n n e acute acute || [22, 29, 29, 28, 121, 28, 0] \n",
      "                  \" le conservatisme eclairé de rivarol , \" revue d' histoire littéraire de la france , 90 e <SAMPLE> , no\n",
      "SorelTracyRegion.net => s o r e e e r r y r r t t t t dot n t t t || [17, 25, 35, 28, 42, 30, 35, 22, 21, 86, 35, 28, 53, 31, 25, 29, 74, 29, 28, 30, 0] \n",
      "                  scrutin québécois du 14 avril , <SAMPLE> , 2003 , accessed 5 january 2010 .\n",
      "22             => twenty two     || [5, 5, 0] \n",
      "                  dodonaea petiolaris yields the diterpene ent 3 β - acetoxy 15 , 16 - epoxylabda - 8 ( 17 ) , 13 ( 16 ) , 14 - trien 18 - oic acid ( c <SAMPLE> h 28 o 6 ) or its enantiomer .\n",
      "July 11, 1860  => july eleventh eighteen sixty nine || [67, 92, 40, 39, 0] \n",
      "                  his inauguration took place <SAMPLE> and directly thereafter he submitted his resignation to the board .\n",
      "480 km2        => four hundred eighty kilometers || [19, 10, 27, 106, 89, 0] \n",
      "                  some <SAMPLE> ( 185 sq mi ) of land along the border were swapped between poland and the soviet union .\n"
     ]
    }
   ],
   "source": [
    "print_local_wrong_predictions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1710000   2% (  3m 53s)   0.233   |   0.00: & -> and (✓) \n",
      "1720000   4% (  7m 43s)   0.164   |   0.00: 2000 -> two thousand (✓) \n",
      "1730000   6% ( 11m 36s)   0.189   |   0.04: Generalised -> generalized (✓) \n",
      "1740000   8% ( 15m 21s)   0.186   |   0.45: USATODAY.com -> u s a t a d y y dot c o m (✗: [43, 17, 22, 30, 25, 26, 22, 86, 74, 21, 25, 32, 0]) \n",
      "1750000  10% ( 19m 19s)   0.221   |   0.01: 1996 -> nineteen ninety six (✓) \n",
      "Saved model to data/models/whole_gen_10_after_words_attention_no_embd/1750000_(EncoderRNN/DecoderRNN)\n",
      "Accuracy: 90.71% (    9071/   10000)\n",
      "1760000  12% ( 24m 26s)   0.151   |   0.00: U.S. -> u s (✓) \n",
      "1770000  14% ( 28m 25s)   0.198   |   0.00: TV -> t v (✓) \n",
      "1780000  16% ( 32m 26s)   0.185   |   0.00: 1851 -> eighteen fifty one (✓) \n",
      "1790000  18% ( 36m 15s)   0.191   |   0.20: Amazon.co.uk -> a m a z o n dot c o dot u k (✓) \n",
      "1800000  20% (  40m 8s)   0.180   |   0.00: - -> to (✓) \n",
      "Saved model to data/models/whole_gen_10_after_words_attention_no_embd/1800000_(EncoderRNN/DecoderRNN)\n",
      "Accuracy: 89.96% (    8996/   10000)\n",
      "1810000  22% ( 45m 21s)   0.181   |   0.00: 234 -> two hundred thirty four (✓) \n",
      "1820000  24% ( 49m 11s)   0.134   |   0.00: 1 -> one (✓) \n",
      "1830000  26% ( 53m 10s)   0.160   |   0.00: & -> and (✓) \n",
      "1840000  28% ( 56m 57s)   0.171   |   0.00: Centre -> center (✓) \n",
      "1850000  30% ( 60m 53s)   0.165   |   0.07: OMTP -> o m t p (✓) \n",
      "Saved model to data/models/whole_gen_10_after_words_attention_no_embd/1850000_(EncoderRNN/DecoderRNN)\n",
      "Accuracy: 90.26% (    9026/   10000)\n",
      "1860000  32% (  66m 5s)   0.184   |   0.00: - -> to (✓) \n",
      "1870000  34% ( 69m 56s)   0.188   |   0.00: gp -> g p (✓) \n",
      "1880000  36% ( 73m 54s)   0.166   |   2.14: Answers.comUniversity -> a n s e s s s s dot s s s s s s s i i i s (✗: [22, 29, 17, 52, 28, 35, 17, 74, 21, 25, 32, 43, 29, 31, 54, 28, 35, 17, 31, 30, 86, 0]) \n",
      "1890000  38% ( 77m 42s)   0.146   |   0.00: café -> cafe (✓) \n",
      "1900000  40% ( 81m 35s)   0.188   |   0.00: & -> and (✓) \n",
      "Saved model to data/models/whole_gen_10_after_words_attention_no_embd/1900000_(EncoderRNN/DecoderRNN)\n",
      "Accuracy: 90.92% (    9092/   10000)\n",
      "1910000  42% (  87m 3s)   0.207   |   0.00: 31 July 1956 -> the thirty first of july nineteen fifty six (✓) \n",
      "1920000  44% ( 91m 12s)   0.207   |   0.00: vol -> volume (✓) \n",
      "1930000  46% ( 95m 19s)   0.181   |   0.01: NCAP's -> n c a p's (✓) \n",
      "1940000  48% ( 99m 15s)   0.174   |   0.01: 95 -> ninety five (✓) \n",
      "1950000  50% (103m 17s)   0.128   |   0.02: 2016 -> twenty sixteen (✓) \n",
      "Saved model to data/models/whole_gen_10_after_words_attention_no_embd/1950000_(EncoderRNN/DecoderRNN)\n",
      "Accuracy: 90.50% (    9050/   10000)\n",
      "1960000  52% (108m 43s)   0.168   |   0.00: 1 -> one (✓) \n",
      "1970000  54% (112m 40s)   0.156   |   0.02: 2010 -> twenty ten (✓) \n",
      "1980000  56% (116m 40s)   0.142   |   0.00: 3 -> three (✓) \n",
      "1990000  58% (120m 39s)   0.219   |   0.00: Honour -> honor (✓) \n",
      "2000000  60% (124m 33s)   0.176   |   0.00: 22 -> twenty two (✓) \n",
      "Saved model to data/models/whole_gen_10_after_words_attention_no_embd/2000000_(EncoderRNN/DecoderRNN)\n",
      "Accuracy: 90.42% (    9042/   10000)\n",
      "2010000  62% (129m 53s)   0.212   |   0.00: tv -> t v (✓) \n",
      "2020000  64% ( 134m 9s)   0.208   |   0.00: & -> and (✓) \n",
      "2030000  66% (138m 20s)   0.185   |   0.00: NY -> n y (✓) \n",
      "2040000  68% (142m 29s)   0.180   |   0.00: PH -> p h (✓) \n",
      "2050000  70% (146m 39s)   0.194   |   0.00: SSBN- -> s s b n (✓) \n",
      "Saved model to data/models/whole_gen_10_after_words_attention_no_embd/2050000_(EncoderRNN/DecoderRNN)\n",
      "Accuracy: 90.98% (    9098/   10000)\n",
      "2060000  72% (152m 12s)   0.164   |   0.00: no -> number (✓) \n",
      "2070000  74% (156m 28s)   0.176   |   0.00: criticised -> criticized (✓) \n",
      "2080000  76% (160m 39s)   0.170   |   7.16: 283 -> two hundred eighty three (✗: [5, 16, 13, 0]) \n",
      "2090000  78% (164m 41s)   0.151   |   0.00: & -> and (✓) \n",
      "2100000  80% (168m 48s)   0.170   |   0.00: 9 -> nine (✓) \n",
      "Saved model to data/models/whole_gen_10_after_words_attention_no_embd/2100000_(EncoderRNN/DecoderRNN)\n",
      "Accuracy: 91.87% (    9187/   10000)\n",
      "2110000  82% (174m 18s)   0.206   |   0.00: 11 -> eleven (✓) \n",
      "2120000  84% (178m 33s)   0.192   |   0.00: JR -> junior (✓) \n",
      "2130000  86% (182m 57s)   0.157   |   1.52: Uglybridges.com -> u g l y b g g g g e s s dot c o m (✗: [43, 53, 42, 86, 36, 35, 31, 26, 53, 28, 17, 74, 21, 25, 32, 0]) \n",
      "2140000  88% (186m 59s)   0.182   |   0.00: HIV- -> h i v (✓) \n",
      "2150000  90% (191m 14s)   0.145   |   0.00: & -> and (✓) \n",
      "Saved model to data/models/whole_gen_10_after_words_attention_no_embd/2150000_(EncoderRNN/DecoderRNN)\n",
      "Accuracy: 90.57% (    9057/   10000)\n",
      "2160000  92% (196m 54s)   0.193   |   0.00: & -> and (✓) \n",
      "2170000  94% (201m 12s)   0.167   |   0.00: .5 -> point five (✓) \n",
      "2180000  96% (205m 28s)   0.192   |   0.00: FIA -> f i a (✓) \n",
      "2190000  98% (209m 41s)   0.188   |   0.00: D.C. -> d c (✓) \n",
      "2200000 100% (214m 19s)   0.185   |   0.00: 31 December 1957 -> the thirty first of december nineteen fifty seven (✓) \n",
      "Saved model to data/models/whole_gen_10_after_words_attention_no_embd/2200000_(EncoderRNN/DecoderRNN)\n",
      "Accuracy: 90.84% (    9084/   10000)\n"
     ]
    }
   ],
   "source": [
    "train_iterations(n_iters=500000, print_every=10000, teacher_forcing_ratio=0, lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bibliotheek.nl => b i b l b l o t e e e e e e || [36, 31, 36, 42, 31, 25, 30, 45, 28, 28, 59, 74, 29, 42, 0] \n",
      "                  \" jacq vogelaar overleden — <SAMPLE> \" ( in dutch ) .\n",
      "Fotopic.net    => f o n o o p dot dot n e t || [37, 25, 30, 25, 24, 31, 21, 74, 29, 28, 30, 0] \n",
      "                  <SAMPLE> offered a free account or premium services that added various features .\n",
      "6.80 km²       => six point six six square kilometers || [20, 46, 16, 25, 106, 89, 0] \n",
      "                  the population in 2011 was 1 , 749 , in an area of <SAMPLE> .\n",
      "Uglybridges.com => u g l b b g g g e s s dot c m || [43, 53, 42, 86, 36, 35, 31, 26, 53, 28, 17, 74, 21, 25, 32, 0] \n",
      "                  \" <SAMPLE> : 64 / 2 64 over croatan sound \" .\n",
      "st             => saint          || [195, 0] \n",
      "                  route 169 leads to hebertville , the main entrance to the lac <SAMPLE> - jean area .\n",
      "10.47 million  => ten point seven seven || [44, 46, 19, 18, 90, 0] \n",
      "                  the series achieved a consolidated series average of <SAMPLE> viewers .\n",
      "M.anifest      => m dot n dot dot f i || [32, 74, 22, 29, 31, 37, 28, 17, 30, 0] \n",
      "                  fellow artistes wanlov , m3 nsa , dex kwasi & <SAMPLE> praised the project as one of the standouts of the year .\n",
      "KIMN           => k i n n        || [59, 31, 32, 29, 0] \n",
      "                  from the late 1950s to the 1980s , <SAMPLE> was the dominant top 40 music station in denver .\n",
      "http://www.ncbi.nlm.nih.gov/books/NBK10113/Wolpert => h t t p colon slash slash w w w dot b b b b n n n n n || [45, 30, 30, 24, 129, 101, 101, 52, 52, 52, 74, 29, 21, 36, 31, 74, 29, 42, 32, 74, 29, 31, 45, 74, 53, 25, 54, 101, 36, 25, 25, 59, 17, 101, 29, 36, 59, 25, 29, 28, 25, 25, 29, 28, 25, 29, 28, 30, 45, 35, 28, 28, 101, 52, 25, 42, 24, 28, 35, 30, 0] \n",
      "                  available from : <SAMPLE> , lewis ; tickle , cheryll ; martinez arias , alfonso ( 2015 ) .\n",
      "Amazon.co.ukThe => a m a z o n dot c dot o n u u u || [22, 32, 22, 105, 25, 29, 74, 21, 25, 74, 43, 59, 30, 45, 28, 0] \n",
      "                  fwd this link , <SAMPLE> next big thing , amazon . co . uk \" crap dates : disastrous encounters from single life : amazon . co . uk : rhodri marsden : books \" .\n"
     ]
    }
   ],
   "source": [
    "print_local_wrong_predictions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2210000   2% (  4m 29s)   0.166   |   1.11: www.cyber1.org -> w w w dot b y e y e o o o dot o r r (✗: [52, 52, 52, 74, 21, 86, 36, 28, 35, 25, 29, 28, 74, 25, 35, 53, 0]) \n",
      "2220000   4% (  8m 56s)   0.161   |   0.00: A. -> a (✓) \n",
      "2230000   6% ( 13m 13s)   0.198   |   0.00: - -> to (✓) \n",
      "2240000   8% (  18m 0s)   0.148   |   0.02: muh -> m u h (✓) \n",
      "2250000  10% ( 23m 49s)   0.219   |   0.00: AYP -> a y p (✓) \n",
      "Saved model to data/models/whole_gen_10_after_words_attention_no_embd/2250000_(EncoderRNN/DecoderRNN)\n",
      "Accuracy: 90.98% (    9098/   10000)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-53-84861d645bfb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_iterations\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_iters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m500000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprint_every\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mteacher_forcing_ratio\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0001\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-29-fc5438e8eb84>\u001b[0m in \u001b[0;36mtrain_iterations\u001b[0;34m(n_iters, lr, teacher_forcing_ratio, print_every, plot_every)\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0muse_teacher_forcing\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mteacher_forcing_ratio\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0ms_bef\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms_aft\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms_class\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms_sentence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_random_sample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         result, loss = train(s_bef=s_bef, s_aft=s_aft, s_sentence=s_sentence,\n",
      "\u001b[0;32m<ipython-input-15-3bf092992f5b>\u001b[0m in \u001b[0;36mget_random_sample\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_random_sample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0msample_row\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbalanced_data_sample_row\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0msentence_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msample_row\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'class'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0msample_row\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'before'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_row\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'a_word_ind'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_row\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'class'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_row\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sentence'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-12-5c26ae5e7ffc>\u001b[0m in \u001b[0;36mbalanced_data_sample_row\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mbalanced_data_accessed_counter\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mbalanced_data_accessed_counter\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mbalanced_data_length\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0.2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0mbalanced_data_randomize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m     \u001b[0mbalanced_data_last_sample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbalanced_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbalanced_data_length\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mbalanced_data_last_sample\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-12-5c26ae5e7ffc>\u001b[0m in \u001b[0;36mbalanced_data_randomize\u001b[0;34m(max_len)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mbalanced_data_randomize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_len\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mglobal\u001b[0m \u001b[0mbalanced_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbalanced_data_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbalanced_data_accessed_counter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mbalanced_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbalanced_data_classes_select\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mbalanced_data_length\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbalanced_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mbalanced_data_accessed_counter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-12-5c26ae5e7ffc>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mbalanced_data_randomize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_len\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mglobal\u001b[0m \u001b[0mbalanced_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbalanced_data_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbalanced_data_accessed_counter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mbalanced_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbalanced_data_classes_select\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mbalanced_data_length\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbalanced_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mbalanced_data_accessed_counter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py3_pytorch_2/lib/python3.6/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36msample\u001b[0;34m(self, n, frac, replace, weights, random_state, axis)\u001b[0m\n\u001b[1;32m   2788\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2789\u001b[0m         \u001b[0mlocs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2790\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_copy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2791\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2792\u001b[0m     _shared_docs['pipe'] = (\"\"\"\n",
      "\u001b[0;32m~/anaconda3/envs/py3_pytorch_2/lib/python3.6/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mtake\u001b[0;34m(self, indices, axis, convert, is_copy, **kwargs)\u001b[0m\n\u001b[1;32m   1815\u001b[0m         new_data = self._data.take(indices,\n\u001b[1;32m   1816\u001b[0m                                    \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_block_manager_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1817\u001b[0;31m                                    convert=True, verify=True)\n\u001b[0m\u001b[1;32m   1818\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_constructor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__finalize__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1819\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py3_pytorch_2/lib/python3.6/site-packages/pandas/core/internals.py\u001b[0m in \u001b[0;36mtake\u001b[0;34m(self, indexer, axis, verify, convert)\u001b[0m\n\u001b[1;32m   4009\u001b[0m         \u001b[0mnew_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4010\u001b[0m         return self.reindex_indexer(new_axis=new_labels, indexer=indexer,\n\u001b[0;32m-> 4011\u001b[0;31m                                     axis=axis, allow_dups=True)\n\u001b[0m\u001b[1;32m   4012\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4013\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmerge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlsuffix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrsuffix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py3_pytorch_2/lib/python3.6/site-packages/pandas/core/internals.py\u001b[0m in \u001b[0;36mreindex_indexer\u001b[0;34m(self, new_axis, indexer, axis, fill_value, allow_dups, copy)\u001b[0m\n\u001b[1;32m   3895\u001b[0m             new_blocks = [blk.take_nd(indexer, axis=axis, fill_tuple=(\n\u001b[1;32m   3896\u001b[0m                 fill_value if fill_value is not None else blk.fill_value,))\n\u001b[0;32m-> 3897\u001b[0;31m                 for blk in self.blocks]\n\u001b[0m\u001b[1;32m   3898\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3899\u001b[0m         \u001b[0mnew_axes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py3_pytorch_2/lib/python3.6/site-packages/pandas/core/internals.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   3895\u001b[0m             new_blocks = [blk.take_nd(indexer, axis=axis, fill_tuple=(\n\u001b[1;32m   3896\u001b[0m                 fill_value if fill_value is not None else blk.fill_value,))\n\u001b[0;32m-> 3897\u001b[0;31m                 for blk in self.blocks]\n\u001b[0m\u001b[1;32m   3898\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3899\u001b[0m         \u001b[0mnew_axes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py3_pytorch_2/lib/python3.6/site-packages/pandas/core/internals.py\u001b[0m in \u001b[0;36mtake_nd\u001b[0;34m(self, indexer, axis, new_mgr_locs, fill_tuple)\u001b[0m\n\u001b[1;32m   1044\u001b[0m             \u001b[0mfill_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfill_tuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1045\u001b[0m             new_values = algos.take_nd(values, indexer, axis=axis,\n\u001b[0;32m-> 1046\u001b[0;31m                                        allow_fill=True, fill_value=fill_value)\n\u001b[0m\u001b[1;32m   1047\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1048\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnew_mgr_locs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py3_pytorch_2/lib/python3.6/site-packages/pandas/core/algorithms.py\u001b[0m in \u001b[0;36mtake_nd\u001b[0;34m(arr, indexer, axis, out, fill_value, mask_info, allow_fill)\u001b[0m\n\u001b[1;32m   1464\u001b[0m     func = _get_take_nd_function(arr.ndim, arr.dtype, out.dtype, axis=axis,\n\u001b[1;32m   1465\u001b[0m                                  mask_info=mask_info)\n\u001b[0;32m-> 1466\u001b[0;31m     \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfill_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1467\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1468\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mflip_order\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_iterations(n_iters=500000, print_every=10000, teacher_forcing_ratio=0, lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "978-1-85828-636-5 => nine seven eight sil eight sil eight sil eight sil six sil six sil six || [15, 18, 16, 58, 9, 58, 16, 14, 16, 5, 16, 58, 20, 13, 20, 58, 14, 0] \n",
      "                  isbn <SAMPLE> heaton , jenny and steptoe , simon .\n",
      "sjhy365.com/   => s h e s s s y i i i i i i i i i i m m || [17, 60, 45, 86, 30, 45, 35, 28, 28, 17, 31, 97, 37, 31, 54, 28, 74, 21, 25, 32, 17, 42, 22, 17, 45, 0] \n",
      "                  \" educational celebrities : huang xianfan — <SAMPLE> 世 纪 华 育 教 育 网 \" .\n",
      "February 3, 1912 => february third nineteen nineteen || [72, 76, 7, 47, 0] \n",
      "                  he died on <SAMPLE> .\n",
      "2.1.2.3        => t w o dot o dot e dot e dot e e e e e e e || [30, 52, 25, 74, 25, 29, 28, 74, 30, 52, 25, 74, 30, 45, 35, 28, 28, 0] \n",
      "                  the rhesus macaque has 32 teeth with a dental formula of <SAMPLE> / 2 . 1 . 2 . 3 and bilophodont molars .\n",
      "KiliLive.com   => k i l l l i e e dot c o m || [59, 31, 42, 31, 42, 31, 54, 28, 74, 21, 25, 32, 0] \n",
      "                  in 2008 50% of the festival was sold to current owners kilimanjaro live aka <SAMPLE> .\n",
      "K. B. E.       => k b b          || [59, 36, 28, 0] \n",
      "                  \" muhammad abdus salam , <SAMPLE> .\n",
      "ThaiURL.com    => t h a i h r r dot dot c o m || [30, 45, 22, 31, 43, 35, 42, 74, 21, 25, 32, 0] \n",
      "                  the company <SAMPLE> in thailand supports . com registrations via its own idn encoding , thaiurl .\n",
      "223rd          => two hundred twenty d || [5, 10, 6, 76, 0] \n",
      "                  the <SAMPLE> mixed brigade ( spanish : 223 .\n",
      "www.theinquirer.net/inquirer/news/2331280/nokia-imaging-sdk-set-for-android-nokia-x-platform => w w w dot s s s s s s s s s s s s s s s s || [52, 52, 52, 74, 30, 45, 28, 31, 29, 111, 43, 31, 35, 28, 35, 74, 29, 28, 30, 17, 42, 22, 17, 45, 31, 29, 111, 43, 31, 35, 28, 35, 17, 42, 22, 17, 45, 29, 28, 52, 17, 17, 42, 22, 17, 45, 30, 52, 25, 30, 45, 35, 28, 28, 30, 45, 35, 28, 28, 25, 29, 28, 30, 52, 25, 28, 31, 53, 45, 30, 25, 17, 42, 22, 17, 45, 29, 25, 59, 31, 22, 26, 22, 17, 45, 31, 32, 22, 53, 31, 29, 53, 26, 22, 17, 45, 17, 26, 59, 26, 22, 17, 45, 17, 28, 30, 26, 22, 17, 45, 37, 25, 35, 26, 22, 17, 45, 22, 29, 26, 35, 25, 31, 26, 26, 22, 17, 45, 29, 25, 59, 31, 22, 26, 22, 17, 45, 97, 26, 22, 17, 45, 24, 42, 22, 30, 37, 25, 35, 32, 0] \n",
      "                  ux checklist — nokia x design guidelines http : / / <SAMPLE> \" announcement of software update v . 1 . 2 . 4 . 1 / 1 . 2 . 4 . 21 \" .\n",
      "20minutes.fr   => t w t o n n n n n e e e m dot || [30, 52, 28, 29, 30, 86, 32, 31, 29, 43, 30, 28, 17, 74, 37, 35, 0] \n",
      "                  20 minuten ( <SAMPLE> ) .\n"
     ]
    }
   ],
   "source": [
    "print_local_wrong_predictions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "balanced_data_randomize = balanced_data_randomize_long"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2251332  10% (   0m 5s)   0.729   |   0.00: - -> to (✓) \n",
      "2251432  20% (   0m 9s)   0.711   |   0.94: MUNTING -> m u n u n n n (✗: m u n t i n g) \n",
      "2251532  30% (  0m 14s)   0.751   |   0.00: ISBN -> i s b n (✓) \n",
      "2251632  40% (  0m 24s)   0.730   |   0.01: 1.5 million -> one point five million (✓) \n",
      "2251732  50% (  0m 28s)   0.714   |   0.25: ACTREC -> a c t r e c (✓) \n",
      "2251832  60% (  0m 32s)   0.741   |   0.01: 390 -> three hundred ninety (✓) (forcing)\n",
      "2251932  70% (  0m 36s)   0.723   |   1.82: H.macrotus -> h u a c dot c r t t (✗: h dot m a c r o t u s) \n",
      "2252032  80% (  0m 40s)   0.718   |   2.70: http://www.omniture.com/en/products/marketing_integration/genesis/applications/15/184 -> h t t p colon slash slash w w w dot e e e e e e e e e e e e e e e e e e e e e e e e n e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e (✗: h t t p colon slash slash w w w dot o m n i t u r e dot com slash e n slash p r o d u c t s slash m a r k e t i n g u n d e r s c o r e i n t e g r a t i o n slash g e n e s i s slash a p p l i c a t i o n s slash f i f t e e n slash o n e e i g h t f o u r) \n",
      "2252132  90% (  0m 45s)   0.716   |   0.00: June 21, 1966 -> june twenty first nineteen sixty six (✓) \n",
      "2252232 100% (  0m 49s)   0.697   |   0.00: & -> and (✓) \n"
     ]
    }
   ],
   "source": [
    "train_iterations(n_iters=1000, print_every=100, teacher_forcing_ratio=0.2, lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2262232  10% (  7m 24s)   0.683   |   1.41: MyEvent.com -> m y e v e t n t dot c o m (✗: m y e v e n t dot c o m) \n",
      "2272232  20% ( 14m 13s)   0.694   |   0.04: April 9, 2014 -> april ninth twenty fourteen (✓) \n",
      "2282232  30% (  21m 3s)   0.680   |   0.00: TV's -> t v's (✓) \n",
      "2292232  40% ( 27m 18s)   0.662   |   0.06: USSA -> u s s a (✓) (forcing)\n",
      "Saved model to data/models/whole_gen_10_after_words_attention_no_embd/2300000_(EncoderRNN/DecoderRNN)\n",
      "Accuracy: 56.24% (    5624/   10000)\n",
      "2302232  50% (  35m 9s)   0.651   |   0.00: Vol -> volume (✓) (forcing)\n",
      "2312232  60% (  41m 9s)   0.635   |   0.01: 10 November 1883 -> the tenth of november eighteen eighty three (✓) (forcing)\n",
      "2322232  70% (  47m 2s)   0.597   |   2.03: TRANSFORMACIONES -> t r a f o o o n n n n n n n n n (✗: t r a n s f o r m a c i o n e s) \n",
      "2332232  80% ( 52m 56s)   0.581   |   2.78: http://www.nytimes.com/2015/06/12/business/media/line-music-a-new-streaming-service-aims-at-japanese-market.html -> h t t p colon slash slash w w w w w w s s s s s slash slash slash slash slash slash dash dash dash dash dash dash dash dash dash dash dash dash dash dash dash dash dash dash dash dash dash dash dash dash dash dash dash dash dash dash dash dash dash dash dash dash dash dash dash dash dash dash dash dash dash dash dash dash dash dash dash dash dash dash dash dash dash dash dash dash dash dash dash dash a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a (✗: h t t p colon slash slash w w w dot n y t i m e s dot com slash t w e n t y f i f t e e n slash o s i x slash t w e l v e slash b u s i n e s s slash m e d i a slash l i n e dash m u s i c dash a dash n e w dash s t r e a m i n g dash s e r v i c e dash a i m s dash a t dash j a p a n e s e dash m a r k e t dot h t m l) \n",
      "2342232  90% ( 58m 44s)   0.547   |   0.01: 19 -> nineteen (✓) \n",
      "Saved model to data/models/whole_gen_10_after_words_attention_no_embd/2350000_(EncoderRNN/DecoderRNN)\n",
      "Accuracy: 64.54% (    6454/   10000)\n",
      "2352232 100% ( 66m 24s)   0.641   |   0.03: P.O.L. -> p o l (✓) \n"
     ]
    }
   ],
   "source": [
    "train_iterations(n_iters=100000, print_every=10000, teacher_forcing_ratio=0.2, lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ISIRTA         => i s i r i a    || [31, 17, 31, 35, 30, 22, 0] \n",
      "                  the initials <SAMPLE> can be seen printed on the wall with chalk .\n",
      "Lenta.ru       => l e n n a dot dot u u || [42, 28, 29, 30, 22, 74, 35, 43, 0] \n",
      "                  \" с т а т ь и : <SAMPLE> : н а у к а и т е х н и к а : р а с с т а н о в к а с и л \" .\n",
      "http://alappuzha.gov.in/ => h t t p colon slash slash a a a a dot dot dot o p o p o o || [45, 30, 30, 24, 129, 101, 101, 22, 42, 22, 24, 24, 43, 105, 45, 22, 74, 53, 25, 54, 74, 31, 29, 101, 0] \n",
      "                  population of pandanad village , <SAMPLE> 2001 survey .\n",
      "legalised      => b              || [652, 0] \n",
      "                  eighteen months later the fa relented , and in july 1885 professionalism was formally <SAMPLE> in england .\n",
      "byznys         => b y y y acute e's || [36, 86, 105, 29, 86, 17, 0] \n",
      "                  \" marihuanovy cannabis cup konci : ted uz je to <SAMPLE> ! \"\n",
      "superleaguegreece.net => s u p e r l e e e e e e e dot dot n e e e || [17, 43, 24, 28, 35, 42, 28, 22, 53, 43, 28, 53, 35, 28, 28, 21, 28, 74, 29, 28, 30, 0] \n",
      "                  updated to games played on 6 april 2016 , as published on <SAMPLE> .\n",
      "Reptarium.cz   => r e p p a i i u dot dot c m m || [35, 28, 24, 30, 22, 35, 31, 43, 32, 74, 21, 105, 0] \n",
      "                  uropeltis dindigalensis at the <SAMPLE> reptile database .\n",
      "27 April 1706  => the twenty seventh of april two o six || [11, 6, 82, 12, 71, 81, 25, 20, 0] \n",
      "                  bernhard i , duke of saxe meiningen ( b . gotha , 10 september 1649 - d . meiningen , <SAMPLE> ) .\n",
      "www.skimountaineering.orgISMF => w w w dot m i i i i i i i i n n n n n n n || [52, 52, 52, 74, 17, 59, 31, 32, 25, 43, 29, 30, 22, 31, 29, 28, 28, 35, 31, 29, 53, 74, 25, 35, 53, 31, 17, 32, 37, 0] \n",
      "                  ismf world championships — individual ( ad ) , <SAMPLE> world championship combined ranking — women , ismf .\n",
      "historylink.org => h i s s i r i i i dot dot o r || [45, 31, 17, 30, 25, 35, 86, 42, 31, 29, 59, 74, 25, 35, 53, 0] \n",
      "                  \" pocock , george yeoman ( 1891 - 1976 ) : seattle 's master racing shell builder — <SAMPLE> \" .\n"
     ]
    }
   ],
   "source": [
    "print_local_wrong_predictions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2362232  10% (   6m 7s)   0.546   |   0.00: January 2, 2009 -> january second two thousand nine (✓) \n",
      "2372232  20% (  12m 8s)   0.633   |   0.57: FRUMEL -> f r u e l l (✗: f r u m e l) \n",
      "2382232  30% ( 18m 13s)   0.573   |   0.87: Exif -> e x i x (✗: e x i f) \n",
      "2392232  40% ( 24m 19s)   0.516   |   2.65: http://acumen.org/investments/investment-model-2/Agdevco.com -> h t t p colon slash slash m e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e (✗: h t t p colon slash slash a c u m e n dot o r g slash i n v e s t m e n t s slash i n v e s t m e n t dash m o d e l dash t w o slash a g d e v c o dot com) (forcing)\n",
      "Saved model to data/models/whole_gen_10_after_words_attention_no_embd/2400000_(EncoderRNN/DecoderRNN)\n",
      "Accuracy: 64.70% (    6470/   10000)\n",
      "2402232  50% ( 32m 12s)   0.512   |   1.49: foradejogo.net -> f o r e j j j j j dot dot e e t (✗: f o r a d e j o g o dot n e t) \n",
      "2412232  60% ( 38m 12s)   0.516   |   0.00: A.B.N. -> a b n (✓) \n",
      "2422232  70% ( 44m 23s)   0.568   |   2.54: //theplacementpapers.50webs.com -> l l a s h a s p s s h h e e e e e e e e e e e e e e e e e e e e e e e e e e e e dot dot e (✗: s l a s h s l a s h t h e p l a c e m e n t p a p e r s dot f i f t y w e b s dot c o m) \n",
      "2432232  80% ( 50m 24s)   0.463   |   0.00: & -> and (✓) \n",
      "2442232  90% ( 56m 37s)   0.521   |   0.05: Wired.com -> w i r e d dot c o m (✓) \n",
      "Saved model to data/models/whole_gen_10_after_words_attention_no_embd/2450000_(EncoderRNN/DecoderRNN)\n",
      "Accuracy: 67.77% (    6777/   10000)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-221-6921fc2a0436>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_iterations\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_iters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprint_every\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mteacher_forcing_ratio\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.001\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-184-27807fc3707c>\u001b[0m in \u001b[0;36mtrain_iterations\u001b[0;34m(n_iters, lr, teacher_forcing_ratio, print_every, plot_every)\u001b[0m\n\u001b[1;32m     24\u001b[0m                              \u001b[0mencoder_optimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoder_optimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder_optimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdecoder_optimizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m                              \u001b[0mloss_function\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNLLLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_teacher_forcing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_teacher_forcing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m                              max_length=40 )\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0mcurrent_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-28-95336e4ebf15>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(s_bef, s_aft, s_sentence, encoder_optimizer, decoder_optimizer, loss_function, use_teacher_forcing, max_length)\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0mdecoded_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecoded_output\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0mencoder_optimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py3_pytorch_2/lib/python3.6/site-packages/torch/autograd/variable.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, retain_variables)\u001b[0m\n\u001b[1;32m    154\u001b[0m                 \u001b[0mVariable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m         \"\"\"\n\u001b[0;32m--> 156\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py3_pytorch_2/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(variables, grad_variables, retain_graph, create_graph, retain_variables)\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[0;32m---> 98\u001b[0;31m         variables, grad_variables, retain_graph)\n\u001b[0m\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_iterations(n_iters=100000, print_every=10000, teacher_forcing_ratio=0.2, lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "balanced_data_randomize = balanced_data_randomize_org\n",
    "balanced_data_randomize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 85.32% (    8532/   10000)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8532"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_model_accuracy(encoder_rnn, test_model_single_sample, n_sample=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_iterations(n_iters=100000, print_every=10000, teacher_forcing_ratio=0.2, lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print_local_wrong_predictions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_iterations(n_iters=500000, print_every=10000, teacher_forcing_ratio=0, lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print_local_wrong_predictions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#state_dict_path = 'data/models/whole_gen_10_after_words_attention_no_embd/2450000_'\n",
    "state_dict_path = 'data/models/whole_gen_10_after_words_attention_no_embd/2250000_'\n",
    "decoder_rnn.load_state_dict(torch.load(state_dict_path + 'DecoderRNN'))\n",
    "encoder_rnn.load_state_dict(torch.load(state_dict_path + 'EncoderRNN'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>token_id</th>\n",
       "      <th>class</th>\n",
       "      <th>before</th>\n",
       "      <th>after</th>\n",
       "      <th>class_org</th>\n",
       "      <th>a_word_ind</th>\n",
       "      <th>sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>588194</th>\n",
       "      <td>672582</td>\n",
       "      <td>19</td>\n",
       "      <td>NUMBERS</td>\n",
       "      <td>7</td>\n",
       "      <td>seven</td>\n",
       "      <td>CARDINAL</td>\n",
       "      <td>[18, 0]</td>\n",
       "      <td>the soviet strategic offensive in manchuria , ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44495</th>\n",
       "      <td>51104</td>\n",
       "      <td>6</td>\n",
       "      <td>NUMBERS</td>\n",
       "      <td>1987</td>\n",
       "      <td>nineteen eighty seven</td>\n",
       "      <td>DATE</td>\n",
       "      <td>[7, 27, 18, 0]</td>\n",
       "      <td>\" i singoli piu venduti del &lt;SAMPLE&gt; \" ( in it...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>453837</th>\n",
       "      <td>521080</td>\n",
       "      <td>10</td>\n",
       "      <td>LETTERS</td>\n",
       "      <td>ML</td>\n",
       "      <td>m l</td>\n",
       "      <td>LETTERS</td>\n",
       "      <td>[32, 42, 0]</td>\n",
       "      <td>wang ll , blasioli j , plas dr , thomas &lt;SAMPL...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>634805</th>\n",
       "      <td>725609</td>\n",
       "      <td>1</td>\n",
       "      <td>NUMBERS</td>\n",
       "      <td>1 March 1969</td>\n",
       "      <td>the first of march nineteen sixty nine</td>\n",
       "      <td>DATE</td>\n",
       "      <td>[11, 56, 12, 62, 7, 39, 15, 0]</td>\n",
       "      <td>on &lt;SAMPLE&gt; , she participated in the melodife...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>462582</th>\n",
       "      <td>530478</td>\n",
       "      <td>17</td>\n",
       "      <td>PLAIN</td>\n",
       "      <td>centres</td>\n",
       "      <td>centers</td>\n",
       "      <td>PLAIN</td>\n",
       "      <td>[187, 0]</td>\n",
       "      <td>the artist taught at the st croix school of ar...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        sentence_id  token_id    class        before  \\\n",
       "588194       672582        19  NUMBERS             7   \n",
       "44495         51104         6  NUMBERS          1987   \n",
       "453837       521080        10  LETTERS            ML   \n",
       "634805       725609         1  NUMBERS  1 March 1969   \n",
       "462582       530478        17    PLAIN       centres   \n",
       "\n",
       "                                         after class_org  \\\n",
       "588194                                   seven  CARDINAL   \n",
       "44495                    nineteen eighty seven      DATE   \n",
       "453837                                     m l   LETTERS   \n",
       "634805  the first of march nineteen sixty nine      DATE   \n",
       "462582                                 centers     PLAIN   \n",
       "\n",
       "                            a_word_ind  \\\n",
       "588194                         [18, 0]   \n",
       "44495                   [7, 27, 18, 0]   \n",
       "453837                     [32, 42, 0]   \n",
       "634805  [11, 56, 12, 62, 7, 39, 15, 0]   \n",
       "462582                        [187, 0]   \n",
       "\n",
       "                                                 sentence  \n",
       "588194  the soviet strategic offensive in manchuria , ...  \n",
       "44495   \" i singoli piu venduti del <SAMPLE> \" ( in it...  \n",
       "453837  wang ll , blasioli j , plas dr , thomas <SAMPL...  \n",
       "634805  on <SAMPLE> , she participated in the melodife...  \n",
       "462582  the artist taught at the st croix school of ar...  "
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "balanced_data.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "class\n",
       "ELECTRONIC    4964\n",
       "LETTERS       6401\n",
       "NUMBERS       5606\n",
       "PLAIN         2187\n",
       "VERBATIM      2000\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "21158"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "balanced_data.groupby('class')['class'].count()\n",
    "len(balanced_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "def balanced_data_randomize_long():\n",
    "    global balanced_data, balanced_data_length, balanced_data_accessed_counter, balanced_data_randomize_freq\n",
    "    \n",
    "    bal_data = pd.concat([v.sample(min(2000, len(v))) for k, v in balanced_data_classes_select])\n",
    "    long_data = sample_data[sample_data['before'].str.len()>8].sample(4000)\n",
    "    elec_data = sample_data[sample_data['class']=='ELECTRONIC']\n",
    "    let_long_data = sample_data[(sample_data['class'] == 'LETTERS') & (sample_data['before'].str.len() > 5)]\n",
    "    balanced_data = pd.concat([bal_data, long_data, elec_data, let_long_data])#.drop_duplicates()\n",
    "    balanced_data = balanced_data[~balanced_data.index.duplicated(keep='first')]\n",
    "    \n",
    "    balanced_data_length = len(balanced_data)\n",
    "    balanced_data_randomize_freq = balanced_data_length * 0.5\n",
    "    balanced_data_accessed_counter = 0\n",
    "\n",
    "balanced_data_randomize = balanced_data_randomize_long\n",
    "balanced_data_randomize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input:   SJ\n",
      "output:  ['s', 'j']\n",
      "target:    s j\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAwkAAAFeCAYAAADOj1PqAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f8924bb31d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def debug_show_attention(input_sentence, output_words, attentions):\n",
    "    # Set up figure with colorbar\n",
    "    fig = plt.figure(figsize=(15,6))\n",
    "    ax = fig.add_subplot(111)\n",
    "    #cax = ax.matshow(attentions.numpy(), cmap='bone')\n",
    "    cax = ax.matshow(attentions, cmap='bone')\n",
    "    fig.colorbar(cax)\n",
    "    # Set up axes\n",
    "    #ax.set_xticklabels([''] + input_sentence.split(' ') + ['<EOS>'], rotation=90)\n",
    "    #ax.set_xticklabels([''] + input_sentence + ['<EOS>'], rotation=90)\n",
    "    ax.set_yticklabels([''] + output_words)\n",
    "    \n",
    "    input_sentence = input_sentence + ['<EOS>']\n",
    "    inp_arr = [\"{}\\n{}\".format(input_sentence[i], input_sentence[-1-i]) for i in range(len(input_sentence))]\n",
    "    ax.set_xticklabels([''] + inp_arr, rotation=0)\n",
    "\n",
    "    # Show label at every tick\n",
    "    ax.xaxis.set_major_locator(matplotlib.ticker.MultipleLocator(1))\n",
    "    ax.yaxis.set_major_locator(matplotlib.ticker.MultipleLocator(1))\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "def debug_eval_sample_show_attention():\n",
    "    \n",
    "    sample_row = balanced_data_sample_row()\n",
    "    #sample_row = balanced_data[balanced_data['before'].str.len()>15].sample(1).iloc[0]\n",
    "    sample = sample_row['before'], sample_row['a_word_ind'], sample_row['class'], sample_row['sentence']\n",
    "\n",
    "    output, decoded_output, decoder_attns_arr, sample = test_model_single_sample(None, \n",
    "                                                            return_more=True, sample=sample)\n",
    "    print('input:  ', sample[0])\n",
    "    print('output: ', decoded_output)\n",
    "    print('target:   ', ' '.join([words_after_common[w] for w in sample[1][:-1]]))\n",
    "\n",
    "    attns = np.array([arr.data[0].cpu().numpy() for arr in decoder_attns_arr])\n",
    "\n",
    "    debug_show_attention(list(sample[0]), decoded_output, attns)\n",
    "    #plt.matshow(attns)\n",
    "\n",
    "debug_eval_sample_show_attention()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "class\n",
       "ELECTRONIC    [ELECTRONIC]\n",
       "LETTERS          [LETTERS]\n",
       "NUMBERS          [NUMBERS]\n",
       "PLAIN              [PLAIN]\n",
       "VERBATIM        [VERBATIM]\n",
       "Name: class, dtype: object"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "balanced_data.groupby('class')['class'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test_in_categories(iter_len = 1000):\n",
    "    wrong_preds = {}\n",
    "    for cat in categories_all:\n",
    "        tmp_data = sample_data[sample_data['class'] == cat].sample(iter_len)\n",
    "        correct_n = 0\n",
    "        wrong_preds_arr = []\n",
    "\n",
    "        for _ in range(iter_len):\n",
    "            sample_row = tmp_data.iloc[_]\n",
    "            sample = sample_row['before'], sample_row['a_word_ind'], sample_row['class'], sample_row['sentence']\n",
    "\n",
    "            output, t1, sample_target, t2 = test_model_single_sample(None, sample=sample)\n",
    "            if output == sample_target:\n",
    "                correct_n += 1\n",
    "            else:\n",
    "                wrong_preds_arr.append([sample_target, output])\n",
    "\n",
    "        print(\"{:>10}: {:>5d}/{:>5d} ({:>4.0%})\".format(cat, correct_n, iter_len, correct_n/iter_len))\n",
    "        wrong_preds[cat] = wrong_preds_arr\n",
    "    return wrong_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ELECTRONIC:   581/ 3000 ( 19%)\n",
      "   LETTERS:  2885/ 3000 ( 96%)\n",
      "   NUMBERS:  2768/ 3000 ( 92%)\n",
      "     PLAIN:  2933/ 3000 ( 98%)\n",
      "  VERBATIM:  2969/ 3000 ( 99%)\n"
     ]
    }
   ],
   "source": [
    "wrong_preds = test_in_categories(3000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['m e acute d o c', 'm e acute o d c'],\n",
       " ['d h a r i w a l', 'd w a w a a a l'],\n",
       " ['c i a n', 'c i a a'],\n",
       " [\"u t e p's\", \"u t t p's\"],\n",
       " ['p n h', 'p n'],\n",
       " ['h r t', 'h t t'],\n",
       " ['f c i t x', 'f x i t x'],\n",
       " [\"m o g g's\", 'm o g g'],\n",
       " ['k e t o s a m i n e', 'k e t e s s i i'],\n",
       " ['t k o d', 't k o k'],\n",
       " ['h u m i m p i l', 'h u m m i i i i'],\n",
       " ['o and c b', 'o and c e'],\n",
       " ['b a t t a g l i e', 'b a t t i t t e e e a'],\n",
       " ['a c n y c', 'a n n c c'],\n",
       " ['v a s s i l e v a', 'v a s s s s a a'],\n",
       " ['l y c h g a t e', 'y y g a t t t t e e'],\n",
       " ['u s c g c', 'u s s c c'],\n",
       " ['a f j r o t c', 'a j r r o t c o'],\n",
       " ['b e l o g l a z o v a', 'b o l o o a a a l l a'],\n",
       " ['d d f i o d e v i c e', 'd v v i o i i i e'],\n",
       " ['x v i i i a', 'x h i i i'],\n",
       " ['c o y g n', 'c o y g n g'],\n",
       " [\"h e acute r o's\", 'h e acute e acute r'],\n",
       " ['c h n m', 'c h m m'],\n",
       " ['h i r a d p a d a', 'h i p i a a d a d a'],\n",
       " ['e v', 'the'],\n",
       " ['n e w c a p', 'n e w a a p'],\n",
       " ['p d f s', 'p d f'],\n",
       " ['u s c c b', 'u s c c c'],\n",
       " ['s o c i e acute t e acute s', 's acute s s s s s s s s'],\n",
       " [\"s e p t a r's\", 's t p t r t'],\n",
       " ['f a o u', 'f a u u'],\n",
       " ['x f i n i t y', 'x f i t f y'],\n",
       " ['i s m m s', 'i m m m s'],\n",
       " ['p s i p r e d', 'p s i s r e e'],\n",
       " ['c h a r l i t o', 'c h a r i i o o'],\n",
       " [\"l a s f s's\", 'l a l f s'],\n",
       " ['f i d l a r', 'f i d d l r'],\n",
       " ['b a a t h', 'b a t a t'],\n",
       " ['c s v', 'c s s'],\n",
       " ['e p c e', 'e p c c'],\n",
       " [\"u s a i d's\", 'u s a s s'],\n",
       " ['w f c r', 'w f f r'],\n",
       " ['k c y y', 'k y y q'],\n",
       " ['s r p s k i h', 's r p r k k k'],\n",
       " ['s c h l t r', 's c c l t r'],\n",
       " ['f c m r c', 'f c m c r'],\n",
       " ['m b r a s', 'm b r a a'],\n",
       " ['o s g t', 'o'],\n",
       " ['c e m z b', 'c e m z z'],\n",
       " ['h i s t o r i k', 'h i s i i i i k'],\n",
       " [\"f f g's\", 'f f g'],\n",
       " ['i h s a', 'i s s a'],\n",
       " [\"u's\", 'saint'],\n",
       " ['c h r o m a n', 'c h r o o a n'],\n",
       " ['n e o c d', 'n o o c d'],\n",
       " ['i s c s i', 'i s s s i'],\n",
       " ['c e m i g', 'c e c i i'],\n",
       " ['s z l a k', 's z l a z'],\n",
       " ['l d o c e', 'l d o d e'],\n",
       " ['x o x', 'x ten'],\n",
       " ['i s i r t a', 'i s i r a a'],\n",
       " ['s o i u s a', 's o u i u a'],\n",
       " ['m u t t o n i', 'm o t t t i i'],\n",
       " ['p n w j l l', 'p n w l l l'],\n",
       " ['a r l f c', 'a l l f c'],\n",
       " ['p r o c e d i m i e n t o s', 'p r o d d o o i i i i o s'],\n",
       " ['x x v i i e', 'x x x i i'],\n",
       " ['r e e s t r', 'r e t s t r'],\n",
       " ['a n e acute', 'a n acute e'],\n",
       " ['l a d e acute u', 'l a a d u u'],\n",
       " [\"w i r's\", 'w i r s'],\n",
       " ['s a b a', 's a s b'],\n",
       " ['n g c s u', 'n c c s u'],\n",
       " ['p f y', 'p y y'],\n",
       " ['p u s h k a s h', 'p a s k s s s s s'],\n",
       " [\"i c a f's\", \"i c a q i's\"],\n",
       " ['a c c l', 'a c c c'],\n",
       " ['b l m c', 'b m m c'],\n",
       " ['n i r m a n', 'n i r r a n'],\n",
       " ['a n n o v a r', 'a n n o n a r'],\n",
       " ['p l a c e n t i n o', 'p l a n a a n n n n'],\n",
       " ['v e l a t u s', 'v e l a l u s'],\n",
       " ['a d v c a p', 'a v v c c p'],\n",
       " ['o c e acute a n o', 'o c e acute acute o n'],\n",
       " ['b p o n', 'b b o n'],\n",
       " ['s t', 'saint'],\n",
       " ['g j m g', 'g j j g'],\n",
       " [\"s h g's\", \"s h y's\"],\n",
       " ['y m p e v', 'y y p e v'],\n",
       " ['m p l a b', 'm p l a a'],\n",
       " [\"r u s e's\", 'r r e s'],\n",
       " ['e z e acute r t', 'e e e z r t'],\n",
       " ['e c f c', 'e c c c'],\n",
       " ['c w g c', 'c w w c'],\n",
       " ['m i c r o r n a', 'm i c r r o a n'],\n",
       " ['s d n y', 's d y y'],\n",
       " ['d n x h d', 'd x x d h'],\n",
       " ['c i l g', 'c i'],\n",
       " ['p a t h a l i a s', 'p a t s a a a a a s'],\n",
       " ['y j s y', 'y j y y'],\n",
       " ['m m o r p g', 'm r o r p g'],\n",
       " ['n a v f a c', 'n a v a a c'],\n",
       " ['d e r f', 'd r e f f'],\n",
       " ['j a l l a', 'j a l l e'],\n",
       " [\"k b a d's\", 'k b a b'],\n",
       " ['o a h s p e', 'o a s p s e'],\n",
       " [\"h q's\", \"h v's\"],\n",
       " [\"m m o g's\", \"m o o m's\"],\n",
       " ['c f i x', 'c f i f'],\n",
       " ['n c h s a a', 'n h h s a a'],\n",
       " ['m t', 'mount'],\n",
       " ['k l m j', 'k m m j'],\n",
       " ['e d i c i o n e s', 'e d i d i i i e'],\n",
       " ['t f p i', 't f f i']]"
      ]
     },
     "execution_count": 289,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wrong_preds['LETTERS']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ELECTRONIC:   165/  999 ( 17%)\n",
      "   LETTERS:   907/  999 ( 91%)\n",
      "   NUMBERS:   837/  999 ( 84%)\n",
      "     PLAIN:   935/  999 ( 94%)\n",
      "  VERBATIM:   986/  999 ( 99%)\n"
     ]
    }
   ],
   "source": [
    "# With training longer words\n",
    "wrong_preds = test_in_categories()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:py3_pytorch_2]",
   "language": "python",
   "name": "conda-env-py3_pytorch_2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
