{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pytorch utils oh: pytorch_utils_oh_2.py\n",
      "Pytorch: 0.2.0_4\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import importlib\n",
    "from pytorch_utils_oh_2 import *\n",
    "import IPython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MODEL_SAVE_PATH = 'whole_gen_12_attn_learning_rates'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pytorch utils oh: pytorch_utils_oh_2.py\n",
      "Pytorch: 0.2.0_4\n"
     ]
    }
   ],
   "source": [
    "import pytorch_utils_oh_2; importlib.reload(pytorch_utils_oh_2); from pytorch_utils_oh_2 import *;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# all_data = pickle.load(open(\"data/en_train_fixed_4_sentences.pkl\", \"rb\" ))\n",
    "all_data = pickle.load(open(\"data/en_train_fixed_5_manual.pkl\", \"rb\" ))\n",
    "# all_data_sentence_index = all_data.set_index('sentence_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data rows: 654333,  (dropped rows: 9263859)\n"
     ]
    }
   ],
   "source": [
    "sample_data = all_data.copy()\n",
    "sample_data = sample_data[sample_data['class'] != 'NOT_CHANGED']\n",
    "sample_data = sample_data[sample_data['class'] != 'MANUAL']\n",
    "# sample_data = sample_data[sample_data['class'] != 'ELECTRONIC']\n",
    "print(\"Data rows: {},  (dropped rows: {})\".format(len(sample_data), len(all_data)-len(sample_data)))\n",
    "sample_data = sample_data.reset_index(drop=True)\n",
    "del(all_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ELECTRONIC', 'LETTERS', 'NUMBERS', 'PLAIN', 'VERBATIM']\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "categories_all = sorted(sample_data[\"class\"].unique())\n",
    "print(categories_all)\n",
    "print(len(categories_all))\n",
    "categories_index = dict((c, i) for i, c in enumerate(categories_all))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utils stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<SOS><EOS>☒ !\"#$%&'(),-./0123456789:;ABCDEFGHIJKLMNOPQRSTUVWXYZ_abcdefghijklmnopqrstuvwxyz~£¥ª²³µº¼½¾éɒʻˈΩμ—€⅓⅔⅛\n"
     ]
    }
   ],
   "source": [
    "chars_normal, chars_normal_index = load_characters_pkl('data/en_features/chars_normal.pkl')\n",
    "print(''.join(chars_normal))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "common_words, common_words_index = load_common_words_10k()\n",
    "len(common_words)\n",
    "common_words[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wv_vecs, wv_words, wv_idx = load_glove('/home/ohu/koodi/data/glove_wordvec/glove.6B.50d.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### After words handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<EOS>', '<SOS>', '<UNK>', '<0000>', '<SAMPLE>', 'two', 'twenty']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "1351"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_after_common = pickle.load(open(\"data/en_features/words_after_ext.pkl\", 'rb'))\n",
    "words_after_index = dict((c, i) for i, c in enumerate(words_after_common))\n",
    "words_after_common[0:7]\n",
    "len(words_after_common)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 1351])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sos_tensor = torch.zeros(1, 1, len(words_after_index))\n",
    "sos_tensor[0, 0, words_after_index[SOS_TOKEN]] = 1\n",
    "sos_tensor.size()\n",
    "#del(onehot_sos)\n",
    "\n",
    "# sos_tensor = torch.LongTensor([words_after_index[SOS_TOKEN]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### More balanced sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "balanced_data_classes_select = list(sample_data.groupby('class'))\n",
    "\n",
    "balanced_data_accessed_counter = 0 \n",
    "balanced_data_randomize_freq = False\n",
    "balanced_data_length = 0\n",
    "\n",
    "def balanced_data_randomize_org(max_len=20000):\n",
    "    global balanced_data, balanced_data_length, balanced_data_accessed_counter, balanced_data_randomize_freq\n",
    "    balanced_data = pd.concat([v.sample(min(max_len, len(v))) for k, v in balanced_data_classes_select])\n",
    "    balanced_data_length = len(balanced_data)\n",
    "    balanced_data_randomize_freq = balanced_data_length * 0.2\n",
    "    balanced_data_accessed_counter = 0\n",
    "balanced_data_randomize = balanced_data_randomize_org\n",
    "\n",
    "def balanced_data_sample_row():\n",
    "    global balanced_data_accessed_counter\n",
    "    global balanced_data_last_sample\n",
    "    balanced_data_accessed_counter += 1\n",
    "    if balanced_data_randomize_freq and balanced_data_accessed_counter > balanced_data_randomize_freq:\n",
    "        balanced_data_randomize()\n",
    "    balanced_data_last_sample = balanced_data.iloc[random.randint(1, balanced_data_length-1)]\n",
    "    return balanced_data_last_sample\n",
    "    \n",
    "balanced_data_randomize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "class\n",
       "ELECTRONIC     4964\n",
       "LETTERS       20000\n",
       "NUMBERS       20000\n",
       "PLAIN         20000\n",
       "VERBATIM      11741\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#all_data.groupby('class')['class'].count()\n",
    "#sample_data.groupby('class')['class'].count()\n",
    "balanced_data.groupby('class')['class'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentence_id                                               576240\n",
       "token_id                                                      10\n",
       "class                                                      PLAIN\n",
       "before                                                         -\n",
       "after                                                         to\n",
       "class_org                                                  PLAIN\n",
       "a_word_ind                                               [57, 0]\n",
       "sentence       \" results of the parliamentary by elections he...\n",
       "Name: 503393, dtype: object"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "balanced_data_sample_row()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LETTERS : PSV's -> p s v's <EOS> [24, 17, 177, 0]\n",
      "['in', '2002', ',', 'takak', 'was', 'picked', 'for', '<SAMPLE>', 'first', 'team', '.']\n",
      "torch.Size([1, 6, 104])\n"
     ]
    }
   ],
   "source": [
    "def get_random_sample():\n",
    "    sample_row = balanced_data_sample_row()   \n",
    "    return sample_row['before'], sample_row['a_word_ind'], sample_row['class'], sample_row['sentence'].split(' ')\n",
    "            \n",
    "def tmp():\n",
    "    s_bef, s_aft, s_class, s_sentence = get_random_sample()\n",
    "    s_aft_str = ' '.join([words_after_common[i] for i in s_aft])\n",
    "    print(s_class, ':', s_bef, '->', s_aft_str, s_aft)\n",
    "    print(s_sentence)\n",
    "    print(string_to_tensor(s_bef, chars_normal_index).shape)\n",
    "tmp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "144 µs ± 2.3 µs per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "get_random_sample()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "use_cuda = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MAX_ATTENTION_LENGTH = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "746"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>token_id</th>\n",
       "      <th>class</th>\n",
       "      <th>before</th>\n",
       "      <th>after</th>\n",
       "      <th>class_org</th>\n",
       "      <th>a_word_ind</th>\n",
       "      <th>sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>132078</th>\n",
       "      <td>151992</td>\n",
       "      <td>1</td>\n",
       "      <td>ELECTRONIC</td>\n",
       "      <td>http://www.pressreference.com/Be-Co/China.html...</td>\n",
       "      <td>h t t p colon slash slash w w w dot p r e s s ...</td>\n",
       "      <td>ELECTRONIC</td>\n",
       "      <td>[45, 30, 30, 24, 129, 101, 101, 52, 52, 52, 74...</td>\n",
       "      <td>see &lt;SAMPLE&gt; netherlands media network .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100607</th>\n",
       "      <td>115633</td>\n",
       "      <td>2</td>\n",
       "      <td>ELECTRONIC</td>\n",
       "      <td>http://www.nasa.gov/audience/forstudents/5-8/f...</td>\n",
       "      <td>h t t p colon slash slash w w w dot n a s a do...</td>\n",
       "      <td>ELECTRONIC</td>\n",
       "      <td>[45, 30, 30, 24, 129, 101, 101, 52, 52, 52, 74...</td>\n",
       "      <td>nasa explores &lt;SAMPLE&gt; .</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        sentence_id  token_id       class  \\\n",
       "132078       151992         1  ELECTRONIC   \n",
       "100607       115633         2  ELECTRONIC   \n",
       "\n",
       "                                                   before  \\\n",
       "132078  http://www.pressreference.com/Be-Co/China.html...   \n",
       "100607  http://www.nasa.gov/audience/forstudents/5-8/f...   \n",
       "\n",
       "                                                    after   class_org  \\\n",
       "132078  h t t p colon slash slash w w w dot p r e s s ...  ELECTRONIC   \n",
       "100607  h t t p colon slash slash w w w dot n a s a do...  ELECTRONIC   \n",
       "\n",
       "                                               a_word_ind  \\\n",
       "132078  [45, 30, 30, 24, 129, 101, 101, 52, 52, 52, 74...   \n",
       "100607  [45, 30, 30, 24, 129, 101, 101, 52, 52, 52, 74...   \n",
       "\n",
       "                                        sentence  \n",
       "132078  see <SAMPLE> netherlands media network .  \n",
       "100607                  nasa explores <SAMPLE> .  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp = sample_data[sample_data['before'].str.len()>MAX_ATTENTION_LENGTH]\n",
    "len(tmp)\n",
    "tmp.sample(2)\n",
    "# tmp[~tmp['before'].str.contains('/')].sample(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EncoderRNN (\n",
       "  (rnn_words): GRU(50, 64, batch_first=True, bidirectional=True)\n",
       "  (rnn_chars): GRU(104, 256, batch_first=True, bidirectional=True)\n",
       ")"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, words_input_size, chars_input_size, words_hidden_size, chars_hidden_size,\n",
    "                 words_layers=1, chars_layers=1):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        \n",
    "        self.words_layers = words_layers\n",
    "        self.chars_layers = chars_layers\n",
    "        self.words_hidden_size = words_hidden_size\n",
    "        self.chars_hidden_size = chars_hidden_size\n",
    "        self.hidden_size = words_hidden_size + chars_hidden_size\n",
    "\n",
    "        self.rnn_words = nn.GRU(words_input_size, words_hidden_size // 2, words_layers,\n",
    "                                 batch_first=True, bidirectional=True)\n",
    "\n",
    "        self.rnn_chars = nn.GRU(chars_input_size, chars_hidden_size // 2, chars_layers,\n",
    "                                 batch_first=True, bidirectional=True)\n",
    "        \n",
    "    def forward(self, word_vectors, string_tensor, hidden = None, init_hidden = True):\n",
    "        if init_hidden:\n",
    "            hidden_words, hidden_chars = self.init_hidden()\n",
    "        \n",
    "        all_outputs_words, hidden_words = self.rnn_words(word_vectors, hidden_words)\n",
    "        output_words = hidden_words.view(1, -1)\n",
    "        \n",
    "        all_outputs_chars, hidden_chars = self.rnn_chars(string_tensor, hidden_chars)\n",
    "        output_chars = hidden_chars.view(1, -1)\n",
    "        \n",
    "        #hidden_states_cat = Variable(torch.zeros(MAX_ATTENTION_LENGTH, self.hidden_size)).cuda()\n",
    "        #for ei in range(min(MAX_ATTENTION_LENGTH, len(string_tensor[0]))):\n",
    "        #    hidden_states_cat[ei] = torch.cat((output_words, all_outputs_chars[0, ei].view(1,-1)), 1)\n",
    "\n",
    "        all_outputs_chars_padded = Variable(torch.zeros(MAX_ATTENTION_LENGTH, self.chars_hidden_size)).cuda()\n",
    "        att_length = min(len(all_outputs_chars[0]), MAX_ATTENTION_LENGTH-1)\n",
    "        all_outputs_chars_padded[0:att_length] = all_outputs_chars[0][0:att_length]\n",
    "        \n",
    "        output = torch.cat((output_words, output_chars), 1)\n",
    "\n",
    "        #output = torch.cat((output_words, output_chars), 1)\n",
    "        \n",
    "        #return output, all_outputs_chars\n",
    "        return output, all_outputs_chars_padded\n",
    "\n",
    "    def init_hidden(self):\n",
    "        var1 = Variable(torch.zeros(2 * self.words_layers, 1, self.words_hidden_size // 2))\n",
    "        var2 = Variable(torch.zeros(2 * self.chars_layers, 1, self.chars_hidden_size // 2))\n",
    "        \n",
    "        var1 = var1.cuda(); var2 = var2.cuda()\n",
    "        return (var1, var2)\n",
    "    \n",
    "    \n",
    "encoder_rnn = EncoderRNN(words_input_size=wv_vecs.shape[-1], chars_input_size=len(chars_normal),\n",
    "                         words_hidden_size=128, chars_hidden_size=512,\n",
    "                         words_layers=1, chars_layers=1).cuda()\n",
    "encoder_rnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRT\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'TRT'"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 640])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([30, 512])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def test_encoder_single_sample():\n",
    "    s_bef, s_aft, s_class, s_sentence = get_random_sample()\n",
    "    #s_bef, s_aft, s_class, s_sentence = get_random_sample(True)\n",
    "    print(s_bef)\n",
    "    \n",
    "    words_t = Variable(words_to_word_vectors_tensor(s_sentence, wv_vecs, wv_idx)).cuda()\n",
    "    \n",
    "    string_t = string_to_tensor(s_bef, chars_normal_index)\n",
    "    string_t = Variable(string_t).cuda()\n",
    "    \n",
    "    return encoder_rnn(words_t, string_t), s_bef\n",
    "    \n",
    "(tmp_encoder_output, tmp_encoder_outputs), tmp = test_encoder_single_sample()\n",
    "tmp\n",
    "tmp_encoder_output.size()\n",
    "tmp_encoder_outputs.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecoderRNN (\n",
       "  (emb_lin): Linear (1351 -> 640)\n",
       "  (dropout): Dropout (p = 0.1)\n",
       "  (attn): Linear (1280 -> 30)\n",
       "  (attn_combine): Linear (1152 -> 640)\n",
       "  (rnn): GRU(640, 640, batch_first=True)\n",
       "  (lin_out): Linear (640 -> 1351)\n",
       ")"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[torch.Size([1, 1351]), torch.Size([1, 640]), torch.Size([1, 30])]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class DecoderRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, chars_encoded_size,\n",
    "                 n_layers=1, dropout_p=0.1, max_length=MAX_ATTENTION_LENGTH):\n",
    "        super(DecoderRNN, self).__init__()\n",
    "        \n",
    "        self.n_layers = n_layers\n",
    "        self.hidden_size = hidden_size\n",
    "        self.max_length = max_length\n",
    "        \n",
    "        self.emb_lin = nn.Linear(input_size, hidden_size)\n",
    "        self.dropout = nn.Dropout(dropout_p)\n",
    "        self.attn = nn.Linear(self.hidden_size+self.hidden_size, self.max_length)\n",
    "        self.attn_combine = nn.Linear(self.hidden_size+chars_encoded_size, self.hidden_size)\n",
    "        \n",
    "        #self.module_attn = torch.nn.ModuleList([self.emb_lin, self.dropout, self.attn, self.attn_combine])\n",
    "        \n",
    "        \n",
    "        self.rnn = nn.GRU(hidden_size, hidden_size, n_layers, batch_first=True, bidirectional=False)\n",
    "        self.lin_out = nn.Linear(hidden_size, input_size)\n",
    "        \n",
    "        #self.module_rnn = torch.nn.ModuleList([self.rnn, self.lin_out])\n",
    "\n",
    "    def forward(self, last_input, hidden, encoder_outputs):\n",
    "        embedded = self.emb_lin(last_input).view(1, 1, -1)\n",
    "        embedded = self.dropout(embedded)\n",
    "        embedded = embedded[0]\n",
    "                \n",
    "        attn_weights = F.softmax(self.attn(torch.cat((embedded, hidden), 1)))\n",
    "        attn_applied = torch.bmm(attn_weights.unsqueeze(0), encoder_outputs.unsqueeze(0))\n",
    "        #return embedded, attn_applied\n",
    "        \n",
    "        rnn_input = torch.cat((embedded, attn_applied[0]), 1)\n",
    "        rnn_input = self.attn_combine(rnn_input).unsqueeze(0)\n",
    "        rnn_input = F.relu(rnn_input)\n",
    "    \n",
    "        output, hidden = self.rnn(rnn_input, hidden.unsqueeze(0))\n",
    "        output = F.log_softmax(self.lin_out(output[0]))\n",
    "        \n",
    "        return output, hidden[0], attn_weights\n",
    "    \n",
    "    def init_rest_hidden(self, input_var):\n",
    "        if self.n_layers > 1:\n",
    "            hid_var = Variable(torch.zeros(self.n_layers - 1, 1, self.hidden_size)).cuda()\n",
    "            res = torch.cat((input_var, hid_var), 0)\n",
    "            return res\n",
    "        else:\n",
    "            return input_var\n",
    "        \n",
    "    def mods_split(self):\n",
    "        mods = list(decoder_rnn.modules())[1:]\n",
    "        for gru_index, mod in enumerate(mods):\n",
    "            #print(mod)\n",
    "            if type(mod) == torch.nn.modules.rnn.GRU:\n",
    "                break\n",
    "        return mods[:gru_index], mods[gru_index:]\n",
    "        \n",
    "    def mods_attn(self):\n",
    "        return self.mods_split()[0]\n",
    "        \n",
    "    def mods_gru(self):\n",
    "        return self.mods_split()[1]\n",
    "\n",
    "decoder_rnn = DecoderRNN(input_size=len(words_after_common), hidden_size=tmp_encoder_output.size()[1],\n",
    "                         chars_encoded_size=tmp_encoder_outputs.size()[1], n_layers=1)\n",
    "decoder_rnn = decoder_rnn.cuda()\n",
    "decoder_rnn\n",
    "\n",
    "tmp = decoder_rnn(Variable(sos_tensor).cuda(), tmp_encoder_output, tmp_encoder_outputs)\n",
    "#tmp\n",
    "[v.size() for v in tmp]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'lr': 3, 'params': <generator object Module.parameters at 0x7efbdd183570>},\n",
       " {'lr': 3, 'params': <generator object Module.parameters at 0x7efbdd183ba0>},\n",
       " {'lr': 3, 'params': <generator object Module.parameters at 0x7efbdd183b48>},\n",
       " {'lr': 3, 'params': <generator object Module.parameters at 0x7efbdd183780>},\n",
       " {'params': <generator object Module.parameters at 0x7efbdd1832b0>},\n",
       " {'params': <generator object Module.parameters at 0x7efbdd1830a0>},\n",
       " {'params': <generator object Module.parameters at 0x7efbdd183518>}]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp = [{'params': mod.parameters(), 'lr': 3} for mod in decoder_rnn.mods_attn()]\n",
    "tmp += [{'params': mod.parameters()} for mod in decoder_rnn.mods_gru()]\n",
    "tmp.append(\n",
    "    {'params': encoder_rnn.parameters()}\n",
    ")\n",
    "tmp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training etc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('localized localized polymerization politicize politicize politicize politicize politicize politicize politicize politicize politicize politicize politicize politicize politicize politicize politicize politicize politicize',\n",
       " 'localized localized polymerization politicize politicize politicize politicize politicize politicize politicize politicize politicize politicize politicize politicize politicize politicize politicize politicize politicize',\n",
       " 'november eighteenth two thousand six',\n",
       " ('November 18, 2006',\n",
       "  [69, 94, 5, 8, 20, 0],\n",
       "  'NUMBERS',\n",
       "  ['the',\n",
       "   'contest',\n",
       "   'on',\n",
       "   '<SAMPLE>',\n",
       "   'marked',\n",
       "   'the',\n",
       "   'first',\n",
       "   'time',\n",
       "   'ever',\n",
       "   'these',\n",
       "   'teams',\n",
       "   'had',\n",
       "   'been',\n",
       "   'ranked',\n",
       "   'no']))"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def test_model_single_sample(model=None, return_more=False, sample=False):\n",
    "    decoder_rnn.eval()\n",
    "    encoder_rnn.eval()\n",
    "    \n",
    "    if not sample:\n",
    "        sample = get_random_sample()\n",
    "    s_bef, s_aft, s_class, s_sentence = sample\n",
    "        \n",
    "    words_t = Variable(words_to_word_vectors_tensor(s_sentence, wv_vecs, wv_idx)).cuda()\n",
    "    \n",
    "    string_t = string_to_tensor(s_bef, chars_normal_index)\n",
    "    string_t = Variable(string_t).cuda()\n",
    "    \n",
    "    encoder_output, encoder_outputs = encoder_rnn(words_t, string_t)\n",
    "    \n",
    "    decoder_input = Variable(sos_tensor).cuda()\n",
    "    decoder_hidden = encoder_output\n",
    "    \n",
    "    decoded_output = []\n",
    "    decoder_attns_arr = []\n",
    "    max_length = 20\n",
    "    for _ in range(max_length):\n",
    "        decoder_output, decoder_hidden, decoder_attns = decoder_rnn(decoder_input, decoder_hidden, encoder_outputs)\n",
    "        decoder_attns_arr.append(decoder_attns)\n",
    "        #return decoder_output\n",
    "\n",
    "        topv, topi = decoder_output.data.topk(1)\n",
    "        word_index = topi[0][0]\n",
    "        word = words_after_common[word_index] # Use own prediction as next input\n",
    "                \n",
    "        if word == EOS_TOKEN:\n",
    "            break\n",
    "\n",
    "        decoded_output.append(word)\n",
    "                \n",
    "        decoder_input = torch.zeros(1, 1, len(words_after_index))\n",
    "        decoder_input[0, 0, word_index] = 1\n",
    "        decoder_input = Variable(decoder_input).cuda()\n",
    "    \n",
    "    output = ' '.join(decoded_output)\n",
    "    sample_target = ' '.join([words_after_common[w] for w in s_aft][:-1])\n",
    "    \n",
    "    decoder_rnn.train()\n",
    "    encoder_rnn.train()\n",
    "    \n",
    "    if return_more:\n",
    "        return output, decoded_output, decoder_attns_arr, sample\n",
    "    \n",
    "    return output, output, sample_target, sample\n",
    "    \n",
    "tmp = test_model_single_sample(None)\n",
    "tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "&              => nines rumors rumors rumors rumors square square square square square square square square square square square square square square square || [55, 0] \n",
      "                  ['minnesota', 'atlas', '<SAMPLE>', 'gazetteer', '.']\n",
      "December 10, 2009 => twelve twelve twelve rumors rumors square square square square square square square square square square square square square square square || [65, 93, 5, 8, 15, 0] \n",
      "                  ['retrieved', '<SAMPLE>', '.']\n"
     ]
    }
   ],
   "source": [
    "def print_local_wrong_predictions(max_results=10):\n",
    "    arr = get_some_wrong_predictions(None, test_model_single_sample, max_iterations=10000, max_results=max_results)\n",
    "    for sample, predict, output in arr:\n",
    "        s_bef, s_aft, s_class, s_sentence = sample\n",
    "        print(\"{:<14} => {:<14} || {} \\n{:>17} {}\".format(s_bef, predict, s_aft, '', s_sentence, ))\n",
    "print_local_wrong_predictions(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.00% (       0/     100)\n",
      "CPU times: user 2.16 s, sys: 24 ms, total: 2.19 s\n",
      "Wall time: 2.18 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "test_model_accuracy(encoder_rnn, test_model_single_sample, n_sample=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train(s_bef, s_aft, s_sentence, optimizer, loss_function,\n",
    "          use_teacher_forcing, max_length=20):\n",
    "    \n",
    "    words_t = Variable(words_to_word_vectors_tensor(s_sentence, wv_vecs, wv_idx)).cuda() \n",
    "    \n",
    "    string_t = string_to_tensor(s_bef, chars_normal_index)\n",
    "    string_t = Variable(string_t).cuda()\n",
    "    \n",
    "    target_arr = s_aft\n",
    "    optimizer.zero_grad()\n",
    "    loss = 0\n",
    "    \n",
    "    \n",
    "    encoder_output, encoder_outputs = encoder_rnn(words_t, string_t)\n",
    "    \n",
    "    \n",
    "    decoder_hidden = encoder_output\n",
    "    decoder_input = Variable(sos_tensor).cuda()\n",
    "\n",
    "    decoded_output = []\n",
    "    for i in range(len(target_arr)):\n",
    "        decoder_output, decoder_hidden, decoder_attns = decoder_rnn(decoder_input, decoder_hidden, encoder_outputs)\n",
    "\n",
    "        decoder_target_i = target_arr[i]\n",
    "        decoder_target_i = Variable(torch.LongTensor([decoder_target_i])).cuda()\n",
    "        loss += loss_function(decoder_output, decoder_target_i)\n",
    "        \n",
    "        topv, topi = decoder_output.data.topk(1)\n",
    "        word_index = topi[0][0]\n",
    "        word = words_after_common[word_index] # Use own prediction as next input\n",
    "        decoded_output.append(word)\n",
    "        \n",
    "        if use_teacher_forcing:\n",
    "            word_index = target_arr[i] # replace input with right target\n",
    "        else:\n",
    "            # use output normally as input \n",
    "            if word == EOS_TOKEN:\n",
    "                break\n",
    "                \n",
    "        decoder_input = torch.zeros(1, 1, len(words_after_index))\n",
    "        decoder_input[0, 0, word_index] = 1\n",
    "        decoder_input = Variable(decoder_input).cuda()\n",
    "        \n",
    "    if decoded_output[-1] == EOS_TOKEN:\n",
    "        decoded_output = decoded_output[:-1]\n",
    "        \n",
    "    loss.backward()\n",
    "    \n",
    "    # not used yet\n",
    "    # https://github.com/pytorch/examples/blob/master/word_language_model/main.py\n",
    "    if clip_parameters_value:\n",
    "        for m in [decoder_rnn, encoder_rnn]:\n",
    "            torch.nn.utils.clip_grad_norm(m.parameters(), clip_parameters_value)\n",
    "\n",
    "    optimizer.step()\n",
    "\n",
    "    return ' '.join(decoded_output), (loss.data[0] / len(target_arr))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = [op for op in decoder_rnn.parameters()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       "-1.0848\n",
       "[torch.cuda.FloatTensor of size 1 (GPU 0)]"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp[0].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 0, 2, 2, 4, 2, 16]"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[len(op['params']) for op in optimizer.param_groups]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_iterations(n_iters=100000, lr=0.001, teacher_forcing_ratio=0.5,\n",
    "                     print_every=10000, plot_every=1000):\n",
    "    global optimizer\n",
    "    start = time.time()\n",
    "    \n",
    "    decoder_rnn.train()\n",
    "    encoder_rnn.train()\n",
    "\n",
    "    current_loss = 0\n",
    "    current_loss_iter = 0\n",
    "\n",
    "    tmp = [{'params': mod.parameters(), 'lr': (lr/10)} for mod in decoder_rnn.mods_attn()]\n",
    "    tmp += [{'params': mod.parameters()} for mod in decoder_rnn.mods_gru()]\n",
    "    tmp.append(\n",
    "        {'params': encoder_rnn.parameters()}\n",
    "    )\n",
    "    optimizer = torch.optim.Adam(tmp, lr=lr)\n",
    "    \n",
    "    loss_function = nn.NLLLoss()\n",
    "    \n",
    "    for iteration in range(1, n_iters + 1):\n",
    "        model_training.iterations += 1\n",
    "        \n",
    "        use_teacher_forcing = random.random() < teacher_forcing_ratio\n",
    "        \n",
    "        s_bef, s_aft, s_class, s_sentence = get_random_sample()\n",
    "        \n",
    "        result, loss = train(s_bef=s_bef, s_aft=s_aft, s_sentence=s_sentence,\n",
    "                             optimizer=optimizer,\n",
    "                             loss_function=nn.NLLLoss(), use_teacher_forcing=use_teacher_forcing,\n",
    "                             max_length=40 )\n",
    "        \n",
    "        current_loss += loss\n",
    "        current_loss_iter += 1\n",
    "\n",
    "        # Print iter number, loss, name and guess\n",
    "        if iteration % print_every == 0:\n",
    "            teacher_forcing_str = \"\"\n",
    "            if use_teacher_forcing:\n",
    "                teacher_forcing_str = \"(forcing)\"\n",
    "            s_aft_sentence = ' '.join([words_after_common[w] for w in s_aft][:-1])\n",
    "            correct = '✓' if result == s_aft_sentence else \"✗: {}\".format(s_aft_sentence)\n",
    "            \n",
    "            print(\"{:>6d} {:>4.0%} ({:>8}) {:>7.3f}   | {:>6.2f}: {} -> {} ({}) {}\".format(\n",
    "                      model_training.iterations, iteration/n_iters, time_since(start),\n",
    "                      current_loss/current_loss_iter, loss,\n",
    "                      s_bef, result, correct, teacher_forcing_str))\n",
    "\n",
    "        # Add current loss avg to list of losses\n",
    "        if iteration % plot_every == 0:\n",
    "            model_training.losses.append(current_loss / plot_every)\n",
    "            model_training.learning_rates.append(lr)\n",
    "            current_loss = 0\n",
    "            current_loss_iter = 0\n",
    "            \n",
    "        if model_training.iterations % 50000 == 0 or model_training.iterations == 10:\n",
    "            model_training.save_models()\n",
    "            acc = test_model_accuracy(encoder_rnn, test_model_single_sample)\n",
    "            model_training.accuracy.append(acc)\n",
    "    \n",
    "    # test_model_accuracy(model, n_sample=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Save path: data/models/whole_gen_12_attn_learning_rates\n"
     ]
    }
   ],
   "source": [
    "model_training = ModelTraining(MODEL_SAVE_PATH, [encoder_rnn, decoder_rnn])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     9  18% (   0m 0s)   7.004   |   7.18: sr -> localized nineteen (✗: senior) (forcing)\n",
      "Saved model to data/models/whole_gen_12_attn_learning_rates/10_(EncoderRNN/DecoderRNN)\n",
      "Accuracy: 0.06% (       6/   10000)\n",
      "    18  36% (  0m 35s)   7.071   |   7.10: & -> <EOS> (✗: and) (forcing)\n",
      "    27  54% (  0m 35s)   6.686   |   6.97: - -> <EOS> (✗: to) (forcing)\n",
      "    36  72% (  0m 36s)   6.341   |   6.92: & -> <EOS> (✗: and) (forcing)\n",
      "    45  90% (  0m 36s)   6.307   |   3.59: W. ->  (✗: w) \n"
     ]
    }
   ],
   "source": [
    "train_iterations(n_iters=50, print_every=9, lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   550  53% (   0m 6s)   3.086   |   4.16: BioLib.cz -> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> (✗: b i o l i b dot c z) (forcing)\n"
     ]
    }
   ],
   "source": [
    "train_iterations(n_iters=(1000-model_training.iterations), print_every=500, lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1e-05"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.0001"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer.param_groups[0]['lr']\n",
    "optimizer.param_groups[6]['lr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  2000  11% (  0m 17s)   2.717   |   4.70: April 27, 2014 -> nineteen twenty a t e o (✗: april twenty seventh twenty fourteen) \n",
      "  3000  22% (  0m 31s)   2.439   |   1.64: USC -> m (✗: u s c) \n",
      "  4000  33% (  0m 46s)   2.177   |   2.90: IVF -> u s (✗: i v f) \n",
      "  5000  44% (   1m 2s)   2.120   |   2.67: kilometres -> theater (✗: kilometers) (forcing)\n",
      "  6000  56% (  1m 19s)   2.001   |   1.53: $91,504 -> nineteen thousand (✗: ninety one thousand five hundred four dollars) \n",
      "  7000  67% (  1m 34s)   1.952   |   0.01: & -> and (✓) \n",
      "  8000  78% (  1m 52s)   1.810   |   2.78: K. A. -> s s (✗: k a) \n",
      "  9000  89% (   2m 9s)   1.768   |   1.89: 50 -> one (✗: fifty) (forcing)\n",
      " 10000 100% (  2m 28s)   1.683   |   1.45: _ -> number (✗: underscore) (forcing)\n"
     ]
    }
   ],
   "source": [
    "train_iterations(n_iters=9000, lr=0.0001, print_every=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "time.sleep(60*60*3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 20000  11% (  2m 44s)   0.767   |   0.99: 511 -> five hundred one (✗: five hundred eleven) \n",
      " 30000  22% (  5m 35s)   0.397   |   0.00: 1997 -> nineteen ninety seven (✓) \n",
      " 40000  33% (  8m 18s)   0.327   |   0.01: 1981 -> nineteen eighty one (✓) \n",
      " 50000  44% ( 11m 13s)   0.273   |   2.60: http://rise.cayey.upr.edu/main/) -> h t t p colon colon slash s e s i i h i s slash slash slash com r slash slash s r e r s e s s e e i e s i n e e e s s s e e e e i n i (✗: h t t p colon slash slash r i s e dot c a y e y dot u p r dot e d u slash m a i n slash c l o s i n g p a r e n t h e s i s) (forcing)\n",
      "Saved model to data/models/whole_gen_12_attn_learning_rates/50000_(EncoderRNN/DecoderRNN)\n",
      "Accuracy: 88.57% (    8857/   10000)\n",
      " 60000  56% ( 14m 59s)   0.230   |   0.04: 2000 -> two thousand (✓) (forcing)\n",
      " 70000  67% ( 17m 52s)   0.209   |   0.01: Nov -> november (✓) \n",
      " 80000  78% ( 20m 44s)   0.253   |   0.62: workhouses.org.uk -> w o r k h o u s e s dot o r g dot u k k (✗: w o r k h o u s e s dot o r g dot u k) \n",
      " 90000  89% ( 23m 39s)   0.181   |   0.00: & -> and (✓) (forcing)\n",
      "100000 100% ( 26m 38s)   0.227   |   0.00: advertising -> advertizing (✓) (forcing)\n",
      "Saved model to data/models/whole_gen_12_attn_learning_rates/100000_(EncoderRNN/DecoderRNN)\n",
      "Accuracy: 91.81% (    9181/   10000)\n"
     ]
    }
   ],
   "source": [
    "train_iterations(n_iters=90000, print_every=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "110000   5% (  2m 52s)   0.203   |   2.66: 3,431 -> thirty thirty three hundred thirty thirty thirty (✗: three thousand four hundred thirty one) (forcing)\n",
      "120000  10% (  5m 44s)   0.271   |   0.15: Ets -> e t's (✓) \n",
      "130000  15% (  8m 38s)   0.229   |   0.00: vol -> volume (✓) (forcing)\n",
      "140000  20% ( 11m 36s)   0.214   |   0.00: CAHPERD -> c a h p e r d (✓) (forcing)\n",
      "150000  25% ( 14m 27s)   0.191   |   0.01: 44 -> forty four (✓) \n",
      "Saved model to data/models/whole_gen_12_attn_learning_rates/150000_(EncoderRNN/DecoderRNN)\n",
      "Accuracy: 92.67% (    9267/   10000)\n",
      "160000  30% (  18m 9s)   0.270   |   0.01: .52 -> point five two (✓) \n",
      "170000  35% (  21m 2s)   0.222   |   0.01: # -> number (✓) \n",
      "180000  40% ( 23m 54s)   0.273   |   0.00: UK -> u k (✓) (forcing)\n",
      "190000  45% ( 26m 47s)   0.203   |   0.00: jr -> junior (✓) (forcing)\n",
      "200000  50% ( 29m 38s)   0.264   |   0.00: ltd -> limited (✓) (forcing)\n",
      "Saved model to data/models/whole_gen_12_attn_learning_rates/200000_(EncoderRNN/DecoderRNN)\n",
      "Accuracy: 91.27% (    9127/   10000)\n",
      "210000  55% ( 33m 23s)   0.263   |   0.00: - -> to (✓) (forcing)\n",
      "220000  60% ( 36m 21s)   0.256   |   0.00: C. -> c (✓) (forcing)\n",
      "230000  65% (  39m 7s)   0.206   |   0.00: & -> and (✓) \n",
      "240000  70% ( 41m 56s)   0.229   |   0.00: 1973 -> nineteen seventy three (✓) \n",
      "250000  75% ( 44m 45s)   0.289   |   0.08: HIV -> h i v (✓) (forcing)\n",
      "Saved model to data/models/whole_gen_12_attn_learning_rates/250000_(EncoderRNN/DecoderRNN)\n",
      "Accuracy: 87.83% (    8783/   10000)\n",
      "260000  80% ( 48m 32s)   0.349   |   0.00: st -> saint (✓) \n",
      "270000  85% ( 51m 24s)   0.399   |   0.00: & -> and (✓) (forcing)\n",
      "280000  90% ( 54m 18s)   0.526   |   0.01: May 23, 2011 -> may twenty third twenty eleven (✓) \n",
      "290000  95% ( 57m 10s)   0.451   |   0.00: labourers -> laborers (✓) (forcing)\n",
      "300000 100% ( 59m 57s)   0.408   |   0.11: AK -> a k (✓) \n",
      "Saved model to data/models/whole_gen_12_attn_learning_rates/300000_(EncoderRNN/DecoderRNN)\n",
      "Accuracy: 84.83% (    8483/   10000)\n"
     ]
    }
   ],
   "source": [
    "train_iterations(n_iters=200000, print_every=10000, teacher_forcing_ratio=0.5, lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "051452-        => one one one one five one one five one sil one sil one sil one sil one sil one sil || [25, 14, 9, 19, 14, 5, 0] \n",
      "                  ['5', 'penguin', 'guide', 'to', 'jazz', 'on', 'cd', ',', 'fifth', 'edition', ',', 'penguin', 'books', ',', 'london', ',', '2000', ',', 'isbn', '0', '-', '14', '-', '<SAMPLE>', 'x', ',', 'p', '.', '620', '.']\n",
      "Occupyatlanta.org => o c c u p a y u m a u n u m a u n u y u || [25, 21, 21, 43, 24, 86, 22, 30, 42, 22, 29, 30, 22, 74, 25, 35, 53, 0] \n",
      "                  ['<SAMPLE>', '(', 'official', 'website', ')', '.']\n",
      "01             => one one        || [25, 9, 0] \n",
      "                  ['airay', 'was', 'born', 'at', 'clifton', 'in', 'westmoreland', 'in', '1600', '/', '<SAMPLE>', '.']\n",
      "WCFT-          => w c f r        || [52, 21, 37, 30, 0] \n",
      "                  ['<SAMPLE>', 'fm', \"'s\", 'main', 'studio', 'is', 'located', 'at', '4', '50', 'route', '2', 'oh', '4', ',', 'highway', 'in', 'selinsgrove', '.']\n",
      "12.1 mph       => twelve point two one || [47, 46, 9, 123, 112, 147, 0] \n",
      "                  ['they', 'could', 'reach', '17', 'knots', '(', '31', 'km', '/', 'h', ';', '20', 'mph', ')', 'on', 'the', 'surface', 'and', '10', '.', '5', 'knots', '(', '19', '.', '4', 'km', '/', 'h', ';', '<SAMPLE>', ')', 'underwater', '.']\n",
      "SWOrchestra.comSteve => t w o r c h s s h s h t || [17, 52, 25, 35, 21, 45, 28, 17, 30, 35, 22, 74, 21, 25, 32, 17, 30, 28, 54, 28, 0] \n",
      "                  ['<SAMPLE>', 'weisberg', ',', 'born', '1963', 'in', 'norfolk', 'virginia', ',', 'is', 'a', 'composer', '/', 'arranger', '/', 'pianist', 'and', 'international', 'recording', 'artist', '/', 'producer', '.']\n",
      "bsnpubs.com    => b s n p u s dot c o dot c o m || [36, 17, 29, 24, 43, 36, 17, 74, 21, 25, 32, 0] \n",
      "                  ['patrice', 'eyries', ',', 'mike', 'callahan', '&', 'david', 'edwards', ',', '\"', 'dunhill', 'album', 'discography', '\"', ',', '<SAMPLE>', '(', 'retrieved', 'september', '29', ',', '2013', ')', '.']\n",
      "$3000          => march dollars  || [13, 8, 85, 0] \n",
      "                  ['the', 'cost', 'of', 'each', '90', '-', 'second', 'episode', 'was', 'approximately', '<SAMPLE>', '.']\n",
      "May 29, 2014   => may twenty ninth of may twenty fourteen || [66, 6, 84, 6, 50, 0] \n",
      "                  ['kecseg', ',', 'ross', '(', '<SAMPLE>', ')', '.']\n",
      "NYTimes.com    => n y t i m y s dot c o m || [29, 86, 30, 31, 32, 28, 17, 74, 21, 25, 32, 0] \n",
      "                  ['\"', 'fashion', \"'s\", 'invisible', 'man', '—', '<SAMPLE>', '\"', '.']\n"
     ]
    }
   ],
   "source": [
    "print_local_wrong_predictions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "310000   5% (  2m 55s)   0.424   |   0.00: UK -> u k (✓) \n",
      "320000  10% (  5m 51s)   0.310   |   0.02: 20 km -> twenty kilometers (✓) \n",
      "330000  15% (  8m 45s)   0.394   |   0.00: vs -> versus (✓) \n",
      "340000  20% ( 11m 32s)   0.377   |   0.00: coloured -> colored (✓) (forcing)\n",
      "350000  25% ( 14m 16s)   0.421   |   0.00: 58 -> fifty eight (✓) \n",
      "Saved model to data/models/whole_gen_12_attn_learning_rates/350000_(EncoderRNN/DecoderRNN)\n",
      "Accuracy: 85.33% (    8533/   10000)\n",
      "360000  30% ( 17m 53s)   0.562   |   0.01: 10 -> ten (✓) (forcing)\n",
      "370000  35% ( 20m 46s)   0.427   |   0.00: - -> to (✓) \n",
      "380000  40% ( 23m 33s)   0.442   |   0.00: # -> number (✓) \n",
      "390000  45% ( 26m 20s)   0.477   |   0.15: Osy -> o s y (✓) \n",
      "400000  50% (  29m 9s)   0.488   |   0.00: 1983 -> nineteen eighty three (✓) (forcing)\n",
      "Saved model to data/models/whole_gen_12_attn_learning_rates/400000_(EncoderRNN/DecoderRNN)\n",
      "Accuracy: 84.11% (    8411/   10000)\n",
      "410000  55% ( 32m 54s)   0.357   |   0.12: January 3, 1921 -> january third nineteen twenty one (✓) (forcing)\n",
      "420000  60% ( 35m 46s)   0.308   |   0.01: 2001 -> two thousand one (✓) \n",
      "430000  65% ( 38m 39s)   0.389   |   0.00: & -> and (✓) \n",
      "440000  70% ( 41m 29s)   0.291   |   0.01: 15th -> fifteenth (✓) (forcing)\n",
      "450000  75% ( 44m 18s)   0.370   |   1.91: DR -> drive (✗: doctor) \n",
      "Saved model to data/models/whole_gen_12_attn_learning_rates/450000_(EncoderRNN/DecoderRNN)\n",
      "Accuracy: 86.00% (    8600/   10000)\n",
      "460000  80% (  48m 0s)   0.393   |   0.00: _ -> underscore (✓) \n",
      "470000  85% ( 50m 47s)   0.367   |   0.72: March 16, 2013 -> march sixth twenty thirteen (✗: march sixteenth twenty thirteen) \n",
      "480000  90% ( 53m 36s)   0.290   |   0.00: 138 -> one hundred thirty eight (✓) (forcing)\n",
      "490000  95% ( 56m 29s)   0.468   |   1.13: TCM.com -> t c m dot c m (✗: t c m dot c o m) \n",
      "500000 100% ( 59m 21s)   0.458   |   0.00: & -> and (✓) (forcing)\n",
      "Saved model to data/models/whole_gen_12_attn_learning_rates/500000_(EncoderRNN/DecoderRNN)\n",
      "Accuracy: 84.59% (    8459/   10000)\n"
     ]
    }
   ],
   "source": [
    "train_iterations(n_iters=200000, print_every=10000, teacher_forcing_ratio=0.3, lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50             => fifty percent  || [38, 0] \n",
      "                  ['if', 'the', 'tapes', 'need', 'permanent', 'preservation', ',', 'they', 'should', 'be', 'stored', 'at', '46', '-', '<SAMPLE>', 'degrees', 'fahrenheit', 'at', '20', '-', '30%', 'relative', 'humidity', '.']\n",
      "cuxhaven.de    => c u x dot o e dot dot o r m e r m || [21, 43, 97, 45, 22, 54, 28, 29, 74, 26, 28, 0] \n",
      "                  ['marie', 'louise', 'rendant', ':', 'kugelbake', ',', 'alte', 'liebe', '&', 'der', 'steubenhoft', '(', 'regionenverlag', 'gmbh', ')', 'isbn', '978', '-', '3', '-', '940389', '-', '35', '-', '0', '(', 'german', ')', 'die', 'kugelbake', 'at', '<SAMPLE>', '(', 'german', ')', 'retrieved', '29', '-', 'feb', '-', '2012', '.']\n",
      "mij            => m              || [32, 31, 60, 0] \n",
      "                  ['\"', 'een', 'tweede', 'plaats', 'telt', 'niet', 'voor', '<SAMPLE>', '\"', '.']\n",
      "Ngobe          => n g o b o o    || [29, 53, 25, 36, 28, 0] \n",
      "                  ['noncomala', 'was', 'the', 'main', 'and', 'creative', 'deity', 'of', 'the', 'ngabe', 'of', 'the', '<SAMPLE>', 'buglé', 'comarca', 'in', 'panama', '.']\n",
      "USATODAY.com   => u s a t a d a y y dot y dot c o || [43, 17, 22, 30, 25, 26, 22, 86, 74, 21, 25, 32, 0] \n",
      "                  ['\"', 'nielsens', ':', 'dallas', ',', \"'\", 'boston', \"'\", 'score', 'key', 'ratings', 'wins', '—', '<SAMPLE>', '\"', '.']\n",
      "09/06/2011     => o twenty sixth two o || [11, 79, 12, 64, 6, 48, 0] \n",
      "                  ['published', 'on', '<SAMPLE>', '17', ':', '00', '.']\n",
      "JosephTheMusical.com => b c u c u c u a u c u c u c u c u c u c || [60, 25, 17, 28, 24, 45, 30, 45, 28, 32, 43, 17, 31, 21, 22, 42, 74, 21, 25, 32, 0] \n",
      "                  ['musical', 'numbers', ',', '<SAMPLE>', '.']\n",
      "mythindex.com  => w y t a y dot c o y y dot c o m || [32, 86, 30, 45, 31, 29, 26, 28, 97, 74, 21, 25, 32, 0] \n",
      "                  ['examples', 'of', 'baubo', 'figurinesgreek', 'mythology', 'index', ':', 'baubo', 'at', '<SAMPLE>', '.']\n",
      "hTERT          => t t e r t      || [45, 30, 28, 35, 30, 0] \n",
      "                  ['\"', 'on', 'the', 'road', 'to', 'immortality', ':', '<SAMPLE>', 'upregulation', 'in', 'cancer', 'cells', '\"', '.']\n",
      "DnaIndia.com   => d n a i a d a a dot a o m || [26, 29, 22, 31, 29, 26, 31, 22, 74, 21, 25, 32, 0] \n",
      "                  ['\"', 'sanskrit', 'daily', 'celebrates', '42', 'nd', 'anniversary', '\"', ',', 'online', 'edition', 'of', '<SAMPLE>', ',', '2007', '-', '07', '-', '15', 'sharath', 's', '.', 'srivatsa', '(', '2006', '-', '07', '-', '03', ')', '.']\n"
     ]
    }
   ],
   "source": [
    "print_local_wrong_predictions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "510000  10% (  2m 49s)   0.291   |   2.65: 15:36 -> fifteen thirty thirty six (✗: fifteen thirty six) \n",
      "520000  20% (  5m 42s)   0.256   |   0.05: 2011 -> twenty eleven (✓) (forcing)\n",
      "530000  30% (  8m 41s)   0.301   |   0.10: VO -> v o (✓) \n",
      "540000  40% ( 11m 33s)   0.270   |   9.70: 11-21-2010 -> the eleventh of november twenty ten (✗: november twenty first twenty ten) \n",
      "550000  50% ( 14m 21s)   0.270   |   0.00: - -> to (✓) (forcing)\n",
      "Saved model to data/models/whole_gen_12_attn_learning_rates/550000_(EncoderRNN/DecoderRNN)\n",
      "Accuracy: 89.26% (    8926/   10000)\n",
      "560000  60% (  18m 6s)   0.310   |   0.01: CZ -> c z (✓) (forcing)\n",
      "570000  70% ( 20m 56s)   0.262   |   0.15: II -> the second (✓) (forcing)\n",
      "580000  80% ( 23m 46s)   0.263   |   0.00: & -> and (✓) \n",
      "590000  90% ( 26m 43s)   0.263   |   0.00: 18 -> eighteen (✓) \n",
      "600000 100% ( 29m 35s)   0.207   |   0.00: _ -> underscore (✓) \n",
      "Saved model to data/models/whole_gen_12_attn_learning_rates/600000_(EncoderRNN/DecoderRNN)\n",
      "Accuracy: 89.11% (    8911/   10000)\n"
     ]
    }
   ],
   "source": [
    "train_iterations(n_iters=100000, print_every=10000, teacher_forcing_ratio=0.5, lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HamptonRoads.com => h a m p a t h o n o n d o m || [45, 22, 32, 24, 30, 25, 29, 35, 25, 22, 26, 17, 74, 21, 25, 32, 0] \n",
      "                  ['<SAMPLE>', '(', 'the', 'virginian', 'pilot', ')', '.']\n",
      "worldcat.org   => w o r l d c a a dot o r g || [52, 25, 35, 42, 26, 21, 22, 30, 74, 25, 35, 53, 0] \n",
      "                  ['\"', 'regionalism', 'and', 'ethnic', 'nationalism', 'in', 'france', ':', 'a', 'case', 'study', 'of', 'corsica', '\"', ',', '<SAMPLE>', ';', 'accessed', '1', 'march', '2014', '.']\n",
      "1994 won       => one hundred ninety four hundred ninety four || [9, 8, 15, 10, 23, 19, 381, 0] \n",
      "                  ['partizan', '<SAMPLE>', '2', ':', '0', '.']\n",
      "http://www.firstworldwar.com/bio/navarre.htm => h t p colon slash slash w w w w w w w w w dot c a h o || [45, 30, 30, 24, 129, 101, 101, 52, 52, 52, 74, 37, 31, 35, 17, 30, 52, 25, 35, 42, 26, 52, 22, 35, 74, 156, 101, 36, 31, 25, 101, 29, 22, 54, 22, 35, 35, 28, 74, 45, 30, 32, 0] \n",
      "                  ['firstworldwar', '.', 'com', 'website', 'page', 'on', 'navarre', 'at', '<SAMPLE>', 'retrieved', '20', 'february', '2013', '.']\n",
      "https://itunes.apple.com/us/album/dreams-single/id1003405694 => h t t p colon slash slash w e e e e e e e e e e e e || [45, 30, 30, 24, 17, 129, 101, 101, 31, 30, 43, 29, 28, 17, 74, 22, 24, 24, 42, 28, 74, 156, 101, 43, 17, 101, 22, 42, 36, 43, 32, 101, 26, 35, 28, 22, 32, 17, 115, 17, 31, 29, 53, 42, 28, 101, 31, 26, 25, 29, 28, 25, 25, 30, 45, 35, 28, 28, 37, 25, 43, 35, 25, 37, 31, 54, 28, 17, 31, 97, 29, 31, 29, 28, 37, 25, 43, 35, 0] \n",
      "                  ['june', '15', ',', '2015', '<SAMPLE>', '.']\n",
      "tues           => three u e s    || [223, 0] \n",
      "                  ['radio', 'info', ':', '\"', 'retro', ':', 'montréal', '/', 'southern', 'québec', '<SAMPLE>']\n",
      "7-10-2015      => seven seven seven seven seven seven seven seven seven seven seven seven seven || [11, 93, 12, 67, 6, 51, 0] \n",
      "                  ['rijec', 'u', 'koju', 'stane', 'recenica', 'by', 'kresimir', 'bagic', ',', 'matica', 'hrvatska', ',', 'retrieved', '<SAMPLE>', '(', 'croatian', ')', 'rose', ',', 'arnold', 'm', '.', '(', '1999', ')', '.']\n",
      "4.0%           => four point percent || [19, 46, 104, 83, 0] \n",
      "                  ['<SAMPLE>', 'of', 'the', 'population', 'were', 'hispanic', 'or', 'latino', 'of', 'any', 'race', '.']\n",
      "20,731         => two thousand seven hundred one || [6, 8, 18, 10, 34, 9, 0] \n",
      "                  ['population', ':', '<SAMPLE>', '(', '2009', 'census', 'results', ')', ';', '25', ',', '927', '(', '1999', 'census', 'results', ')', '.']\n",
      "Newspapers.com => n e w s p a p e s dot c o m || [29, 28, 52, 17, 24, 22, 24, 28, 35, 17, 74, 21, 25, 32, 0] \n",
      "                  ['\"', '19', 'dec', '1972', ',', 'page', '24', '-', 'at', '<SAMPLE>', '\"', '.']\n"
     ]
    }
   ],
   "source": [
    "print_local_wrong_predictions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "610000  10% (  2m 47s)   0.485   |   0.69: ZK- -> z hundred (✗: z k) \n",
      "620000  20% (  5m 34s)   0.529   |   0.00: centre -> center (✓) \n",
      "630000  30% (  8m 26s)   0.445   |   0.02: February 19, 1953 -> february nineteenth nineteen fifty three (✓) \n",
      "640000  40% ( 11m 15s)   0.473   |   0.00: & -> and (✓) \n",
      "650000  50% (  14m 3s)   0.407   |   0.00: 6 -> six (✓) \n",
      "Saved model to data/models/whole_gen_12_attn_learning_rates/650000_(EncoderRNN/DecoderRNN)\n",
      "Accuracy: 84.51% (    8451/   10000)\n",
      "660000  60% ( 17m 47s)   0.447   |   0.09: November 5, 2009 -> november fifth two thousand nine (✓) \n",
      "670000  70% ( 20m 39s)   0.481   |   0.00: J. -> j (✓) \n",
      "680000  80% ( 23m 25s)   0.454   |   0.59: 3702 -> three thousand seven hundred two o (✗: three thousand seven hundred two) \n",
      "690000  90% ( 26m 13s)   0.509   |   0.56: 1000 -> one o (✗: one thousand) \n",
      "700000 100% (  29m 2s)   0.471   |   0.00: & -> and (✓) \n",
      "Saved model to data/models/whole_gen_12_attn_learning_rates/700000_(EncoderRNN/DecoderRNN)\n",
      "Accuracy: 83.73% (    8373/   10000)\n"
     ]
    }
   ],
   "source": [
    "train_iterations(n_iters=100000, print_every=10000, teacher_forcing_ratio=0.1, lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1800           => eighteen o     || [40, 10, 0] \n",
      "                  ['the', 'british', 'recaptured', 'her', 'in', '<SAMPLE>', ',', 'returned', 'her', 'to', 'service', ',', 'but', 'sold', 'her', 'in', '1801', '.']\n",
      "79.8           => seventy point nine eight || [33, 15, 46, 16, 0] \n",
      "                  ['for', 'every', '100', 'females', 'age', '18', 'and', 'over', ',', 'there', 'were', '<SAMPLE>', 'males', '.']\n",
      "Download.com   => d o w n n dot o m dot c dot o m || [26, 25, 52, 29, 42, 25, 22, 26, 74, 21, 25, 32, 0] \n",
      "                  ['\"', '<SAMPLE>', 'wraps', 'downloads', 'in', 'bloatware', ',', 'lies', 'about', 'motivations', '\"', '.']\n",
      "III            => two            || [13, 0] \n",
      "                  ['22', ':', 'st', 'mary', 'magdalene', 'penitent', ',', '<SAMPLE>', 'class', '.']\n",
      "SANDF          => s a n d f f    || [17, 22, 29, 26, 37, 0] \n",
      "                  ['col', 'l', 'b', 'van', 'stade', ',', 'senior', 'staff', 'officer', 'rationalisation', ',', '<SAMPLE>', '(', '1997', ')', '.']\n",
      "Climateprediction.net => a l i m a t o n o o o o r || [21, 42, 31, 32, 22, 30, 28, 24, 35, 28, 26, 31, 21, 30, 31, 25, 29, 74, 29, 28, 30, 0] \n",
      "                  ['<SAMPLE>', 'is', 'working', 'on', 'model', 'uncertainties', 'not', 'the', 'scenarios', '.']\n",
      "seq            => year           || [17, 28, 111, 0] \n",
      "                  ['343', 'et', '<SAMPLE>', '.']\n",
      "2.84           => two point eight eight || [5, 46, 16, 19, 0] \n",
      "                  ['the', 'average', 'household', 'size', 'was', '2', '.', '33', 'and', 'the', 'average', 'family', 'size', 'was', '<SAMPLE>', '.']\n",
      "30 kg          => thirty kilometers || [34, 172, 0] \n",
      "                  ['stoye', 'made', 'the', 'bodywork', ',', 'which', 'is', 'aluminium', 'and', 'contributes', 'to', 'the', 'trailer', 'weighing', 'only', '<SAMPLE>', '(', '66', 'lb', ')', '.']\n",
      "8 June 2010    => the eighth of june twenty sixteen || [11, 80, 12, 68, 6, 44, 0] \n",
      "                  ['brantley', ',', 'max', '(', '<SAMPLE>', ')', '.']\n"
     ]
    }
   ],
   "source": [
    "print_local_wrong_predictions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "710000   5% (  2m 51s)   0.424   |   0.00: 42 -> forty two (✓) \n",
      "720000  10% (  5m 37s)   0.313   |   0.01: N. -> n (✓) \n",
      "730000  15% (  8m 28s)   0.450   |   0.00: ISBN -> i s b n (✓) \n",
      "740000  20% ( 11m 25s)   0.397   |   0.02: IAAF -> i a a f (✓) \n",
      "750000  25% ( 14m 13s)   0.314   |   0.00: dr -> doctor (✓) (forcing)\n",
      "Saved model to data/models/whole_gen_12_attn_learning_rates/750000_(EncoderRNN/DecoderRNN)\n",
      "Accuracy: 85.66% (    8566/   10000)\n",
      "760000  30% ( 17m 53s)   0.467   |   0.00: U.S. -> u s (✓) \n",
      "770000  35% ( 20m 54s)   0.349   |   0.00: M. -> m (✓) \n",
      "780000  40% ( 23m 50s)   0.346   |   0.00: favourite -> favorite (✓) \n",
      "790000  45% ( 26m 42s)   0.413   |   0.00: & -> and (✓) \n",
      "800000  50% ( 29m 33s)   0.383   |   0.00: LLC -> l l c (✓) \n",
      "Saved model to data/models/whole_gen_12_attn_learning_rates/800000_(EncoderRNN/DecoderRNN)\n",
      "Accuracy: 85.08% (    8508/   10000)\n",
      "810000  55% ( 33m 16s)   0.398   |   0.00: 1996 -> nineteen ninety six (✓) \n",
      "820000  60% (  36m 3s)   0.354   |   0.00: st -> saint (✓) \n",
      "830000  65% ( 38m 52s)   0.343   |   0.00: 2013 -> twenty thirteen (✓) \n",
      "840000  70% ( 41m 37s)   0.457   |   1.14: openPagov.org -> november p e n o a o o (✗: o p e n p a g o v dot o r g) \n",
      "850000  75% ( 44m 25s)   0.321   |   0.00: behaviour -> behavior (✓) \n",
      "Saved model to data/models/whole_gen_12_attn_learning_rates/850000_(EncoderRNN/DecoderRNN)\n",
      "Accuracy: 85.05% (    8505/   10000)\n",
      "860000  80% (  48m 5s)   0.406   |   0.06: LNU -> l n u (✓) \n",
      "870000  85% ( 50m 50s)   0.301   |   0.00: - -> to (✓) \n",
      "880000  90% ( 53m 44s)   0.377   |   0.00: vs -> versus (✓) \n",
      "890000  95% ( 56m 34s)   0.362   |   0.01: USA. -> u s a (✓) (forcing)\n",
      "900000 100% ( 59m 27s)   0.364   |   0.07: # -> number (✓) \n",
      "Saved model to data/models/whole_gen_12_attn_learning_rates/900000_(EncoderRNN/DecoderRNN)\n",
      "Accuracy: 85.80% (    8580/   10000)\n"
     ]
    }
   ],
   "source": [
    "train_iterations(n_iters=200000, print_every=10000, teacher_forcing_ratio=0.1, lr=0.0005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4:29:10        => ten o ten      || [19, 245, 6, 15, 215, 55, 44, 182, 0] \n",
      "                  ['yusuke', 'mamada', '(', 'jpn', ')', '<SAMPLE>', 'women', \"'s\", 'half', 'marathon', '1', '.']\n",
      "6.6/km²        => six point six k || [20, 46, 20, 112, 106, 89, 0] \n",
      "                  ['there', 'were', '998', 'housing', 'units', 'at', 'an', 'average', 'density', 'of', '17', '.', '2', 'per', 'square', 'mile', '(', '<SAMPLE>', ')', '.']\n",
      "SAT            => s a t          || [222, 0] \n",
      "                  ['in', '2006', '<SAMPLE>', 'had', '724', 'members', '.']\n",
      "xstarsnews.com => x s t a r n e s e o c e o m o c o c o m || [97, 17, 30, 22, 35, 17, 29, 28, 52, 17, 74, 21, 25, 32, 0] \n",
      "                  ['\"', 'winners', 'of', 'the', '2007', 'ficeb', 'ninfa', 'awards', '\"', ',', 'h', '.', 'b', '.', ',', 'october', '10', ',', '2007', ',', '<SAMPLE>', '.']\n",
      "qu'un          => u u            || [111, 43, 43, 29, 0] \n",
      "                  ['in', 'exile', ',', 'hugo', 'dedicated', 'it', 'to', 'his', 'home', 'country', ':', 'livre', ',', '<SAMPLE>', 'vent', \"t'\", 'emporteen', 'france', ',', 'ou', 'je', 'suis', 'né', '!']\n",
      "http://www.allelefrequencies.net => h t slash slash w w t t slash slash slash w t r w r w r w r || [45, 30, 30, 24, 129, 101, 101, 52, 52, 52, 74, 22, 42, 42, 28, 42, 28, 37, 35, 28, 111, 43, 28, 29, 21, 31, 28, 17, 74, 29, 28, 30, 0] \n",
      "                  ['\"', 'new', 'allele', 'frequency', 'database', ':', '<SAMPLE>', '\"', '.']\n",
      "personalised   => paralyzed      || [592, 0] \n",
      "                  ['it', 'also', 'demonstrates', 'how', 'efficiency', 'can', 'be', 'reached', 'in', 'an', 'economy', 'with', 'public', 'goods', 'by', 'the', 'use', 'of', '<SAMPLE>', 'prices', '.']\n",
      "2019           => two thousand nine || [6, 7, 0] \n",
      "                  ['the', 'project', 'is', 'expected', 'to', 'be', 'handed', 'over', 'to', 'its', 'owner', ',', 'tennet', ',', 'in', '<SAMPLE>', '.']\n",
      "www.nycsubway.org => w w w dot n a  || [52, 52, 52, 74, 29, 86, 21, 17, 43, 36, 52, 22, 86, 74, 25, 35, 53, 0] \n",
      "                  ['\"', '<SAMPLE>', ':', 'new', 'york', 'city', 'subway', 'track', 'maps', '\"', '.']\n",
      "youtube.com    => b o u t a c o dot dot o o m || [86, 25, 43, 30, 43, 36, 28, 74, 21, 25, 32, 0] \n",
      "                  ['youtube', '—', 'harvest', 'show', '—', 'hyland', 'interview', '-', '3', '-', '28', '-', '11', '<SAMPLE>', '.']\n"
     ]
    }
   ],
   "source": [
    "print_local_wrong_predictions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "910000   3% (  2m 49s)   0.349   |   0.00: & -> and (✓) \n",
      "920000   7% (  5m 43s)   0.357   |   0.03: Mbiwa -> m b i w a (✓) \n",
      "930000  10% (  8m 34s)   0.206   |   0.00: MLC -> m l c (✓) \n",
      "940000  13% ( 11m 26s)   0.279   |   0.00: & -> and (✓) \n",
      "950000  17% ( 14m 15s)   0.403   |   0.00: 1954 -> nineteen fifty four (✓) \n",
      "Saved model to data/models/whole_gen_12_attn_learning_rates/950000_(EncoderRNN/DecoderRNN)\n",
      "Accuracy: 88.46% (    8846/   10000)\n",
      "960000  20% (  18m 1s)   0.252   |   4.20: Prologue -> p r (✗: prolog) \n",
      "970000  23% ( 20m 55s)   0.351   |   0.01: WGCH -> w g c h (✓) \n",
      "980000  27% ( 23m 46s)   0.302   |   0.00: & -> and (✓) \n",
      "990000  30% ( 26m 36s)   0.307   |   4.29: 1060s -> one hundred (✗: ten sixties) \n",
      "1000000  33% ( 29m 32s)   0.319   |   0.23: FLN -> n l n (✗: f l n) \n",
      "Saved model to data/models/whole_gen_12_attn_learning_rates/1000000_(EncoderRNN/DecoderRNN)\n",
      "Accuracy: 88.66% (    8866/   10000)\n",
      "1010000  37% ( 33m 18s)   0.301   |   2.77: DigitalSignageToday.com -> d g g a r l i o g i o o o g i o o o o o g o o o (✗: d i g i t a l s i g n a g e t o d a y dot c o m) \n",
      "1020000  40% ( 36m 10s)   0.285   |   0.02: A. -> a (✓) \n",
      "1030000  43% (  39m 0s)   0.256   |   0.00: & -> and (✓) \n",
      "1040000  47% ( 41m 46s)   0.278   |   0.00: 2001 -> two thousand one (✓) (forcing)\n",
      "1050000  50% ( 44m 33s)   0.301   |   0.00: vol -> volume (✓) \n",
      "Saved model to data/models/whole_gen_12_attn_learning_rates/1050000_(EncoderRNN/DecoderRNN)\n",
      "Accuracy: 88.97% (    8897/   10000)\n",
      "1060000  53% ( 48m 12s)   0.236   |   0.02: 1931 -> nineteen thirty one (✓) \n",
      "1070000  57% (  51m 2s)   0.273   |   0.00: & -> and (✓) \n",
      "1080000  60% ( 53m 58s)   0.297   |   0.00: - -> to (✓) \n",
      "1090000  63% ( 56m 48s)   0.277   |   0.00: June 3, 2015 -> june third twenty fifteen (✓) \n",
      "1100000  67% ( 59m 40s)   0.304   |   0.00: G. -> g (✓) \n",
      "Saved model to data/models/whole_gen_12_attn_learning_rates/1100000_(EncoderRNN/DecoderRNN)\n",
      "Accuracy: 88.67% (    8867/   10000)\n",
      "1110000  70% ( 63m 16s)   0.247   |   0.04: eds -> e d s (✓) \n",
      "1120000  73% (  66m 6s)   0.250   |   0.00: NDR -> n d r (✓) \n",
      "1130000  77% (  69m 6s)   0.271   |   0.00: - -> to (✓) \n",
      "1140000  80% (  72m 2s)   0.266   |   1.86: 1987 -> nineteen eighty seven (✗: one thousand nine hundred eighty seven) \n",
      "1150000  83% ( 74m 49s)   0.267   |   0.02: VSAT -> v s a t (✓) \n",
      "Saved model to data/models/whole_gen_12_attn_learning_rates/1150000_(EncoderRNN/DecoderRNN)\n",
      "Accuracy: 89.29% (    8929/   10000)\n",
      "1160000  87% ( 78m 29s)   0.290   |   0.00: 1 -> one (✓) \n",
      "1170000  90% ( 81m 23s)   0.277   |   0.00: H. -> h (✓) \n",
      "1180000  93% ( 84m 24s)   0.196   |   0.01: ISBN -> i s b n (✓) (forcing)\n",
      "1190000  97% ( 87m 10s)   0.334   |   0.01: December 2001 -> december two thousand one (✓) \n",
      "1200000 100% ( 89m 58s)   0.269   |   0.02: October 29, 2010 -> october twenty ninth twenty ten (✓) \n",
      "Saved model to data/models/whole_gen_12_attn_learning_rates/1200000_(EncoderRNN/DecoderRNN)\n",
      "Accuracy: 89.45% (    8945/   10000)\n"
     ]
    }
   ],
   "source": [
    "train_iterations(n_iters=300000, print_every=10000, teacher_forcing_ratio=0.1, lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11             => eleven         || [9, 9, 0] \n",
      "                  ['rnx', '(', 'hox', '<SAMPLE>', 'l', '2', ',', 'tlx', '3', ')', 'belongs', 'to', 'a', 'family', 'of', 'orphan', 'homeobox', 'genes', 'that', 'encode', 'dna', '-', 'binding', 'nuclear', 'transcription', 'factors', '.']\n",
      "recolonise     => recognize      || [891, 0] \n",
      "                  ['organisms', 'that', 'dislike', 'this', 'disturbance', 'are', 'replaced', 'by', 'others', 'better', 'able', 'to', 'rapidly', '<SAMPLE>', '\"', 'clean', '\"', 'sediment', '.']\n",
      "Thecorporatecounsel.net => t e t t r t t t t t t t e t t t e t t t || [30, 45, 28, 21, 25, 35, 24, 25, 35, 22, 30, 28, 21, 25, 43, 29, 17, 28, 42, 74, 29, 28, 30, 0] \n",
      "                  ['<SAMPLE>', ',', 'accessed', 'march', '31', ',', '2011', 'vanderwerff', ',', 'todd', '(', 'may', '12', ',', '2014', ')', '.']\n",
      "optimised      => o              || [689, 0] \n",
      "                  ['by', '2006', ',', 'the', 'emergency', 'services', 'in', 'the', 'tunnel', 'will', 'be', 'upgraded', ',', 'with', 'the', 'escape', 'path', 'being', '<SAMPLE>', '.']\n",
      "ynetnews.com   => m n e t n e e s dot c o m || [86, 29, 28, 30, 29, 28, 52, 17, 74, 21, 25, 32, 0] \n",
      "                  ['liberman', 'says', 'israel', 'must', 'not', 'be', 'guided', 'by', 'revenge', ',', '<SAMPLE>', ';', 'accessed', '24', 'december', '2014', '.']\n",
      "Reuters.com    => r e u e e r s dot c o m || [35, 28, 43, 30, 28, 35, 17, 74, 21, 25, 32, 0] \n",
      "                  ['\"', 'newpark', 'resources', 'inc', '(', 'nr', '.', 'n', ')', 'quote', '<SAMPLE>', '\"', '.']\n",
      "Newsweb.no     => n e w s e e b dot o o || [29, 28, 52, 17, 52, 28, 36, 74, 29, 25, 0] \n",
      "                  ['<SAMPLE>', '(', 'in', '(', 'norwegian', ')', ')', '.']\n",
      "1979           => nineteen seventy nine || [9, 8, 15, 10, 33, 15, 0] \n",
      "                  ['the', 'australian', 'scout', 'jamboree', 'has', 'been', 'held', 'in', 'the', 'parkland', 'twice', ',', 'during', 'the', 'summers', 'of', '<SAMPLE>', '/', '80', 'and', '1994', '/', '95', '.']\n",
      "lawsociety.ie  => l a w s o i i e e dot e t || [42, 22, 52, 17, 25, 21, 31, 28, 30, 86, 74, 31, 28, 0] \n",
      "                  ['max', 'abrahamson', 'profile', ',', '<SAMPLE>', ';', 'accessed', '7', 'march', '2016', '.']\n",
      "http://www.andrewoswald.com/cv-research-history.htmlDavid => h t t p colon slash slash w w w w w w w w w w w w w || [45, 30, 30, 24, 129, 101, 101, 52, 52, 52, 74, 22, 29, 26, 35, 28, 52, 25, 17, 52, 22, 42, 26, 74, 156, 101, 21, 54, 115, 35, 28, 17, 28, 22, 35, 21, 45, 115, 45, 31, 17, 30, 25, 35, 86, 74, 45, 30, 32, 42, 26, 22, 54, 31, 26, 0] \n",
      "                  ['cv', 'and', 'research', 'history', '<SAMPLE>', 'g', 'blanchflower', ';', 'andrew', 'j', 'oswald', '(', '1994', ')', '.']\n"
     ]
    }
   ],
   "source": [
    "print_local_wrong_predictions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1210000   3% (  2m 51s)   0.332   |   0.86: 22 October 1918 -> the twenty second of october nineteen twenty (✗: the twenty second of october nineteen eighteen) \n",
      "1220000   7% (  5m 41s)   0.361   |   0.00: & -> and (✓) \n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-109-53c2e74240bd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_iterations\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_iters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m300000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprint_every\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mteacher_forcing_ratio\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0005\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-72-714df54beb04>\u001b[0m in \u001b[0;36mtrain_iterations\u001b[0;34m(n_iters, lr, teacher_forcing_ratio, print_every, plot_every)\u001b[0m\n\u001b[1;32m     29\u001b[0m                              \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m                              \u001b[0mloss_function\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNLLLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_teacher_forcing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_teacher_forcing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m                              max_length=40 )\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0mcurrent_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-71-04cb44f8a564>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(s_bef, s_aft, s_sentence, optimizer, loss_function, use_teacher_forcing, max_length)\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0mtopv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtopi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecoder_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtopk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0mword_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtopi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m         \u001b[0mword\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwords_after_common\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mword_index\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m# Use own prediction as next input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m         \u001b[0mdecoded_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "train_iterations(n_iters=300000, print_every=10000, teacher_forcing_ratio=0, lr=0.0005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5e-05"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.0005"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer.param_groups[0]['lr']\n",
    "optimizer.param_groups[6]['lr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "state_dict_path = 'data/models/whole_gen_12_attn_learning_rates/1150000_'\n",
    "\n",
    "decoder_rnn.load_state_dict(torch.load(state_dict_path + 'DecoderRNN'))\n",
    "encoder_rnn.load_state_dict(torch.load(state_dict_path + 'EncoderRNN'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "movies.nytimes.com => m o v e s h e s s i c o m || [32, 25, 54, 31, 28, 17, 74, 29, 86, 30, 31, 32, 28, 17, 74, 21, 25, 32, 0] \n",
      "                  ['new', 'york', 'times', 'overview', 'of', 'film', ',', '<SAMPLE>', ';', 'accessed', 'august', '10', ',', '2015', '.']\n",
      "StatisticsPro-Football-Reference.com => o a t i s h s e s e s e s e s e s f s e || [17, 30, 22, 30, 31, 17, 30, 31, 21, 17, 24, 35, 25, 26, 22, 17, 45, 37, 25, 25, 30, 36, 22, 42, 42, 26, 22, 17, 45, 35, 28, 37, 28, 35, 28, 29, 21, 28, 74, 21, 25, 32, 0] \n",
      "                  ['pro', '-', 'football', '-', 'reference', '.', 'com', ':', '2012', 'nfl', 'standings', ',', 'team', '&', 'offensive', '<SAMPLE>', ':', '2012', 'nfl', 'opposition', '&', 'defensive', 'statisticsgeneral', 'referenceszimmer', ',', 'john', ';', 'marini', ',', 'matt', ',', 'eds', '.']\n",
      "TRIUMF's       => t r i u m's f's department || [30, 35, 31, 43, 32, 239, 0] \n",
      "                  ['<SAMPLE>', 'nuclear', 'medicine', 'department', 'is', 'part', 'of', 'this', 'division', '.']\n",
      "J.U.L.I.A.     => j u l dot i i  || [60, 43, 42, 31, 22, 0] \n",
      "                  ['\"', 'sci', 'fi', 'pc', 'adventure', 'game', '<SAMPLE>', 'to', 'be', 'published', 'lace', 'mamba', 'global', '\"', '.']\n",
      "SHOWBUZZDAILY's => s h o w b u z z s dot z a || [17, 45, 25, 52, 36, 43, 105, 105, 26, 22, 31, 42, 217, 0] \n",
      "                  ['\"', '<SAMPLE>', 'top', '150', 'sunday', 'cable', 'originals', '(', 'comments', ')', '\"', '.']\n",
      "Oahspe         => o a h s o e's  || [25, 22, 45, 17, 24, 28, 0] \n",
      "                  ['the', '<SAMPLE>', 'stichting', ',', 'in', 'the', 'netherlands', '.']\n",
      "Indiatimes.com => i n d i a t i m m a c o m m s || [31, 29, 26, 31, 22, 30, 31, 32, 28, 17, 74, 21, 25, 32, 0] \n",
      "                  ['the', 'times', 'of', 'india', '(', '<SAMPLE>', ')', '.']\n",
      "beneventocalciospa.it => b e n e e e n t t t t t t t t t t t t t || [36, 28, 29, 28, 54, 28, 29, 30, 25, 21, 22, 42, 21, 31, 25, 17, 24, 22, 74, 31, 30, 0] \n",
      "                  ['benevento', 'calcio', '(', 'in', 'italian', ')', '(', '<SAMPLE>', ')', '.']\n",
      "S.C.C.A.       => s c c dot a    || [17, 21, 21, 22, 0] \n",
      "                  ['the', '<SAMPLE>', 'ordered', 'its', 'members', 'not', 'to', 'compete', 'in', 'the', 'canadian', 'race', 'because', 'prize', 'money', 'was', 'being', 'given', '.', '\"']\n",
      "Metromatinee.com => m e t o m m a n i c dot c o m m || [32, 28, 30, 35, 25, 32, 22, 30, 31, 29, 28, 28, 74, 21, 25, 32, 0] \n",
      "                  ['on', 'june', '25', '2013', ',', 'the', 'making', 'of', 'the', 'song', '\"', 'manjil', 'mungippongum', '\"', 'was', 'leaked', 'on', 'the', 'net', 'by', '<SAMPLE>', '.']\n"
     ]
    }
   ],
   "source": [
    "print_local_wrong_predictions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1229334  50% (   1m 1s)   0.635   |   1.94: rootsweb.com -> r o o d s b d dot c o m (✗: r o o t s w e b dot c o m) \n",
      "1230334 100% (  1m 36s)   0.649   |   0.02: 1949 -> nineteen forty nine (✓) (forcing)\n"
     ]
    }
   ],
   "source": [
    "train_iterations(n_iters=2000, print_every=1000, teacher_forcing_ratio=0.2, lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "time.sleep(24*60*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1240334   5% (  5m 54s)   0.636   |   3.06: 4SeasonsOfAsthma.ca -> s p s f s i i s s s s s s s s s s s s s s s s (✗: f o u r s e a s o n s o f a s t h m a dot c a) \n",
      "Saved model to data/models/whole_gen_12_attn_learning_rates/1250000_(EncoderRNN/DecoderRNN)\n",
      "Accuracy: 66.31% (    6631/   10000)\n",
      "1250334  10% ( 12m 45s)   0.578   |   0.03: RIMPUFF -> r i m p u f f (✓) \n",
      "1260334  15% ( 17m 59s)   0.611   |   0.00: P. -> p (✓) (forcing)\n",
      "1270334  20% (  23m 9s)   0.636   |   0.07: MOELCI -> m o e l c i (✓) \n",
      "1280334  25% ( 28m 11s)   0.569   |   0.00: J. -> j (✓) \n",
      "1290334  30% ( 33m 24s)   0.605   |   0.04: NORCECA -> n o r c e c a (✓) \n",
      "Saved model to data/models/whole_gen_12_attn_learning_rates/1300000_(EncoderRNN/DecoderRNN)\n",
      "Accuracy: 68.13% (    6813/   10000)\n",
      "1300334  35% (  40m 8s)   0.552   |   1.85: SENSATIONSFILMS -> s e n s a i i s s s s s s o o (✗: s e n s a t i o n s f i l m s) (forcing)\n",
      "1310334  40% ( 45m 26s)   0.553   |   0.00: - -> to (✓) \n",
      "1320334  45% ( 50m 38s)   0.654   |   2.64: reviewBillboard.com -> c e v e i i l l dot c o c o o o l m o o m (✗: r e v i e w b i l l b o a r d dot c o m) \n",
      "1330334  50% ( 55m 55s)   0.550   |   1.42: mwdreviews.com -> m w d r e v i e e s e dot c o m (✗: m w d r e v i e w s dot c o m) \n",
      "1340334  55% (  61m 3s)   0.582   |   0.00: advertising -> advertizing (✓) \n",
      "Saved model to data/models/whole_gen_12_attn_learning_rates/1350000_(EncoderRNN/DecoderRNN)\n",
      "Accuracy: 68.82% (    6882/   10000)\n",
      "1350334  60% ( 67m 53s)   0.589   |   0.01: N.C.C. -> n c c (✓) (forcing)\n",
      "1360334  65% ( 72m 58s)   0.592   |   0.02: A.F.C. -> a f c (✓) \n",
      "1370334  70% ( 78m 11s)   0.567   |   0.00: 1 -> one (✓) \n",
      "1380334  75% ( 83m 31s)   0.589   |   0.06: IMDb.com -> i m d b dot c o m (✓) (forcing)\n",
      "1390334  80% ( 88m 51s)   0.572   |   1.48: SoundersFC.com -> s o u t d e s s s c c o m (✗: s o u n d e r s f c dot c o m) \n",
      "Saved model to data/models/whole_gen_12_attn_learning_rates/1400000_(EncoderRNN/DecoderRNN)\n",
      "Accuracy: 70.55% (    7055/   10000)\n",
      "1400334  85% ( 95m 34s)   0.600   |   0.02: 24 October 2002 -> the twenty fourth of october two thousand two (✓) \n",
      "1410334  90% (100m 52s)   0.576   |   2.45: ISIHighlyCited.com -> i i i i i g l i i dot l i c o m (✗: i s i h i g h l y c i t e d dot c o m) \n",
      "1420334  95% ( 106m 6s)   0.538   |   0.04: SANRAL -> s a n r a l (✓) (forcing)\n",
      "1430334 100% (111m 16s)   0.561   |   2.27: TouringCarTimes.com -> c o u i n g c o r r g c o m (✗: t o u r i n g c a r t i m e s dot c o m) \n"
     ]
    }
   ],
   "source": [
    "train_iterations(n_iters=200000, print_every=10000, teacher_forcing_ratio=0.2, lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2007-01-02     => the second of february two thousand seven || [11, 73, 12, 63, 5, 8, 18, 0] \n",
      "                  ['jackson', ',', 'mike', '(', '<SAMPLE>', ')', '.']\n",
      "AVANTVIEW      => a v a n t v i i e || [22, 54, 22, 29, 30, 54, 31, 28, 52, 0] \n",
      "                  ['<SAMPLE>', 'solutions', 'limited', '—', 'www', '.', 'avantview', '.', 'com', '.']\n",
      "DESTAPE        => d e s t a p    || [26, 28, 17, 30, 22, 24, 28, 0] \n",
      "                  ['\"', 'technical', 'services', '<SAMPLE>', '—', 'mercer', 'county', '\"', '(', 'pdf', ')', '.']\n",
      "14V            => fourteen hundred || [50, 282, 0] \n",
      "                  ['the', 'prc', '350', 'had', 'its', 'own', '<SAMPLE>', '4', 'ah', 'nicad', 'and', 'a', 'battery', 'cassette', 'for', 'use', 'with', 'alkaline', 'or', 'dry', 'cells', '.']\n",
      "BONVICINO      => six o n v i n i n i o || [36, 25, 29, 54, 31, 21, 31, 29, 25, 0] \n",
      "                  ['weksler', ',', 'marcelo', ';', 'cibele', 'r', '.', '<SAMPLE>', '(', '2007', ')', '.']\n",
      "eurominiconferencegraz2013.wordpress.com => e o r e i e e o r e r o r i o o r o i o || [28, 43, 35, 25, 32, 31, 29, 31, 21, 25, 29, 37, 28, 35, 28, 29, 21, 28, 53, 35, 22, 105, 30, 52, 28, 29, 30, 86, 30, 45, 31, 35, 30, 28, 28, 29, 74, 52, 25, 35, 26, 24, 35, 28, 17, 17, 74, 21, 25, 32, 0] \n",
      "                  ['senior', 'researcher', '\"', 'at', 'linkedin', '.', 'com', ',', '2015', 'euro', 'mini', 'conference', 'graz', '2013', ',', 'at', '<SAMPLE>', '.']\n",
      "£250 million   => five hundred fifty million || [5, 10, 38, 90, 124, 0] \n",
      "                  ['it', 'was', 'estimated', 'that', '<SAMPLE>', 'was', 'invested', 'into', 'this', 'project', 'and', 'the', 'factory', 'outputs', '1', '.', '2', 'billion', 'bottles', 'per', 'year', '.']\n",
      "COMCOS         => c o m c o's s  || [21, 25, 32, 21, 25, 17, 0] \n",
      "                  ['the', '11th', '(', 'sindhughosh', 'class', 'submarine', ')', 'and', '8th', '(', 'foxtrot', 'class', ')', 'submarine', 'squadrons', 'operate', 'under', '<SAMPLE>', '(', 'e', ')', '.']\n",
      "GobiernoUSA.gov => g o b e r g o o s s e s dot o o s || [53, 25, 36, 31, 28, 35, 29, 25, 43, 17, 22, 74, 53, 25, 54, 0] \n",
      "                  ['to', 'reach', 'hispanic', 'audiences', 'online', ',', '<SAMPLE>', 'has', 'a', 'proactive', 'outreach', 'program', '.']\n",
      "Billboard.biz  => b i l l b o a r d dot dot c m || [36, 31, 42, 42, 36, 25, 22, 35, 26, 74, 36, 31, 105, 0] \n",
      "                  ['<SAMPLE>', '(', 'april', '19', ',', '2014', ')', '.']\n"
     ]
    }
   ],
   "source": [
    "print_local_wrong_predictions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1440334   2% (  5m 15s)   0.622   |   0.00: 8 November 2010 -> the eighth of november twenty ten (✓) \n",
      "Saved model to data/models/whole_gen_12_attn_learning_rates/1450000_(EncoderRNN/DecoderRNN)\n",
      "Accuracy: 70.06% (    7006/   10000)\n",
      "1450334   4% ( 11m 47s)   0.609   |   0.65: www.laurenknowsbest.com -> w w w dot c o m (✗: w w w dot l a u r e n k n o w s b e s t dot c o m) \n",
      "1460334   6% (  17m 6s)   0.539   |   1.08: 21,455 -> twenty thousand thousand five hundred fifty five (✗: twenty one thousand four hundred fifty five) \n",
      "1470334   8% ( 22m 19s)   0.546   |   0.17: Here.com -> h e r e dot c o m (✓) \n",
      "1480334  10% ( 27m 29s)   0.503   |   2.64: http://www.uslsoccer.com/home/688866.html -> h t t p colon slash slash w w w w w w w slash slash w w w dot i o i i x w i i i x w i i i x w i i i x w i i i x w i o e i x w i o e x w i (✗: h t t p colon slash slash w w w dot u s l s o c c e r dot com slash h o m e slash s i x e i g h t e i g h t e i g h t s i x s i x dot h t m l) \n",
      "1490334  12% (  33m 0s)   0.632   |   0.00: centre -> center (✓) \n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-168-84861d645bfb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_iterations\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_iters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m500000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprint_every\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mteacher_forcing_ratio\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0001\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-72-714df54beb04>\u001b[0m in \u001b[0;36mtrain_iterations\u001b[0;34m(n_iters, lr, teacher_forcing_ratio, print_every, plot_every)\u001b[0m\n\u001b[1;32m     29\u001b[0m                              \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m                              \u001b[0mloss_function\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNLLLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_teacher_forcing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_teacher_forcing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m                              max_length=40 )\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0mcurrent_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-71-04cb44f8a564>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(s_bef, s_aft, s_sentence, optimizer, loss_function, use_teacher_forcing, max_length)\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0mtopv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtopi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecoder_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtopk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0mword_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtopi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m         \u001b[0mword\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwords_after_common\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mword_index\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m# Use own prediction as next input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m         \u001b[0mdecoded_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "train_iterations(n_iters=500000, print_every=10000, teacher_forcing_ratio=0, lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#state_dict_path = 'data/models/whole_gen_12_attn_learning_rates/1400000_'\n",
    "state_dict_path = 'data/models/whole_gen_12_attn_learning_rates/1150000_'\n",
    "\n",
    "decoder_rnn.load_state_dict(torch.load(state_dict_path + 'DecoderRNN'))\n",
    "encoder_rnn.load_state_dict(torch.load(state_dict_path + 'EncoderRNN'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "# balanced_data = balanced_data_org\n",
    "balanced_data_randomize = balanced_data_randomize_org\n",
    "balanced_data_randomize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 88.94% (    8894/   10000)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8894"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_model_accuracy(encoder_rnn, test_model_single_sample, n_sample=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "state_dict_path = 'data/models/whole_gen_12_attn_learning_rates/1400000_'\n",
    "#state_dict_path = 'data/models/whole_gen_12_attn_learning_rates/1150000_'\n",
    "\n",
    "decoder_rnn.load_state_dict(torch.load(state_dict_path + 'DecoderRNN'))\n",
    "encoder_rnn.load_state_dict(torch.load(state_dict_path + 'EncoderRNN'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "balanced_data_randomize = balanced_data_randomize_org\n",
    "balanced_data_randomize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 88.79% (    8879/   10000)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8879"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_model_accuracy(encoder_rnn, test_model_single_sample, n_sample=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clip_parameters_value = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1498996  50% (   0m 4s)   0.405   |   0.00: & -> and (✓) \n",
      "1499046 100% (  0m 10s)   0.298   |   0.03: I.D. -> i d (✓) \n"
     ]
    }
   ],
   "source": [
    "train_iterations(n_iters=100, print_every=50, teacher_forcing_ratio=0.2, lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 88.80% (     888/    1000)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.888"
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_model_accuracy(encoder_rnn, test_model_single_sample, n_sample=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "balanced_data_randomize = balanced_data_randomize_long\n",
    "balanced_data_randomize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to data/models/whole_gen_12_attn_learning_rates/1500000_(EncoderRNN/DecoderRNN)\n",
      "Accuracy: 71.02% (    7102/   10000)\n",
      "1509046   3% (  9m 42s)   0.488   |   0.01: 3 July 1942 -> the third of july nineteen forty two (✓) \n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-263-cc395d632976>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_iterations\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_iters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m300000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprint_every\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mteacher_forcing_ratio\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0001\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-72-714df54beb04>\u001b[0m in \u001b[0;36mtrain_iterations\u001b[0;34m(n_iters, lr, teacher_forcing_ratio, print_every, plot_every)\u001b[0m\n\u001b[1;32m     29\u001b[0m                              \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m                              \u001b[0mloss_function\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNLLLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_teacher_forcing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_teacher_forcing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m                              max_length=40 )\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0mcurrent_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-259-5732afbaeb38>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(s_bef, s_aft, s_sentence, optimizer, loss_function, use_teacher_forcing, max_length)\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0mtopv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtopi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecoder_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtopk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0mword_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtopi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m         \u001b[0mword\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwords_after_common\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mword_index\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m# Use own prediction as next input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m         \u001b[0mdecoded_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "train_iterations(n_iters=300000, print_every=10000, teacher_forcing_ratio=0, lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print_local_wrong_predictions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_iterations(n_iters=100000, print_every=10000, teacher_forcing_ratio=0.2, lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_local_wrong_predictions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iterations(n_iters=500000, print_every=10000, teacher_forcing_ratio=0, lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_local_wrong_predictions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iterations(n_iters=400000, print_every=10000, teacher_forcing_ratio=0, lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "balanced_data.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "balanced_data.groupby('class')['class'].count()\n",
    "len(balanced_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def balanced_data_randomize_long():\n",
    "    global balanced_data, balanced_data_length, balanced_data_accessed_counter, balanced_data_randomize_freq\n",
    "    \n",
    "    bal_data = pd.concat([v.sample(min(2000, len(v))) for k, v in balanced_data_classes_select])\n",
    "    long_data = sample_data[sample_data['before'].str.len()>8].sample(4000)\n",
    "    elec_data = sample_data[sample_data['class']=='ELECTRONIC']\n",
    "    let_long_data = sample_data[(sample_data['class'] == 'LETTERS') & (sample_data['before'].str.len() > 5)]\n",
    "    balanced_data = pd.concat([bal_data, long_data, elec_data, let_long_data])#.drop_duplicates()\n",
    "    balanced_data = balanced_data[~balanced_data.index.duplicated(keep='first')]\n",
    "    \n",
    "    balanced_data_length = len(balanced_data)\n",
    "    balanced_data_randomize_freq = balanced_data_length * 0.5\n",
    "    balanced_data_accessed_counter = 0\n",
    "\n",
    "balanced_data_randomize = balanced_data_randomize_long\n",
    "balanced_data_randomize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input:   March 30, 2009\n",
      "output:  ['march', 'thirtieth', 'two', 'thousand', 'nine']\n",
      "target:    march thirtieth two thousand nine\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAzIAAAFbCAYAAAAOUbuWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nkiRJUncsZCRJkiR1x0JGkiRJUnf+P2jLRi6aN/BzAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7efc2bf91710>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def debug_show_attention(input_sentence, output_words, attentions):\n",
    "    # Set up figure with colorbar\n",
    "    fig = plt.figure(figsize=(15,6))\n",
    "    ax = fig.add_subplot(111)\n",
    "    #cax = ax.matshow(attentions.numpy(), cmap='bone')\n",
    "    cax = ax.matshow(attentions, cmap='bone')\n",
    "    fig.colorbar(cax)\n",
    "    # Set up axes\n",
    "    #ax.set_xticklabels([''] + input_sentence.split(' ') + ['<EOS>'], rotation=90)\n",
    "    #ax.set_xticklabels([''] + input_sentence + ['<EOS>'], rotation=90)\n",
    "    ax.set_yticklabels([''] + output_words)\n",
    "    \n",
    "    input_sentence = input_sentence + ['<EOS>']\n",
    "    #inp_arr = [\"{}\\n{}\".format(input_sentence[i], input_sentence[-1-i]) for i in range(len(input_sentence))]\n",
    "    inp_arr = input_sentence\n",
    "    ax.set_xticklabels([''] + inp_arr, rotation=0)\n",
    "\n",
    "    # Show label at every tick\n",
    "    ax.xaxis.set_major_locator(matplotlib.ticker.MultipleLocator(1))\n",
    "    ax.yaxis.set_major_locator(matplotlib.ticker.MultipleLocator(1))\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "def debug_eval_sample_show_attention():\n",
    "    \n",
    "    sample_row = balanced_data_sample_row()\n",
    "    #sample_row = balanced_data[balanced_data['before'].str.len()>15].sample(1).iloc[0]\n",
    "    sample = sample_row['before'], sample_row['a_word_ind'], sample_row['class'], sample_row['sentence'].split(' ')\n",
    "\n",
    "    output, decoded_output, decoder_attns_arr, sample = test_model_single_sample(None, \n",
    "                                                            return_more=True, sample=sample)\n",
    "    print('input:  ', sample[0])\n",
    "    print('output: ', decoded_output)\n",
    "    print('target:   ', ' '.join([words_after_common[w] for w in sample[1][:-1]]))\n",
    "\n",
    "    attns = np.array([arr.data[0].cpu().numpy() for arr in decoder_attns_arr])\n",
    "\n",
    "    debug_show_attention(list(sample[0]), decoded_output, attns)\n",
    "    #plt.matshow(attns)\n",
    "\n",
    "debug_eval_sample_show_attention()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "balanced_data.groupby('class')['class'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test_in_categories(iter_len = 1000):\n",
    "    wrong_preds = {}\n",
    "    for cat in categories_all:\n",
    "        tmp_data = sample_data[sample_data['class'] == cat].sample(iter_len)\n",
    "        correct_n = 0\n",
    "        wrong_preds_arr = []\n",
    "\n",
    "        for _ in range(iter_len):\n",
    "            sample_row = tmp_data.iloc[_]\n",
    "            sample = sample_row['before'], sample_row['a_word_ind'], sample_row['class'], sample_row['sentence']\n",
    "\n",
    "            output, t1, sample_target, t2 = test_model_single_sample(None, sample=sample)\n",
    "            if output == sample_target:\n",
    "                correct_n += 1\n",
    "            else:\n",
    "                wrong_preds_arr.append([sample_target, output])\n",
    "\n",
    "        print(\"{:>10}: {:>5d}/{:>5d} ({:>4.0%})\".format(cat, correct_n, iter_len, correct_n/iter_len))\n",
    "        wrong_preds[cat] = wrong_preds_arr\n",
    "    return wrong_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wrong_preds = test_in_categories(3000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wrong_preds['LETTERS']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# With training longer words\n",
    "wrong_preds = test_in_categories()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:py3_pytorch_2]",
   "language": "python",
   "name": "conda-env-py3_pytorch_2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
