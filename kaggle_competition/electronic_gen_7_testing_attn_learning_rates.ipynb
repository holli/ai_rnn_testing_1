{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pytorch utils oh: pytorch_utils_oh_2.py\n",
      "Pytorch: 0.2.0_4\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import importlib\n",
    "from pytorch_utils_oh_2 import *\n",
    "import IPython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MODEL_SAVE_PATH = 'electronic_gen_7_testing_attn_learning_rates'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pytorch utils oh: pytorch_utils_oh_2.py\n",
      "Pytorch: 0.2.0_4\n"
     ]
    }
   ],
   "source": [
    "import pytorch_utils_oh_2; importlib.reload(pytorch_utils_oh_2); from pytorch_utils_oh_2 import *;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# all_data = pickle.load(open(\"data/en_train_fixed_4_sentences.pkl\", \"rb\" ))\n",
    "all_data = pickle.load(open(\"data/en_train_fixed_5_manual.pkl\", \"rb\" ))\n",
    "# all_data_sentence_index = all_data.set_index('sentence_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>token_id</th>\n",
       "      <th>class</th>\n",
       "      <th>before</th>\n",
       "      <th>after</th>\n",
       "      <th>class_org</th>\n",
       "      <th>a_word_ind</th>\n",
       "      <th>sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7902035</th>\n",
       "      <td>598858</td>\n",
       "      <td>18</td>\n",
       "      <td>LETTERS</td>\n",
       "      <td>TEISSIER</td>\n",
       "      <td>t e i s s i e r</td>\n",
       "      <td>LETTERS</td>\n",
       "      <td>[30, 28, 31, 17, 17, 31, 28, 35, 0]</td>\n",
       "      <td>chefs et notables au temps du protectorat : 18...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3119091</th>\n",
       "      <td>240834</td>\n",
       "      <td>8</td>\n",
       "      <td>ELECTRONIC</td>\n",
       "      <td>RubyGems.org</td>\n",
       "      <td>r u b y g e m s dot o r g</td>\n",
       "      <td>ELECTRONIC</td>\n",
       "      <td>[35, 43, 36, 86, 53, 28, 32, 17, 74, 25, 35, 5...</td>\n",
       "      <td>there are over 70 , 000 ruby gems hosted on &lt;S...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         sentence_id  token_id       class        before  \\\n",
       "7902035       598858        18     LETTERS      TEISSIER   \n",
       "3119091       240834         8  ELECTRONIC  RubyGems.org   \n",
       "\n",
       "                             after   class_org  \\\n",
       "7902035            t e i s s i e r     LETTERS   \n",
       "3119091  r u b y g e m s dot o r g  ELECTRONIC   \n",
       "\n",
       "                                                a_word_ind  \\\n",
       "7902035                [30, 28, 31, 17, 17, 31, 28, 35, 0]   \n",
       "3119091  [35, 43, 36, 86, 53, 28, 32, 17, 74, 25, 35, 5...   \n",
       "\n",
       "                                                  sentence  \n",
       "7902035  chefs et notables au temps du protectorat : 18...  \n",
       "3119091  there are over 70 , 000 ruby gems hosted on <S...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "32992"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data = all_data[(all_data['class'] == 'LETTERS') | (all_data['class'] == 'ELECTRONIC')]\n",
    "all_data = all_data[all_data['after'].str.len() > 5]\n",
    "all_data.sample(2)\n",
    "len(all_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sample_data = all_data.copy()\n",
    "sample_data = sample_data.reset_index(drop=True)\n",
    "del(all_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sample_data = all_data.copy()\n",
    "sample_data = sample_data[sample_data['class'] == 'ELECTRONIC']\n",
    "print(\"Data rows: {},  (dropped rows: {})\".format(len(sample_data), len(all_data)-len(sample_data)))\n",
    "sample_data = sample_data.reset_index(drop=True)\n",
    "del(all_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ELECTRONIC', 'LETTERS']\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "categories_all = sorted(sample_data[\"class\"].unique())\n",
    "print(categories_all)\n",
    "print(len(categories_all))\n",
    "categories_index = dict((c, i) for i, c in enumerate(categories_all))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>token_id</th>\n",
       "      <th>class</th>\n",
       "      <th>before</th>\n",
       "      <th>after</th>\n",
       "      <th>class_org</th>\n",
       "      <th>a_word_ind</th>\n",
       "      <th>sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3131</th>\n",
       "      <td>77591</td>\n",
       "      <td>0</td>\n",
       "      <td>ELECTRONIC</td>\n",
       "      <td>CBC.ca</td>\n",
       "      <td>c b c dot c a</td>\n",
       "      <td>ELECTRONIC</td>\n",
       "      <td>[21, 36, 21, 74, 21, 22, 0]</td>\n",
       "      <td>&lt;SAMPLE&gt; : hershey confirms smiths falls plant...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18270</th>\n",
       "      <td>428446</td>\n",
       "      <td>1</td>\n",
       "      <td>LETTERS</td>\n",
       "      <td>Htar</td>\n",
       "      <td>h t a r</td>\n",
       "      <td>LETTERS</td>\n",
       "      <td>[45, 30, 22, 35, 0]</td>\n",
       "      <td>htar &lt;SAMPLE&gt; khin ( 5 march 2012 ) .</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       sentence_id  token_id       class  before          after   class_org  \\\n",
       "3131         77591         0  ELECTRONIC  CBC.ca  c b c dot c a  ELECTRONIC   \n",
       "18270       428446         1     LETTERS    Htar        h t a r     LETTERS   \n",
       "\n",
       "                        a_word_ind  \\\n",
       "3131   [21, 36, 21, 74, 21, 22, 0]   \n",
       "18270          [45, 30, 22, 35, 0]   \n",
       "\n",
       "                                                sentence  \n",
       "3131   <SAMPLE> : hershey confirms smiths falls plant...  \n",
       "18270              htar <SAMPLE> khin ( 5 march 2012 ) .  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_data.sample(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utils stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<SOS><EOS>☒ !\"#$%&'(),-./0123456789:;ABCDEFGHIJKLMNOPQRSTUVWXYZ_abcdefghijklmnopqrstuvwxyz~£¥ª²³µº¼½¾éɒʻˈΩμ—€⅓⅔⅛\n"
     ]
    }
   ],
   "source": [
    "chars_normal, chars_normal_index = load_characters_pkl('data/en_features/chars_normal.pkl')\n",
    "print(''.join(chars_normal))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wv_vecs, wv_words, wv_idx = load_glove('/home/ohu/koodi/data/glove_wordvec/glove.6B.50d.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "arr = list(sample_data['after'])\n",
    "arr = [s.split(' ') for s in arr]\n",
    "words_after = [EOS_TOKEN, SOS_TOKEN, UNKNOWN_WORD_TOKEN, NUMBER_WORD_TOKEN, SAMPLE_WORD_TOKEN]\n",
    "words_after = words_after + sorted(list(set(np.concatenate(arr))))\n",
    "words_after_index = dict((c, i) for i, c in enumerate(words_after))\n",
    "words_after_by_length = sorted(words_after, key=len, reverse=True)\n",
    "words_after_regex = re.compile('(' + ')|('.join(words_after_by_length) + ')')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "152"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(words_after)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "chars_after = [EOS_TOKEN, SOS_TOKEN] + sorted(list(set(list(''.join(list(sample_data['after']))))))\n",
    "chars_after_index = dict((c, i) for i, c in enumerate(chars_after))\n",
    "''.join(chars_after)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[32, 26, 92, 19, 0]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "['dot', 'd', 'o', 'c', '<EOS>']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def after_sentence_to_word_indexes(sentence, include_eos=True):\n",
    "    reg = re.finditer(words_after_regex, sentence)\n",
    "    arr = [words_after_index[s[0]] for s in reg]\n",
    "    if include_eos:\n",
    "        arr += [words_after_index[EOS_TOKEN]]\n",
    "    return arr\n",
    "tmp = after_sentence_to_word_indexes('dot d o c')\n",
    "tmp\n",
    "[words_after[t] for t in tmp]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 152])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sos_tensor = torch.zeros(1, 1, len(words_after_index))\n",
    "sos_tensor[0, 0, words_after_index[SOS_TOKEN]] = 1\n",
    "sos_tensor.size()\n",
    "#del(onehot_sos)\n",
    "\n",
    "# sos_tensor = torch.LongTensor([words_after_index[SOS_TOKEN]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LETTERS KPBL -> k p b l <EOS> [72, 100, 13, 76, 0]\n",
      "torch.Size([1, 5, 104])\n",
      "['\"', '<SAMPLE>', 'facility', 'record', '\"', '.']\n",
      "torch.Size([1, 6, 50])\n"
     ]
    }
   ],
   "source": [
    "balanced_data_length = len(sample_data)\n",
    "def get_random_sample(return_last = False):\n",
    "    global sample_row_last\n",
    "    sample_row = balanced_data_last_sample = sample_data.iloc[random.randint(1, balanced_data_length-1)]\n",
    "    if return_last:\n",
    "        sample_row = sample_row_last\n",
    "    else:\n",
    "        sample_row_last = sample_row\n",
    "    \n",
    "    a_words_ind = after_sentence_to_word_indexes(sample_row['after'], include_eos=True)\n",
    "    return sample_row['before'], a_words_ind, sample_row['class'], sample_row['sentence'].split(' ')\n",
    "            \n",
    "def tmp():\n",
    "    s_bef, s_aft, s_class, s_sentence = get_random_sample()\n",
    "    s_aft_str = ' '.join([words_after[i] for i in s_aft])\n",
    "    print(s_class, s_bef, '->', s_aft_str, s_aft)\n",
    "    print(string_to_tensor(s_bef, chars_normal_index).shape)\n",
    "    \n",
    "    print(s_sentence)\n",
    "    words_t = words_to_word_vectors_tensor(s_sentence, wv_vecs, wv_idx)\n",
    "    print(words_t.size())\n",
    "\n",
    "tmp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "279 µs ± 9.95 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "get_random_sample()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "use_cuda = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MAX_ATTENTION_LENGTH = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "498"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>token_id</th>\n",
       "      <th>class</th>\n",
       "      <th>before</th>\n",
       "      <th>after</th>\n",
       "      <th>class_org</th>\n",
       "      <th>a_word_ind</th>\n",
       "      <th>sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19652</th>\n",
       "      <td>456297</td>\n",
       "      <td>16</td>\n",
       "      <td>ELECTRONIC</td>\n",
       "      <td>http://www.whccamp.hhs.gov/pdfs/fr2002_documen...</td>\n",
       "      <td>h t t p colon slash slash w w w dot w h c c a ...</td>\n",
       "      <td>ELECTRONIC</td>\n",
       "      <td>[45, 30, 30, 24, 129, 101, 101, 52, 52, 52, 74...</td>\n",
       "      <td>u . s . government printing office , whcamp we...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16657</th>\n",
       "      <td>388660</td>\n",
       "      <td>2</td>\n",
       "      <td>ELECTRONIC</td>\n",
       "      <td>http://www.tompaine.com/articles/what_ownershi...</td>\n",
       "      <td>h t t p colon slash slash w w w dot t o m p a ...</td>\n",
       "      <td>ELECTRONIC</td>\n",
       "      <td>[45, 30, 30, 24, 129, 101, 101, 52, 52, 52, 74...</td>\n",
       "      <td>online at &lt;SAMPLE&gt; karabell , oct 11 , 2008 .</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       sentence_id  token_id       class  \\\n",
       "19652       456297        16  ELECTRONIC   \n",
       "16657       388660         2  ELECTRONIC   \n",
       "\n",
       "                                                  before  \\\n",
       "19652  http://www.whccamp.hhs.gov/pdfs/fr2002_documen...   \n",
       "16657  http://www.tompaine.com/articles/what_ownershi...   \n",
       "\n",
       "                                                   after   class_org  \\\n",
       "19652  h t t p colon slash slash w w w dot w h c c a ...  ELECTRONIC   \n",
       "16657  h t t p colon slash slash w w w dot t o m p a ...  ELECTRONIC   \n",
       "\n",
       "                                              a_word_ind  \\\n",
       "19652  [45, 30, 30, 24, 129, 101, 101, 52, 52, 52, 74...   \n",
       "16657  [45, 30, 30, 24, 129, 101, 101, 52, 52, 52, 74...   \n",
       "\n",
       "                                                sentence  \n",
       "19652  u . s . government printing office , whcamp we...  \n",
       "16657      online at <SAMPLE> karabell , oct 11 , 2008 .  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp = sample_data[sample_data['before'].str.len()>MAX_ATTENTION_LENGTH]\n",
    "len(tmp)\n",
    "tmp.sample(2)\n",
    "# tmp[~tmp['before'].str.contains('/')].sample(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EncoderRNN (\n",
       "  (rnn_words): GRU(50, 64, batch_first=True, bidirectional=True)\n",
       "  (rnn_chars): GRU(104, 128, batch_first=True, bidirectional=True)\n",
       ")"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, words_input_size, chars_input_size, words_hidden_size, chars_hidden_size,\n",
    "                 words_layers=1, chars_layers=1):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        \n",
    "        self.words_layers = words_layers\n",
    "        self.chars_layers = chars_layers\n",
    "        self.words_hidden_size = words_hidden_size\n",
    "        self.chars_hidden_size = chars_hidden_size\n",
    "        self.hidden_size = words_hidden_size + chars_hidden_size\n",
    "\n",
    "        self.rnn_words = nn.GRU(words_input_size, words_hidden_size // 2, words_layers,\n",
    "                                 batch_first=True, bidirectional=True)\n",
    "\n",
    "        self.rnn_chars = nn.GRU(chars_input_size, chars_hidden_size // 2, chars_layers,\n",
    "                                 batch_first=True, bidirectional=True)\n",
    "        \n",
    "    def forward(self, word_vectors, string_tensor, hidden = None, init_hidden = True):\n",
    "        if init_hidden:\n",
    "            hidden_words, hidden_chars = self.init_hidden()\n",
    "        \n",
    "        all_outputs_words, hidden_words = self.rnn_words(word_vectors, hidden_words)\n",
    "        output_words = hidden_words.view(1, -1)\n",
    "        \n",
    "        all_outputs_chars, hidden_chars = self.rnn_chars(string_tensor, hidden_chars)\n",
    "        output_chars = hidden_chars.view(1, -1)\n",
    "        \n",
    "        #hidden_states_cat = Variable(torch.zeros(MAX_ATTENTION_LENGTH, self.hidden_size)).cuda()\n",
    "        #for ei in range(min(MAX_ATTENTION_LENGTH, len(string_tensor[0]))):\n",
    "        #    hidden_states_cat[ei] = torch.cat((output_words, all_outputs_chars[0, ei].view(1,-1)), 1)\n",
    "\n",
    "        all_outputs_chars_padded = Variable(torch.zeros(MAX_ATTENTION_LENGTH, self.chars_hidden_size)).cuda()\n",
    "        att_length = min(len(all_outputs_chars[0]), MAX_ATTENTION_LENGTH-1)\n",
    "        all_outputs_chars_padded[0:att_length] = all_outputs_chars[0][0:att_length]\n",
    "        \n",
    "        output = torch.cat((output_words, output_chars), 1)\n",
    "\n",
    "        #output = torch.cat((output_words, output_chars), 1)\n",
    "        \n",
    "        #return output, all_outputs_chars\n",
    "        return output, all_outputs_chars_padded\n",
    "\n",
    "    def init_hidden(self):\n",
    "        var1 = Variable(torch.zeros(2 * self.words_layers, 1, self.words_hidden_size // 2))\n",
    "        var2 = Variable(torch.zeros(2 * self.chars_layers, 1, self.chars_hidden_size // 2))\n",
    "        \n",
    "        var1 = var1.cuda(); var2 = var2.cuda()\n",
    "        return (var1, var2)\n",
    "    \n",
    "    \n",
    "encoder_rnn = EncoderRNN(words_input_size=wv_vecs.shape[-1], chars_input_size=len(chars_normal),\n",
    "                         words_hidden_size=128, chars_hidden_size=256,\n",
    "                         words_layers=1, chars_layers=1).cuda()\n",
    "encoder_rnn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "allmusic.com\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'allmusic.com'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 384])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([50, 256])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def test_encoder_single_sample():\n",
    "    s_bef, s_aft, s_class, s_sentence = get_random_sample()\n",
    "    #s_bef, s_aft, s_class, s_sentence = get_random_sample(True)\n",
    "    print(s_bef)\n",
    "    \n",
    "    words_t = Variable(words_to_word_vectors_tensor(s_sentence, wv_vecs, wv_idx)).cuda()\n",
    "    \n",
    "    string_t = string_to_tensor(s_bef, chars_normal_index)\n",
    "    string_t = Variable(string_t).cuda()\n",
    "    \n",
    "    return encoder_rnn(words_t, string_t), s_bef\n",
    "    \n",
    "(tmp_encoder_output, tmp_encoder_outputs), tmp = test_encoder_single_sample()\n",
    "tmp\n",
    "tmp_encoder_output.size()\n",
    "tmp_encoder_outputs.size()\n",
    "#torch.eq(encoder_output, encoder_outputs[len(tmp)]).data.all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecoderRNN (\n",
       "  (emb_lin): Linear (152 -> 384)\n",
       "  (dropout): Dropout (p = 0.1)\n",
       "  (attn): Linear (768 -> 50)\n",
       "  (attn_combine): Linear (640 -> 384)\n",
       "  (rnn): GRU(384, 384, batch_first=True)\n",
       "  (lin_out): Linear (384 -> 152)\n",
       ")"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[torch.Size([1, 152]), torch.Size([1, 384]), torch.Size([1, 50])]"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class DecoderRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, chars_encoded_size,\n",
    "                 n_layers=1, dropout_p=0.1, max_length=MAX_ATTENTION_LENGTH):\n",
    "        super(DecoderRNN, self).__init__()\n",
    "        \n",
    "        self.n_layers = n_layers\n",
    "        self.hidden_size = hidden_size\n",
    "        self.max_length = max_length\n",
    "        \n",
    "        self.emb_lin = nn.Linear(input_size, hidden_size)\n",
    "        self.dropout = nn.Dropout(dropout_p)\n",
    "        self.attn = nn.Linear(self.hidden_size+self.hidden_size, self.max_length)\n",
    "        self.attn_combine = nn.Linear(self.hidden_size+chars_encoded_size, self.hidden_size)\n",
    "        \n",
    "        #self.module_attn = torch.nn.ModuleList([self.emb_lin, self.dropout, self.attn, self.attn_combine])\n",
    "        \n",
    "        \n",
    "        self.rnn = nn.GRU(hidden_size, hidden_size, n_layers, batch_first=True, bidirectional=False)\n",
    "        self.lin_out = nn.Linear(hidden_size, input_size)\n",
    "        \n",
    "        #self.module_rnn = torch.nn.ModuleList([self.rnn, self.lin_out])\n",
    "\n",
    "    def forward(self, last_input, hidden, encoder_outputs):\n",
    "        embedded = self.emb_lin(last_input).view(1, 1, -1)\n",
    "        embedded = self.dropout(embedded)\n",
    "        embedded = embedded[0]\n",
    "                \n",
    "        attn_weights = F.softmax(self.attn(torch.cat((embedded, hidden), 1)))\n",
    "        attn_applied = torch.bmm(attn_weights.unsqueeze(0), encoder_outputs.unsqueeze(0))\n",
    "        #return embedded, attn_applied\n",
    "        \n",
    "        rnn_input = torch.cat((embedded, attn_applied[0]), 1)\n",
    "        rnn_input = self.attn_combine(rnn_input).unsqueeze(0)\n",
    "        rnn_input = F.relu(rnn_input)\n",
    "    \n",
    "        output, hidden = self.rnn(rnn_input, hidden.unsqueeze(0))\n",
    "        output = F.log_softmax(self.lin_out(output[0]))\n",
    "        \n",
    "        return output, hidden[0], attn_weights\n",
    "    \n",
    "    def init_rest_hidden(self, input_var):\n",
    "        if self.n_layers > 1:\n",
    "            hid_var = Variable(torch.zeros(self.n_layers - 1, 1, self.hidden_size)).cuda()\n",
    "            res = torch.cat((input_var, hid_var), 0)\n",
    "            return res\n",
    "        else:\n",
    "            return input_var\n",
    "        \n",
    "    def mods_split(self):\n",
    "        mods = list(decoder_rnn.modules())[1:]\n",
    "        for gru_index, mod in enumerate(mods):\n",
    "            #print(mod)\n",
    "            if type(mod) == torch.nn.modules.rnn.GRU:\n",
    "                break\n",
    "        return mods[:gru_index], mods[gru_index:]\n",
    "        \n",
    "    def mods_attn(self):\n",
    "        return self.mods_split()[0]\n",
    "        \n",
    "    def mods_gru(self):\n",
    "        return self.mods_split()[1]\n",
    "\n",
    "decoder_rnn = DecoderRNN(input_size=len(words_after), hidden_size=tmp_encoder_output.size()[1],\n",
    "                         chars_encoded_size=tmp_encoder_outputs.size()[1], n_layers=1)\n",
    "decoder_rnn = decoder_rnn.cuda()\n",
    "decoder_rnn\n",
    "\n",
    "tmp = decoder_rnn(Variable(sos_tensor).cuda(), tmp_encoder_output, tmp_encoder_outputs)\n",
    "#tmp\n",
    "[v.size() for v in tmp]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'lr': 3, 'params': <generator object Module.parameters at 0x7f203a989ba0>},\n",
       " {'lr': 3, 'params': <generator object Module.parameters at 0x7f203a4d4ba0>},\n",
       " {'lr': 3, 'params': <generator object Module.parameters at 0x7f203a4d4eb8>},\n",
       " {'lr': 3, 'params': <generator object Module.parameters at 0x7f203a4d4c50>},\n",
       " {'params': <generator object Module.parameters at 0x7f203b2bad00>},\n",
       " {'params': <generator object Module.parameters at 0x7f203b2ba468>},\n",
       " {'params': <generator object Module.parameters at 0x7f203b2baba0>}]"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp = [{'params': mod.parameters(), 'lr': 3} for mod in decoder_rnn.mods_attn()]\n",
    "tmp += [{'params': mod.parameters()} for mod in decoder_rnn.mods_gru()]\n",
    "tmp.append(\n",
    "    {'params': encoder_rnn.parameters()}\n",
    ")\n",
    "tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training etc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('getcorrected getcorrected getcorrected eight eight eight eight eight eight eight eight eight eight eight eight eight eight eight eight eight eight eight eight eight eight eight eight eight eight eight',\n",
       " 'getcorrected getcorrected getcorrected eight eight eight eight eight eight eight eight eight eight eight eight eight eight eight eight eight eight eight eight eight eight eight eight eight eight eight',\n",
       " 'h t t p colon slash slash i s l a n d n e w s p a p e r s dot c a slash i s l a n d o r a slash o b j e c t slash g u a r d i a n p e r c e n t t h r e e a o n e n i n e t h r e e s e v e n o o n e o n e s i x dash o o o n e',\n",
       " ('http://islandnewspapers.ca/islandora/object/guardian%3A19370116-001',\n",
       "  [59,\n",
       "   124,\n",
       "   124,\n",
       "   100,\n",
       "   23,\n",
       "   117,\n",
       "   117,\n",
       "   65,\n",
       "   113,\n",
       "   76,\n",
       "   5,\n",
       "   87,\n",
       "   26,\n",
       "   87,\n",
       "   33,\n",
       "   141,\n",
       "   113,\n",
       "   100,\n",
       "   5,\n",
       "   100,\n",
       "   33,\n",
       "   109,\n",
       "   113,\n",
       "   32,\n",
       "   19,\n",
       "   5,\n",
       "   117,\n",
       "   65,\n",
       "   113,\n",
       "   76,\n",
       "   5,\n",
       "   87,\n",
       "   26,\n",
       "   92,\n",
       "   109,\n",
       "   5,\n",
       "   117,\n",
       "   92,\n",
       "   13,\n",
       "   68,\n",
       "   33,\n",
       "   19,\n",
       "   124,\n",
       "   117,\n",
       "   52,\n",
       "   134,\n",
       "   5,\n",
       "   109,\n",
       "   26,\n",
       "   65,\n",
       "   5,\n",
       "   87,\n",
       "   100,\n",
       "   33,\n",
       "   109,\n",
       "   19,\n",
       "   33,\n",
       "   87,\n",
       "   124,\n",
       "   124,\n",
       "   59,\n",
       "   109,\n",
       "   33,\n",
       "   33,\n",
       "   5,\n",
       "   92,\n",
       "   87,\n",
       "   33,\n",
       "   87,\n",
       "   65,\n",
       "   87,\n",
       "   33,\n",
       "   124,\n",
       "   59,\n",
       "   109,\n",
       "   33,\n",
       "   33,\n",
       "   113,\n",
       "   33,\n",
       "   138,\n",
       "   33,\n",
       "   87,\n",
       "   92,\n",
       "   92,\n",
       "   87,\n",
       "   33,\n",
       "   92,\n",
       "   87,\n",
       "   33,\n",
       "   113,\n",
       "   65,\n",
       "   145,\n",
       "   28,\n",
       "   92,\n",
       "   92,\n",
       "   92,\n",
       "   87,\n",
       "   33,\n",
       "   0],\n",
       "  'ELECTRONIC',\n",
       "  ['see',\n",
       "   ':',\n",
       "   '<SAMPLE>',\n",
       "   'reviewed',\n",
       "   '01',\n",
       "   '.',\n",
       "   '11',\n",
       "   '.',\n",
       "   '2015',\n",
       "   'lac',\n",
       "   'archivianet',\n",
       "   ':',\n",
       "   'war',\n",
       "   'diary',\n",
       "   'no',\n",
       "   '2',\n",
       "   'siege',\n",
       "   'battery',\n",
       "   ',',\n",
       "   'december',\n",
       "   '1917',\n",
       "   '-',\n",
       "   'page',\n",
       "   '4',\n",
       "   '.']))"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def test_model_single_sample(model=None, return_more=False, sample=False):\n",
    "    decoder_rnn.eval()\n",
    "    encoder_rnn.eval()\n",
    "    \n",
    "    if not sample:\n",
    "        sample = get_random_sample()\n",
    "    s_bef, s_aft, s_class, s_sentence = sample\n",
    "        \n",
    "    words_t = Variable(words_to_word_vectors_tensor(s_sentence, wv_vecs, wv_idx)).cuda()\n",
    "    \n",
    "    string_t = string_to_tensor(s_bef, chars_normal_index)\n",
    "    string_t = Variable(string_t).cuda()\n",
    "    \n",
    "    encoder_output, encoder_outputs = encoder_rnn(words_t, string_t)\n",
    "\n",
    "    decoder_input = Variable(sos_tensor).cuda()\n",
    "    decoder_hidden = encoder_output\n",
    "\n",
    "    decoded_output = []\n",
    "    decoder_attns_arr = []\n",
    "    max_length = 30\n",
    "    for _ in range(max_length):\n",
    "        decoder_output, decoder_hidden, decoder_attns = decoder_rnn(decoder_input, decoder_hidden, encoder_outputs)\n",
    "        decoder_attns_arr.append(decoder_attns)\n",
    "        #return decoder_output\n",
    "\n",
    "        topv, topi = decoder_output.data.topk(1)\n",
    "        word_index = topi[0][0]\n",
    "        word = words_after[word_index] # Use own prediction as next input\n",
    "                \n",
    "        if word == EOS_TOKEN:\n",
    "            break\n",
    "\n",
    "        decoded_output.append(word)\n",
    "        \n",
    "        decoder_input = torch.zeros(1, 1, len(words_after_index))\n",
    "        decoder_input[0, 0, word_index] = 1\n",
    "        decoder_input = Variable(decoder_input).cuda()\n",
    "    \n",
    "    output = ' '.join(decoded_output)\n",
    "    sample_target = ' '.join([words_after[w] for w in s_aft][:-1])\n",
    "    \n",
    "    decoder_rnn.train()\n",
    "    encoder_rnn.train()\n",
    "    \n",
    "    if return_more:\n",
    "        return output, decoded_output, decoder_attns_arr, sample\n",
    "    \n",
    "    return output, output, sample_target, sample\n",
    "    \n",
    "tmp = test_model_single_sample()\n",
    "tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NHLer          => w's w's w's f's f's f's f's f's f's f's f's f's f's f's f's f's f's f's f's f's f's f's f's f's f's f's f's f's f's f's || [87, 59, 76, 33, 109, 0] \n",
      "                  ['the', 'president', 'of', 'the', 'team', 'is', 'another', 'former', '<SAMPLE>', ',', 'dale', 'hawerchuk', '.']\n",
      "DVDs           => deletecyberbullying aip aip aip r's r's r's r's r's r's r's r's r's r's r's r's r's r's r's r's r's r's r's r's r's r's r's r's r's r's || [26, 138, 27, 0] \n",
      "                  ['unlike', '<SAMPLE>', 'and', 'cds', ',', 'dmd', 'do', 'not', 'have', 'metallic', 'layers', ',', 'so', 'they', 'are', 'nearly', 'transparent', '.']\n"
     ]
    }
   ],
   "source": [
    "def print_local_wrong_predictions(max_results=10):\n",
    "    arr = get_some_wrong_predictions(None, test_model_single_sample, max_iterations=10000, max_results=max_results)\n",
    "    for sample, predict, output in arr:\n",
    "        s_bef, s_aft, s_class, s_sentence = sample\n",
    "        print(\"{:<14} => {:<14} || {} \\n{:>17} {}\".format(s_bef, predict, s_aft, '', s_sentence, ))\n",
    "print_local_wrong_predictions(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.00% (       0/     100)\n",
      "CPU times: user 3.38 s, sys: 64 ms, total: 3.44 s\n",
      "Wall time: 3.44 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "test_model_accuracy(decoder_rnn, test_model_single_sample, n_sample=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train(s_bef, s_aft, s_sentence, optimizer, loss_function,\n",
    "          use_teacher_forcing, max_length=20):\n",
    "    \n",
    "    words_t = Variable(words_to_word_vectors_tensor(s_sentence, wv_vecs, wv_idx)).cuda()\n",
    "    \n",
    "    string_t = string_to_tensor(s_bef, chars_normal_index)\n",
    "    string_t = Variable(string_t).cuda()\n",
    "    \n",
    "    encoder_output, encoder_outputs = encoder_rnn(words_t, string_t)\n",
    "    \n",
    "   \n",
    "    decoder_hidden = encoder_output\n",
    "    decoder_input = Variable(sos_tensor).cuda()\n",
    "    \n",
    "    ###\n",
    "    target_arr = s_aft\n",
    "    #target_arr = after_sentence_to_word_indexes(s_aft, include_eos=True)\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    loss = 0\n",
    "    \n",
    "    decoded_output = []\n",
    "    for i in range(len(target_arr)):\n",
    "        decoder_output, decoder_hidden, decoder_attns = decoder_rnn(decoder_input, decoder_hidden, encoder_outputs)\n",
    "\n",
    "        #decoder_target_i = chars_after_index[target_arr[i]]\n",
    "        decoder_target_i = target_arr[i]\n",
    "        decoder_target_i = Variable(torch.LongTensor([decoder_target_i])).cuda()\n",
    "        loss += loss_function(decoder_output, decoder_target_i)\n",
    "        \n",
    "        topv, topi = decoder_output.data.topk(1)\n",
    "        word_index = topi[0][0]\n",
    "        word = words_after[word_index] # Use own prediction as next input\n",
    "        decoded_output.append(word)\n",
    "        \n",
    "        if use_teacher_forcing:\n",
    "            word_index = target_arr[i] # replace input with right target\n",
    "        else:\n",
    "            # use output normally as input \n",
    "            if word == EOS_TOKEN:\n",
    "                break\n",
    "                \n",
    "        decoder_input = torch.zeros(1, 1, len(words_after_index))\n",
    "        decoder_input[0, 0, word_index] = 1\n",
    "        decoder_input = Variable(decoder_input).cuda()\n",
    "        #decoder_input = Variable(torch.LongTensor([word_index])).cuda()\n",
    "        \n",
    "    if decoded_output[-1] == EOS_TOKEN:\n",
    "        decoded_output = decoded_output[:-1]\n",
    "        \n",
    "    loss.backward()\n",
    "\n",
    "    optimizer.step()\n",
    "\n",
    "    return ' '.join(decoded_output), (loss.data[0] / len(target_arr))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_iterations(n_iters=100000, lr=0.001, teacher_forcing_ratio=0.5,\n",
    "                     print_every=10000, plot_every=1000):\n",
    "    global optimizer\n",
    "    start = time.time()\n",
    "    \n",
    "    decoder_rnn.train()\n",
    "    encoder_rnn.train()\n",
    "\n",
    "    current_loss = 0\n",
    "    current_loss_iter = 0\n",
    "\n",
    "    tmp = [{'params': mod.parameters(), 'lr': (lr/10)} for mod in decoder_rnn.mods_attn()]\n",
    "    tmp += [{'params': mod.parameters()} for mod in decoder_rnn.mods_gru()]\n",
    "    tmp.append(\n",
    "        {'params': encoder_rnn.parameters()}\n",
    "    )\n",
    "    #print(tmp)\n",
    "    optimizer = torch.optim.Adam(tmp, lr=lr)\n",
    "    #return optimizer\n",
    "    #encoder_optimizer = torch.optim.Adam(encoder_rnn.parameters(), lr=lr)\n",
    "    #decoder_optimizer = torch.optim.Adam(decoder_rnn.parameters(), lr=lr)\n",
    "    loss_function = nn.NLLLoss()\n",
    "    \n",
    "    for iteration in range(1, n_iters + 1):\n",
    "        model_training.iterations += 1\n",
    "        \n",
    "        use_teacher_forcing = random.random() < teacher_forcing_ratio\n",
    "        \n",
    "        s_bef, s_aft, s_class, s_sentence = get_random_sample()\n",
    "        \n",
    "        result, loss = train(s_bef=s_bef, s_aft=s_aft, s_sentence=s_sentence,\n",
    "                             optimizer=optimizer, \n",
    "                             loss_function=nn.NLLLoss(), use_teacher_forcing=use_teacher_forcing,\n",
    "                             max_length=40 )\n",
    "        \n",
    "        current_loss += loss\n",
    "        current_loss_iter += 1\n",
    "\n",
    "        # Print iter number, loss, name and guess\n",
    "        if iteration % print_every == 0:\n",
    "            teacher_forcing_str = \"\"\n",
    "            if use_teacher_forcing:\n",
    "                teacher_forcing_str = \"(forcing)\"\n",
    "            s_aft_sentence = ' '.join([words_after[w] for w in s_aft][:-1])\n",
    "            correct = '✓' if result == s_aft_sentence else \"✗: {}\".format(s_aft_sentence)\n",
    "            \n",
    "            print(\"{:>6d} {:>4.0%} ({:>8}) {:>7.3f}   | {:>6.2f}: {} -> {} ({}) {}\".format(\n",
    "                      model_training.iterations, iteration/n_iters, time_since(start),\n",
    "                      current_loss/current_loss_iter, loss,\n",
    "                      s_bef, result, correct, teacher_forcing_str))\n",
    "\n",
    "        # Add current loss avg to list of losses\n",
    "        if iteration % plot_every == 0:\n",
    "            model_training.losses.append(current_loss / plot_every)\n",
    "            model_training.learning_rates.append(lr)\n",
    "            current_loss = 0\n",
    "            current_loss_iter = 0\n",
    "            \n",
    "        if model_training.iterations % 50000 == 0: # or model_training.iterations == 10:\n",
    "            model_training.save_models()\n",
    "            acc = test_model_accuracy(encoder_rnn, test_model_single_sample)\n",
    "            model_training.accuracy.append(acc)\n",
    "    \n",
    "    # test_model_accuracy(model, n_sample=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Save path: data/models/electronic_gen_7_testing_attn_learning_rates_1\n"
     ]
    }
   ],
   "source": [
    "model_training = ModelTraining(MODEL_SAVE_PATH, [encoder_rnn, decoder_rnn])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  1009  18% (   0m 1s)   2.814   |   1.82: Uboat.net -> i s s s n (✗: u b o a t dot n e t) \n",
      "  1018  36% (   0m 1s)   2.846   |   1.79: ISBN -> i s s (✗: i s b n) \n",
      "  1027  54% (   0m 1s)   2.843   |   3.17: NeighborCity.com -> a s s s t e e e e e e <EOS> <EOS> <EOS> <EOS> <EOS> (✗: n e i g h b o r c i t y dot c o m) (forcing)\n",
      "  1036  72% (   0m 1s)   2.775   |   2.65: KNAG -> i s s (✗: k n a g) \n",
      "  1045  90% (   0m 1s)   2.764   |   2.52: Actg -> i s s (✗: a c t g) \n"
     ]
    }
   ],
   "source": [
    "train_iterations(n_iters=50, print_every=9, lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1e-05"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.0001"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer.param_groups[0]['lr']\n",
    "optimizer.param_groups[6]['lr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   550  53% (   0m 9s)   2.696   |   2.46: ISBN -> i s <EOS> <EOS> (✗: i s b n) (forcing)\n"
     ]
    }
   ],
   "source": [
    "train_iterations(n_iters=(1000-model_training.iterations), print_every=500, lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.00% (       0/   10000)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_model_accuracy(encoder_rnn, test_model_single_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iterations(n_iters=49000, print_every=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iterations(n_iters=50000, print_every=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "state_dict_path = 'data/models/electronic_gen_6_testing_attn/100000_'\n",
    "#state_dict_path = 'data/models/electronic_gen_6_testing_attn/50000_'\n",
    "decoder_rnn.load_state_dict(torch.load(state_dict_path + 'DecoderRNN'))\n",
    "encoder_rnn.load_state_dict(torch.load(state_dict_path + 'EncoderRNN'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input:   SoundMeet.net\n",
      "output:  i a a a a e\n",
      "target:    soundmeetdotnet\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAxAAAAFbCAYAAABF+Wh7AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f2054864da0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def debug_show_attention(input_sentence, output_words, attentions):\n",
    "    # Set up figure with colorbar\n",
    "    fig = plt.figure(figsize=(15,6))\n",
    "    ax = fig.add_subplot(111)\n",
    "    #cax = ax.matshow(attentions.numpy(), cmap='bone')\n",
    "    cax = ax.matshow(attentions, cmap='bone')\n",
    "    fig.colorbar(cax)\n",
    "    # Set up axes\n",
    "    #ax.set_xticklabels([''] + input_sentence.split(' ') + ['<EOS>'], rotation=90)\n",
    "    #ax.set_xticklabels([''] + input_sentence + ['<EOS>'], rotation=90)\n",
    "    ax.set_yticklabels([''] + output_words)\n",
    "    \n",
    "    input_sentence = input_sentence + ['<EOS>']\n",
    "    #inp_arr = [\"{}\\n{}\".format(input_sentence[i], input_sentence[-1-i]) for i in range(len(input_sentence))]\n",
    "    inp_arr = input_sentence\n",
    "    ax.set_xticklabels([''] + inp_arr, rotation=0)\n",
    "\n",
    "    # Show label at every tick\n",
    "    ax.xaxis.set_major_locator(matplotlib.ticker.MultipleLocator(1))\n",
    "    ax.yaxis.set_major_locator(matplotlib.ticker.MultipleLocator(1))\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "def debug_eval_sample_show_attention():\n",
    "    global sample_row_last\n",
    "    #sample_row = balanced_data_sample_row()\n",
    "    sample_row = sample_data[sample_data['before'].str.len()>10].sample(1).iloc[0]\n",
    "    sample_row_last = sample_row\n",
    "       \n",
    "    a_words_ind = after_sentence_to_word_indexes(sample_row['after'], include_eos=True)\n",
    "    sample = sample_row['before'], a_words_ind, sample_row['class'], sample_row['sentence'].split(' ')\n",
    "\n",
    "    output, decoded_output, decoder_attns_arr, sample = test_model_single_sample(None, \n",
    "                                                            return_more=True, sample=sample)\n",
    "    print('input:  ', sample[0])\n",
    "    print('output: ', ' '.join(decoded_output))\n",
    "    print('target:   ', ''.join([words_after[w] for w in a_words_ind[:-1]]))\n",
    "\n",
    "    attns = np.array([arr.data[0].cpu().numpy() for arr in decoder_attns_arr])\n",
    "\n",
    "    debug_show_attention(list(sample[0]), decoded_output, attns)\n",
    "    #plt.matshow(attns)\n",
    "\n",
    "debug_eval_sample_show_attention()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentence_id                                               360158\n",
       "token_id                                                       3\n",
       "class                                                 ELECTRONIC\n",
       "before         https://www.gov.uk/government/organisations/te...\n",
       "after          h t t p s colon slash slash w w w dot g o v do...\n",
       "class_org                                             ELECTRONIC\n",
       "a_word_ind     [45, 30, 30, 24, 17, 129, 101, 101, 52, 52, 52...\n",
       "sentence                             available from : <SAMPLE> .\n",
       "Name: 15512, dtype: object"
      ]
     },
     "execution_count": 329,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_row_last"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentence_id                                               360158\n",
       "token_id                                                       3\n",
       "class                                                 ELECTRONIC\n",
       "before         https://www.gov.uk/government/organisations/te...\n",
       "after          h t t p s colon slash slash w w w dot g o v do...\n",
       "class_org                                             ELECTRONIC\n",
       "a_word_ind     [45, 30, 30, 24, 17, 129, 101, 101, 52, 52, 52...\n",
       "sentence                             available from : <SAMPLE> .\n",
       "Name: 15512, dtype: object"
      ]
     },
     "execution_count": 370,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_row_last = sample_data.loc[15512]\n",
    "sample_row_last"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:py3_pytorch_2]",
   "language": "python",
   "name": "conda-env-py3_pytorch_2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
