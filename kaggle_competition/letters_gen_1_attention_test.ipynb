{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pytorch utils oh: pytorch_utils_oh_2.py\n",
      "Pytorch: 0.2.0_4\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import importlib\n",
    "from pytorch_utils_oh_2 import *\n",
    "import IPython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MODEL_SAVE_PATH = 'letters_gen_1_attn_test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pytorch utils oh: pytorch_utils_oh_2.py\n",
      "Pytorch: 0.2.0_4\n"
     ]
    }
   ],
   "source": [
    "import pytorch_utils_oh_2; importlib.reload(pytorch_utils_oh_2); from pytorch_utils_oh_2 import *;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# all_data = pickle.load(open(\"data/en_train_fixed_4_sentences.pkl\", \"rb\" ))\n",
    "all_data = pickle.load(open(\"data/en_train_fixed_5_manual.pkl\", \"rb\" ))\n",
    "# all_data_sentence_index = all_data.set_index('sentence_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data rows: 152986,  (dropped rows: 9765206)\n"
     ]
    }
   ],
   "source": [
    "sample_data = all_data.copy()\n",
    "#sample_data = sample_data[sample_data['class'] != 'NOT_CHANGED']\n",
    "#sample_data = sample_data[sample_data['class'] != 'MANUAL']\n",
    "\n",
    "sample_data =  sample_data[sample_data['class'] == 'LETTERS']\n",
    "\n",
    "print(\"Data rows: {},  (dropped rows: {})\".format(len(sample_data), len(all_data)-len(sample_data)))\n",
    "sample_data = sample_data.reset_index(drop=True)\n",
    "del(all_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['LETTERS']\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "categories_all = sorted(sample_data[\"class\"].unique())\n",
    "print(categories_all)\n",
    "print(len(categories_all))\n",
    "categories_index = dict((c, i) for i, c in enumerate(categories_all))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utils stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<SOS><EOS>☒ !\"#$%&'(),-./0123456789:;ABCDEFGHIJKLMNOPQRSTUVWXYZ_abcdefghijklmnopqrstuvwxyz~£¥ª²³µº¼½¾éɒʻˈΩμ—€⅓⅔⅛\n"
     ]
    }
   ],
   "source": [
    "chars_normal, chars_normal_index = load_characters_pkl('data/en_features/chars_normal.pkl')\n",
    "print(''.join(chars_normal))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "common_words, common_words_index = load_common_words_10k()\n",
    "len(common_words)\n",
    "common_words[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wv_vecs, wv_words, wv_idx = load_glove('/home/ohu/koodi/data/glove_wordvec/glove.6B.50d.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### After words handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<EOS>', '<SOS>', '<UNK>', '<0000>', '<SAMPLE>', 'two', 'twenty']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "1351"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_after_common = pickle.load(open(\"data/en_features/words_after_ext.pkl\", 'rb'))\n",
    "words_after_index = dict((c, i) for i, c in enumerate(words_after_common))\n",
    "words_after_common[0:7]\n",
    "len(words_after_common)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#onehot_sos = torch.zeros(1, 1, len(words_after_index))\n",
    "#onehot_sos[0, 0, words_after_index[SOS_TOKEN]] = 1\n",
    "#onehot_sos.size()\n",
    "#del(onehot_sos)\n",
    "\n",
    "sos_tensor = torch.LongTensor([words_after_index[SOS_TOKEN]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### More balanced sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "balanced_data_classes_select = list(sample_data.groupby('class'))\n",
    "\n",
    "balanced_data_accessed_counter = 0 \n",
    "balanced_data_length = 0\n",
    "def balanced_data_randomize(max_len=20000):\n",
    "    global balanced_data, balanced_data_length, balanced_data_accessed_counter\n",
    "    balanced_data = pd.concat([v.sample(min(max_len, len(v))) for k, v in balanced_data_classes_select])\n",
    "    balanced_data_length = len(balanced_data)\n",
    "    balanced_data_accessed_counter = 0\n",
    "\n",
    "def balanced_data_sample_row():\n",
    "    global balanced_data_accessed_counter\n",
    "    global balanced_data_last_sample\n",
    "    balanced_data_accessed_counter += 1\n",
    "    if balanced_data_accessed_counter/balanced_data_length > 0.2:\n",
    "        balanced_data_randomize()\n",
    "    balanced_data_last_sample = balanced_data.iloc[random.randint(1, balanced_data_length-1)]\n",
    "    return balanced_data_last_sample\n",
    "    \n",
    "balanced_data_randomize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105 µs ± 751 ns per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "balanced_data_sample_row()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "class\n",
       "LETTERS    20000\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#all_data.groupby('class')['class'].count()\n",
    "#sample_data.groupby('class')['class'].count()\n",
    "balanced_data.groupby('class')['class'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentence_id                                               512765\n",
       "token_id                                                      12\n",
       "class                                                    LETTERS\n",
       "before                                                        CD\n",
       "after                                                        c d\n",
       "class_org                                                LETTERS\n",
       "a_word_ind                                           [21, 26, 0]\n",
       "sentence       the first drama cd was released in september 1...\n",
       "Name: 103986, dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " balanced_data_sample_row()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LETTERS : GHz -> g h z <EOS> [53, 45, 105, 0]\n",
      "iqrf is a technology for wireless packet oriented communication via radio frequency ( rf ) in sub <SAMPLE> ism bands .\n",
      "torch.Size([1, 4, 104])\n"
     ]
    }
   ],
   "source": [
    "def get_random_sample():\n",
    "    sample_row = balanced_data_sample_row()\n",
    "    sentence_id = sample_row['class']\n",
    "    \n",
    "    return sample_row['before'], sample_row['a_word_ind'], sample_row['class'], sample_row['sentence']\n",
    "            \n",
    "def tmp():\n",
    "    s_bef, s_aft, s_class, s_sentence = get_random_sample()\n",
    "    s_aft_str = ' '.join([words_after_common[i] for i in s_aft])\n",
    "    print(s_class, ':', s_bef, '->', s_aft_str, s_aft)\n",
    "    print(s_sentence)\n",
    "    print(string_to_tensor(s_bef, chars_normal_index).shape)\n",
    "tmp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "151 µs ± 898 ns per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "get_random_sample()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "use_cuda = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MAX_ATTENTION_LENGTH = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EncoderRNN (\n",
       "  (rnn_words): LSTM(50, 64, batch_first=True, bidirectional=True)\n",
       "  (rnn_chars): LSTM(104, 128, batch_first=True, bidirectional=True)\n",
       ")"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, words_input_size, chars_input_size, words_hidden_size, chars_hidden_size,\n",
    "                 words_layers=1, chars_layers=1):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        \n",
    "        self.words_layers = words_layers\n",
    "        self.chars_layers = chars_layers\n",
    "        self.words_hidden_size = words_hidden_size\n",
    "        self.chars_hidden_size = chars_hidden_size\n",
    "        self.hidden_size = words_hidden_size + chars_hidden_size\n",
    "\n",
    "        self.rnn_words = nn.LSTM(words_input_size, words_hidden_size // 2, words_layers,\n",
    "                                 batch_first=True, bidirectional=True)\n",
    "\n",
    "        self.rnn_chars = nn.LSTM(chars_input_size, chars_hidden_size // 2, chars_layers,\n",
    "                                batch_first=True, bidirectional=True)\n",
    "        \n",
    "    def forward(self, word_vectors, string_tensor, hidden = None, init_hidden = True):\n",
    "        if init_hidden:\n",
    "            hidden_words, hidden_chars = self.init_hidden()\n",
    "        \n",
    "        #all_outputs_words, hidden_words = self.rnn_words(word_vectors, hidden_words)\n",
    "        #output_words = all_outputs_words[:, -1]\n",
    "        \n",
    "        all_outputs_chars, hidden_chars = self.rnn_chars(string_tensor, hidden_chars)\n",
    "        output_chars = all_outputs_chars[:, -1].view(-1)\n",
    "        \n",
    "        #hidden_states_cat = Variable(torch.zeros(MAX_ATTENTION_LENGTH, self.hidden_size)).cuda()\n",
    "        hidden_states_cat = Variable(torch.zeros(MAX_ATTENTION_LENGTH, self.chars_hidden_size)).cuda()\n",
    "        for ei in range(min(MAX_ATTENTION_LENGTH, len(string_tensor[0]))):\n",
    "            #hidden_states_cat[ei] = torch.cat((output_words, all_outputs_chars[:,ei]), 1)\n",
    "            hidden_states_cat[ei] = all_outputs_chars[0,ei]\n",
    "                \n",
    "        #output = torch.cat((output_words, output_chars), 1)\n",
    "        #output = torch.cat((output_words, output_chars), 1)\n",
    "        \n",
    "        #return output, all_outputs_chars\n",
    "        return output_chars, hidden_states_cat #all_outputs_chars\n",
    "\n",
    "    def init_hidden(self):\n",
    "        var1_1 = Variable(torch.zeros(2 * self.words_layers, 1, self.words_hidden_size // 2))\n",
    "        var1_2 = Variable(torch.zeros(2 * self.words_layers, 1, self.words_hidden_size // 2))\n",
    "        var2_1 = Variable(torch.zeros(2 * self.chars_layers, 1, self.chars_hidden_size // 2))\n",
    "        var2_2 = Variable(torch.zeros(2 * self.chars_layers, 1, self.chars_hidden_size // 2))\n",
    "        \n",
    "        var1_1 = var1_1.cuda(); var1_2 = var1_2.cuda()\n",
    "        var2_1 = var2_1.cuda(); var2_2 = var2_2.cuda()\n",
    "        return ((var1_1, var1_2), (var2_1, var2_2))\n",
    "    \n",
    "    \n",
    "encoder_rnn = EncoderRNN(words_input_size=wv_vecs.shape[-1], chars_input_size=len(chars_normal),\n",
    "                         words_hidden_size=128, chars_hidden_size=256,\n",
    "                         words_layers=1, chars_layers=1).cuda()\n",
    "encoder_rnn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "encoder_rnn.load_state_dict(torch.load('data/models/numbers_gen_8_attention/50000_EncoderRNN'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FC\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([256])"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 256])"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string_t = \"\"\n",
    "def test_encoder_single_sample():\n",
    "    s_bef, s_aft, s_class, s_sentence = get_random_sample()\n",
    "    print(s_bef)\n",
    "    \n",
    "    words_t = Variable(words_to_word_vectors_tensor(list(s_sentence), wv_vecs, wv_idx)).cuda()\n",
    "    \n",
    "    string_t = string_to_tensor(s_bef, chars_normal_index)\n",
    "    string_t = Variable(string_t).cuda()\n",
    "    \n",
    "    return encoder_rnn(words_t, string_t)\n",
    "    \n",
    "encoder_output, encoder_outputs = test_encoder_single_sample()\n",
    "encoder_output.size()\n",
    "encoder_outputs.size()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecoderRNN (\n",
       "  (rnn): GRU(256, 256, batch_first=True)\n",
       "  (lin_out): Linear (256 -> 1351)\n",
       "  (embedding): Embedding(1351, 256)\n",
       "  (attn): Linear (512 -> 10)\n",
       "  (attn_combine): Linear (512 -> 256)\n",
       "  (dropout): Dropout (p = 0.1)\n",
       ")"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[torch.Size([1, 1351]), torch.Size([1, 1, 256]), torch.Size([1, 10])]"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class DecoderRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, n_layers=1, dropout_p=0.1, max_length=MAX_ATTENTION_LENGTH):\n",
    "        super(DecoderRNN, self).__init__()\n",
    "        self.n_layers = n_layers\n",
    "        self.hidden_size = hidden_size\n",
    "        \n",
    "        \n",
    "        self.rnn = nn.GRU(hidden_size, hidden_size, n_layers,\n",
    "                                 batch_first=True, bidirectional=False)\n",
    "        \n",
    "        self.lin_out = nn.Linear(hidden_size, input_size)\n",
    "\n",
    "        \n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        self.max_length = max_length\n",
    "        self.attn = nn.Linear(hidden_size*2, self.max_length)\n",
    "        self.attn_combine = nn.Linear(self.hidden_size * 2, self.hidden_size)\n",
    "        self.dropout = nn.Dropout(dropout_p)\n",
    "        \n",
    "    #def forward(self, char, hidden):\n",
    "    def forward(self, last_input, hidden, encoder_outputs):\n",
    "        embedded = self.embedding(last_input).view(1, 1, -1)\n",
    "        embedded = self.dropout(embedded)\n",
    "        #IPython.core.debugger.Pdb().set_trace()\n",
    "        #attn_weights = F.softmax(self.attn(torch.cat((char[0], hidden[0]), 1)))\n",
    "        attn_weights = F.softmax(self.attn(torch.cat((embedded[0], hidden[0]), 1)))\n",
    "        attn_applied = torch.bmm(attn_weights.unsqueeze(0), encoder_outputs.unsqueeze(0))\n",
    "        \n",
    "        output = torch.cat((embedded[0], attn_applied[0]), 1)\n",
    "        output = self.attn_combine(output).unsqueeze(0)\n",
    "\n",
    "        \n",
    "        output = F.relu(output)\n",
    "        output, hidden = self.rnn(output, hidden)\n",
    "\n",
    "        output = F.log_softmax(self.lin_out(output[0]))\n",
    "        return output, hidden, attn_weights\n",
    "    \n",
    "    def init_rest_hidden(self, input_var):\n",
    "        if self.n_layers > 1:\n",
    "            hid_var = Variable(torch.zeros(self.n_layers - 1, 1, self.hidden_size)).cuda()\n",
    "            res = torch.cat((input_var, hid_var), 0)\n",
    "            return res\n",
    "        else:\n",
    "            return input_var\n",
    "        \n",
    "\n",
    "decoder_rnn = DecoderRNN(input_size=len(words_after_common), hidden_size=encoder_output.size()[0], n_layers=1)\n",
    "decoder_rnn = decoder_rnn.cuda()\n",
    "decoder_rnn\n",
    "\n",
    "tmp_outputs = Variable(torch.zeros(MAX_ATTENTION_LENGTH, encoder_output.size()[0])).cuda()\n",
    "tmp_hiddens = decoder_rnn.init_rest_hidden(encoder_output.view(1,1,-1))\n",
    "tmp = decoder_rnn(Variable(sos_tensor).cuda(), tmp_hiddens, tmp_outputs)\n",
    "[v.size() for v in tmp]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "(0 ,.,.) = \n",
       "  1.2000  2.4000  3.6000  4.8000\n",
       "[torch.FloatTensor of size 1x1x4]"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.bmm(torch.FloatTensor([1,0.1,0.1]).view(1,1,-1), torch.arange(0, 12).view(1,3,-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[torch.Size([1, 1351]), torch.Size([1, 1, 256]), torch.Size([1, 10])]"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      " 465\n",
      "[torch.cuda.LongTensor of size 1x1 (GPU 0)]\n",
      "\n",
      "sad\n"
     ]
    }
   ],
   "source": [
    "tmp_outputs = Variable(torch.zeros(MAX_ATTENTION_LENGTH, encoder_output.size()[0])).cuda()\n",
    "tmp_hiddens = decoder_rnn.init_rest_hidden(encoder_output.view(1,1,-1))\n",
    "tmp = decoder_rnn(Variable(sos_tensor).cuda(), tmp_hiddens, tmp_outputs)\n",
    "[v.size() for v in tmp]\n",
    "print(tmp[0].topk(1)[1])\n",
    "print(words_after_common[tmp[0].topk(1)[1].data[0][0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training etc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('savory savory savory savory savory savory savory savory savory savory savory savory savory savory savory savory savory savory savory savory',\n",
       " 'savory savory savory savory savory savory savory savory savory savory savory savory savory savory savory savory savory savory savory savory',\n",
       " 'g h',\n",
       " ('GH',\n",
       "  [53, 45, 0],\n",
       "  'LETTERS',\n",
       "  'york had previously auditioned for two other roles on <SAMPLE> but was rejected .'))"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def test_model_single_sample(model=None, return_more=False):\n",
    "    decoder_rnn.eval()\n",
    "    encoder_rnn.eval()\n",
    "    \n",
    "    s_bef, s_aft, s_class, s_sentence = sample = get_random_sample()\n",
    "        \n",
    "    words_t = Variable(words_to_word_vectors_tensor(list(s_sentence), wv_vecs, wv_idx)).cuda()\n",
    "    \n",
    "    string_t = string_to_tensor(s_bef, chars_normal_index)\n",
    "    string_t = Variable(string_t).cuda()\n",
    "    \n",
    "    encoder_output, encoder_outputs = encoder_rnn(words_t, string_t)\n",
    "    \n",
    "    #encoder_output = encoder_output.view(1,1,-1)\n",
    "    \n",
    "    decoder_hidden = decoder_rnn.init_rest_hidden(encoder_outputs[0].view(1,1,-1))\n",
    "    decoder_input = Variable(sos_tensor).cuda()\n",
    "\n",
    "    decoded_output = []\n",
    "    decoder_attns_arr = []\n",
    "    max_length = 20\n",
    "    for _ in range(max_length):\n",
    "        decoder_output, decoder_hidden, decoder_attns = decoder_rnn(decoder_input, decoder_hidden, encoder_outputs)\n",
    "        decoder_attns_arr.append(decoder_attns)\n",
    "        #return decoder_output\n",
    "\n",
    "        topv, topi = decoder_output.data.topk(1)\n",
    "        word_index = topi[0][0]\n",
    "        word = words_after_common[word_index] # Use own prediction as next input\n",
    "                \n",
    "        if word == EOS_TOKEN:\n",
    "            break\n",
    "\n",
    "        decoded_output.append(word)\n",
    "        \n",
    "        decoder_intput = torch.LongTensor([word_index])\n",
    "        #decoder_input = torch.zeros(1, 1, len(words_after_index))\n",
    "        #decoder_input[0, 0, word_index] = 1\n",
    "        #decoder_input = Variable(decoder_input).cuda()\n",
    "    \n",
    "    output = ' '.join(decoded_output)\n",
    "    sample_target = ' '.join([words_after_common[w] for w in s_aft][:-1])\n",
    "    \n",
    "    decoder_rnn.train()\n",
    "    encoder_rnn.train()\n",
    "    \n",
    "    if return_more:\n",
    "        return output, decoded_output, decoder_attns_arr, sample\n",
    "    \n",
    "    return output, output, sample_target, sample\n",
    "    \n",
    "tmp = test_model_single_sample(None)\n",
    "tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L.             => savory savory savory savory savory savory savory savory savory savory savory savory savory savory savory savory savory savory savory savory || [42, 0] \n",
      "                  \" sergeant ola <SAMPLE> mize \" .\n",
      "BTH            => t's savory savory savory savory savory savory savory savory savory savory savory savory savory savory savory savory savory savory savory || [36, 30, 45, 0] \n",
      "                  in 2012 , the transaxle yo yo sleep time record was broken by the c3 yoyodesign <SAMPLE> , with a time of 30 : 28 . 30 minutes .\n"
     ]
    }
   ],
   "source": [
    "def print_local_wrong_predictions(max_results=10):\n",
    "    arr = get_some_wrong_predictions(None, test_model_single_sample, max_iterations=10000, max_results=max_results)\n",
    "    for sample, predict, output in arr:\n",
    "        s_bef, s_aft, s_class, s_sentence = sample\n",
    "        print(\"{:<14} => {:<14} || {} \\n{:>17} {}\".format(s_bef, predict, s_aft, '', s_sentence, ))\n",
    "print_local_wrong_predictions(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train(s_bef, s_aft, s_sentence, encoder_optimizer, decoder_optimizer, loss_function,\n",
    "          use_teacher_forcing, max_length=20):\n",
    "    \n",
    "    words_t = Variable(words_to_word_vectors_tensor(list(s_sentence), wv_vecs, wv_idx)).cuda()\n",
    "    \n",
    "    string_t = string_to_tensor(s_bef, chars_normal_index)\n",
    "    string_t = Variable(string_t).cuda()\n",
    "    \n",
    "    encoder_output, encoder_outputs = encoder_rnn(words_t, string_t)\n",
    "    \n",
    "    #encoder_output = encoder_output.view(1,1,-1)\n",
    "    \n",
    "    decoder_hidden = decoder_rnn.init_rest_hidden(encoder_outputs[0].view(1,1,-1))\n",
    "    decoder_input = Variable(sos_tensor).cuda()\n",
    "    \n",
    "    ###\n",
    "    target_arr = s_aft\n",
    "    #target_arr = after_sentence_to_word_indexes(s_aft, include_eos=True)\n",
    "    \n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "    loss = 0\n",
    "    \n",
    "    decoded_output = []\n",
    "    for i in range(len(target_arr)):\n",
    "        decoder_output, decoder_hidden, decoder_attns = decoder_rnn(decoder_input, decoder_hidden, encoder_outputs)\n",
    "\n",
    "        #decoder_target_i = chars_after_index[target_arr[i]]\n",
    "        decoder_target_i = target_arr[i]\n",
    "        decoder_target_i = Variable(torch.LongTensor([decoder_target_i])).cuda()\n",
    "        loss += loss_function(decoder_output, decoder_target_i)\n",
    "        \n",
    "        topv, topi = decoder_output.data.topk(1)\n",
    "        word_index = topi[0][0]\n",
    "        word = words_after_common[word_index] # Use own prediction as next input\n",
    "        decoded_output.append(word)\n",
    "        \n",
    "        if use_teacher_forcing:\n",
    "            word_index = target_arr[i] # replace input with right target\n",
    "        else:\n",
    "            # use output normally as input \n",
    "            if word == EOS_TOKEN:\n",
    "                break\n",
    "                \n",
    "        decoder_intput = torch.LongTensor([word_index])\n",
    "        \n",
    "    if decoded_output[-1] == EOS_TOKEN:\n",
    "        decoded_output = decoded_output[:-1]\n",
    "        \n",
    "    loss.backward()\n",
    "\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "\n",
    "    return ' '.join(decoded_output), (loss.data[0] / len(target_arr))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_iterations(n_iters=100000, lr=0.001, teacher_forcing_ratio=0.5,\n",
    "                     print_every=10000, plot_every=1000):\n",
    "\n",
    "    start = time.time()\n",
    "    \n",
    "    decoder_rnn.train()\n",
    "    encoder_rnn.train()\n",
    "\n",
    "    current_loss = 0\n",
    "    current_loss_iter = 0\n",
    "\n",
    "    encoder_optimizer = torch.optim.Adam(encoder_rnn.parameters(), lr=lr)\n",
    "    decoder_optimizer = torch.optim.Adam(decoder_rnn.parameters(), lr=lr)\n",
    "    loss_function = nn.NLLLoss()\n",
    "    \n",
    "    for iteration in range(1, n_iters + 1):\n",
    "        model_training.iterations += 1\n",
    "        \n",
    "        use_teacher_forcing = random.random() < teacher_forcing_ratio\n",
    "        \n",
    "        s_bef, s_aft, s_class, s_sentence = get_random_sample()\n",
    "        \n",
    "        result, loss = train(s_bef=s_bef, s_aft=s_aft, s_sentence=s_sentence,\n",
    "                             encoder_optimizer=encoder_optimizer, decoder_optimizer=decoder_optimizer,\n",
    "                             loss_function=nn.NLLLoss(), use_teacher_forcing=use_teacher_forcing,\n",
    "                             max_length=40 )\n",
    "        \n",
    "        current_loss += loss\n",
    "        current_loss_iter += 1\n",
    "\n",
    "        # Print iter number, loss, name and guess\n",
    "        if iteration % print_every == 0:\n",
    "            teacher_forcing_str = \"\"\n",
    "            if use_teacher_forcing:\n",
    "                teacher_forcing_str = \"(forcing)\"\n",
    "            s_aft_sentence = ' '.join([words_after_common[w] for w in s_aft][:-1])\n",
    "            correct = '✓' if result == s_aft_sentence else \"✗: {}\".format(s_aft)\n",
    "            \n",
    "            print(\"{:>6d} {:>4.0%} ({:>8}) {:>7.3f}   | {:>6.2f}: {} -> {} ({}) {}\".format(\n",
    "                      model_training.iterations, iteration/n_iters, time_since(start),\n",
    "                      current_loss/current_loss_iter, loss,\n",
    "                      s_bef, result, correct, teacher_forcing_str))\n",
    "\n",
    "        # Add current loss avg to list of losses\n",
    "        if iteration % plot_every == 0:\n",
    "            model_training.losses.append(current_loss / plot_every)\n",
    "            model_training.learning_rates.append(lr)\n",
    "            current_loss = 0\n",
    "            current_loss_iter = 0\n",
    "            \n",
    "        if model_training.iterations % 50000 == 0: # or model_training.iterations == 10:\n",
    "            model_training.save_models()\n",
    "            acc = test_model_accuracy(encoder_rnn, test_model_single_sample)\n",
    "            model_training.accuracy.append(acc)\n",
    "    \n",
    "    # test_model_accuracy(model, n_sample=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Save path: data/models/letters_gen_1_attn_test_3\n"
     ]
    }
   ],
   "source": [
    "model_training = ModelTraining(MODEL_SAVE_PATH, [encoder_rnn, decoder_rnn])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     9  18% (   0m 0s)   6.944   |   7.02: nsu -> t's <EOS> <EOS> (✗: [29, 17, 43, 0]) (forcing)\n",
      "    18  36% (   0m 0s)   5.813   |   3.55: V. ->  (✗: [54, 0]) \n",
      "    27  54% (   0m 0s)   5.604   |   2.27: S. W. ->  (✗: [17, 52, 0]) \n",
      "    36  72% (   0m 0s)   5.290   |   3.53: J. ->  (✗: [60, 0]) \n",
      "    45  90% (   0m 0s)   5.085   |   1.69: PDF ->  (✗: [24, 26, 37, 0]) \n"
     ]
    }
   ],
   "source": [
    "train_iterations(n_iters=50, print_every=9, lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   550  53% (   0m 5s)   2.464   |   2.58: LPL -> p <EOS> <EOS> (✗: [42, 24, 42, 0]) (forcing)\n"
     ]
    }
   ],
   "source": [
    "train_iterations(n_iters=(1000-model_training.iterations), print_every=500, lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  2000  11% (  0m 12s)   1.805   |   2.25: GWB -> b b i (✗: [53, 52, 36, 0]) (forcing)\n",
      "  3000  22% (  0m 26s)   1.101   |   2.16: AZ -> a a (✗: [22, 105, 0]) \n",
      "  4000  33% (  0m 39s)   0.697   |   0.38: K- -> k (✓) (forcing)\n",
      "  5000  44% (  0m 52s)   0.507   |   0.25: DSL -> d s l (✓) \n",
      "  6000  56% (   1m 5s)   0.323   |   0.01: N. -> n (✓) \n",
      "  7000  67% (  1m 17s)   0.244   |   0.01: K. -> k (✓) \n",
      "  8000  78% (  1m 30s)   0.174   |   0.23: IOLR -> i o r r (✗: [31, 25, 42, 35, 0]) (forcing)\n",
      "  9000  89% (  1m 43s)   0.143   |   0.00: PDF -> p d f (✓) (forcing)\n",
      " 10000 100% (  1m 56s)   0.183   |   0.00: NFL -> n f l (✓) (forcing)\n"
     ]
    }
   ],
   "source": [
    "train_iterations(n_iters=9000, lr=0.001, print_every=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iterations(n_iters=90000, print_every=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_local_wrong_predictions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iterations(n_iters=200000, print_every=10000, teacher_forcing_ratio=0.5, lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print_local_wrong_predictions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_iterations(n_iters=100000, print_every=10000, teacher_forcing_ratio=0.3, lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print_local_wrong_predictions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_iterations(n_iters=100000, print_every=10000, teacher_forcing_ratio=0.5, lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print_local_wrong_predictions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_iterations(n_iters=100000, print_every=10000, teacher_forcing_ratio=0.1, lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print_local_wrong_predictions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_iterations(n_iters=200000, print_every=10000, teacher_forcing_ratio=0.1, lr=0.0005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print_local_wrong_predictions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_iterations(n_iters=300000, print_every=10000, teacher_forcing_ratio=0.1, lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print_local_wrong_predictions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_iterations(n_iters=200000, print_every=10000, teacher_forcing_ratio=0, lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print_local_wrong_predictions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_iterations(n_iters=200000, print_every=10000, teacher_forcing_ratio=0, lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print_local_wrong_predictions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_iterations(n_iters=500000, print_every=10000, teacher_forcing_ratio=0, lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print_local_wrong_predictions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_iterations(n_iters=500000, print_every=10000, teacher_forcing_ratio=0, lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print_local_wrong_predictions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_iterations(n_iters=500000, print_every=10000, teacher_forcing_ratio=0, lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print_local_wrong_predictions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_iterations(n_iters=500000, print_every=10000, teacher_forcing_ratio=0, lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print_local_wrong_predictions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input:   ['P', 'D', 'F']\n",
      "output:  ['p', 'd', 'f']\n",
      "target:    p d f\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAwoAAAFmCAYAAADNkW0pAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRIwlozqIAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f58ec1c4080>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def debug_show_attention(input_sentence, output_words, attentions):\n",
    "    # Set up figure with colorbar\n",
    "    fig = plt.figure(figsize=(15,6))\n",
    "    ax = fig.add_subplot(111)\n",
    "    #cax = ax.matshow(attentions.numpy(), cmap='bone')\n",
    "    cax = ax.matshow(attentions, cmap='bone')\n",
    "    fig.colorbar(cax)\n",
    "    # Set up axes\n",
    "    #ax.set_xticklabels([''] + input_sentence.split(' ') + ['<EOS>'], rotation=90)\n",
    "    ax.set_xticklabels([''] + input_sentence + ['<EOS>'], rotation=90)\n",
    "    ax.set_yticklabels([''] + output_words)\n",
    "\n",
    "    # Show label at every tick\n",
    "    ax.xaxis.set_major_locator(matplotlib.ticker.MultipleLocator(1))\n",
    "    ax.yaxis.set_major_locator(matplotlib.ticker.MultipleLocator(1))\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "def debug_eval_sample_show_attention():\n",
    "    #output_words, attentions = evaluate(encoder1, attn_decoder1, input_sentence)\n",
    "    output, decoded_output, decoder_attns_arr, sample = test_model_single_sample(None, return_more=True)\n",
    "    print('input: ', [words_after_common[w] for w in sample[1]])\n",
    "    print(output)\n",
    "\n",
    "    showAttention(input_sentence, output_words, attentions)\n",
    "\n",
    "    \n",
    "output, decoded_output, decoder_attns_arr, sample = test_model_single_sample(None, return_more=True)\n",
    "print('input:  ', list(sample[0]))\n",
    "print('output: ', decoded_output)\n",
    "print('target:   ', ' '.join([words_after_common[w] for w in sample[1][:-1]]))\n",
    "\n",
    "attns = np.array([arr.data[0].cpu().numpy() for arr in decoder_attns_arr])\n",
    "\n",
    "debug_show_attention(list(sample[0]), decoded_output, attns)\n",
    "\n",
    "#debug_eval_sample_show_attention()\n",
    "#tmp = [r/sum(r) for r in attns]\n",
    "#plt.matshow(tmp)\n",
    "#plt.matshow(attns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.matshow(attns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = [r/sum(r) for r in attns]\n",
    "plt.matshow(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.argmax(attns, 1)\n",
    "[attns[k,v] for k, v in enumerate(np.argmax(attns, 1))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:py3_pytorch_2]",
   "language": "python",
   "name": "conda-env-py3_pytorch_2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
