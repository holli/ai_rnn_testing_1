{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pytorch utils oh: pytorch_utils_oh_2.py\n",
      "Pytorch: 0.2.0_4\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import importlib\n",
    "from pytorch_utils_oh_2 import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pytorch utils oh: pytorch_utils_oh_2.py\n",
      "Pytorch: 0.2.0_4\n"
     ]
    }
   ],
   "source": [
    "import pytorch_utils_oh_2; importlib.reload(pytorch_utils_oh_2); from pytorch_utils_oh_2 import *;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "chars_normal, chars_normal_index = load_characters_pkl('data/en_features/chars_normal.pkl')\n",
    "common_words, common_words_index = load_common_words_10k()\n",
    "chars_with_changes = pickle.load(open('data/en_features/chars_with_changes.pkl', \"rb\"))\n",
    "chars_with_no_changes_re = re.compile(\"[^{}]\".format(''.join(chars_with_changes)))\n",
    "chars_with_single_output_dict = pickle.load(open('data/en_features/chars_with_single_output_dict.pkl', \"rb\"));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "956046"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data_org = pd.read_csv('data/en_test_2.csv', keep_default_na=False)\n",
    "len(test_data_org)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_data = test_data_org.copy()\n",
    "test_data_sentence_index = test_data.set_index('sentence_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>token_id</th>\n",
       "      <th>before</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>305292</th>\n",
       "      <td>22746</td>\n",
       "      <td>11</td>\n",
       "      <td>coach</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>321626</th>\n",
       "      <td>23944</td>\n",
       "      <td>1</td>\n",
       "      <td>direct</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        sentence_id  token_id  before\n",
       "305292        22746        11   coach\n",
       "321626        23944         1  direct"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.sample(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentences like in other data_preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def prepare_sentence_tokenized_by_rows(pd_rows):\n",
    "    global current_row\n",
    "    iter_len = len(pd_rows)\n",
    "    rows_iter = pd_rows.itertuples()\n",
    "    iteration_idx = 0\n",
    "    start = time.time()\n",
    "    \n",
    "    for sample_row in log_progress(rows_iter, every=10, size=iter_len):\n",
    "        before = sample_row.before\n",
    "        current_row = sample_row\n",
    "\n",
    "        sent_rows = test_data_sentence_index.loc[sample_row.sentence_id]\n",
    "        befores = list(sent_rows.before)\n",
    "        token_id_idx = list(sent_rows['token_id']).index(sample_row.token_id)\n",
    "        \n",
    "        befores = [simple_tokeniser(w) for w in befores]\n",
    "        befores[token_id_idx] = [SAMPLE_WORD_TOKEN]\n",
    "        befores = np.concatenate(befores)\n",
    "    \n",
    "        sentence = ' '.join(befores)\n",
    "\n",
    "        test_data.at[sample_row.Index, 'sentence'] = sentence\n",
    "        \n",
    "        iteration_idx += 1\n",
    "        if iteration_idx%(len(test_data)//10) == 0 or iteration_idx == 5000:\n",
    "            print(\"{:>7d} {:>2.2%} ({:>8})\".format(iteration_idx, iteration_idx/iter_len, time_since(start)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93abd9239a184ef1b5906de8c0ea7461"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   5000 0.52% (   0m 3s)\n",
      "  95604 10.00% (   1m 5s)\n",
      " 191208 20.00% (  2m 11s)\n",
      " 286812 30.00% (  3m 16s)\n",
      " 382416 40.00% (  4m 22s)\n",
      " 478020 50.00% (  5m 27s)\n",
      " 573624 60.00% (  6m 35s)\n",
      " 669228 70.00% (  7m 39s)\n",
      " 764832 80.00% (  8m 43s)\n",
      " 860436 90.00% (  9m 48s)\n",
      " 956040 100.00% ( 10m 53s)\n"
     ]
    }
   ],
   "source": [
    "prepare_sentence_tokenized_by_rows(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>token_id</th>\n",
       "      <th>before</th>\n",
       "      <th>sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>register</td>\n",
       "      <td>the party applied to &lt;SAMPLE&gt; this with the el...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>this</td>\n",
       "      <td>the party applied to register &lt;SAMPLE&gt; with th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>with</td>\n",
       "      <td>the party applied to register this &lt;SAMPLE&gt; th...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    sentence_id  token_id    before  \\\n",
       "30            3         4  register   \n",
       "31            3         5      this   \n",
       "32            3         6      with   \n",
       "\n",
       "                                             sentence  \n",
       "30  the party applied to <SAMPLE> this with the el...  \n",
       "31  the party applied to register <SAMPLE> with th...  \n",
       "32  the party applied to register this <SAMPLE> th...  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data[30:33]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pickle.dump(test_data, open('data/en_test_2_sentences.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification (category_8_fixes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "categories_all = ['ELECTRONIC', 'LETTERS', 'NOT_CHANGED', 'NUMBERS', 'PLAIN', 'VERBATIM']\n",
    "categories_index = dict((c, i) for i, c in enumerate(categories_all))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manual figuring out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def manual_pre_checks(before):\n",
    "    if chars_with_no_changes_re.search(before): #contains chars that were never changed\n",
    "        return before \n",
    "    if before in chars_with_single_output_dict:\n",
    "        return chars_with_single_output_dict[before]\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'epsilon'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'利'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "manual_pre_checks('yes')\n",
    "manual_pre_checks('Ε')\n",
    "manual_pre_checks('利')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class CategorizeRNN(nn.Module):\n",
    "    def __init__(self, output_size, words_input_size, chars_input_size, words_hidden_size, chars_hidden_size,\n",
    "                 words_dropout=0, chars_dropout=0, words_layers=1, chars_layers=1):\n",
    "        super(CategorizeRNN, self).__init__()\n",
    "        \n",
    "        self.words_layers = words_layers\n",
    "        self.chars_layers = chars_layers\n",
    "        self.words_hidden_size = words_hidden_size\n",
    "        self.chars_hidden_size = chars_hidden_size\n",
    "\n",
    "        self.rnn_words = nn.LSTM(words_input_size, words_hidden_size // 2, words_layers,\n",
    "                                 dropout=words_dropout, batch_first=True, bidirectional=True)\n",
    "\n",
    "        self.rnn_chars = nn.LSTM(chars_input_size, chars_hidden_size // 2, chars_layers,\n",
    "                                 dropout=chars_dropout, batch_first=True, bidirectional=True)\n",
    "        \n",
    "        self.lin_output = nn.Linear(words_hidden_size+chars_hidden_size, output_size)\n",
    "        \n",
    "    def forward(self, words_tensor, string_tensor, init_hidden = True):\n",
    "        if init_hidden:\n",
    "            hidden_words, hidden_chars = self.init_hidden()\n",
    "        \n",
    "        all_outputs_words, hidden_words = self.rnn_words(words_tensor, hidden_words)\n",
    "        output_words = all_outputs_words[:, -1]\n",
    "        \n",
    "        all_outputs_chars, hidden_chars = self.rnn_chars(string_tensor, hidden_chars)\n",
    "        output_chars = all_outputs_chars[:, -1]\n",
    "        \n",
    "        output = torch.cat((output_words, output_chars), 1)\n",
    "        \n",
    "        output = self.lin_output(output)\n",
    "        output = F.log_softmax(output)\n",
    "        \n",
    "        return output\n",
    "\n",
    "    def init_hidden(self):\n",
    "        var1_1 = Variable(torch.zeros(2 * self.words_layers, 1, self.words_hidden_size // 2))\n",
    "        var1_2 = Variable(torch.zeros(2 * self.words_layers, 1, self.words_hidden_size // 2))\n",
    "        var2_1 = Variable(torch.zeros(2 * self.chars_layers, 1, self.chars_hidden_size // 2))\n",
    "        var2_2 = Variable(torch.zeros(2 * self.chars_layers, 1, self.chars_hidden_size // 2))\n",
    "        var1_1 = var1_1.cuda(); var1_2 = var1_2.cuda()\n",
    "        var2_1 = var2_1.cuda(); var2_2 = var2_2.cuda()\n",
    "        return ((var1_1, var1_2), (var2_1, var2_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CategorizeRNN (\n",
       "  (rnn_words): LSTM(8192, 128, num_layers=2, batch_first=True, dropout=0.2, bidirectional=True)\n",
       "  (rnn_chars): LSTM(104, 192, num_layers=2, batch_first=True, dropout=0.2, bidirectional=True)\n",
       "  (lin_output): Linear (640 -> 6)\n",
       ")"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_model = CategorizeRNN(len(categories_all), \n",
    "                      words_input_size=len(common_words), chars_input_size=len(chars_normal),\n",
    "                      words_hidden_size=256, chars_hidden_size=384,\n",
    "                      words_layers=2, chars_layers=2,\n",
    "                      words_dropout=0.2, chars_dropout=0.2)\n",
    "cat_model = cat_model.cuda()\n",
    "\n",
    "cat_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cat_model.load_state_dict(torch.load('data/models/category_8_fixes/700000_CategorizeRNN'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('NOT_CHANGED', 1.0)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "('NOT_CHANGED', 1.0)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def categorize(s_bef, s_sentence):\n",
    "    model = cat_model\n",
    "    \n",
    "    # MODEL HAD A BUG, IT WAS USING ONLY CHARS INSTEAD OF SENTENCES!!\n",
    "    # MODEL HAD A BUG, IT WAS USING ONLY CHARS INSTEAD OF SENTENCES!!\n",
    "    # MODEL HAD A BUG, IT WAS USING ONLY CHARS INSTEAD OF SENTENCES!!\n",
    "    words_t = words_to_tensor(list(s_sentence), common_words_index)\n",
    "    # words_t = words_to_tensor(sentence_arr_tokenize(s_sentence), common_words_index)\n",
    "    words_t = Variable(words_t).cuda()\n",
    "    \n",
    "    string_t = string_to_tensor(s_bef, chars_normal_index)\n",
    "    string_t = Variable(string_t).cuda()\n",
    "    \n",
    "    output = model(words_t, string_t)\n",
    "    guess = category_from_output(output, categories_all)\n",
    "    confidence = torch.nn.functional.softmax(output).topk(1)[0].data[0][0]\n",
    "    return guess[0], confidence\n",
    "\n",
    "categorize('hello', ['<SAMPLE> it\\'s me'])\n",
    "categorize('hello', 'Hello welcome to <SAMPLE>'.split(' '))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_rows_category(pd_rows):\n",
    "    global current_row\n",
    "    iter_len = len(pd_rows)\n",
    "    rows_iter = pd_rows.itertuples()\n",
    "    iteration_idx = 0\n",
    "    start = time.time()\n",
    "    \n",
    "    #for sample_row in test_data[0:100].itertuples():\n",
    "    for sample_row in log_progress(rows_iter, every=10, size=iter_len):\n",
    "        before = sample_row.before\n",
    "        sentence = sample_row.sentence\n",
    "        manual_pre_check_after = manual_pre_checks(before)\n",
    "        \n",
    "        if manual_pre_check_after:\n",
    "            test_data.at[sample_row.Index, 'after'] = manual_pre_check_after\n",
    "            test_data.at[sample_row.Index, 'pred_class'] = 'MANUAL'\n",
    "            continue\n",
    "            \n",
    "        try:\n",
    "            category, category_conf = categorize(before, sentence)\n",
    "            test_data.at[sample_row.Index, 'pred_class'] = category\n",
    "            test_data.at[sample_row.Index, 'pred_c_conf'] = category_conf\n",
    "            if category == 'NOT_CHANGED':\n",
    "                test_data.at[sample_row.Index, 'after'] = before\n",
    "        except: # Exception as inst:\n",
    "            test_data.at[sample_row.Index, 'pred_class'] = 'PROBLEM'\n",
    "            continue\n",
    "\n",
    "        iteration_idx += 1\n",
    "        if ((iteration_idx % (int(iter_len*0.1)) == 0 and iteration_idx > 1000) or\n",
    "            iteration_idx == 5000):\n",
    "            print(\"{:>7d} {:>2.2%} ({:>8})\".format(iteration_idx, iteration_idx/iter_len, time_since(start)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49d4ee0e969648f8ad516ac8753a4436"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "run_rows_category(test_data[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>token_id</th>\n",
       "      <th>before</th>\n",
       "      <th>sentence</th>\n",
       "      <th>pred_class</th>\n",
       "      <th>pred_c_conf</th>\n",
       "      <th>after</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>Channel</td>\n",
       "      <td>there 's more to clear &lt;SAMPLE&gt; than ' the lar...</td>\n",
       "      <td>NOT_CHANGED</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Channel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>Than</td>\n",
       "      <td>there 's more to clear channel &lt;SAMPLE&gt; ' the ...</td>\n",
       "      <td>NOT_CHANGED</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Than</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>'</td>\n",
       "      <td>there 's more to clear channel than &lt;SAMPLE&gt; t...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    sentence_id  token_id   before  \\\n",
       "8             1         4  Channel   \n",
       "9             1         5     Than   \n",
       "10            1         6        '   \n",
       "\n",
       "                                             sentence   pred_class  \\\n",
       "8   there 's more to clear <SAMPLE> than ' the lar...  NOT_CHANGED   \n",
       "9   there 's more to clear channel <SAMPLE> ' the ...  NOT_CHANGED   \n",
       "10  there 's more to clear channel than <SAMPLE> t...          NaN   \n",
       "\n",
       "    pred_c_conf    after  \n",
       "8           1.0  Channel  \n",
       "9           1.0     Than  \n",
       "10          NaN      NaN  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data[8:(8+3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd8c79ccb6134367a1328aec12759c93"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   5000 0.52% (  0m 37s)\n",
      "  95604 10.00% ( 11m 38s)\n",
      " 191208 20.00% ( 23m 13s)\n",
      " 286812 30.00% ( 35m 25s)\n",
      " 382416 40.00% ( 47m 25s)\n",
      " 478020 50.00% (  59m 8s)\n",
      " 573624 60.00% (  71m 2s)\n",
      " 669228 70.00% ( 82m 59s)\n",
      " 764832 80.00% ( 94m 48s)\n",
      " 860436 90.00% (106m 37s)\n"
     ]
    }
   ],
   "source": [
    "run_rows_category(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>token_id</th>\n",
       "      <th>before</th>\n",
       "      <th>sentence</th>\n",
       "      <th>pred_class</th>\n",
       "      <th>pred_c_conf</th>\n",
       "      <th>after</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>190558</th>\n",
       "      <td>14352</td>\n",
       "      <td>3</td>\n",
       "      <td>,</td>\n",
       "      <td>royal tunbridge wells &lt;SAMPLE&gt; kent : panini c...</td>\n",
       "      <td>NOT_CHANGED</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>772292</th>\n",
       "      <td>56682</td>\n",
       "      <td>7</td>\n",
       "      <td>.</td>\n",
       "      <td>\" thjalfarar ia 1951 - 2007 \" &lt;SAMPLE&gt;</td>\n",
       "      <td>NOT_CHANGED</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>931507</th>\n",
       "      <td>68225</td>\n",
       "      <td>15</td>\n",
       "      <td>including</td>\n",
       "      <td>this allowed efilecabinet to expand from servi...</td>\n",
       "      <td>NOT_CHANGED</td>\n",
       "      <td>0.999999</td>\n",
       "      <td>including</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>379102</th>\n",
       "      <td>28158</td>\n",
       "      <td>26</td>\n",
       "      <td>.</td>\n",
       "      <td>the museum of polo and hall of fame is a 501 (...</td>\n",
       "      <td>NOT_CHANGED</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>262339</th>\n",
       "      <td>19606</td>\n",
       "      <td>5</td>\n",
       "      <td>figs</td>\n",
       "      <td>it is usually eaten with &lt;SAMPLE&gt; during the s...</td>\n",
       "      <td>NOT_CHANGED</td>\n",
       "      <td>0.999925</td>\n",
       "      <td>figs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        sentence_id  token_id     before  \\\n",
       "190558        14352         3          ,   \n",
       "772292        56682         7          .   \n",
       "931507        68225        15  including   \n",
       "379102        28158        26          .   \n",
       "262339        19606         5       figs   \n",
       "\n",
       "                                                 sentence   pred_class  \\\n",
       "190558  royal tunbridge wells <SAMPLE> kent : panini c...  NOT_CHANGED   \n",
       "772292             \" thjalfarar ia 1951 - 2007 \" <SAMPLE>  NOT_CHANGED   \n",
       "931507  this allowed efilecabinet to expand from servi...  NOT_CHANGED   \n",
       "379102  the museum of polo and hall of fame is a 501 (...  NOT_CHANGED   \n",
       "262339  it is usually eaten with <SAMPLE> during the s...  NOT_CHANGED   \n",
       "\n",
       "        pred_c_conf      after  \n",
       "190558     1.000000          ,  \n",
       "772292     1.000000          .  \n",
       "931507     0.999999  including  \n",
       "379102     1.000000          .  \n",
       "262339     0.999925       figs  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pickle.dump(test_data, open('data/en_test_2_3_categorized.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Whole RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MAX_ATTENTION_LENGTH = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wv_vecs, wv_words, wv_idx = load_glove('/home/ohu/koodi/data/glove_wordvec/glove.6B.50d.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<EOS>', '<SOS>', '<UNK>', '<0000>', '<SAMPLE>', 'two', 'twenty']"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "1351"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_after_common = pickle.load(open(\"data/en_features/words_after_ext.pkl\", 'rb'))\n",
    "words_after_index = dict((c, i) for i, c in enumerate(words_after_common))\n",
    "words_after_common[0:7]\n",
    "len(words_after_common)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 1351])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sos_tensor = torch.zeros(1, 1, len(words_after_index))\n",
    "sos_tensor[0, 0, words_after_index[SOS_TOKEN]] = 1\n",
    "sos_tensor.size()\n",
    "#del(onehot_sos)\n",
    "\n",
    "# sos_tensor = torch.LongTensor([words_after_index[SOS_TOKEN]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EncoderRNN (\n",
       "  (rnn_words): LSTM(50, 128, batch_first=True, bidirectional=True)\n",
       "  (rnn_chars): LSTM(104, 192, batch_first=True, bidirectional=True)\n",
       ")"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, words_input_size, chars_input_size, words_hidden_size, chars_hidden_size,\n",
    "                 words_layers=1, chars_layers=1):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        \n",
    "        self.words_layers = words_layers\n",
    "        self.chars_layers = chars_layers\n",
    "        self.words_hidden_size = words_hidden_size\n",
    "        self.chars_hidden_size = chars_hidden_size\n",
    "        self.hidden_size = words_hidden_size + chars_hidden_size\n",
    "\n",
    "        self.rnn_words = nn.LSTM(words_input_size, words_hidden_size // 2, words_layers,\n",
    "                                 batch_first=True, bidirectional=True)\n",
    "\n",
    "        self.rnn_chars = nn.LSTM(chars_input_size, chars_hidden_size // 2, chars_layers,\n",
    "                                batch_first=True, bidirectional=True)\n",
    "        \n",
    "    def forward(self, word_vectors, string_tensor, hidden = None, init_hidden = True):\n",
    "        if init_hidden:\n",
    "            hidden_words, hidden_chars = self.init_hidden()\n",
    "        \n",
    "        all_outputs_words, hidden_words = self.rnn_words(word_vectors, hidden_words)\n",
    "        output_words = all_outputs_words[:, -1]\n",
    "        \n",
    "        all_outputs_chars, hidden_chars = self.rnn_chars(string_tensor, hidden_chars)\n",
    "        output_chars = all_outputs_chars[:, -1]\n",
    "        \n",
    "        hidden_states_cat = Variable(torch.zeros(MAX_ATTENTION_LENGTH, self.hidden_size)).cuda()\n",
    "        for ei in range(min(MAX_ATTENTION_LENGTH, len(string_tensor[0]))):\n",
    "            hidden_states_cat[ei] = torch.cat((output_words, all_outputs_chars[0, ei].view(1,-1)), 1)\n",
    "                \n",
    "        output = torch.cat((output_words[0], output_chars[0]), 0)\n",
    "\n",
    "        #output = torch.cat((output_words, output_chars), 1)\n",
    "        \n",
    "        #return output, all_outputs_chars\n",
    "        return output, hidden_states_cat\n",
    "\n",
    "    def init_hidden(self):\n",
    "        var1_1 = Variable(torch.zeros(2 * self.words_layers, 1, self.words_hidden_size // 2))\n",
    "        var1_2 = Variable(torch.zeros(2 * self.words_layers, 1, self.words_hidden_size // 2))\n",
    "        var2_1 = Variable(torch.zeros(2 * self.chars_layers, 1, self.chars_hidden_size // 2))\n",
    "        var2_2 = Variable(torch.zeros(2 * self.chars_layers, 1, self.chars_hidden_size // 2))\n",
    "        \n",
    "        var1_1 = var1_1.cuda(); var1_2 = var1_2.cuda()\n",
    "        var2_1 = var2_1.cuda(); var2_2 = var2_2.cuda()\n",
    "        return ((var1_1, var1_2), (var2_1, var2_2))\n",
    "    \n",
    "    \n",
    "encoder_rnn = EncoderRNN(words_input_size=wv_vecs.shape[-1], chars_input_size=len(chars_normal),\n",
    "                         words_hidden_size=256, chars_hidden_size=384,\n",
    "                         words_layers=1, chars_layers=1).cuda()\n",
    "encoder_rnn\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecoderRNN (\n",
       "  (rnn): GRU(640, 640, batch_first=True)\n",
       "  (lin_out): Linear (640 -> 1351)\n",
       "  (emb_lin): Linear (1351 -> 640)\n",
       "  (attn): Linear (1280 -> 30)\n",
       "  (attn_combine): Linear (1280 -> 640)\n",
       "  (dropout): Dropout (p = 0.1)\n",
       ")"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class DecoderRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, n_layers=1, dropout_p=0.1, max_length=MAX_ATTENTION_LENGTH):\n",
    "        super(DecoderRNN, self).__init__()\n",
    "        self.n_layers = n_layers\n",
    "        self.hidden_size = hidden_size\n",
    "        \n",
    "        #self.rnn = nn.GRU(input_size, hidden_size, n_layers,\n",
    "        self.rnn = nn.GRU(hidden_size, hidden_size, n_layers,\n",
    "                                 batch_first=True, bidirectional=False)\n",
    "        \n",
    "        self.lin_out = nn.Linear(hidden_size, input_size)\n",
    "        #self.softmax = nn.LogSoftmax()\n",
    "        \n",
    "        #self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        self.emb_lin = nn.Linear(input_size, hidden_size)\n",
    "        self.max_length = max_length\n",
    "        self.attn = nn.Linear(hidden_size*2, self.max_length)\n",
    "        self.attn_combine = nn.Linear(self.hidden_size * 2, self.hidden_size)\n",
    "        self.dropout = nn.Dropout(dropout_p)\n",
    "        \n",
    "    #def forward(self, char, hidden):\n",
    "    def forward(self, last_input, hidden, encoder_outputs):\n",
    "        #embedded = self.embedding(last_input).view(1, 1, -1)\n",
    "        embedded = self.emb_lin(last_input).view(1, 1, -1)\n",
    "        embedded = self.dropout(embedded)\n",
    "        #IPython.core.debugger.Pdb().set_trace()\n",
    "        #attn_weights = F.softmax(self.attn(torch.cat((char[0], hidden[0]), 1)))\n",
    "        attn_weights = F.softmax(self.attn(torch.cat((embedded[0], hidden[0]), 1)))\n",
    "        attn_applied = torch.bmm(attn_weights.unsqueeze(0), encoder_outputs.unsqueeze(0))\n",
    "        \n",
    "        output = torch.cat((embedded[0], attn_applied[0]), 1)\n",
    "        output = self.attn_combine(output).unsqueeze(0)\n",
    "\n",
    "        \n",
    "        output = F.relu(output)\n",
    "        output, hidden = self.rnn(output, hidden)\n",
    "\n",
    "        output = F.log_softmax(self.lin_out(output[0]))\n",
    "        return output, hidden, attn_weights\n",
    "    \n",
    "    def init_rest_hidden(self, input_var):\n",
    "        if self.n_layers > 1:\n",
    "            hid_var = Variable(torch.zeros(self.n_layers - 1, 1, self.hidden_size)).cuda()\n",
    "            res = torch.cat((input_var, hid_var), 0)\n",
    "            return res\n",
    "        else:\n",
    "            return input_var\n",
    "        \n",
    "\n",
    "decoder_rnn = DecoderRNN(input_size=len(words_after_common), hidden_size=640, n_layers=1)\n",
    "decoder_rnn = decoder_rnn.cuda()\n",
    "decoder_rnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def whole_encoder_decoder(s_bef, sentence):\n",
    "    decoder_rnn.eval()\n",
    "    encoder_rnn.eval()\n",
    "    \n",
    "    words_t = Variable(words_to_word_vectors_tensor(list(sentence), wv_vecs, wv_idx)).cuda()\n",
    "    # NOTE THIS IS A BUG, DO NOT PASS LIST(S_SENTENCE) BY DEFAULT\n",
    "        # NOTE THIS IS A BUG, DO NOT PASS LIST(S_SENTENCE) BY DEFAULT\n",
    "     # NOTE THIS IS A BUG, DO NOT PASS LIST(S_SENTENCE) BY DEFAULT\n",
    "       # NOTE THIS IS A BUG, DO NOT PASS LIST(S_SENTENCE) BY DEFAULT\n",
    "    # NOTE THIS IS A BUG, DO NOT PASS LIST(S_SENTENCE) BY DEFAULT\n",
    "        \n",
    "    \n",
    "    string_t = string_to_tensor(s_bef, chars_normal_index)\n",
    "    string_t = Variable(string_t).cuda()\n",
    "    \n",
    "    encoder_output, encoder_outputs = encoder_rnn(words_t, string_t)\n",
    "    \n",
    "    decoder_hidden = decoder_rnn.init_rest_hidden(encoder_outputs[0].view(1,1,-1))\n",
    "    decoder_input = Variable(sos_tensor).cuda()\n",
    "    \n",
    "    decoded_output = []\n",
    "    decoded_output_prob = []\n",
    "    max_length = 20\n",
    "    \n",
    "    for _ in range(max_length):\n",
    "        decoder_output, decoder_hidden, decoder_attns = decoder_rnn(decoder_input, decoder_hidden, encoder_outputs)\n",
    "\n",
    "        topv, topi = decoder_output.data.topk(1)\n",
    "        word_index = topi[0][0]\n",
    "        word = words_after_common[word_index] # Use own prediction as next input\n",
    "        decoded_output_prob.append(topv[0][0])\n",
    "                \n",
    "        if word == EOS_TOKEN:\n",
    "            break\n",
    "\n",
    "        decoded_output.append(word)\n",
    "        \n",
    "        \n",
    "        decoder_input = torch.zeros(1, 1, len(words_after_index))\n",
    "        decoder_input[0, 0, word_index] = 1\n",
    "        decoder_input = Variable(decoder_input).cuda()\n",
    "    \n",
    "    output = ' '.join(decoded_output)\n",
    "    \n",
    "    return output, (sum(decoded_output_prob), np.average(decoded_output_prob))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('the twelfth of october twenty ten',\n",
       " (-2.7835006713867188, -0.39764295305524555))"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "whole_encoder_decoder('12.12.2017', 'and here is our <SAMPLE> sentence')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running the stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#state_dict_path = 'data/models/whole_gen_11_fixes/500000_'\n",
    "state_dict_path = 'data/models/whole_gen_11_fixes/2750000_'\n",
    "decoder_rnn.load_state_dict(torch.load(state_dict_path + 'DecoderRNN'))\n",
    "encoder_rnn.load_state_dict(torch.load(state_dict_path + 'EncoderRNN'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_rows_on_gen_whole_rnn(pd_rows):\n",
    "    global current_row\n",
    "    iter_len = len(pd_rows)\n",
    "    rows_iter = pd_rows.itertuples()\n",
    "    iteration_idx = 0\n",
    "    start = time.time()\n",
    "    \n",
    "    #for sample_row in test_data[0:100].itertuples():\n",
    "    for sample_row in log_progress(rows_iter, every=100, size=iter_len):\n",
    "        current_row = sample_row\n",
    "        \n",
    "        result = whole_encoder_decoder(sample_row.before, sample_row.sentence)\n",
    "\n",
    "        iteration_idx += 1\n",
    "        if iteration_idx%10000 == 0:\n",
    "            print(\"{:>7d} {:>2.2%} ({:>8})\".format(iteration_idx, iteration_idx/iter_len, time_since(start)))\n",
    "\n",
    "        test_data.at[sample_row.Index, 'after'] = result[0]\n",
    "        test_data.at[sample_row.Index, 'after_conf_sum'] = result[1][0]\n",
    "        test_data.at[sample_row.Index, 'after_conf_avg'] = result[1][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gen_data = test_data[~test_data['pred_class'].isin(['MANUAL', 'NOT_CHANGED'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>token_id</th>\n",
       "      <th>before</th>\n",
       "      <th>sentence</th>\n",
       "      <th>pred_class</th>\n",
       "      <th>pred_c_conf</th>\n",
       "      <th>after</th>\n",
       "      <th>after_conf_sum</th>\n",
       "      <th>after_conf_avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2016-03-31</td>\n",
       "      <td>last modified &lt;SAMPLE&gt; .</td>\n",
       "      <td>NUMBERS</td>\n",
       "      <td>1.0</td>\n",
       "      <td>the thirty first of march twenty sixteen</td>\n",
       "      <td>-0.403225</td>\n",
       "      <td>-0.050403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>April 2017</td>\n",
       "      <td>the party applied to register this with the el...</td>\n",
       "      <td>NUMBERS</td>\n",
       "      <td>1.0</td>\n",
       "      <td>april twenty fourteen</td>\n",
       "      <td>-0.004974</td>\n",
       "      <td>-0.001244</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    sentence_id  token_id      before  \\\n",
       "2             0         2  2016-03-31   \n",
       "37            3        11  April 2017   \n",
       "\n",
       "                                             sentence pred_class  pred_c_conf  \\\n",
       "2                            last modified <SAMPLE> .    NUMBERS          1.0   \n",
       "37  the party applied to register this with the el...    NUMBERS          1.0   \n",
       "\n",
       "                                       after  after_conf_sum  after_conf_avg  \n",
       "2   the thirty first of march twenty sixteen       -0.403225       -0.050403  \n",
       "37                     april twenty fourteen       -0.004974       -0.001244  "
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen_data[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3eebe5b37c024c58bf79394c26c90762"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  10000 11.21% (  1m 26s)\n",
      "  20000 22.41% (  2m 47s)\n",
      "  30000 33.62% (   4m 6s)\n",
      "  40000 44.82% (  5m 24s)\n",
      "  50000 56.03% (  6m 42s)\n",
      "  60000 67.24% (   8m 0s)\n",
      "  70000 78.44% (  9m 18s)\n",
      "  80000 89.65% ( 10m 36s)\n"
     ]
    }
   ],
   "source": [
    "run_rows_on_gen_whole_rnn(gen_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>token_id</th>\n",
       "      <th>before</th>\n",
       "      <th>sentence</th>\n",
       "      <th>pred_class</th>\n",
       "      <th>pred_c_conf</th>\n",
       "      <th>after</th>\n",
       "      <th>after_conf_sum</th>\n",
       "      <th>after_conf_avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2016-03-31</td>\n",
       "      <td>last modified &lt;SAMPLE&gt; .</td>\n",
       "      <td>NUMBERS</td>\n",
       "      <td>1.0</td>\n",
       "      <td>the thirty first of march twenty sixteen</td>\n",
       "      <td>-0.419025</td>\n",
       "      <td>-0.052378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>April 2017</td>\n",
       "      <td>the party applied to register this with the el...</td>\n",
       "      <td>NUMBERS</td>\n",
       "      <td>1.0</td>\n",
       "      <td>april twenty fourteen</td>\n",
       "      <td>-0.008377</td>\n",
       "      <td>-0.002094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>3</td>\n",
       "      <td>17</td>\n",
       "      <td>May 2017</td>\n",
       "      <td>the party applied to register this with the el...</td>\n",
       "      <td>NUMBERS</td>\n",
       "      <td>1.0</td>\n",
       "      <td>may twenty seventeen</td>\n",
       "      <td>-0.000137</td>\n",
       "      <td>-0.000034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>21 February 2017</td>\n",
       "      <td>&lt;SAMPLE&gt; .</td>\n",
       "      <td>NUMBERS</td>\n",
       "      <td>1.0</td>\n",
       "      <td>the twenty first of february twenty eleven</td>\n",
       "      <td>-0.573418</td>\n",
       "      <td>-0.071677</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    sentence_id  token_id            before  \\\n",
       "2             0         2        2016-03-31   \n",
       "37            3        11        April 2017   \n",
       "43            3        17          May 2017   \n",
       "45            4         0  21 February 2017   \n",
       "\n",
       "                                             sentence pred_class  pred_c_conf  \\\n",
       "2                            last modified <SAMPLE> .    NUMBERS          1.0   \n",
       "37  the party applied to register this with the el...    NUMBERS          1.0   \n",
       "43  the party applied to register this with the el...    NUMBERS          1.0   \n",
       "45                                         <SAMPLE> .    NUMBERS          1.0   \n",
       "\n",
       "                                         after  after_conf_sum  after_conf_avg  \n",
       "2     the thirty first of march twenty sixteen       -0.419025       -0.052378  \n",
       "37                       april twenty fourteen       -0.008377       -0.002094  \n",
       "43                        may twenty seventeen       -0.000137       -0.000034  \n",
       "45  the twenty first of february twenty eleven       -0.573418       -0.071677  "
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data[~test_data['pred_class'].isin(['MANUAL', 'NOT_CHANGED'])][0:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>token_id</th>\n",
       "      <th>before</th>\n",
       "      <th>sentence</th>\n",
       "      <th>pred_class</th>\n",
       "      <th>pred_c_conf</th>\n",
       "      <th>after</th>\n",
       "      <th>after_conf_sum</th>\n",
       "      <th>after_conf_avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>357</th>\n",
       "      <td>33</td>\n",
       "      <td>5</td>\n",
       "      <td>2016</td>\n",
       "      <td>college board , class of &lt;SAMPLE&gt; sat particip...</td>\n",
       "      <td>NUMBERS</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>two thousand</td>\n",
       "      <td>-0.802635</td>\n",
       "      <td>-0.267545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>358</th>\n",
       "      <td>33</td>\n",
       "      <td>6</td>\n",
       "      <td>SAT</td>\n",
       "      <td>college board , class of 2016 &lt;SAMPLE&gt; partici...</td>\n",
       "      <td>PLAIN</td>\n",
       "      <td>0.984779</td>\n",
       "      <td>saturday</td>\n",
       "      <td>-0.630402</td>\n",
       "      <td>-0.315201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>364</th>\n",
       "      <td>33</td>\n",
       "      <td>12</td>\n",
       "      <td>2017</td>\n",
       "      <td>college board , class of 2016 sat participatio...</td>\n",
       "      <td>NUMBERS</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>twenty thousand</td>\n",
       "      <td>-1.052792</td>\n",
       "      <td>-0.350931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>525</th>\n",
       "      <td>48</td>\n",
       "      <td>6</td>\n",
       "      <td>2016</td>\n",
       "      <td>\" greenwood elementary school fast facts &lt;SAMP...</td>\n",
       "      <td>NUMBERS</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>twenty thousand</td>\n",
       "      <td>-0.769245</td>\n",
       "      <td>-0.256415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>958</th>\n",
       "      <td>82</td>\n",
       "      <td>13</td>\n",
       "      <td>6 years</td>\n",
       "      <td>eighteen pupils were killed , of whom sixteen ...</td>\n",
       "      <td>NUMBERS</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>six thousand e a e</td>\n",
       "      <td>-3.654732</td>\n",
       "      <td>-0.609122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1074</th>\n",
       "      <td>93</td>\n",
       "      <td>6</td>\n",
       "      <td>021798</td>\n",
       "      <td>patent and exclusivity for : n &lt;SAMPLE&gt; .</td>\n",
       "      <td>NUMBERS</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>o seven seven seven seven eight eight</td>\n",
       "      <td>-4.490807</td>\n",
       "      <td>-0.561351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1092</th>\n",
       "      <td>95</td>\n",
       "      <td>4</td>\n",
       "      <td>2020</td>\n",
       "      <td>the projected deficit in &lt;SAMPLE&gt; / 21 is £415...</td>\n",
       "      <td>NUMBERS</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>two thousand two</td>\n",
       "      <td>-1.264744</td>\n",
       "      <td>-0.316186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1096</th>\n",
       "      <td>95</td>\n",
       "      <td>8</td>\n",
       "      <td>£415 million</td>\n",
       "      <td>the projected deficit in 2020 / 21 is &lt;SAMPLE&gt; .</td>\n",
       "      <td>NUMBERS</td>\n",
       "      <td>0.999975</td>\n",
       "      <td>four hundred hundred million pounds</td>\n",
       "      <td>-2.201344</td>\n",
       "      <td>-0.366891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1312</th>\n",
       "      <td>116</td>\n",
       "      <td>7</td>\n",
       "      <td>2016</td>\n",
       "      <td>\" miles franklin literary award , the &lt;SAMPLE&gt;...</td>\n",
       "      <td>NUMBERS</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>twenty thousand</td>\n",
       "      <td>-0.786472</td>\n",
       "      <td>-0.262157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1573</th>\n",
       "      <td>137</td>\n",
       "      <td>7</td>\n",
       "      <td>28 years</td>\n",
       "      <td>the transfer of the concession took nearly &lt;SA...</td>\n",
       "      <td>NUMBERS</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>two two thousand s s</td>\n",
       "      <td>-2.829502</td>\n",
       "      <td>-0.471584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1663</th>\n",
       "      <td>145</td>\n",
       "      <td>3</td>\n",
       "      <td>CAPSULE</td>\n",
       "      <td>\" the mad &lt;SAMPLE&gt; markets \" .</td>\n",
       "      <td>LETTERS</td>\n",
       "      <td>0.824684</td>\n",
       "      <td>c a s s l l l</td>\n",
       "      <td>-2.938728</td>\n",
       "      <td>-0.367341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1664</th>\n",
       "      <td>145</td>\n",
       "      <td>4</td>\n",
       "      <td>MARKETS</td>\n",
       "      <td>\" the mad capsule &lt;SAMPLE&gt; \" .</td>\n",
       "      <td>LETTERS</td>\n",
       "      <td>0.638339</td>\n",
       "      <td>m a r r a t t</td>\n",
       "      <td>-5.532867</td>\n",
       "      <td>-0.691608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1688</th>\n",
       "      <td>146</td>\n",
       "      <td>21</td>\n",
       "      <td>2016</td>\n",
       "      <td>\" petra castellana ( castellane — alpes de hau...</td>\n",
       "      <td>NUMBERS</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>twenty thousand</td>\n",
       "      <td>-0.764271</td>\n",
       "      <td>-0.254757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1870</th>\n",
       "      <td>162</td>\n",
       "      <td>5</td>\n",
       "      <td>SPACEWAY</td>\n",
       "      <td>it is based upon the &lt;SAMPLE&gt; k ₐ - band commu...</td>\n",
       "      <td>LETTERS</td>\n",
       "      <td>0.729722</td>\n",
       "      <td>s a c w a a a y</td>\n",
       "      <td>-5.977821</td>\n",
       "      <td>-0.664202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013</th>\n",
       "      <td>173</td>\n",
       "      <td>1</td>\n",
       "      <td>2016</td>\n",
       "      <td>introvigne &lt;SAMPLE&gt; , p . 277 .</td>\n",
       "      <td>NUMBERS</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>twenty thousand</td>\n",
       "      <td>-0.730412</td>\n",
       "      <td>-0.243471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2066</th>\n",
       "      <td>176</td>\n",
       "      <td>20</td>\n",
       "      <td>2017</td>\n",
       "      <td>it was released on may 19 , 2017 , and serves ...</td>\n",
       "      <td>NUMBERS</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>twenty seventeen</td>\n",
       "      <td>-0.634109</td>\n",
       "      <td>-0.211370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2096</th>\n",
       "      <td>178</td>\n",
       "      <td>16</td>\n",
       "      <td>long-term</td>\n",
       "      <td>armoring may restrict beach / ocean access , e...</td>\n",
       "      <td>LETTERS</td>\n",
       "      <td>0.640466</td>\n",
       "      <td>l r t t t t t t</td>\n",
       "      <td>-3.123688</td>\n",
       "      <td>-0.347076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2214</th>\n",
       "      <td>188</td>\n",
       "      <td>11</td>\n",
       "      <td>17.4 feet</td>\n",
       "      <td>in some areas of the downtown core , the depth...</td>\n",
       "      <td>NUMBERS</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>fourteen seven seven s</td>\n",
       "      <td>-4.460953</td>\n",
       "      <td>-0.892191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2331</th>\n",
       "      <td>197</td>\n",
       "      <td>11</td>\n",
       "      <td>IQTREE</td>\n",
       "      <td>this can be accomplished with several differen...</td>\n",
       "      <td>LETTERS</td>\n",
       "      <td>0.959851</td>\n",
       "      <td>i r e e e</td>\n",
       "      <td>-1.526367</td>\n",
       "      <td>-0.254395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2510</th>\n",
       "      <td>211</td>\n",
       "      <td>5</td>\n",
       "      <td>2017</td>\n",
       "      <td>29 : 1 ( winter &lt;SAMPLE&gt; ) .</td>\n",
       "      <td>NUMBERS</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>twenty thousand</td>\n",
       "      <td>-1.223579</td>\n",
       "      <td>-0.407860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2590</th>\n",
       "      <td>217</td>\n",
       "      <td>12</td>\n",
       "      <td>10</td>\n",
       "      <td>the bruins rallied , however , to win in an up...</td>\n",
       "      <td>NUMBERS</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>ten</td>\n",
       "      <td>-0.493256</td>\n",
       "      <td>-0.246628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2747</th>\n",
       "      <td>230</td>\n",
       "      <td>3</td>\n",
       "      <td>7,000 acres</td>\n",
       "      <td>the commune contains &lt;SAMPLE&gt; ( 2 , 800 hectar...</td>\n",
       "      <td>NUMBERS</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>seven</td>\n",
       "      <td>-1.237671</td>\n",
       "      <td>-0.618835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2749</th>\n",
       "      <td>230</td>\n",
       "      <td>5</td>\n",
       "      <td>2,800 hectares</td>\n",
       "      <td>the commune contains 7 , 000 acres ( &lt;SAMPLE&gt; ...</td>\n",
       "      <td>NUMBERS</td>\n",
       "      <td>0.999996</td>\n",
       "      <td>twenty</td>\n",
       "      <td>-0.789734</td>\n",
       "      <td>-0.394867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2842</th>\n",
       "      <td>237</td>\n",
       "      <td>2</td>\n",
       "      <td>Jaffé</td>\n",
       "      <td>j . &lt;SAMPLE&gt; , regesta pontificum romanorum to...</td>\n",
       "      <td>PLAIN</td>\n",
       "      <td>0.999721</td>\n",
       "      <td>j a f f f e</td>\n",
       "      <td>-2.679064</td>\n",
       "      <td>-0.382723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3020</th>\n",
       "      <td>253</td>\n",
       "      <td>5</td>\n",
       "      <td>man-made</td>\n",
       "      <td>brown 's falls reservoir is a &lt;SAMPLE&gt; lake lo...</td>\n",
       "      <td>ELECTRONIC</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>m a a a m e e</td>\n",
       "      <td>-3.934570</td>\n",
       "      <td>-0.491821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3034</th>\n",
       "      <td>254</td>\n",
       "      <td>4</td>\n",
       "      <td>90,000 tons</td>\n",
       "      <td>\" delhi metro prevents &lt;SAMPLE&gt; of co₂ \" .</td>\n",
       "      <td>NUMBERS</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>ninety trillion thousand</td>\n",
       "      <td>-1.304703</td>\n",
       "      <td>-0.326176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3175</th>\n",
       "      <td>264</td>\n",
       "      <td>4</td>\n",
       "      <td>co-founder</td>\n",
       "      <td>he is also the &lt;SAMPLE&gt; of the open roof festi...</td>\n",
       "      <td>ELECTRONIC</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>the</td>\n",
       "      <td>-0.401718</td>\n",
       "      <td>-0.200859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3387</th>\n",
       "      <td>282</td>\n",
       "      <td>5</td>\n",
       "      <td>$210,000</td>\n",
       "      <td>the painting was sold for &lt;SAMPLE&gt; ( us$610 , ...</td>\n",
       "      <td>NUMBERS</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>one hundred ten thousand dollars</td>\n",
       "      <td>-2.105618</td>\n",
       "      <td>-0.350936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3389</th>\n",
       "      <td>282</td>\n",
       "      <td>7</td>\n",
       "      <td>US$610,408</td>\n",
       "      <td>the painting was sold for $210 , 000 ( &lt;SAMPLE...</td>\n",
       "      <td>NUMBERS</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>four hundred six thousand four hundred eight</td>\n",
       "      <td>-7.526974</td>\n",
       "      <td>-0.940872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3391</th>\n",
       "      <td>282</td>\n",
       "      <td>9</td>\n",
       "      <td>2016 dollars</td>\n",
       "      <td>the painting was sold for $210 , 000 ( us$610 ...</td>\n",
       "      <td>NUMBERS</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>two thousand sixteen sixteen dollars w l l</td>\n",
       "      <td>-5.257607</td>\n",
       "      <td>-0.584179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>951379</th>\n",
       "      <td>69655</td>\n",
       "      <td>7</td>\n",
       "      <td>8 million m²</td>\n",
       "      <td>in 2016 in moscow , built about &lt;SAMPLE&gt; of re...</td>\n",
       "      <td>NUMBERS</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>eight million seven</td>\n",
       "      <td>-2.184418</td>\n",
       "      <td>-0.546104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>951385</th>\n",
       "      <td>69655</td>\n",
       "      <td>13</td>\n",
       "      <td>3.3 million m²</td>\n",
       "      <td>in 2016 in moscow , built about 8 million m² o...</td>\n",
       "      <td>NUMBERS</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>three point three three million miles</td>\n",
       "      <td>-2.690887</td>\n",
       "      <td>-0.384412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>951437</th>\n",
       "      <td>69659</td>\n",
       "      <td>13</td>\n",
       "      <td>1980</td>\n",
       "      <td>she was an adjunct music instructor at de anza...</td>\n",
       "      <td>NUMBERS</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>nineteen eighty</td>\n",
       "      <td>-0.967319</td>\n",
       "      <td>-0.322440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>951449</th>\n",
       "      <td>69659</td>\n",
       "      <td>25</td>\n",
       "      <td>1981</td>\n",
       "      <td>she was an adjunct music instructor at de anza...</td>\n",
       "      <td>NUMBERS</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>one thousand one hundred eighty one</td>\n",
       "      <td>-2.147610</td>\n",
       "      <td>-0.306801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>951468</th>\n",
       "      <td>69661</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>on 10 july &lt;SAMPLE&gt; 17 , , de guzman joined ei...</td>\n",
       "      <td>NUMBERS</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>twenty</td>\n",
       "      <td>-0.580856</td>\n",
       "      <td>-0.290428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>951945</th>\n",
       "      <td>69697</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>23 december 2015 - the &lt;SAMPLE&gt; - lane expansi...</td>\n",
       "      <td>NUMBERS</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>ten</td>\n",
       "      <td>-0.616699</td>\n",
       "      <td>-0.308350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>952168</th>\n",
       "      <td>69714</td>\n",
       "      <td>5</td>\n",
       "      <td>Historywc.rootsweb.com</td>\n",
       "      <td>georgia info pickens county courthouse &lt;SAMPLE...</td>\n",
       "      <td>ELECTRONIC</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>h o o b o o o o o o o o o o o</td>\n",
       "      <td>-16.522930</td>\n",
       "      <td>-1.032683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>952293</th>\n",
       "      <td>69723</td>\n",
       "      <td>13</td>\n",
       "      <td>09:37 EDT</td>\n",
       "      <td>the hijackers crashed the aircraft into the we...</td>\n",
       "      <td>NUMBERS</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>zero thirty seven e e</td>\n",
       "      <td>-3.439220</td>\n",
       "      <td>-0.573203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>952351</th>\n",
       "      <td>69727</td>\n",
       "      <td>11</td>\n",
       "      <td>21 years</td>\n",
       "      <td>making their 15th straight trip to the postsea...</td>\n",
       "      <td>NUMBERS</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>two two thousand o</td>\n",
       "      <td>-3.541504</td>\n",
       "      <td>-0.708301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>952475</th>\n",
       "      <td>69737</td>\n",
       "      <td>3</td>\n",
       "      <td>::</td>\n",
       "      <td>\" white card &lt;SAMPLE&gt; safework sa \" .</td>\n",
       "      <td>PLAIN</td>\n",
       "      <td>0.873395</td>\n",
       "      <td>point face</td>\n",
       "      <td>-1.191162</td>\n",
       "      <td>-0.397054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>952679</th>\n",
       "      <td>69751</td>\n",
       "      <td>1</td>\n",
       "      <td>NELSON'S</td>\n",
       "      <td>\" &lt;SAMPLE&gt; nightmares \" , sunday times , 15 oc...</td>\n",
       "      <td>LETTERS</td>\n",
       "      <td>0.574411</td>\n",
       "      <td>n l l e e n n</td>\n",
       "      <td>-4.884834</td>\n",
       "      <td>-0.610604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>952680</th>\n",
       "      <td>69751</td>\n",
       "      <td>2</td>\n",
       "      <td>NIGHTMARES</td>\n",
       "      <td>\" nelson' s &lt;SAMPLE&gt; \" , sunday times , 15 oct...</td>\n",
       "      <td>LETTERS</td>\n",
       "      <td>0.907000</td>\n",
       "      <td>n e m m m m e e a</td>\n",
       "      <td>-10.668266</td>\n",
       "      <td>-1.066827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>953024</th>\n",
       "      <td>69775</td>\n",
       "      <td>1</td>\n",
       "      <td>2016</td>\n",
       "      <td>\" &lt;SAMPLE&gt; european championships results \" .</td>\n",
       "      <td>NUMBERS</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>twenty sixteen</td>\n",
       "      <td>-0.790882</td>\n",
       "      <td>-0.263627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>953156</th>\n",
       "      <td>69784</td>\n",
       "      <td>20</td>\n",
       "      <td>2012</td>\n",
       "      <td>pional &amp; john talabot - \" brave \" ( 2012 ) the...</td>\n",
       "      <td>NUMBERS</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>two twelve</td>\n",
       "      <td>-1.285938</td>\n",
       "      <td>-0.428646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>953251</th>\n",
       "      <td>69791</td>\n",
       "      <td>1</td>\n",
       "      <td>BMD-1</td>\n",
       "      <td>the &lt;SAMPLE&gt; also provided a basis for the btr...</td>\n",
       "      <td>NUMBERS</td>\n",
       "      <td>0.636910</td>\n",
       "      <td>b sil one</td>\n",
       "      <td>-2.525764</td>\n",
       "      <td>-0.631441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>953481</th>\n",
       "      <td>69805</td>\n",
       "      <td>12</td>\n",
       "      <td>km/h</td>\n",
       "      <td>trials will begin at 160 km / h and will be in...</td>\n",
       "      <td>LETTERS</td>\n",
       "      <td>0.526254</td>\n",
       "      <td>per h of</td>\n",
       "      <td>-0.827072</td>\n",
       "      <td>-0.206768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>954139</th>\n",
       "      <td>69854</td>\n",
       "      <td>19</td>\n",
       "      <td>http://dos.myflorida.com/elections/data-statis...</td>\n",
       "      <td>florida department of transportation , divisio...</td>\n",
       "      <td>ELECTRONIC</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>street</td>\n",
       "      <td>-0.512451</td>\n",
       "      <td>-0.256226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>954157</th>\n",
       "      <td>69856</td>\n",
       "      <td>1</td>\n",
       "      <td>2016</td>\n",
       "      <td>white &lt;SAMPLE&gt; , pp .</td>\n",
       "      <td>NUMBERS</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>twenty sixteen</td>\n",
       "      <td>-0.722672</td>\n",
       "      <td>-0.240891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>954170</th>\n",
       "      <td>69858</td>\n",
       "      <td>3</td>\n",
       "      <td>46.8 cm</td>\n",
       "      <td>its dimensions are &lt;SAMPLE&gt; x 43 cm .</td>\n",
       "      <td>NUMBERS</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>forty six point eight centimeters</td>\n",
       "      <td>-1.435234</td>\n",
       "      <td>-0.239206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>954320</th>\n",
       "      <td>69870</td>\n",
       "      <td>2</td>\n",
       "      <td>co-founder</td>\n",
       "      <td>he was &lt;SAMPLE&gt; of the erfurter gartenbauverei...</td>\n",
       "      <td>ELECTRONIC</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>the</td>\n",
       "      <td>-0.449524</td>\n",
       "      <td>-0.224762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>954356</th>\n",
       "      <td>69872</td>\n",
       "      <td>13</td>\n",
       "      <td>4:38.36</td>\n",
       "      <td>\" women 's 400 im prelims : klochkova dominant...</td>\n",
       "      <td>NUMBERS</td>\n",
       "      <td>0.999999</td>\n",
       "      <td>four thirty thirty eight thirty eight eight three</td>\n",
       "      <td>-6.393177</td>\n",
       "      <td>-0.710353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>954451</th>\n",
       "      <td>69879</td>\n",
       "      <td>12</td>\n",
       "      <td>2017</td>\n",
       "      <td>\" great american brass band festival — june 1 ...</td>\n",
       "      <td>NUMBERS</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>twenty seventeen</td>\n",
       "      <td>-0.912880</td>\n",
       "      <td>-0.304293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>954640</th>\n",
       "      <td>69895</td>\n",
       "      <td>0</td>\n",
       "      <td>Changsha.com</td>\n",
       "      <td>&lt;SAMPLE&gt; ( in chinese ) .</td>\n",
       "      <td>ELECTRONIC</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>c c c s s s s</td>\n",
       "      <td>-6.428780</td>\n",
       "      <td>-0.803597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>954917</th>\n",
       "      <td>69916</td>\n",
       "      <td>8</td>\n",
       "      <td>2016</td>\n",
       "      <td>statistik austria — bevolkerung zu jahresbegin...</td>\n",
       "      <td>NUMBERS</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>two thousand</td>\n",
       "      <td>-0.772491</td>\n",
       "      <td>-0.257497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>954988</th>\n",
       "      <td>69921</td>\n",
       "      <td>1</td>\n",
       "      <td>2017</td>\n",
       "      <td>his &lt;SAMPLE&gt; play the penitent previewed off b...</td>\n",
       "      <td>NUMBERS</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>twenty thousand</td>\n",
       "      <td>-0.996437</td>\n",
       "      <td>-0.332146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>955339</th>\n",
       "      <td>69949</td>\n",
       "      <td>1</td>\n",
       "      <td>1 902368 43 6</td>\n",
       "      <td>isbn &lt;SAMPLE&gt; .</td>\n",
       "      <td>NUMBERS</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>one sil six three two two two two two three</td>\n",
       "      <td>-11.993740</td>\n",
       "      <td>-1.090340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>955595</th>\n",
       "      <td>69966</td>\n",
       "      <td>4</td>\n",
       "      <td>2010</td>\n",
       "      <td>in fact , the &lt;SAMPLE&gt; barbados census recorde...</td>\n",
       "      <td>NUMBERS</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>twenty ten</td>\n",
       "      <td>-1.104164</td>\n",
       "      <td>-0.368055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>955654</th>\n",
       "      <td>69971</td>\n",
       "      <td>16</td>\n",
       "      <td>real-time</td>\n",
       "      <td>scanned synthesis represents a powerful and ef...</td>\n",
       "      <td>LETTERS</td>\n",
       "      <td>0.671907</td>\n",
       "      <td>realize</td>\n",
       "      <td>-0.835815</td>\n",
       "      <td>-0.417908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>955756</th>\n",
       "      <td>69981</td>\n",
       "      <td>7</td>\n",
       "      <td>line-up</td>\n",
       "      <td>in 2013 , jones began her own &lt;SAMPLE&gt; of en v...</td>\n",
       "      <td>LETTERS</td>\n",
       "      <td>0.890825</td>\n",
       "      <td>l u e i i</td>\n",
       "      <td>-5.241158</td>\n",
       "      <td>-0.873526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>955797</th>\n",
       "      <td>69984</td>\n",
       "      <td>3</td>\n",
       "      <td>1321</td>\n",
       "      <td>13 ( bdw &lt;SAMPLE&gt; ) bwv anh .</td>\n",
       "      <td>NUMBERS</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>thirteen thousand one</td>\n",
       "      <td>-0.912209</td>\n",
       "      <td>-0.228052</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7316 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        sentence_id  token_id  \\\n",
       "357              33         5   \n",
       "358              33         6   \n",
       "364              33        12   \n",
       "525              48         6   \n",
       "958              82        13   \n",
       "1074             93         6   \n",
       "1092             95         4   \n",
       "1096             95         8   \n",
       "1312            116         7   \n",
       "1573            137         7   \n",
       "1663            145         3   \n",
       "1664            145         4   \n",
       "1688            146        21   \n",
       "1870            162         5   \n",
       "2013            173         1   \n",
       "2066            176        20   \n",
       "2096            178        16   \n",
       "2214            188        11   \n",
       "2331            197        11   \n",
       "2510            211         5   \n",
       "2590            217        12   \n",
       "2747            230         3   \n",
       "2749            230         5   \n",
       "2842            237         2   \n",
       "3020            253         5   \n",
       "3034            254         4   \n",
       "3175            264         4   \n",
       "3387            282         5   \n",
       "3389            282         7   \n",
       "3391            282         9   \n",
       "...             ...       ...   \n",
       "951379        69655         7   \n",
       "951385        69655        13   \n",
       "951437        69659        13   \n",
       "951449        69659        25   \n",
       "951468        69661         2   \n",
       "951945        69697         3   \n",
       "952168        69714         5   \n",
       "952293        69723        13   \n",
       "952351        69727        11   \n",
       "952475        69737         3   \n",
       "952679        69751         1   \n",
       "952680        69751         2   \n",
       "953024        69775         1   \n",
       "953156        69784        20   \n",
       "953251        69791         1   \n",
       "953481        69805        12   \n",
       "954139        69854        19   \n",
       "954157        69856         1   \n",
       "954170        69858         3   \n",
       "954320        69870         2   \n",
       "954356        69872        13   \n",
       "954451        69879        12   \n",
       "954640        69895         0   \n",
       "954917        69916         8   \n",
       "954988        69921         1   \n",
       "955339        69949         1   \n",
       "955595        69966         4   \n",
       "955654        69971        16   \n",
       "955756        69981         7   \n",
       "955797        69984         3   \n",
       "\n",
       "                                                   before  \\\n",
       "357                                                  2016   \n",
       "358                                                   SAT   \n",
       "364                                                  2017   \n",
       "525                                                  2016   \n",
       "958                                               6 years   \n",
       "1074                                               021798   \n",
       "1092                                                 2020   \n",
       "1096                                         £415 million   \n",
       "1312                                                 2016   \n",
       "1573                                             28 years   \n",
       "1663                                              CAPSULE   \n",
       "1664                                              MARKETS   \n",
       "1688                                                 2016   \n",
       "1870                                             SPACEWAY   \n",
       "2013                                                 2016   \n",
       "2066                                                 2017   \n",
       "2096                                            long-term   \n",
       "2214                                            17.4 feet   \n",
       "2331                                               IQTREE   \n",
       "2510                                                 2017   \n",
       "2590                                                   10   \n",
       "2747                                          7,000 acres   \n",
       "2749                                       2,800 hectares   \n",
       "2842                                                Jaffé   \n",
       "3020                                             man-made   \n",
       "3034                                          90,000 tons   \n",
       "3175                                           co-founder   \n",
       "3387                                             $210,000   \n",
       "3389                                           US$610,408   \n",
       "3391                                         2016 dollars   \n",
       "...                                                   ...   \n",
       "951379                                       8 million m²   \n",
       "951385                                     3.3 million m²   \n",
       "951437                                               1980   \n",
       "951449                                               1981   \n",
       "951468                                                 20   \n",
       "951945                                                 10   \n",
       "952168                             Historywc.rootsweb.com   \n",
       "952293                                          09:37 EDT   \n",
       "952351                                           21 years   \n",
       "952475                                                 ::   \n",
       "952679                                           NELSON'S   \n",
       "952680                                         NIGHTMARES   \n",
       "953024                                               2016   \n",
       "953156                                               2012   \n",
       "953251                                              BMD-1   \n",
       "953481                                               km/h   \n",
       "954139  http://dos.myflorida.com/elections/data-statis...   \n",
       "954157                                               2016   \n",
       "954170                                            46.8 cm   \n",
       "954320                                         co-founder   \n",
       "954356                                            4:38.36   \n",
       "954451                                               2017   \n",
       "954640                                       Changsha.com   \n",
       "954917                                               2016   \n",
       "954988                                               2017   \n",
       "955339                                      1 902368 43 6   \n",
       "955595                                               2010   \n",
       "955654                                          real-time   \n",
       "955756                                            line-up   \n",
       "955797                                               1321   \n",
       "\n",
       "                                                 sentence  pred_class  \\\n",
       "357     college board , class of <SAMPLE> sat particip...     NUMBERS   \n",
       "358     college board , class of 2016 <SAMPLE> partici...       PLAIN   \n",
       "364     college board , class of 2016 sat participatio...     NUMBERS   \n",
       "525     \" greenwood elementary school fast facts <SAMP...     NUMBERS   \n",
       "958     eighteen pupils were killed , of whom sixteen ...     NUMBERS   \n",
       "1074            patent and exclusivity for : n <SAMPLE> .     NUMBERS   \n",
       "1092    the projected deficit in <SAMPLE> / 21 is £415...     NUMBERS   \n",
       "1096     the projected deficit in 2020 / 21 is <SAMPLE> .     NUMBERS   \n",
       "1312    \" miles franklin literary award , the <SAMPLE>...     NUMBERS   \n",
       "1573    the transfer of the concession took nearly <SA...     NUMBERS   \n",
       "1663                       \" the mad <SAMPLE> markets \" .     LETTERS   \n",
       "1664                       \" the mad capsule <SAMPLE> \" .     LETTERS   \n",
       "1688    \" petra castellana ( castellane — alpes de hau...     NUMBERS   \n",
       "1870    it is based upon the <SAMPLE> k ₐ - band commu...     LETTERS   \n",
       "2013                      introvigne <SAMPLE> , p . 277 .     NUMBERS   \n",
       "2066    it was released on may 19 , 2017 , and serves ...     NUMBERS   \n",
       "2096    armoring may restrict beach / ocean access , e...     LETTERS   \n",
       "2214    in some areas of the downtown core , the depth...     NUMBERS   \n",
       "2331    this can be accomplished with several differen...     LETTERS   \n",
       "2510                         29 : 1 ( winter <SAMPLE> ) .     NUMBERS   \n",
       "2590    the bruins rallied , however , to win in an up...     NUMBERS   \n",
       "2747    the commune contains <SAMPLE> ( 2 , 800 hectar...     NUMBERS   \n",
       "2749    the commune contains 7 , 000 acres ( <SAMPLE> ...     NUMBERS   \n",
       "2842    j . <SAMPLE> , regesta pontificum romanorum to...       PLAIN   \n",
       "3020    brown 's falls reservoir is a <SAMPLE> lake lo...  ELECTRONIC   \n",
       "3034           \" delhi metro prevents <SAMPLE> of co₂ \" .     NUMBERS   \n",
       "3175    he is also the <SAMPLE> of the open roof festi...  ELECTRONIC   \n",
       "3387    the painting was sold for <SAMPLE> ( us$610 , ...     NUMBERS   \n",
       "3389    the painting was sold for $210 , 000 ( <SAMPLE...     NUMBERS   \n",
       "3391    the painting was sold for $210 , 000 ( us$610 ...     NUMBERS   \n",
       "...                                                   ...         ...   \n",
       "951379  in 2016 in moscow , built about <SAMPLE> of re...     NUMBERS   \n",
       "951385  in 2016 in moscow , built about 8 million m² o...     NUMBERS   \n",
       "951437  she was an adjunct music instructor at de anza...     NUMBERS   \n",
       "951449  she was an adjunct music instructor at de anza...     NUMBERS   \n",
       "951468  on 10 july <SAMPLE> 17 , , de guzman joined ei...     NUMBERS   \n",
       "951945  23 december 2015 - the <SAMPLE> - lane expansi...     NUMBERS   \n",
       "952168  georgia info pickens county courthouse <SAMPLE...  ELECTRONIC   \n",
       "952293  the hijackers crashed the aircraft into the we...     NUMBERS   \n",
       "952351  making their 15th straight trip to the postsea...     NUMBERS   \n",
       "952475              \" white card <SAMPLE> safework sa \" .       PLAIN   \n",
       "952679  \" <SAMPLE> nightmares \" , sunday times , 15 oc...     LETTERS   \n",
       "952680  \" nelson' s <SAMPLE> \" , sunday times , 15 oct...     LETTERS   \n",
       "953024      \" <SAMPLE> european championships results \" .     NUMBERS   \n",
       "953156  pional & john talabot - \" brave \" ( 2012 ) the...     NUMBERS   \n",
       "953251  the <SAMPLE> also provided a basis for the btr...     NUMBERS   \n",
       "953481  trials will begin at 160 km / h and will be in...     LETTERS   \n",
       "954139  florida department of transportation , divisio...  ELECTRONIC   \n",
       "954157                              white <SAMPLE> , pp .     NUMBERS   \n",
       "954170              its dimensions are <SAMPLE> x 43 cm .     NUMBERS   \n",
       "954320  he was <SAMPLE> of the erfurter gartenbauverei...  ELECTRONIC   \n",
       "954356  \" women 's 400 im prelims : klochkova dominant...     NUMBERS   \n",
       "954451  \" great american brass band festival — june 1 ...     NUMBERS   \n",
       "954640                          <SAMPLE> ( in chinese ) .  ELECTRONIC   \n",
       "954917  statistik austria — bevolkerung zu jahresbegin...     NUMBERS   \n",
       "954988  his <SAMPLE> play the penitent previewed off b...     NUMBERS   \n",
       "955339                                    isbn <SAMPLE> .     NUMBERS   \n",
       "955595  in fact , the <SAMPLE> barbados census recorde...     NUMBERS   \n",
       "955654  scanned synthesis represents a powerful and ef...     LETTERS   \n",
       "955756  in 2013 , jones began her own <SAMPLE> of en v...     LETTERS   \n",
       "955797                      13 ( bdw <SAMPLE> ) bwv anh .     NUMBERS   \n",
       "\n",
       "        pred_c_conf                                              after  \\\n",
       "357        1.000000                                       two thousand   \n",
       "358        0.984779                                           saturday   \n",
       "364        1.000000                                    twenty thousand   \n",
       "525        1.000000                                    twenty thousand   \n",
       "958        1.000000                                 six thousand e a e   \n",
       "1074       1.000000              o seven seven seven seven eight eight   \n",
       "1092       1.000000                                   two thousand two   \n",
       "1096       0.999975                four hundred hundred million pounds   \n",
       "1312       1.000000                                    twenty thousand   \n",
       "1573       1.000000                               two two thousand s s   \n",
       "1663       0.824684                                      c a s s l l l   \n",
       "1664       0.638339                                      m a r r a t t   \n",
       "1688       1.000000                                    twenty thousand   \n",
       "1870       0.729722                                    s a c w a a a y   \n",
       "2013       1.000000                                    twenty thousand   \n",
       "2066       1.000000                                   twenty seventeen   \n",
       "2096       0.640466                                    l r t t t t t t   \n",
       "2214       1.000000                             fourteen seven seven s   \n",
       "2331       0.959851                                          i r e e e   \n",
       "2510       1.000000                                    twenty thousand   \n",
       "2590       1.000000                                                ten   \n",
       "2747       1.000000                                              seven   \n",
       "2749       0.999996                                             twenty   \n",
       "2842       0.999721                                        j a f f f e   \n",
       "3020       1.000000                                      m a a a m e e   \n",
       "3034       1.000000                           ninety trillion thousand   \n",
       "3175       1.000000                                                the   \n",
       "3387       1.000000                   one hundred ten thousand dollars   \n",
       "3389       1.000000       four hundred six thousand four hundred eight   \n",
       "3391       1.000000         two thousand sixteen sixteen dollars w l l   \n",
       "...             ...                                                ...   \n",
       "951379     1.000000                                eight million seven   \n",
       "951385     1.000000              three point three three million miles   \n",
       "951437     1.000000                                    nineteen eighty   \n",
       "951449     1.000000                one thousand one hundred eighty one   \n",
       "951468     1.000000                                             twenty   \n",
       "951945     1.000000                                                ten   \n",
       "952168     1.000000                      h o o b o o o o o o o o o o o   \n",
       "952293     1.000000                              zero thirty seven e e   \n",
       "952351     1.000000                                 two two thousand o   \n",
       "952475     0.873395                                         point face   \n",
       "952679     0.574411                                      n l l e e n n   \n",
       "952680     0.907000                                  n e m m m m e e a   \n",
       "953024     1.000000                                     twenty sixteen   \n",
       "953156     1.000000                                         two twelve   \n",
       "953251     0.636910                                          b sil one   \n",
       "953481     0.526254                                           per h of   \n",
       "954139     1.000000                                             street   \n",
       "954157     1.000000                                     twenty sixteen   \n",
       "954170     1.000000                  forty six point eight centimeters   \n",
       "954320     1.000000                                                the   \n",
       "954356     0.999999  four thirty thirty eight thirty eight eight three   \n",
       "954451     1.000000                                   twenty seventeen   \n",
       "954640     1.000000                                      c c c s s s s   \n",
       "954917     1.000000                                       two thousand   \n",
       "954988     1.000000                                    twenty thousand   \n",
       "955339     1.000000        one sil six three two two two two two three   \n",
       "955595     1.000000                                         twenty ten   \n",
       "955654     0.671907                                            realize   \n",
       "955756     0.890825                                          l u e i i   \n",
       "955797     1.000000                              thirteen thousand one   \n",
       "\n",
       "        after_conf_sum  after_conf_avg  \n",
       "357          -0.802635       -0.267545  \n",
       "358          -0.630402       -0.315201  \n",
       "364          -1.052792       -0.350931  \n",
       "525          -0.769245       -0.256415  \n",
       "958          -3.654732       -0.609122  \n",
       "1074         -4.490807       -0.561351  \n",
       "1092         -1.264744       -0.316186  \n",
       "1096         -2.201344       -0.366891  \n",
       "1312         -0.786472       -0.262157  \n",
       "1573         -2.829502       -0.471584  \n",
       "1663         -2.938728       -0.367341  \n",
       "1664         -5.532867       -0.691608  \n",
       "1688         -0.764271       -0.254757  \n",
       "1870         -5.977821       -0.664202  \n",
       "2013         -0.730412       -0.243471  \n",
       "2066         -0.634109       -0.211370  \n",
       "2096         -3.123688       -0.347076  \n",
       "2214         -4.460953       -0.892191  \n",
       "2331         -1.526367       -0.254395  \n",
       "2510         -1.223579       -0.407860  \n",
       "2590         -0.493256       -0.246628  \n",
       "2747         -1.237671       -0.618835  \n",
       "2749         -0.789734       -0.394867  \n",
       "2842         -2.679064       -0.382723  \n",
       "3020         -3.934570       -0.491821  \n",
       "3034         -1.304703       -0.326176  \n",
       "3175         -0.401718       -0.200859  \n",
       "3387         -2.105618       -0.350936  \n",
       "3389         -7.526974       -0.940872  \n",
       "3391         -5.257607       -0.584179  \n",
       "...                ...             ...  \n",
       "951379       -2.184418       -0.546104  \n",
       "951385       -2.690887       -0.384412  \n",
       "951437       -0.967319       -0.322440  \n",
       "951449       -2.147610       -0.306801  \n",
       "951468       -0.580856       -0.290428  \n",
       "951945       -0.616699       -0.308350  \n",
       "952168      -16.522930       -1.032683  \n",
       "952293       -3.439220       -0.573203  \n",
       "952351       -3.541504       -0.708301  \n",
       "952475       -1.191162       -0.397054  \n",
       "952679       -4.884834       -0.610604  \n",
       "952680      -10.668266       -1.066827  \n",
       "953024       -0.790882       -0.263627  \n",
       "953156       -1.285938       -0.428646  \n",
       "953251       -2.525764       -0.631441  \n",
       "953481       -0.827072       -0.206768  \n",
       "954139       -0.512451       -0.256226  \n",
       "954157       -0.722672       -0.240891  \n",
       "954170       -1.435234       -0.239206  \n",
       "954320       -0.449524       -0.224762  \n",
       "954356       -6.393177       -0.710353  \n",
       "954451       -0.912880       -0.304293  \n",
       "954640       -6.428780       -0.803597  \n",
       "954917       -0.772491       -0.257497  \n",
       "954988       -0.996437       -0.332146  \n",
       "955339      -11.993740       -1.090340  \n",
       "955595       -1.104164       -0.368055  \n",
       "955654       -0.835815       -0.417908  \n",
       "955756       -5.241158       -0.873526  \n",
       "955797       -0.912209       -0.228052  \n",
       "\n",
       "[7316 rows x 9 columns]"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen_data[gen_data['after_conf_avg'] < -0.2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "current_row"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modify data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result_data = test_data.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "tmp = list(result_data.columns)\n",
    "tmp[tmp.index('before')] = 'after'\n",
    "result_data.columns = tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result_data['id'] = result_data.apply(lambda row: \"{}_{}\".format(row['sentence_id'], row['token_id']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>token_id</th>\n",
       "      <th>before</th>\n",
       "      <th>sentence</th>\n",
       "      <th>pred_class</th>\n",
       "      <th>pred_c_conf</th>\n",
       "      <th>after</th>\n",
       "      <th>after_conf_sum</th>\n",
       "      <th>after_conf_avg</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>357385</th>\n",
       "      <td>26563</td>\n",
       "      <td>8</td>\n",
       "      <td>show's</td>\n",
       "      <td>she held that position from may 2000 through t...</td>\n",
       "      <td>NOT_CHANGED</td>\n",
       "      <td>1.0</td>\n",
       "      <td>show's</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26563_8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3448</th>\n",
       "      <td>287</td>\n",
       "      <td>4</td>\n",
       "      <td>.</td>\n",
       "      <td>community media group llc &lt;SAMPLE&gt;</td>\n",
       "      <td>NOT_CHANGED</td>\n",
       "      <td>1.0</td>\n",
       "      <td>.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>287_4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        sentence_id  token_id  before  \\\n",
       "357385        26563         8  show's   \n",
       "3448            287         4       .   \n",
       "\n",
       "                                                 sentence   pred_class  \\\n",
       "357385  she held that position from may 2000 through t...  NOT_CHANGED   \n",
       "3448                   community media group llc <SAMPLE>  NOT_CHANGED   \n",
       "\n",
       "        pred_c_conf   after  after_conf_sum  after_conf_avg       id  \n",
       "357385          1.0  show's             NaN             NaN  26563_8  \n",
       "3448            1.0       .             NaN             NaN    287_4  "
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_data.sample(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "result_data.loc[10, 'after'] = '\"'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result_file_path = 'data/en_submission_2_3.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result_data.to_csv(result_file_path, index=False, columns=['id', 'after'], quoting=csv.QUOTE_ALL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:py3_pytorch_2]",
   "language": "python",
   "name": "conda-env-py3_pytorch_2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
