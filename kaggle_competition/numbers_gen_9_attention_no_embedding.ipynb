{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pytorch utils oh: pytorch_utils_oh_2.py\n",
      "Pytorch: 0.2.0_4\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import importlib\n",
    "from pytorch_utils_oh_2 import *\n",
    "import IPython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MODEL_SAVE_PATH = 'numbers_gen_9_attention_no_embedding'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pytorch utils oh: pytorch_utils_oh_2.py\n",
      "Pytorch: 0.2.0_4\n"
     ]
    }
   ],
   "source": [
    "import pytorch_utils_oh_2; importlib.reload(pytorch_utils_oh_2); from pytorch_utils_oh_2 import *;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# all_data = pickle.load(open(\"data/en_train_fixed_4_sentences.pkl\", \"rb\" ))\n",
    "all_data = pickle.load(open(\"data/en_train_fixed_5_manual.pkl\", \"rb\" ))\n",
    "# all_data_sentence_index = all_data.set_index('sentence_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data rows: 448170,  (dropped rows: 9470022)\n"
     ]
    }
   ],
   "source": [
    "sample_data = all_data.copy()\n",
    "#sample_data = sample_data[sample_data['class'] != 'NOT_CHANGED']\n",
    "#sample_data = sample_data[sample_data['class'] != 'MANUAL']\n",
    "\n",
    "sample_data =  sample_data[sample_data['class'] == 'NUMBERS']\n",
    "\n",
    "print(\"Data rows: {},  (dropped rows: {})\".format(len(sample_data), len(all_data)-len(sample_data)))\n",
    "sample_data = sample_data.reset_index(drop=True)\n",
    "del(all_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['NUMBERS']\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "categories_all = sorted(sample_data[\"class\"].unique())\n",
    "print(categories_all)\n",
    "print(len(categories_all))\n",
    "categories_index = dict((c, i) for i, c in enumerate(categories_all))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utils stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<SOS><EOS>☒ !\"#$%&'(),-./0123456789:;ABCDEFGHIJKLMNOPQRSTUVWXYZ_abcdefghijklmnopqrstuvwxyz~£¥ª²³µº¼½¾éɒʻˈΩμ—€⅓⅔⅛\n"
     ]
    }
   ],
   "source": [
    "chars_normal, chars_normal_index = load_characters_pkl('data/en_features/chars_normal.pkl')\n",
    "print(''.join(chars_normal))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "common_words, common_words_index = load_common_words_10k()\n",
    "len(common_words)\n",
    "common_words[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wv_vecs, wv_words, wv_idx = load_glove('/home/ohu/koodi/data/glove_wordvec/glove.6B.50d.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### After words handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<EOS>', '<SOS>', '<UNK>', '<0000>', '<SAMPLE>', 'two', 'twenty']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "1351"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_after_common = pickle.load(open(\"data/en_features/words_after_ext.pkl\", 'rb'))\n",
    "words_after_index = dict((c, i) for i, c in enumerate(words_after_common))\n",
    "words_after_common[0:7]\n",
    "len(words_after_common)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 1351])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sos_tensor = torch.zeros(1, 1, len(words_after_index))\n",
    "sos_tensor[0, 0, words_after_index[SOS_TOKEN]] = 1\n",
    "sos_tensor.size()\n",
    "#del(onehot_sos)\n",
    "\n",
    "#sos_tensor = torch.LongTensor([words_after_index[SOS_TOKEN]])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### More balanced sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "balanced_data_classes_select = list(sample_data.groupby('class'))\n",
    "\n",
    "balanced_data_accessed_counter = 0 \n",
    "balanced_data_length = 0\n",
    "def balanced_data_randomize(max_len=20000):\n",
    "    global balanced_data, balanced_data_length, balanced_data_accessed_counter\n",
    "    balanced_data = pd.concat([v.sample(min(max_len, len(v))) for k, v in balanced_data_classes_select])\n",
    "    balanced_data_length = len(balanced_data)\n",
    "    balanced_data_accessed_counter = 0\n",
    "\n",
    "def balanced_data_sample_row():\n",
    "    global balanced_data_accessed_counter\n",
    "    global balanced_data_last_sample\n",
    "    balanced_data_accessed_counter += 1\n",
    "    if balanced_data_accessed_counter/balanced_data_length > 0.2:\n",
    "        balanced_data_randomize()\n",
    "    balanced_data_last_sample = balanced_data.iloc[random.randint(1, balanced_data_length-1)]\n",
    "    return balanced_data_last_sample\n",
    "    \n",
    "balanced_data_randomize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "111 µs ± 1.28 µs per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "balanced_data_sample_row()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "class\n",
       "NUMBERS    20000\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#all_data.groupby('class')['class'].count()\n",
    "#sample_data.groupby('class')['class'].count()\n",
    "balanced_data.groupby('class')['class'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentence_id                                           745207\n",
       "token_id                                                   5\n",
       "class                                                NUMBERS\n",
       "before                                         Mar. 21, 2012\n",
       "after                       march twenty first twenty twelve\n",
       "class_org                                               DATE\n",
       "a_word_ind                             [62, 6, 56, 6, 47, 0]\n",
       "sentence       mar . 21 , 2014 ) ( notice filed <SAMPLE> ) .\n",
       "Name: 446571, dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " balanced_data_sample_row()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NUMBERS : 1971 -> nineteen seventy one <EOS> [7, 33, 9, 0]\n",
      "stenton <SAMPLE> , anglo saxon england , p . 418 fn .\n",
      "torch.Size([1, 5, 104])\n"
     ]
    }
   ],
   "source": [
    "def get_random_sample():\n",
    "    sample_row = balanced_data_sample_row()\n",
    "    sentence_id = sample_row['class']\n",
    "    \n",
    "    return sample_row['before'], sample_row['a_word_ind'], sample_row['class'], sample_row['sentence']\n",
    "            \n",
    "def tmp():\n",
    "    s_bef, s_aft, s_class, s_sentence = get_random_sample()\n",
    "    s_aft_str = ' '.join([words_after_common[i] for i in s_aft])\n",
    "    print(s_class, ':', s_bef, '->', s_aft_str, s_aft)\n",
    "    print(s_sentence)\n",
    "    print(string_to_tensor(s_bef, chars_normal_index).shape)\n",
    "tmp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "158 µs ± 1.02 µs per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "get_random_sample()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "use_cuda = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MAX_ATTENTION_LENGTH = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EncoderRNN (\n",
       "  (rnn_words): LSTM(50, 64, batch_first=True, bidirectional=True)\n",
       "  (rnn_chars): LSTM(104, 128, batch_first=True, bidirectional=True)\n",
       ")"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, words_input_size, chars_input_size, words_hidden_size, chars_hidden_size,\n",
    "                 words_layers=1, chars_layers=1):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        \n",
    "        self.words_layers = words_layers\n",
    "        self.chars_layers = chars_layers\n",
    "        self.words_hidden_size = words_hidden_size\n",
    "        self.chars_hidden_size = chars_hidden_size\n",
    "        self.hidden_size = words_hidden_size + chars_hidden_size\n",
    "\n",
    "        self.rnn_words = nn.LSTM(words_input_size, words_hidden_size // 2, words_layers,\n",
    "                                 batch_first=True, bidirectional=True)\n",
    "\n",
    "        self.rnn_chars = nn.LSTM(chars_input_size, chars_hidden_size // 2, chars_layers,\n",
    "                                batch_first=True, bidirectional=True)\n",
    "        \n",
    "    def forward(self, word_vectors, string_tensor, hidden = None, init_hidden = True):\n",
    "        if init_hidden:\n",
    "            hidden_words, hidden_chars = self.init_hidden()\n",
    "        \n",
    "        all_outputs_words, hidden_words = self.rnn_words(word_vectors, hidden_words)\n",
    "        output_words = all_outputs_words[:, -1]\n",
    "        \n",
    "        all_outputs_chars, hidden_chars = self.rnn_chars(string_tensor, hidden_chars)\n",
    "        output_chars = all_outputs_chars[:, -1]\n",
    "        \n",
    "        hidden_states_cat = Variable(torch.zeros(MAX_ATTENTION_LENGTH, self.hidden_size)).cuda()\n",
    "        for ei in range(min(MAX_ATTENTION_LENGTH, len(string_tensor[0]))):\n",
    "            hidden_states_cat[ei] = torch.cat((output_words, all_outputs_chars[0, ei].view(1,-1)), 1)\n",
    "                \n",
    "        output = torch.cat((output_words[0], output_chars[0]), 0)\n",
    "        #output = torch.cat((output_words, output_chars), 1)\n",
    "        \n",
    "        #return output, all_outputs_chars\n",
    "        return output, hidden_states_cat\n",
    "\n",
    "    def init_hidden(self):\n",
    "        var1_1 = Variable(torch.zeros(2 * self.words_layers, 1, self.words_hidden_size // 2))\n",
    "        var1_2 = Variable(torch.zeros(2 * self.words_layers, 1, self.words_hidden_size // 2))\n",
    "        var2_1 = Variable(torch.zeros(2 * self.chars_layers, 1, self.chars_hidden_size // 2))\n",
    "        var2_2 = Variable(torch.zeros(2 * self.chars_layers, 1, self.chars_hidden_size // 2))\n",
    "        \n",
    "        var1_1 = var1_1.cuda(); var1_2 = var1_2.cuda()\n",
    "        var2_1 = var2_1.cuda(); var2_2 = var2_2.cuda()\n",
    "        return ((var1_1, var1_2), (var2_1, var2_2))\n",
    "    \n",
    "    \n",
    "encoder_rnn = EncoderRNN(words_input_size=wv_vecs.shape[-1], chars_input_size=len(chars_normal),\n",
    "                         words_hidden_size=128, chars_hidden_size=256,\n",
    "                         words_layers=1, chars_layers=1).cuda()\n",
    "encoder_rnn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'$25,108'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([384])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([20, 384])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def test_encoder_single_sample():\n",
    "    s_bef, s_aft, s_class, s_sentence = get_random_sample()\n",
    "    \n",
    "    words_t = Variable(words_to_word_vectors_tensor(list(s_sentence), wv_vecs, wv_idx)).cuda()\n",
    "    \n",
    "    string_t = string_to_tensor(s_bef, chars_normal_index)\n",
    "    string_t = Variable(string_t).cuda()\n",
    "    \n",
    "    return encoder_rnn(words_t, string_t), s_bef\n",
    "    \n",
    "(encoder_output, encoder_outputs), tmp = test_encoder_single_sample()\n",
    "tmp\n",
    "encoder_output.size()\n",
    "encoder_outputs.size()\n",
    "list(encoder_output.data.cpu().numpy()) == list(encoder_outputs[len(tmp)].data.cpu().numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecoderRNN (\n",
       "  (rnn): GRU(384, 384, batch_first=True)\n",
       "  (lin_out): Linear (384 -> 1351)\n",
       "  (emb_lin): Linear (1351 -> 384)\n",
       "  (attn): Linear (768 -> 20)\n",
       "  (attn_combine): Linear (768 -> 384)\n",
       "  (dropout): Dropout (p = 0.1)\n",
       ")"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[torch.Size([1, 1351]), torch.Size([1, 1, 384]), torch.Size([1, 20])]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class DecoderRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, n_layers=1, dropout_p=0.1, max_length=MAX_ATTENTION_LENGTH):\n",
    "        super(DecoderRNN, self).__init__()\n",
    "        self.n_layers = n_layers\n",
    "        self.hidden_size = hidden_size\n",
    "        \n",
    "        \n",
    "        self.rnn = nn.GRU(hidden_size, hidden_size, n_layers,\n",
    "                                 batch_first=True, bidirectional=False)\n",
    "        \n",
    "        self.lin_out = nn.Linear(hidden_size, input_size)\n",
    "\n",
    "        self.emb_lin = nn.Linear(input_size, hidden_size)\n",
    "        #self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        self.max_length = max_length\n",
    "        self.attn = nn.Linear(hidden_size*2, self.max_length)\n",
    "        self.attn_combine = nn.Linear(self.hidden_size * 2, self.hidden_size)\n",
    "        self.dropout = nn.Dropout(dropout_p)\n",
    "        \n",
    "    #def forward(self, char, hidden):\n",
    "    def forward(self, last_input, hidden, encoder_outputs):\n",
    "        #embedded = self.embedding(last_input).view(1, 1, -1)\n",
    "        embedded = self.emb_lin(last_input).view(1, 1, -1)\n",
    "        embedded = self.dropout(embedded)\n",
    "        #IPython.core.debugger.Pdb().set_trace()\n",
    "        #attn_weights = F.softmax(self.attn(torch.cat((char[0], hidden[0]), 1)))\n",
    "        attn_weights = F.softmax(self.attn(torch.cat((embedded[0], hidden[0]), 1)))\n",
    "        attn_applied = torch.bmm(attn_weights.unsqueeze(0), encoder_outputs.unsqueeze(0))\n",
    "        \n",
    "        output = torch.cat((embedded[0], attn_applied[0]), 1)\n",
    "        output = self.attn_combine(output).unsqueeze(0)\n",
    "\n",
    "        \n",
    "        output = F.relu(output)\n",
    "        output, hidden = self.rnn(output, hidden)\n",
    "\n",
    "        output = F.log_softmax(self.lin_out(output[0]))\n",
    "        return output, hidden, attn_weights\n",
    "    \n",
    "    def init_rest_hidden(self, input_var):\n",
    "        if self.n_layers > 1:\n",
    "            hid_var = Variable(torch.zeros(self.n_layers - 1, 1, self.hidden_size)).cuda()\n",
    "            res = torch.cat((input_var, hid_var), 0)\n",
    "            return res\n",
    "        else:\n",
    "            return input_var\n",
    "        \n",
    "\n",
    "decoder_rnn = DecoderRNN(input_size=len(words_after_common), hidden_size=encoder_output.size()[0], n_layers=1)\n",
    "decoder_rnn = decoder_rnn.cuda()\n",
    "decoder_rnn\n",
    "\n",
    "tmp_outputs = Variable(torch.zeros(MAX_ATTENTION_LENGTH, encoder_output.size()[0])).cuda()\n",
    "tmp_hiddens = decoder_rnn.init_rest_hidden(encoder_output.view(1,1,-1))\n",
    "tmp = decoder_rnn(Variable(sos_tensor).cuda(), tmp_hiddens, tmp_outputs)\n",
    "[v.size() for v in tmp]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[torch.Size([1, 1351]), torch.Size([1, 1, 384]), torch.Size([1, 20])]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      " 674\n",
      "[torch.cuda.LongTensor of size 1x1 (GPU 0)]\n",
      "\n",
      "characterize\n"
     ]
    }
   ],
   "source": [
    "tmp_outputs = Variable(torch.zeros(MAX_ATTENTION_LENGTH, encoder_output.size()[0])).cuda()\n",
    "tmp_hiddens = decoder_rnn.init_rest_hidden(encoder_output.view(1,1,-1))\n",
    "tmp = decoder_rnn(Variable(sos_tensor).cuda(), tmp_hiddens, tmp_outputs)\n",
    "[v.size() for v in tmp]\n",
    "print(tmp[0].topk(1)[1])\n",
    "print(words_after_common[tmp[0].topk(1)[1].data[0][0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training etc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('galvanized characterize license license license license license license license license license license license license license license license license license license',\n",
       " 'galvanized characterize license license license license license license license license license license license license license license license license license license',\n",
       " 'the thirteenth of april twenty thirteen',\n",
       " ('13 April 2013', [11, 100, 12, 71, 6, 49, 0], 'NUMBERS', 'as of <SAMPLE> .'))"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def test_model_single_sample(model=None, return_more=False):\n",
    "    decoder_rnn.eval()\n",
    "    encoder_rnn.eval()\n",
    "    \n",
    "    s_bef, s_aft, s_class, s_sentence = sample = get_random_sample()\n",
    "        \n",
    "    words_t = Variable(words_to_word_vectors_tensor(list(s_sentence), wv_vecs, wv_idx)).cuda()\n",
    "    \n",
    "    string_t = string_to_tensor(s_bef, chars_normal_index)\n",
    "    string_t = Variable(string_t).cuda()\n",
    "    \n",
    "    encoder_output, encoder_outputs = encoder_rnn(words_t, string_t)\n",
    "    \n",
    "    #encoder_output = encoder_output.view(1,1,-1)\n",
    "    \n",
    "    decoder_hidden = decoder_rnn.init_rest_hidden(encoder_outputs[0].view(1,1,-1))\n",
    "    decoder_input = Variable(sos_tensor).cuda()\n",
    "\n",
    "    decoded_output = []\n",
    "    decoder_attns_arr = []\n",
    "    max_length = 20\n",
    "    for _ in range(max_length):\n",
    "        decoder_output, decoder_hidden, decoder_attns = decoder_rnn(decoder_input, decoder_hidden, encoder_outputs)\n",
    "        decoder_attns_arr.append(decoder_attns)\n",
    "        #return decoder_output\n",
    "\n",
    "        topv, topi = decoder_output.data.topk(1)\n",
    "        word_index = topi[0][0]\n",
    "        word = words_after_common[word_index] # Use own prediction as next input\n",
    "                \n",
    "        if word == EOS_TOKEN:\n",
    "            break\n",
    "\n",
    "        decoded_output.append(word)\n",
    "        \n",
    "        #decoder_intput = torch.LongTensor([word_index])\n",
    "        decoder_input = torch.zeros(1, 1, len(words_after_index))\n",
    "        decoder_input[0, 0, word_index] = 1\n",
    "        decoder_input = Variable(decoder_input).cuda()\n",
    "    \n",
    "    output = ' '.join(decoded_output)\n",
    "    sample_target = ' '.join([words_after_common[w] for w in s_aft][:-1])\n",
    "    \n",
    "    decoder_rnn.train()\n",
    "    encoder_rnn.train()\n",
    "    \n",
    "    if return_more:\n",
    "        return output, decoded_output, decoder_attns_arr, sample\n",
    "    \n",
    "    return output, output, sample_target, sample\n",
    "    \n",
    "tmp = test_model_single_sample(None)\n",
    "tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-2             => galvanized characterize license license license license license license license license license license license license license license license license license license || [119, 5, 0] \n",
      "                  kultsu fc 22 15 4 3 56 24 49 promoted - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - <SAMPLE> .\n",
      "7,611          => cafe eighteenths license license license license license license license license license license license license license license license license license license || [18, 8, 20, 10, 48, 0] \n",
      "                  the city has 188 barrios or wards and approximately <SAMPLE> blocks .\n"
     ]
    }
   ],
   "source": [
    "def print_local_wrong_predictions(max_results=10):\n",
    "    arr = get_some_wrong_predictions(None, test_model_single_sample, max_iterations=10000, max_results=max_results)\n",
    "    for sample, predict, output in arr:\n",
    "        s_bef, s_aft, s_class, s_sentence = sample\n",
    "        print(\"{:<14} => {:<14} || {} \\n{:>17} {}\".format(s_bef, predict, s_aft, '', s_sentence, ))\n",
    "print_local_wrong_predictions(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train(s_bef, s_aft, s_sentence, encoder_optimizer, decoder_optimizer, loss_function,\n",
    "          use_teacher_forcing, max_length=20):\n",
    "    \n",
    "    words_t = Variable(words_to_word_vectors_tensor(list(s_sentence), wv_vecs, wv_idx)).cuda()\n",
    "    \n",
    "    string_t = string_to_tensor(s_bef, chars_normal_index)\n",
    "    string_t = Variable(string_t).cuda()\n",
    "    \n",
    "    encoder_output, encoder_outputs = encoder_rnn(words_t, string_t)\n",
    "    \n",
    "    #encoder_output = encoder_output.view(1,1,-1)\n",
    "    \n",
    "    decoder_hidden = decoder_rnn.init_rest_hidden(encoder_outputs[0].view(1,1,-1))\n",
    "    decoder_input = Variable(sos_tensor).cuda()\n",
    "    \n",
    "    ###\n",
    "    target_arr = s_aft\n",
    "    #target_arr = after_sentence_to_word_indexes(s_aft, include_eos=True)\n",
    "    \n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "    loss = 0\n",
    "    \n",
    "    decoded_output = []\n",
    "    for i in range(len(target_arr)):\n",
    "        decoder_output, decoder_hidden, decoder_attns = decoder_rnn(decoder_input, decoder_hidden, encoder_outputs)\n",
    "\n",
    "        #decoder_target_i = chars_after_index[target_arr[i]]\n",
    "        decoder_target_i = target_arr[i]\n",
    "        decoder_target_i = Variable(torch.LongTensor([decoder_target_i])).cuda()\n",
    "        loss += loss_function(decoder_output, decoder_target_i)\n",
    "        \n",
    "        topv, topi = decoder_output.data.topk(1)\n",
    "        word_index = topi[0][0]\n",
    "        word = words_after_common[word_index] # Use own prediction as next input\n",
    "        decoded_output.append(word)\n",
    "        \n",
    "        if use_teacher_forcing:\n",
    "            word_index = target_arr[i] # replace input with right target\n",
    "        else:\n",
    "            # use output normally as input \n",
    "            if word == EOS_TOKEN:\n",
    "                break\n",
    "                \n",
    "        decoder_input = torch.zeros(1, 1, len(words_after_index))\n",
    "        decoder_input[0, 0, word_index] = 1\n",
    "        decoder_input = Variable(decoder_input).cuda()\n",
    "        \n",
    "    if decoded_output[-1] == EOS_TOKEN:\n",
    "        decoded_output = decoded_output[:-1]\n",
    "        \n",
    "    loss.backward()\n",
    "\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "\n",
    "    return ' '.join(decoded_output), (loss.data[0] / len(target_arr))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_iterations(n_iters=100000, lr=0.001, teacher_forcing_ratio=0.5,\n",
    "                     print_every=10000, plot_every=1000):\n",
    "\n",
    "    start = time.time()\n",
    "    \n",
    "    decoder_rnn.train()\n",
    "    encoder_rnn.train()\n",
    "\n",
    "    current_loss = 0\n",
    "    current_loss_iter = 0\n",
    "\n",
    "    encoder_optimizer = torch.optim.Adam(encoder_rnn.parameters(), lr=lr)\n",
    "    decoder_optimizer = torch.optim.Adam(decoder_rnn.parameters(), lr=lr)\n",
    "    loss_function = nn.NLLLoss()\n",
    "    \n",
    "    for iteration in range(1, n_iters + 1):\n",
    "        model_training.iterations += 1\n",
    "        \n",
    "        use_teacher_forcing = random.random() < teacher_forcing_ratio\n",
    "        \n",
    "        s_bef, s_aft, s_class, s_sentence = get_random_sample()\n",
    "        \n",
    "        result, loss = train(s_bef=s_bef, s_aft=s_aft, s_sentence=s_sentence,\n",
    "                             encoder_optimizer=encoder_optimizer, decoder_optimizer=decoder_optimizer,\n",
    "                             loss_function=nn.NLLLoss(), use_teacher_forcing=use_teacher_forcing,\n",
    "                             max_length=40 )\n",
    "        \n",
    "        current_loss += loss\n",
    "        current_loss_iter += 1\n",
    "\n",
    "        # Print iter number, loss, name and guess\n",
    "        if iteration % print_every == 0:\n",
    "            teacher_forcing_str = \"\"\n",
    "            if use_teacher_forcing:\n",
    "                teacher_forcing_str = \"(forcing)\"\n",
    "            s_aft_sentence = ' '.join([words_after_common[w] for w in s_aft][:-1])\n",
    "            correct = '✓' if result == s_aft_sentence else \"✗: {}\".format(s_aft)\n",
    "            \n",
    "            print(\"{:>6d} {:>4.0%} ({:>8}) {:>7.3f}   | {:>6.2f}: {} -> {} ({}) {}\".format(\n",
    "                      model_training.iterations, iteration/n_iters, time_since(start),\n",
    "                      current_loss/current_loss_iter, loss,\n",
    "                      s_bef, result, correct, teacher_forcing_str))\n",
    "\n",
    "        # Add current loss avg to list of losses\n",
    "        if iteration % plot_every == 0:\n",
    "            model_training.losses.append(current_loss / plot_every)\n",
    "            model_training.learning_rates.append(lr)\n",
    "            current_loss = 0\n",
    "            current_loss_iter = 0\n",
    "            \n",
    "        if model_training.iterations % 50000 == 0: # or model_training.iterations == 10:\n",
    "            model_training.save_models()\n",
    "            acc = test_model_accuracy(encoder_rnn, test_model_single_sample)\n",
    "            model_training.accuracy.append(acc)\n",
    "    \n",
    "    # test_model_accuracy(model, n_sample=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Save path: data/models/numbers_gen_9_attention_no_embedding\n"
     ]
    }
   ],
   "source": [
    "model_training = ModelTraining(MODEL_SAVE_PATH, [encoder_rnn, decoder_rnn])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     9  18% (   0m 0s)   7.198   |   7.19: 2008-06-11 -> thousand thousand thousand license license license license license (✗: [11, 92, 12, 68, 5, 8, 16, 0]) \n",
      "    18  36% (   0m 0s)   6.478   |   2.05: €1.41 -> thousand (✗: [9, 544, 55, 41, 9, 213, 0]) \n",
      "    27  54% (   0m 0s)   6.216   |   7.09: 2007 -> thousand <EOS> <EOS> (✗: [5, 8, 18, 0]) (forcing)\n",
      "    36  72% (   0m 0s)   5.878   |   3.54: 2002 -> thousand (✗: [5, 8, 5, 0]) \n",
      "    45  90% (   0m 0s)   5.783   |   1.78: 1939 ->  (✗: [7, 34, 15, 0]) \n"
     ]
    }
   ],
   "source": [
    "train_iterations(n_iters=50, print_every=9, lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   550  53% (   0m 8s)   2.984   |   2.80: 18 November 1960 -> the twenty twenty (✗: [11, 94, 12, 69, 7, 39, 0]) \n"
     ]
    }
   ],
   "source": [
    "train_iterations(n_iters=(1000-model_training.iterations), print_every=500, lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  2000  11% (  0m 19s)   2.579   |   1.62: 3 -> one (✗: [13, 0]) (forcing)\n",
      "  3000  22% (  0m 39s)   2.424   |   1.87: 1960 -> nineteen thousand (✗: [7, 39, 0]) (forcing)\n",
      "  4000  33% (  0m 59s)   2.335   |   1.84: 22 August 2008 -> the twenty of of nineteen thousand (✗: [11, 6, 73, 12, 70, 5, 8, 16, 0]) \n",
      "  5000  44% (  1m 19s)   2.270   |   1.74: 28 -> two <EOS> (✗: [6, 16, 0]) (forcing)\n",
      "  6000  56% (  1m 39s)   2.104   |   2.77: 96 -> one (✗: [23, 20, 0]) \n",
      "  7000  67% (  1m 59s)   2.017   |   3.05: March 1444 -> october twenty thousand eight (✗: [62, 50, 41, 19, 0]) (forcing)\n",
      "  8000  78% (  2m 19s)   1.961   |   3.43: -9 -> two (✗: [119, 15, 0]) \n",
      "  9000  89% (  2m 40s)   1.915   |   1.80: $200,000 -> two thousand thousand (✗: [5, 10, 8, 85, 0]) \n",
      " 10000 100% (   3m 0s)   1.853   |   2.50: 38 -> two (✗: [34, 16, 0]) \n"
     ]
    }
   ],
   "source": [
    "train_iterations(n_iters=9000, lr=0.0001, print_every=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 20000  11% (  3m 43s)   0.693   |   0.26: 20% -> twenty percent (✓) (forcing)\n",
      " 30000  22% (  7m 25s)   0.462   |   0.01: 1988 -> nineteen eighty eight (✓) \n",
      " 40000  33% ( 11m 20s)   0.395   |   2.17: I-94 -> minus one four hundred (✗: [31, 23, 19, 0]) (forcing)\n",
      " 50000  44% (  15m 9s)   0.310   |   0.00: 2005 -> two thousand five (✓) \n",
      "Saved model to data/models/numbers_gen_9_attention_no_embedding/50000_(EncoderRNN/DecoderRNN)\n",
      "Accuracy: 79.00% (    7900/   10000)\n",
      " 60000  56% ( 20m 20s)   0.335   |   0.66: March 17, 1964 -> march sixteenth nineteen sixty four (✗: [62, 99, 7, 39, 19, 0]) (forcing)\n",
      " 70000  67% ( 24m 21s)   0.303   |   0.00: 1899 -> eighteen ninety nine (✓) \n",
      " 80000  78% ( 28m 12s)   0.273   |   0.03: 1990 -> nineteen ninety (✓) (forcing)\n",
      " 90000  89% (  32m 1s)   0.241   |   0.01: 19 March 2013 -> the nineteenth of march twenty thirteen (✓) \n",
      "100000 100% ( 35m 49s)   0.236   |   0.00: 3 -> three (✓) \n",
      "Saved model to data/models/numbers_gen_9_attention_no_embedding/100000_(EncoderRNN/DecoderRNN)\n",
      "Accuracy: 85.24% (    8524/   10000)\n"
     ]
    }
   ],
   "source": [
    "train_iterations(n_iters=90000, print_every=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17             => seventeen      || [9, 18, 0] \n",
      "                  twelve y 1 b - <SAMPLE> s were delivered to the 2 d bombardment group for evaluation .\n",
      "September 28, 1785 => september twenty eighth eighteen eighty five || [64, 6, 80, 81, 27, 14, 0] \n",
      "                  according to the cape fear historical institute , his date of birth is <SAMPLE> .\n",
      "2015-05-09     => the fifth of may twenty fifteen || [11, 84, 12, 66, 6, 51, 0] \n",
      "                  retrieved on <SAMPLE> .\n",
      "4.58           => four point eight eight || [19, 46, 14, 16, 0] \n",
      "                  he ran a <SAMPLE> 40 at the nfl combine .\n",
      "March 3, 1839  => march third eighteen thirty two || [62, 76, 40, 34, 15, 0] \n",
      "                  rumsey was elected as a whig to the twenty fifth congress , serving from march 4 , 1837 to <SAMPLE> .\n",
      "250 million    => two hundred fifty || [5, 10, 38, 90, 0] \n",
      "                  victor moses in february 2016 , bought a 6 - bedrooom mansion worth <SAMPLE> naira in lekki lagos , nigeria .\n",
      "1940-09-16     => the first of september nineteen eighty six || [11, 98, 12, 64, 7, 41, 0] \n",
      "                  reading room manchester ( <SAMPLE> ) .\n",
      "2008-03-20     => the twentieth of june two || [11, 88, 12, 62, 5, 8, 16, 0] \n",
      "                  archived from the original on <SAMPLE> .\n",
      "$1,153,908     => one million one one one one one one one one one one one one one one one one one one || [9, 90, 9, 10, 38, 13, 8, 15, 10, 16, 85, 0] \n",
      "                  carey : \" adam 's won <SAMPLE> worth of prizes today on the price is right . \"\n",
      "Sept 17, 2014  => september twenty fourteen || [64, 99, 6, 50, 0] \n",
      "                  reuters <SAMPLE> \" yougov referendum prediction : yes 46% , no 54% \" .\n"
     ]
    }
   ],
   "source": [
    "print_local_wrong_predictions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_iterations(n_iters=50000, print_every=10000, teacher_forcing_ratio=0.5, lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_iterations(n_iters=50000, print_every=10000, teacher_forcing_ratio=0.5, lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print_local_wrong_predictions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_iterations(n_iters=100000, print_every=10000, teacher_forcing_ratio=0.3, lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print_local_wrong_predictions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_iterations(n_iters=100000, print_every=10000, teacher_forcing_ratio=0.5, lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print_local_wrong_predictions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_iterations(n_iters=100000, print_every=10000, teacher_forcing_ratio=0.1, lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print_local_wrong_predictions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_iterations(n_iters=200000, print_every=10000, teacher_forcing_ratio=0.1, lr=0.0005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print_local_wrong_predictions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_iterations(n_iters=300000, print_every=10000, teacher_forcing_ratio=0.1, lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print_local_wrong_predictions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_iterations(n_iters=200000, print_every=10000, teacher_forcing_ratio=0, lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print_local_wrong_predictions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_iterations(n_iters=200000, print_every=10000, teacher_forcing_ratio=0, lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print_local_wrong_predictions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_iterations(n_iters=500000, print_every=10000, teacher_forcing_ratio=0, lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print_local_wrong_predictions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_iterations(n_iters=500000, print_every=10000, teacher_forcing_ratio=0, lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print_local_wrong_predictions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_iterations(n_iters=500000, print_every=10000, teacher_forcing_ratio=0, lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print_local_wrong_predictions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_iterations(n_iters=500000, print_every=10000, teacher_forcing_ratio=0, lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print_local_wrong_predictions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input:   21 April\n",
      "output:  ['the', 'twenty', 'first', 'of', 'april']\n",
      "target:    the twenty first of april\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAyYAAAFeCAYAAABw2Qu3AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f18a3d3cba8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def debug_show_attention(input_sentence, output_words, attentions):\n",
    "    # Set up figure with colorbar\n",
    "    fig = plt.figure(figsize=(15,6))\n",
    "    ax = fig.add_subplot(111)\n",
    "    #cax = ax.matshow(attentions.numpy(), cmap='bone')\n",
    "    cax = ax.matshow(attentions, cmap='bone')\n",
    "    fig.colorbar(cax)\n",
    "    # Set up axes\n",
    "    #ax.set_xticklabels([''] + input_sentence.split(' ') + ['<EOS>'], rotation=90)\n",
    "    ax.set_xticklabels([''] + input_sentence + ['<EOS>'], rotation=90)\n",
    "    ax.set_yticklabels([''] + output_words)\n",
    "\n",
    "    # Show label at every tick\n",
    "    ax.xaxis.set_major_locator(matplotlib.ticker.MultipleLocator(1))\n",
    "    ax.yaxis.set_major_locator(matplotlib.ticker.MultipleLocator(1))\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "def debug_eval_sample_show_attention():\n",
    "    output, decoded_output, decoder_attns_arr, sample = test_model_single_sample(None, return_more=True)\n",
    "    print('input:  ', sample[0])\n",
    "    print('output: ', decoded_output)\n",
    "    print('target:   ', ' '.join([words_after_common[w] for w in sample[1][:-1]]))\n",
    "\n",
    "    attns = np.array([arr.data[0].cpu().numpy() for arr in decoder_attns_arr])\n",
    "\n",
    "    debug_show_attention(list(sample[0]), decoded_output, attns)\n",
    "    #plt.matshow(attns)\n",
    "    \n",
    "debug_eval_sample_show_attention()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input:   December 8, 2013\n",
      "output:  ['september', 'twenty', 'twenty', 'thousand']\n",
      "target:    december eighth twenty thirteen\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAzkAAAFbCAYAAAD2sUBhAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f1884df7a58>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def debug_show_attention(input_sentence, output_words, attentions):\n",
    "    # Set up figure with colorbar\n",
    "    fig = plt.figure(figsize=(15,6))\n",
    "    ax = fig.add_subplot(111)\n",
    "    #cax = ax.matshow(attentions.numpy(), cmap='bone')\n",
    "    cax = ax.matshow(attentions, cmap='bone')\n",
    "    fig.colorbar(cax)\n",
    "    # Set up axes\n",
    "    #ax.set_xticklabels([''] + input_sentence.split(' ') + ['<EOS>'], rotation=90)\n",
    "    ax.set_xticklabels([''] + input_sentence + ['<EOS>'], rotation=90)\n",
    "    ax.set_yticklabels([''] + output_words)\n",
    "\n",
    "    # Show label at every tick\n",
    "    ax.xaxis.set_major_locator(matplotlib.ticker.MultipleLocator(1))\n",
    "    ax.yaxis.set_major_locator(matplotlib.ticker.MultipleLocator(1))\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "def debug_eval_sample_show_attention():\n",
    "    output, decoded_output, decoder_attns_arr, sample = test_model_single_sample(None, return_more=True)\n",
    "    print('input:  ', sample[0])\n",
    "    print('output: ', decoded_output)\n",
    "    print('target:   ', ' '.join([words_after_common[w] for w in sample[1][:-1]]))\n",
    "\n",
    "    attns = np.array([arr.data[0].cpu().numpy() for arr in decoder_attns_arr])\n",
    "\n",
    "    debug_show_attention(list(sample[0]), decoded_output, attns)\n",
    "    #plt.matshow(attns)\n",
    "    \n",
    "debug_eval_sample_show_attention()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:py3_pytorch_2]",
   "language": "python",
   "name": "conda-env-py3_pytorch_2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
