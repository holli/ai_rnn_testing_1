{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import importlib\n",
    "from pytorch_utils_oh_2 import *\n",
    "import IPython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MODEL_SAVE_PATH = 'whole_gen_13_2_only_chars_smaller'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pytorch utils oh: pytorch_utils_oh_2.py\n",
      "Pytorch: 0.2.0_4\n"
     ]
    }
   ],
   "source": [
    "import pytorch_utils_oh_2; importlib.reload(pytorch_utils_oh_2); from pytorch_utils_oh_2 import *;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# all_data = pickle.load(open(\"data/en_train_fixed_4_sentences.pkl\", \"rb\" ))\n",
    "all_data = pickle.load(open(\"data/en_train_fixed_5_manual.pkl\", \"rb\" ))\n",
    "# all_data_sentence_index = all_data.set_index('sentence_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data rows: 1654328,  (dropped rows: 8263864)\n"
     ]
    }
   ],
   "source": [
    "sample_data = all_data.copy()\n",
    "sample_data = sample_data[sample_data['class'] != 'NOT_CHANGED']\n",
    "sample_data = sample_data[sample_data['class'] != 'MANUAL']\n",
    "sample_data = sample_data[sample_data['before'].str.len() > 0]\n",
    "sample_data = pd.concat([sample_data, all_data[all_data['class_org'] == 'PLAIN'].sample(1000000)])\n",
    "# sample_data = sample_data[sample_data['class'] != 'ELECTRONIC']\n",
    "sample_data = sample_data.reset_index(drop=True)\n",
    "print(\"Data rows: {},  (dropped rows: {})\".format(len(sample_data), len(all_data)-len(sample_data)))\n",
    "del(all_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>token_id</th>\n",
       "      <th>class</th>\n",
       "      <th>before</th>\n",
       "      <th>after</th>\n",
       "      <th>class_org</th>\n",
       "      <th>a_word_ind</th>\n",
       "      <th>sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1021305</th>\n",
       "      <td>201966</td>\n",
       "      <td>9</td>\n",
       "      <td>NOT_CHANGED</td>\n",
       "      <td>before</td>\n",
       "      <td>before</td>\n",
       "      <td>PLAIN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>the match was reduced to 35 overs per side &lt;SA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999788</th>\n",
       "      <td>317477</td>\n",
       "      <td>13</td>\n",
       "      <td>NOT_CHANGED</td>\n",
       "      <td>frequently</td>\n",
       "      <td>frequently</td>\n",
       "      <td>PLAIN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>he does state that quarrels between palace wom...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1137756</th>\n",
       "      <td>67477</td>\n",
       "      <td>4</td>\n",
       "      <td>NOT_CHANGED</td>\n",
       "      <td>on</td>\n",
       "      <td>on</td>\n",
       "      <td>PLAIN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>archived from the original &lt;SAMPLE&gt; august 10 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>835873</th>\n",
       "      <td>266101</td>\n",
       "      <td>0</td>\n",
       "      <td>NOT_CHANGED</td>\n",
       "      <td>Wurtz</td>\n",
       "      <td>Wurtz</td>\n",
       "      <td>PLAIN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;SAMPLE&gt; received no academic studies , but ha...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         sentence_id  token_id        class      before       after class_org  \\\n",
       "1021305       201966         9  NOT_CHANGED      before      before     PLAIN   \n",
       "999788        317477        13  NOT_CHANGED  frequently  frequently     PLAIN   \n",
       "1137756        67477         4  NOT_CHANGED          on          on     PLAIN   \n",
       "835873        266101         0  NOT_CHANGED       Wurtz       Wurtz     PLAIN   \n",
       "\n",
       "        a_word_ind                                           sentence  \n",
       "1021305        NaN  the match was reduced to 35 overs per side <SA...  \n",
       "999788         NaN  he does state that quarrels between palace wom...  \n",
       "1137756        NaN  archived from the original <SAMPLE> august 10 ...  \n",
       "835873         NaN  <SAMPLE> received no academic studies , but ha...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_data.sample(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ELECTRONIC', 'LETTERS', 'NOT_CHANGED', 'NUMBERS', 'PLAIN', 'VERBATIM']\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "categories_all = sorted(sample_data[\"class\"].unique())\n",
    "print(categories_all)\n",
    "print(len(categories_all))\n",
    "categories_index = dict((c, i) for i, c in enumerate(categories_all))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>token_id</th>\n",
       "      <th>class</th>\n",
       "      <th>before</th>\n",
       "      <th>after</th>\n",
       "      <th>class_org</th>\n",
       "      <th>a_word_ind</th>\n",
       "      <th>sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>235664</th>\n",
       "      <td>270703</td>\n",
       "      <td>5</td>\n",
       "      <td>LETTERS</td>\n",
       "      <td>Uson</td>\n",
       "      <td>u s o n</td>\n",
       "      <td>LETTERS</td>\n",
       "      <td>[43, 17, 25, 29, 0]</td>\n",
       "      <td>matthews , lynn d . ; &lt;SAMPLE&gt; , juan m . ( 20...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>659392</th>\n",
       "      <td>170845</td>\n",
       "      <td>18</td>\n",
       "      <td>NOT_CHANGED</td>\n",
       "      <td>sur</td>\n",
       "      <td>sur</td>\n",
       "      <td>PLAIN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>champigny is a railway station in the commune ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        sentence_id  token_id        class before    after class_org  \\\n",
       "235664       270703         5      LETTERS   Uson  u s o n   LETTERS   \n",
       "659392       170845        18  NOT_CHANGED    sur      sur     PLAIN   \n",
       "\n",
       "                 a_word_ind                                           sentence  \n",
       "235664  [43, 17, 25, 29, 0]  matthews , lynn d . ; <SAMPLE> , juan m . ( 20...  \n",
       "659392                  NaN  champigny is a railway station in the commune ...  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_data.sample(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sample_data = sample_data[sample_data['before'].str.len() > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>token_id</th>\n",
       "      <th>class</th>\n",
       "      <th>before</th>\n",
       "      <th>after</th>\n",
       "      <th>class_org</th>\n",
       "      <th>a_word_ind</th>\n",
       "      <th>sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [sentence_id, token_id, class, before, after, class_org, a_word_ind, sentence]\n",
       "Index: []"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_data[sample_data['after'].str.len() < 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utils stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<SOS><EOS>☒ !\"#$%&'(),-./0123456789:;ABCDEFGHIJKLMNOPQRSTUVWXYZ_abcdefghijklmnopqrstuvwxyz~£¥ª²³µº¼½¾éɒʻˈΩμ—€⅓⅔⅛\n"
     ]
    }
   ],
   "source": [
    "chars_normal, chars_normal_index = load_characters_pkl('data/en_features/chars_normal.pkl')\n",
    "print(''.join(chars_normal))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<SOS><EOS>☒ 'abcdefghijklmnopqrstuvwxyzé\n"
     ]
    }
   ],
   "source": [
    "chars_after = sorted(list(set(''.join(list(sample_data['after'].unique())).lower())))\n",
    "chars_after = [SOS_TOKEN, EOS_TOKEN, UNKNOWN_CHAR] + chars_after\n",
    "chars_after_index = dict((c, i) for i, c in enumerate(chars_after))\n",
    "print(''.join(chars_after))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "chars_after, chars_after_index = load_characters_pkl('data/en_features/chars_after_1.pkl')\n",
    "print(''.join(chars_after))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wv_vecs, wv_words, wv_idx = load_glove('/home/ohu/koodi/data/glove_wordvec/glove.6B.50d.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### After words handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 32])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sos_tensor = torch.zeros(1, 1, len(chars_after_index))\n",
    "sos_tensor[0, 0, chars_after_index[SOS_TOKEN]] = 1\n",
    "sos_tensor.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### More balanced sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import collections\n",
    "\n",
    "balanced_data_classes_select = list(sample_data.groupby('class'))\n",
    "\n",
    "balanced_data_accessed_counter = 0 \n",
    "balanced_data_randomize_freq = False\n",
    "balanced_data_length = 0\n",
    "\n",
    "last_samples = collections.deque(maxlen=100)\n",
    "balanced_data_last_sample = last_samples\n",
    "\n",
    "def balanced_data_randomize_org(max_len=30000):\n",
    "    global balanced_data, balanced_data_length, balanced_data_accessed_counter, balanced_data_randomize_freq\n",
    "    balanced_data = pd.concat([v.sample(min(max_len, len(v))) for k, v in balanced_data_classes_select])\n",
    "    balanced_data = pd.concat([balanced_data, sample_data[sample_data['class']=='NOT_CHANGED'].sample(int(max_len*2))])\n",
    "    balanced_data_length = len(balanced_data)\n",
    "    balanced_data_randomize_freq = balanced_data_length * 0.2\n",
    "    balanced_data_accessed_counter = 0\n",
    "balanced_data_randomize = balanced_data_randomize_org\n",
    "\n",
    "def balanced_data_sample_row():\n",
    "    global balanced_data_accessed_counter\n",
    "    global balanced_data_last_sample\n",
    "    balanced_data_accessed_counter += 1\n",
    "    if balanced_data_randomize_freq and balanced_data_accessed_counter > balanced_data_randomize_freq:\n",
    "        balanced_data_randomize()\n",
    "        \n",
    "    sample = balanced_data.iloc[random.randint(1, balanced_data_length-1)]\n",
    "    last_samples.append(sample)\n",
    "    balanced_data_last_sample = sample\n",
    "    return sample\n",
    "    \n",
    "balanced_data_randomize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "class\n",
       "ELECTRONIC      4964\n",
       "LETTERS        30000\n",
       "NOT_CHANGED    90000\n",
       "NUMBERS        30000\n",
       "PLAIN          30000\n",
       "VERBATIM       11741\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#all_data.groupby('class')['class'].count()\n",
    "#sample_data.groupby('class')['class'].count()\n",
    "balanced_data.groupby('class')['class'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentence_id                                               392314\n",
       "token_id                                                      17\n",
       "class                                                 ELECTRONIC\n",
       "before         https://diva.sfsu.edu/collections/sfbatv/bundl...\n",
       "after          h t t p s colon slash slash d i v a dot s f s ...\n",
       "class_org                                             ELECTRONIC\n",
       "a_word_ind     [45, 30, 30, 24, 17, 129, 101, 101, 26, 31, 54...\n",
       "sentence       watch the full 60 minute version of this 1973 ...\n",
       "Name: 340541, dtype: object"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "balanced_data_sample_row()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentence_id                                               392314\n",
       "token_id                                                      17\n",
       "class                                                 ELECTRONIC\n",
       "before         https://diva.sfsu.edu/collections/sfbatv/bundl...\n",
       "after          h t t p s colon slash slash d i v a dot s f s ...\n",
       "class_org                                             ELECTRONIC\n",
       "a_word_ind     [45, 30, 30, 24, 17, 129, 101, 101, 26, 31, 54...\n",
       "sentence       watch the full 60 minute version of this 1973 ...\n",
       "Name: 340541, dtype: object"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_samples[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PLAIN : - -> to\n",
      "['505', '<SAMPLE>', '510', 'fritz', 'engbarth', '(', '2009', ')', '.']\n",
      "torch.Size([1, 2, 104])\n"
     ]
    }
   ],
   "source": [
    "def get_random_sample():\n",
    "    sample_row = balanced_data_sample_row()   \n",
    "    return sample_row['before'], sample_row['after'].lower(), sample_row['class'], sample_row['sentence'].split(' ')\n",
    "            \n",
    "def tmp():\n",
    "    s_bef, s_aft, s_class, s_sentence = get_random_sample()\n",
    "    print(s_class, ':', s_bef, '->', s_aft)\n",
    "    print(s_sentence)\n",
    "    print(string_to_tensor(s_bef, chars_normal_index).shape)\n",
    "tmp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 0 ns, sys: 0 ns, total: 0 ns\n",
      "Wall time: 281 µs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('Department',\n",
       " 'department',\n",
       " 'NOT_CHANGED',\n",
       " ['university', 'of', 'memphis', 'athletic', '<SAMPLE>', '.'])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "get_random_sample()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "use_cuda = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MAX_ATTENTION_LENGTH = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "754"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>token_id</th>\n",
       "      <th>class</th>\n",
       "      <th>before</th>\n",
       "      <th>after</th>\n",
       "      <th>class_org</th>\n",
       "      <th>a_word_ind</th>\n",
       "      <th>sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>402909</th>\n",
       "      <td>464991</td>\n",
       "      <td>1</td>\n",
       "      <td>ELECTRONIC</td>\n",
       "      <td>StiftungSteffi-LineKino.deWistrich</td>\n",
       "      <td>s t i f t u n g s t e f f i d a s h l i n e k ...</td>\n",
       "      <td>ELECTRONIC</td>\n",
       "      <td>[17, 30, 31, 37, 30, 43, 29, 53, 17, 30, 28, 3...</td>\n",
       "      <td>murnau &lt;SAMPLE&gt; , robert s . 1982 .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>641126</th>\n",
       "      <td>732304</td>\n",
       "      <td>2</td>\n",
       "      <td>ELECTRONIC</td>\n",
       "      <td>http://www.crnns.ca/documents/ProfessionalBoun...</td>\n",
       "      <td>h t t p colon slash slash w w w dot c r n n s ...</td>\n",
       "      <td>ELECTRONIC</td>\n",
       "      <td>[45, 30, 30, 24, 129, 101, 101, 52, 52, 52, 74...</td>\n",
       "      <td>retrieved from &lt;SAMPLE&gt; , m . , &amp; blazer riley...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        sentence_id  token_id       class  \\\n",
       "402909       464991         1  ELECTRONIC   \n",
       "641126       732304         2  ELECTRONIC   \n",
       "\n",
       "                                                   before  \\\n",
       "402909                 StiftungSteffi-LineKino.deWistrich   \n",
       "641126  http://www.crnns.ca/documents/ProfessionalBoun...   \n",
       "\n",
       "                                                    after   class_org  \\\n",
       "402909  s t i f t u n g s t e f f i d a s h l i n e k ...  ELECTRONIC   \n",
       "641126  h t t p colon slash slash w w w dot c r n n s ...  ELECTRONIC   \n",
       "\n",
       "                                               a_word_ind  \\\n",
       "402909  [17, 30, 31, 37, 30, 43, 29, 53, 17, 30, 28, 3...   \n",
       "641126  [45, 30, 30, 24, 129, 101, 101, 52, 52, 52, 74...   \n",
       "\n",
       "                                                 sentence  \n",
       "402909                murnau <SAMPLE> , robert s . 1982 .  \n",
       "641126  retrieved from <SAMPLE> , m . , & blazer riley...  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp = sample_data[sample_data['before'].str.len()>MAX_ATTENTION_LENGTH]\n",
    "len(tmp)\n",
    "tmp.sample(2)\n",
    "# tmp[~tmp['before'].str.contains('/')].sample(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EncoderRNN (\n",
       "  (rnn_words): GRU(50, 64, batch_first=True, bidirectional=True)\n",
       "  (rnn_chars): GRU(104, 128, batch_first=True, bidirectional=True)\n",
       ")"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, words_input_size, chars_input_size, words_hidden_size, chars_hidden_size,\n",
    "                 words_layers=1, chars_layers=1):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        \n",
    "        self.words_layers = words_layers\n",
    "        self.chars_layers = chars_layers\n",
    "        self.words_hidden_size = words_hidden_size\n",
    "        self.chars_hidden_size = chars_hidden_size\n",
    "        self.hidden_size = words_hidden_size + chars_hidden_size\n",
    "\n",
    "        self.rnn_words = nn.GRU(words_input_size, words_hidden_size // 2, words_layers,\n",
    "                                 batch_first=True, bidirectional=True)\n",
    "\n",
    "        self.rnn_chars = nn.GRU(chars_input_size, chars_hidden_size // 2, chars_layers,\n",
    "                                 batch_first=True, bidirectional=True)\n",
    "        \n",
    "    def forward(self, word_vectors, string_tensor, hidden = None, init_hidden = True):\n",
    "        if init_hidden:\n",
    "            hidden_words, hidden_chars = self.init_hidden()\n",
    "        \n",
    "        all_outputs_words, hidden_words = self.rnn_words(word_vectors, hidden_words)\n",
    "        output_words = hidden_words.view(1, -1)\n",
    "        \n",
    "        all_outputs_chars, hidden_chars = self.rnn_chars(string_tensor, hidden_chars)\n",
    "        output_chars = hidden_chars.view(1, -1)\n",
    "        \n",
    "        #hidden_states_cat = Variable(torch.zeros(MAX_ATTENTION_LENGTH, self.hidden_size)).cuda()\n",
    "        #for ei in range(min(MAX_ATTENTION_LENGTH, len(string_tensor[0]))):\n",
    "        #    hidden_states_cat[ei] = torch.cat((output_words, all_outputs_chars[0, ei].view(1,-1)), 1)\n",
    "\n",
    "        all_outputs_chars_padded = Variable(torch.zeros(MAX_ATTENTION_LENGTH, self.chars_hidden_size)).cuda()\n",
    "        att_length = min(len(all_outputs_chars[0]), MAX_ATTENTION_LENGTH-1)\n",
    "        all_outputs_chars_padded[0:att_length] = all_outputs_chars[0][0:att_length]\n",
    "        \n",
    "        output = torch.cat((output_words, output_chars), 1)\n",
    "\n",
    "        #output = torch.cat((output_words, output_chars), 1)\n",
    "        \n",
    "        #return output, all_outputs_chars\n",
    "        return output, all_outputs_chars_padded\n",
    "\n",
    "    def init_hidden(self):\n",
    "        var1 = Variable(torch.zeros(2 * self.words_layers, 1, self.words_hidden_size // 2))\n",
    "        var2 = Variable(torch.zeros(2 * self.chars_layers, 1, self.chars_hidden_size // 2))\n",
    "        \n",
    "        var1 = var1.cuda(); var2 = var2.cuda()\n",
    "        return (var1, var2)\n",
    "    \n",
    "    \n",
    "encoder_rnn = EncoderRNN(words_input_size=wv_vecs.shape[-1], chars_input_size=len(chars_normal),\n",
    "                         words_hidden_size=128, chars_hidden_size=256,\n",
    "                         words_layers=1, chars_layers=1).cuda()\n",
    "encoder_rnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'S.'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 384])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([30, 256])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def test_encoder_single_sample():\n",
    "    s_bef, s_aft, s_class, s_sentence = get_random_sample()\n",
    "    #s_bef, s_aft, s_class, s_sentence = get_random_sample(True)\n",
    "    print(s_bef)\n",
    "    \n",
    "    words_t = Variable(words_to_word_vectors_tensor(s_sentence, wv_vecs, wv_idx)).cuda()\n",
    "    \n",
    "    string_t = string_to_tensor(s_bef, chars_normal_index)\n",
    "    string_t = Variable(string_t).cuda()\n",
    "    \n",
    "    return encoder_rnn(words_t, string_t), s_bef\n",
    "    \n",
    "(tmp_encoder_output, tmp_encoder_outputs), tmp = test_encoder_single_sample()\n",
    "tmp\n",
    "tmp_encoder_output.size()\n",
    "tmp_encoder_outputs.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecoderRNN (\n",
       "  (emb_lin): Linear (32 -> 384)\n",
       "  (dropout): Dropout (p = 0.1)\n",
       "  (attn): Linear (768 -> 30)\n",
       "  (attn_combine): Linear (640 -> 384)\n",
       "  (rnn): GRU(384, 384, batch_first=True)\n",
       "  (lin_out): Linear (384 -> 32)\n",
       ")"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[torch.Size([1, 32]), torch.Size([1, 384]), torch.Size([1, 30])]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class DecoderRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, chars_encoded_size,\n",
    "                 n_layers=1, dropout_p=0.1, max_length=MAX_ATTENTION_LENGTH):\n",
    "        super(DecoderRNN, self).__init__()\n",
    "        \n",
    "        self.n_layers = n_layers\n",
    "        self.hidden_size = hidden_size\n",
    "        self.max_length = max_length\n",
    "        \n",
    "        self.emb_lin = nn.Linear(input_size, hidden_size)\n",
    "        self.dropout = nn.Dropout(dropout_p)\n",
    "        self.attn = nn.Linear(self.hidden_size+self.hidden_size, self.max_length)\n",
    "        self.attn_combine = nn.Linear(self.hidden_size+chars_encoded_size, self.hidden_size)\n",
    "        \n",
    "        #self.module_attn = torch.nn.ModuleList([self.emb_lin, self.dropout, self.attn, self.attn_combine])\n",
    "        \n",
    "        \n",
    "        self.rnn = nn.GRU(hidden_size, hidden_size, n_layers, batch_first=True, bidirectional=False)\n",
    "        self.lin_out = nn.Linear(hidden_size, input_size)\n",
    "        \n",
    "        #self.module_rnn = torch.nn.ModuleList([self.rnn, self.lin_out])\n",
    "\n",
    "    def forward(self, last_input, hidden, encoder_outputs):\n",
    "        embedded = self.emb_lin(last_input).view(1, 1, -1)\n",
    "        embedded = self.dropout(embedded)\n",
    "        embedded = embedded[0]\n",
    "                \n",
    "        attn_weights = F.softmax(self.attn(torch.cat((embedded, hidden), 1)))\n",
    "        attn_applied = torch.bmm(attn_weights.unsqueeze(0), encoder_outputs.unsqueeze(0))\n",
    "        #return embedded, attn_applied\n",
    "        \n",
    "        rnn_input = torch.cat((embedded, attn_applied[0]), 1)\n",
    "        rnn_input = self.attn_combine(rnn_input).unsqueeze(0)\n",
    "        rnn_input = F.relu(rnn_input)\n",
    "    \n",
    "        output, hidden = self.rnn(rnn_input, hidden.unsqueeze(0))\n",
    "        output = F.log_softmax(self.lin_out(output[0]))\n",
    "        \n",
    "        return output, hidden[0], attn_weights\n",
    "    \n",
    "    def init_rest_hidden(self, input_var):\n",
    "        if self.n_layers > 1:\n",
    "            hid_var = Variable(torch.zeros(self.n_layers - 1, 1, self.hidden_size)).cuda()\n",
    "            res = torch.cat((input_var, hid_var), 0)\n",
    "            return res\n",
    "        else:\n",
    "            return input_var\n",
    "        \n",
    "    def mods_split(self):\n",
    "        mods = list(decoder_rnn.modules())[1:]\n",
    "        for gru_index, mod in enumerate(mods):\n",
    "            #print(mod)\n",
    "            if type(mod) == torch.nn.modules.rnn.GRU:\n",
    "                break\n",
    "        return mods[:gru_index], mods[gru_index:]\n",
    "        \n",
    "    def mods_attn(self):\n",
    "        return self.mods_split()[0]\n",
    "        \n",
    "    def mods_gru(self):\n",
    "        return self.mods_split()[1]\n",
    "\n",
    "decoder_rnn = DecoderRNN(input_size=len(chars_after), hidden_size=tmp_encoder_output.size()[1],\n",
    "                         chars_encoded_size=tmp_encoder_outputs.size()[1], n_layers=1)\n",
    "decoder_rnn = decoder_rnn.cuda()\n",
    "decoder_rnn\n",
    "\n",
    "tmp = decoder_rnn(Variable(sos_tensor).cuda(), tmp_encoder_output, tmp_encoder_outputs)\n",
    "#tmp\n",
    "[v.size() for v in tmp]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'lr': 3, 'params': <generator object Module.parameters at 0x7effaabfe2b0>},\n",
       " {'lr': 3, 'params': <generator object Module.parameters at 0x7effaabfe468>},\n",
       " {'lr': 3, 'params': <generator object Module.parameters at 0x7effaabfe5c8>},\n",
       " {'lr': 3, 'params': <generator object Module.parameters at 0x7effaabfe620>},\n",
       " {'params': <generator object Module.parameters at 0x7effaab3d678>},\n",
       " {'params': <generator object Module.parameters at 0x7effaab3d6d0>},\n",
       " {'params': <generator object Module.parameters at 0x7effaab3d410>}]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp = [{'params': mod.parameters(), 'lr': 3} for mod in decoder_rnn.mods_attn()]\n",
    "tmp += [{'params': mod.parameters()} for mod in decoder_rnn.mods_gru()]\n",
    "tmp.append(\n",
    "    {'params': encoder_rnn.parameters()}\n",
    ")\n",
    "tmp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training etc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('vvvrhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhh',\n",
       " 'vvvrhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhh',\n",
       " 'peptides',\n",
       " ('peptides',\n",
       "  'peptides',\n",
       "  'NOT_CHANGED',\n",
       "  ['\"',\n",
       "   'phytochelatins',\n",
       "   ',',\n",
       "   'the',\n",
       "   'heavy',\n",
       "   'metal',\n",
       "   'binding',\n",
       "   '<SAMPLE>',\n",
       "   'of',\n",
       "   'plants',\n",
       "   ',',\n",
       "   'are',\n",
       "   'synthesized',\n",
       "   'from',\n",
       "   'glutathione',\n",
       "   'by',\n",
       "   'a',\n",
       "   'specific',\n",
       "   'gamma',\n",
       "   'glutamylcysteine',\n",
       "   'dipeptidyl',\n",
       "   'transpeptidase',\n",
       "   '(',\n",
       "   'phytochelatin',\n",
       "   'synthase',\n",
       "   ')',\n",
       "   '\"',\n",
       "   '.']))"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def test_model_single_sample(model=None, return_more=False, sample=False):\n",
    "    decoder_rnn.eval()\n",
    "    encoder_rnn.eval()\n",
    "    global encoder_output, encoder_outputs, decoded_output, char_index\n",
    "    \n",
    "    if not sample:\n",
    "        sample = get_random_sample()\n",
    "    s_bef, s_aft, s_class, s_sentence = sample\n",
    "        \n",
    "    words_t = Variable(words_to_word_vectors_tensor(s_sentence, wv_vecs, wv_idx)).cuda()\n",
    "    \n",
    "    string_t = string_to_tensor(s_bef, chars_normal_index)\n",
    "    string_t = Variable(string_t).cuda()\n",
    "    \n",
    "    encoder_output, encoder_outputs = encoder_rnn(words_t, string_t)\n",
    "    \n",
    "    decoder_input = Variable(sos_tensor).cuda()\n",
    "    decoder_hidden = encoder_output\n",
    "    \n",
    "    decoded_output = []\n",
    "    decoder_attns_arr = []\n",
    "    max_length = 50\n",
    "    for _ in range(max_length):\n",
    "        decoder_output, decoder_hidden, decoder_attns = decoder_rnn(decoder_input, decoder_hidden, encoder_outputs)\n",
    "        decoder_attns_arr.append(decoder_attns)\n",
    "        #return decoder_output\n",
    "\n",
    "        topv, topi = decoder_output.data.topk(1)\n",
    "        char_index = topi[0][0]\n",
    "        char = chars_after[char_index] # Use own prediction as next input\n",
    "                \n",
    "        if char == EOS_TOKEN:\n",
    "            break\n",
    "\n",
    "        decoded_output.append(char)\n",
    "                \n",
    "        decoder_input = torch.zeros(1, 1, len(chars_after_index))\n",
    "        decoder_input[0, 0, char_index] = 1\n",
    "        decoder_input = Variable(decoder_input).cuda()\n",
    "    \n",
    "    output = ''.join(decoded_output)\n",
    "    sample_target = s_aft\n",
    "    \n",
    "    decoder_rnn.train()\n",
    "    encoder_rnn.train()\n",
    "    \n",
    "    if return_more:\n",
    "        return output, decoded_output, decoder_attns_arr, sample\n",
    "    \n",
    "    return output, output, sample_target, sample\n",
    "    \n",
    "tmp = test_model_single_sample(None)\n",
    "tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2006           => prrrhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhh || two thousand six \n",
      "                  ['vaughan', '<SAMPLE>', ',', 'pp', '.']\n",
      "Bike           =>                || bike \n",
      "                  ['in', '1990', ',', 'a', 'single', ',', '\"', '<SAMPLE>', 'boy', '\"', ',', 'was', 'released', 'on', \"rhodes'\", 'own', 'sacred', 'record', 'label', '.']\n"
     ]
    }
   ],
   "source": [
    "def print_local_wrong_predictions(max_results=10):\n",
    "    arr = get_some_wrong_predictions(None, test_model_single_sample, max_iterations=10000, max_results=max_results)\n",
    "    for sample, predict, output in arr:\n",
    "        s_bef, s_aft, s_class, s_sentence = sample\n",
    "        print(\"{:<14} => {:<14} || {} \\n{:>17} {}\".format(s_bef, predict, s_aft, '', s_sentence, ))\n",
    "print_local_wrong_predictions(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "test_model_accuracy(encoder_rnn, test_model_single_sample, n_sample=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train(s_bef, s_aft, s_sentence, optimizer, loss_function,\n",
    "          use_teacher_forcing, max_length=20):\n",
    "    \n",
    "    global encoder_output, encoder_outputs, decoded_output, char_index\n",
    "    \n",
    "    words_t = Variable(words_to_word_vectors_tensor(s_sentence, wv_vecs, wv_idx)).cuda() \n",
    "    \n",
    "    string_t = string_to_tensor(s_bef, chars_normal_index)\n",
    "    string_t = Variable(string_t).cuda()\n",
    "    \n",
    "    target_arr = [chars_after_index[c] for c in list(s_aft)] + [chars_after_index[EOS_TOKEN]]\n",
    "    optimizer.zero_grad()\n",
    "    loss = 0\n",
    "    \n",
    "    \n",
    "    encoder_output, encoder_outputs = encoder_rnn(words_t, string_t)\n",
    "    \n",
    "    \n",
    "    decoder_hidden = encoder_output\n",
    "    decoder_input = Variable(sos_tensor).cuda()\n",
    "\n",
    "    decoded_output = []\n",
    "    for i in range(len(target_arr)):\n",
    "        decoder_output, decoder_hidden, decoder_attns = decoder_rnn(decoder_input, decoder_hidden, encoder_outputs)\n",
    "\n",
    "        decoder_target_i = target_arr[i]\n",
    "        decoder_target_i = Variable(torch.LongTensor([decoder_target_i])).cuda()\n",
    "        loss += loss_function(decoder_output, decoder_target_i)\n",
    "        \n",
    "        topv, topi = decoder_output.data.topk(1)\n",
    "        char_index = topi[0][0]\n",
    "        char = chars_after[char_index] # Use own prediction as next input\n",
    "        decoded_output.append(char)\n",
    "        \n",
    "        if use_teacher_forcing:\n",
    "            char_index = target_arr[i] # replace input with right target\n",
    "        else:\n",
    "            # use output normally as input \n",
    "            if char == EOS_TOKEN:\n",
    "                break\n",
    "                \n",
    "        decoder_input = torch.zeros(1, 1, len(chars_after_index))\n",
    "        decoder_input[0, 0, char_index] = 1\n",
    "        decoder_input = Variable(decoder_input).cuda()\n",
    "        \n",
    "    if decoded_output[-1] == EOS_TOKEN:\n",
    "        decoded_output = decoded_output[:-1]\n",
    "\n",
    "    loss.backward()\n",
    "    \n",
    "    # https://github.com/pytorch/examples/blob/master/word_language_model/main.py\n",
    "    clip_parameters_value = 0.25\n",
    "    clips = []\n",
    "    if clip_parameters_value:\n",
    "        for m in [decoder_rnn, encoder_rnn]:\n",
    "            clips.append(torch.nn.utils.clip_grad_norm(m.parameters(), clip_parameters_value))\n",
    "\n",
    "    optimizer.step()\n",
    "\n",
    "    return ''.join(decoded_output), (loss.data[0] / len(target_arr))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = [p for p in encoder_rnn.parameters()]\n",
    "#parameters\n",
    "tmp = [p.grad.max().data[0] for p in parameters]\n",
    "tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.001\n",
    "tmp = [{'params': mod.parameters(), 'lr': (lr/10)} for mod in decoder_rnn.mods_attn()]\n",
    "tmp += [{'params': mod.parameters()} for mod in decoder_rnn.mods_gru()]\n",
    "tmp.append(\n",
    "    {'params': encoder_rnn.parameters()}\n",
    ")\n",
    "optimizer = torch.optim.Adam(tmp, lr=lr)    \n",
    "loss_function = nn.NLLLoss()\n",
    "train(s_bef, s_aft, s_sentence, optimizer, loss_function, use_teacher_forcing=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_bef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_samples[-2]['before']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = last_samples[-2]\n",
    "s_bef = tmp['before'][0:5]\n",
    "s_aft = tmp['after'][0:5]\n",
    "s_sentence = tmp['sentence'].split(' ')\n",
    "s_bef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "words_t = Variable(words_to_word_vectors_tensor(s_sentence, wv_vecs, wv_idx)).cuda() \n",
    "string_t = string_to_tensor(s_bef, chars_normal_index)\n",
    "string_t = Variable(string_t).cuda()\n",
    "target_arr = [chars_after_index[c] for c in list(s_aft)] + [chars_after_index[EOS_TOKEN]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "encoder_output, encoder_outputs = encoder_rnn(words_t, string_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_output[0,0:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_outputs[0,0:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_outputs[0,-4:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "decoder_hidden = encoder_output\n",
    "decoder_input = Variable(sos_tensor).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "decoder_output, decoder_hidden, decoder_attns = decoder_rnn(decoder_input, decoder_hidden, encoder_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topv, topi = decoder_output.data.topk(1)\n",
    "char_index = topi[0][0]\n",
    "char_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_iterations(n_iters=100000, lr=0.001, teacher_forcing_ratio=0.5,\n",
    "                     print_every=10000, plot_every=1000):\n",
    "    global optimizer\n",
    "    start = time.time()\n",
    "    \n",
    "    decoder_rnn.train()\n",
    "    encoder_rnn.train()\n",
    "\n",
    "    current_loss = 0\n",
    "    current_loss_iter = 0\n",
    "\n",
    "    tmp = [{'params': mod.parameters(), 'lr': (lr/10)} for mod in decoder_rnn.mods_attn()]\n",
    "    tmp += [{'params': mod.parameters()} for mod in decoder_rnn.mods_gru()]\n",
    "    tmp.append(\n",
    "        {'params': encoder_rnn.parameters()}\n",
    "    )\n",
    "    optimizer = torch.optim.Adam(tmp, lr=lr)\n",
    "    \n",
    "    loss_function = nn.NLLLoss()\n",
    "    \n",
    "    for iteration in range(1, n_iters + 1):\n",
    "        model_training.iterations += 1\n",
    "        \n",
    "        use_teacher_forcing = random.random() < teacher_forcing_ratio\n",
    "        \n",
    "        s_bef, s_aft, s_class, s_sentence = get_random_sample()\n",
    "        \n",
    "        result, loss = train(s_bef=s_bef, s_aft=s_aft, s_sentence=s_sentence,\n",
    "                             optimizer=optimizer,\n",
    "                             loss_function=nn.NLLLoss(), use_teacher_forcing=use_teacher_forcing,\n",
    "                             max_length=40 )\n",
    "        \n",
    "        current_loss += loss\n",
    "        current_loss_iter += 1\n",
    "\n",
    "        # Print iter number, loss, name and guess\n",
    "        if iteration % print_every == 0:\n",
    "            teacher_forcing_str = \"\"\n",
    "            if use_teacher_forcing:\n",
    "                teacher_forcing_str = \"(forcing)\"\n",
    "            correct = '✓' if result == s_aft else \"✗: {}\".format(s_aft)\n",
    "            \n",
    "            print(\"{:>6d} {:>4.0%} ({:>8}) {:>7.3f}   | {:>6.2f}: {} -> {} ({}) {}\".format(\n",
    "                      model_training.iterations, iteration/n_iters, time_since(start),\n",
    "                      current_loss/current_loss_iter, loss,\n",
    "                      s_bef, result, correct, teacher_forcing_str))\n",
    "\n",
    "        # Add current loss avg to list of losses\n",
    "        if iteration % plot_every == 0:\n",
    "            model_training.losses.append(current_loss / plot_every)\n",
    "            model_training.learning_rates.append(lr)\n",
    "            current_loss = 0\n",
    "            current_loss_iter = 0\n",
    "            \n",
    "        if model_training.iterations % 50000 == 0 or model_training.iterations == 10:\n",
    "            model_training.save_models()\n",
    "            acc = test_model_accuracy(encoder_rnn, test_model_single_sample)\n",
    "            model_training.accuracy.append(acc)\n",
    "    \n",
    "    # test_model_accuracy(model, n_sample=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Save path: data/models/whole_gen_13_2_only_chars_smaller\n"
     ]
    }
   ],
   "source": [
    "model_training = ModelTraining(MODEL_SAVE_PATH, [encoder_rnn, decoder_rnn])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     9  18% (   0m 0s)   2.514   |   3.45: RFEF -> <EOS><EOS>hhhhhh (✗: r f e f) (forcing)\n",
      "Saved model to data/models/whole_gen_13_2_only_chars_smaller/10_(EncoderRNN/DecoderRNN)\n",
      "Accuracy: 0.00% (       0/   10000)\n",
      "    18  36% (  2m 43s)   2.458   |   0.20: 2006 ->  (✗: two thousand six) \n",
      "    27  54% (  2m 43s)   2.332   |   3.43: 458 ->   <EOS><EOS><EOS><EOS><EOS><EOS><EOS><EOS><EOS><EOS><EOS><EOS><EOS><EOS><EOS><EOS><EOS><EOS><EOS><EOS><EOS><EOS> (✗: four hundred fifty eight) (forcing)\n",
      "    36  72% (  2m 44s)   2.279   |   3.39: TradingFloor.com -> <EOS><EOS><EOS><EOS><EOS><EOS><EOS><EOS><EOS><EOS><EOS><EOS><EOS><EOS><EOS><EOS><EOS><EOS><EOS><EOS><EOS><EOS><EOS><EOS><EOS><EOS><EOS><EOS><EOS><EOS><EOS><EOS><EOS> (✗: t r a d i n g f l o o r dot c o m) (forcing)\n",
      "    45  90% (  2m 44s)   2.233   |   3.38: Edge -> <EOS><EOS><EOS><EOS> (✗: edge) (forcing)\n"
     ]
    }
   ],
   "source": [
    "train_iterations(n_iters=50, print_every=9, lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   550  53% (  0m 10s)   2.101   |   3.01: DJ -> to (✗: d j) \n"
     ]
    }
   ],
   "source": [
    "train_iterations(n_iters=(1000-model_training.iterations), print_every=500, lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1e-05"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.0001"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer.param_groups[0]['lr']\n",
    "optimizer.param_groups[6]['lr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  2000  11% (  0m 25s)   2.287   |   2.93: wiki -> toee (✗: wiki) (forcing)\n",
      "  3000  22% (  0m 55s)   2.245   |   0.95: - -> to (✓) \n",
      "  4000  33% (  1m 23s)   2.184   |   2.33: leaves -> pennen (✗: leaves) (forcing)\n",
      "  5000  44% (  1m 53s)   2.096   |   0.36: & -> and (✓) (forcing)\n",
      "  6000  56% (  2m 23s)   2.039   |   2.49: July 2, 2013 -> ceneet eeeees o<EOS>te e enteent (✗: july second twenty thirteen) (forcing)\n",
      "  7000  67% (  2m 51s)   1.948   |   2.55: from -> sare (✗: from) \n",
      "  8000  78% (  3m 21s)   1.937   |   2.66: 2007 -> theeteen ninteen ti (✗: two thousand seven) \n",
      "  9000  89% (  3m 51s)   1.764   |   2.24: 1859 -> nineteen nineteen ni (✗: eighteen fifty nine) \n",
      " 10000 100% (  4m 21s)   1.642   |   1.48: G.E. -> d f (✗: g e) (forcing)\n"
     ]
    }
   ],
   "source": [
    "train_iterations(n_iters=9000, lr=0.0001, print_every=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 20000  11% (   5m 2s)   0.691   |   1.79: Mazzetti -> maneette (✗: mazzetti) (forcing)\n",
      " 30000  22% ( 10m 16s)   0.349   |   2.23: 1888boldsystems.orgThaibugsShibuya -> eie sielh sie aleot s a s a s a s a s a s a s s a s a s e s a s a s a s a s a s s a s s a s a s s  (✗: o n e e i g h t e i g h t e i g h t b o l d s y s t e m s dot o r g t h a i b u g s s h i b u y a) \n",
      " 40000  33% ( 15m 35s)   0.351   |   0.00: Duarte -> duarte (✓) \n",
      " 50000  44% ( 20m 55s)   0.300   |   0.00: & -> and (✓) \n",
      "Saved model to data/models/whole_gen_13_2_only_chars_smaller/50000_(EncoderRNN/DecoderRNN)\n",
      "Accuracy: 86.52% (    8652/   10000)\n",
      " 60000  56% ( 27m 50s)   0.224   |   0.00: Retrieved -> retrieved (✓) \n",
      " 70000  67% ( 32m 57s)   0.269   |   0.00: 2014 -> twenty fourteen (✓) (forcing)\n",
      " 80000  78% (  38m 4s)   0.212   |   0.00: bids -> bids (✓) \n",
      " 90000  89% (  43m 8s)   0.234   |   0.01: RightChange's -> rightchange's (✓) \n",
      "100000 100% ( 48m 20s)   0.203   |   0.86: 2012-11-3 -> the twird of de erber twonty fhe<EOS>ve (✗: the third of november twenty twelve) (forcing)\n",
      "Saved model to data/models/whole_gen_13_2_only_chars_smaller/100000_(EncoderRNN/DecoderRNN)\n",
      "Accuracy: 90.73% (    9073/   10000)\n"
     ]
    }
   ],
   "source": [
    "train_iterations(n_iters=90000, print_every=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "110000  10% (   5m 0s)   0.256   |   0.11: 98% -> ninety eight porcent (✗: ninety eight percent) (forcing)\n",
      "120000  20% (  10m 1s)   0.166   |   0.00: 1974 -> nineteen seventy four (✓) (forcing)\n",
      "130000  30% ( 15m 16s)   0.209   |   0.00: Bd -> b d (✓) \n",
      "140000  40% ( 20m 18s)   0.204   |   0.00: Schools -> schools (✓) \n",
      "150000  50% ( 25m 17s)   0.212   |   0.00: and -> and (✓) \n",
      "Saved model to data/models/whole_gen_13_2_only_chars_smaller/150000_(EncoderRNN/DecoderRNN)\n",
      "Accuracy: 91.02% (    9102/   10000)\n",
      "160000  60% ( 31m 55s)   0.241   |   0.01: March 6, 2010 -> march sixth twenty ten (✓) (forcing)\n",
      "170000  70% ( 36m 56s)   0.253   |  13.16: INT'L -> i n t w l (✗: international) \n",
      "180000  80% ( 41m 58s)   0.222   |   0.00: PDF -> p d f (✓) \n",
      "190000  90% ( 47m 10s)   0.272   |   0.01: ANC -> a n c (✓) \n",
      "200000 100% ( 52m 13s)   0.203   |   0.00: Leiden -> leiden (✓) \n",
      "Saved model to data/models/whole_gen_13_2_only_chars_smaller/200000_(EncoderRNN/DecoderRNN)\n",
      "Accuracy: 91.00% (    9100/   10000)\n"
     ]
    }
   ],
   "source": [
    "train_iterations(n_iters=100000, print_every=10000, teacher_forcing_ratio=0.5, lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "210000  10% (   5m 4s)   0.289   |   0.00: # -> number (✓) (forcing)\n",
      "220000  20% ( 10m 13s)   0.271   |   0.00: to -> to (✓) (forcing)\n",
      "230000  30% ( 15m 19s)   0.232   |   3.25: internationalization -> internationaliaiiiiii (✗: internationalization) \n",
      "240000  40% ( 20m 16s)   0.250   |   0.00: coup -> coup (✓) \n",
      "250000  50% ( 25m 20s)   0.231   |   1.59: usnews.com -> u s n e w s dot dot c  (✗: u s n e w s dot c o m) \n",
      "Saved model to data/models/whole_gen_13_2_only_chars_smaller/250000_(EncoderRNN/DecoderRNN)\n",
      "Accuracy: 88.46% (    8846/   10000)\n",
      "260000  60% ( 32m 21s)   0.286   |   0.00: E. -> e (✓) \n",
      "270000  70% ( 37m 26s)   0.241   |   0.00: will -> will (✓) (forcing)\n",
      "280000  80% ( 42m 18s)   0.261   |   0.00: C. -> c (✓) \n",
      "290000  90% ( 47m 24s)   0.356   |   0.00: ISBN -> i s b n (✓) (forcing)\n",
      "300000 100% ( 52m 31s)   0.271   |   0.00: behaviours -> behaviors (✓) \n",
      "Saved model to data/models/whole_gen_13_2_only_chars_smaller/300000_(EncoderRNN/DecoderRNN)\n",
      "Accuracy: 87.89% (    8789/   10000)\n"
     ]
    }
   ],
   "source": [
    "train_iterations(n_iters=100000, print_every=10000, teacher_forcing_ratio=0.4, lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "310000  10% (   5m 0s)   0.226   |   0.07: Eurobasket.com -> e u r o t a s k e t dot c o m (✗: e u r o b a s k e t dot c o m) \n",
      "320000  20% (  10m 5s)   0.235   |   0.00: satire -> satire (✓) \n",
      "330000  30% ( 15m 27s)   0.179   |   0.00: has -> has (✓) \n",
      "340000  40% ( 20m 34s)   0.167   |   0.00: ltd -> limited (✓) \n",
      "350000  50% ( 25m 37s)   0.211   |   0.00: Arabic -> arabic (✓) (forcing)\n",
      "Saved model to data/models/whole_gen_13_2_only_chars_smaller/350000_(EncoderRNN/DecoderRNN)\n",
      "Accuracy: 92.46% (    9246/   10000)\n",
      "360000  60% ( 32m 14s)   0.210   |   2.74: 2007-01-02 -> the two th of   auguar two thousand eight (✗: the second of january two thousand seven) \n",
      "370000  70% ( 37m 24s)   0.218   |   0.00: up -> up (✓) \n",
      "380000  80% ( 42m 25s)   0.163   |   0.00: & -> and (✓) (forcing)\n",
      "390000  90% ( 47m 29s)   0.191   |   0.00: the -> the (✓) \n",
      "400000 100% ( 52m 29s)   0.183   |   0.00: HMS -> h m s (✓) \n",
      "Saved model to data/models/whole_gen_13_2_only_chars_smaller/400000_(EncoderRNN/DecoderRNN)\n",
      "Accuracy: 92.75% (    9275/   10000)\n"
     ]
    }
   ],
   "source": [
    "train_iterations(n_iters=100000, print_every=10000, teacher_forcing_ratio=0.3, lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TKO'd          => t k o's        || t k o d \n",
      "                  ['according', 'to', 'boxrec', '.', 'com', 'cobbs', 'was', '<SAMPLE>', 'in', 'the', 'second', 'round', 'of', 'a', 'scheduled', 'four', 'round', 'bout', '.']\n",
      "9 January 2015 => the nineth of augary twenty fifteen || the ninth of january twenty fifteen \n",
      "                  ['archived', 'from', 'the', 'original', 'on', '<SAMPLE>', '.']\n",
      "#Stolpersteine => h sth o pecto  m o e e t   m e t   mete e t   e t  || hash tag stolpersteine \n",
      "                  ['\"', 'there', 'are', '48', ',', '000', '<SAMPLE>', 'in', '18', 'countries', 'in', 'europe', '\"', '.']\n",
      "July 23, 2011  => july twenty sirst twenty eleven || july twenty third twenty eleven \n",
      "                  ['<SAMPLE>', '.']\n",
      "WTOK-TV.com    => w t o k dot c o dot c o m || w t o k d a s h t v dot c o m \n",
      "                  ['meridian', 'mississippi', ':', '<SAMPLE>', '.']\n",
      "Rhe            => rhe            || r h e \n",
      "                  ['rh', '1', '<SAMPLE>', '6', '26', '.']\n",
      "/WRAL.com      => s w a s o mob i dot c o m || s l a s h w r a l dot c o m \n",
      "                  ['associated', 'press', '<SAMPLE>', '\"', 'senator', 'peter', \"'\", 'pete', \"'\", 'samuel', 'brunstetter', '\"', '.']\n",
      "February 2003  => february two thousand thirteen || february two thousand three \n",
      "                  ['on', '<SAMPLE>', ',', 'the', 'restoring', 'works', 'and', 'conservation', 'of', 'the', 'valuable', 'relics', 'began', '.']\n",
      "US$71.4 million => u s aul nilet f i l l l o e l l o e l l l o e l l  || seventy one point four million dollars \n",
      "                  ['six', 'days', 'of', 'torrential', 'rain', 'led', 'to', 'a', 'damage', 'total', 'of', '200', 'million', 'kina', '(', '<SAMPLE>', ')', '.']\n",
      "I.             => i              || one \n",
      "                  ['spad', 'xii', '/', 'xiii', 'aces', 'of', 'world', 'war', '<SAMPLE>', 'p', '.', '23', '.']\n"
     ]
    }
   ],
   "source": [
    "print_local_wrong_predictions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "410000  10% (   5m 1s)   0.298   |   0.00: & -> and (✓) (forcing)\n",
      "420000  20% (  10m 0s)   0.392   |   1.35: Pokernews.com -> p o k e t e e n o a s o m m  (✗: p o k e r n e w s dot c o m) \n",
      "430000  30% ( 15m 10s)   0.325   |   0.00: recognised -> recognized (✓) \n",
      "440000  40% ( 20m 10s)   0.372   |   0.00: CS -> c s (✓) \n",
      "450000  50% (  25m 7s)   0.395   |   0.00: B. -> b (✓) \n",
      "Saved model to data/models/whole_gen_13_2_only_chars_smaller/450000_(EncoderRNN/DecoderRNN)\n",
      "Accuracy: 87.19% (    8719/   10000)\n",
      "460000  60% ( 31m 50s)   0.392   |   1.22: PositiveSingles.com -> p o s i i i i i s e i t n t n t t t m n  (✗: p o s i t i v e s i n g l e s dot c o m) \n",
      "470000  70% ( 36m 56s)   0.243   |   1.25: no -> no (✗: number) \n",
      "480000  80% ( 41m 53s)   0.388   |   0.00: Mariner -> mariner (✓) \n",
      "490000  90% ( 46m 59s)   0.367   |   0.00: 2001 -> two thousand one (✓) \n",
      "500000 100% ( 52m 12s)   0.344   |   0.00: while -> while (✓) \n",
      "Saved model to data/models/whole_gen_13_2_only_chars_smaller/500000_(EncoderRNN/DecoderRNN)\n",
      "Accuracy: 85.77% (    8577/   10000)\n"
     ]
    }
   ],
   "source": [
    "train_iterations(n_iters=100000, print_every=10000, teacher_forcing_ratio=0.1, lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10,000         => one thousand   || ten thousand \n",
      "                  ['wetc', 'has', 'been', 'granted', 'an', 'fcc', 'construction', 'permit', 'to', 'increase', 'day', 'power', 'to', '<SAMPLE>', 'watts', '.']\n",
      "2003-07-20     => the eeot                             e   e  e  e   || the twentieth of july two thousand three \n",
      "                  ['worlds', '2003', 'results', ':', 'men', \"'s\", '400', 'free', 'relay', '-', '-', 'final', 'published', 'by', 'omega', 'timing', '(', 'official', 'timer', ')', 'on', '<SAMPLE>', '.']\n",
      "ChessGames.com => c h e s s s a m a m t m m m m m m m m m m m m m m  || c h e s s g a m e s dot c o m \n",
      "                  ['there', 'is', 'a', 'selection', 'of', '105', 'of', 'his', 'games', 'at', '<SAMPLE>', '.']\n",
      "71.9%          => sevene   poe t t  t et et  ee ne ne  ne  ne  ne    || seventy one point nine percent \n",
      "                  ['<SAMPLE>', 'of', 'all', 'admissions', 'were', 'made', 'via', 'the', 'emergency', 'department', '.']\n",
      "obs            => o b            || o b s \n",
      "                  ['\"', 'jpl', 'small', 'body', 'database', 'browser', ':', '13', 'egeria', '\"', '(', '2008', '-', '11', '-', '04', 'last', '<SAMPLE>', ')', '.']\n",
      "924            => inenuhhdr td ffoundred eeven || nine two four \n",
      "                  ['also', 'building', 'a', '<SAMPLE>', 'gtr', 'rally', 'race', 'car', ',', 'and', '2', 'other', 'gtr', \"'s\", '(', 'miller', '&', 'bf', 'goodrich', ')', '.']\n",
      "March 12, 2012 => march  ewel wtltttltltltettetetltetetltetetltetete || march twelfth twenty twelve \n",
      "                  ['rose', ',', 'wesley', '(', '<SAMPLE>', ')', '.']\n",
      "1980s          => nineteen eighttes || nineteen eighties \n",
      "                  ['in', 'the', 'late', '<SAMPLE>', ',', 'st', 'antony', \"'s\", 'college', ',', 'oxford', 'invited', 'him', 'to', 'become', 'an', 'associate', 'member', '.']\n",
      "19 May 2014    => the nintnenth of o       eee  eeeeeee  eeeeeeee  e || the nineteenth of may twenty fourteen \n",
      "                  ['updated', 'to', 'games', 'played', 'on', '<SAMPLE>', '.']\n",
      "Rs             => rssss          || r's \n",
      "                  ['\"', 'iball', 'slide', '3', 'g', '7345', 'q', '-', '800', 'voice', 'calling', 'tablet', 'available', 'online', 'at', '<SAMPLE>', '.']\n"
     ]
    }
   ],
   "source": [
    "print_local_wrong_predictions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "510000   5% (   5m 1s)   0.334   |   0.00: 1917 -> nineteen seventeen (✓) \n",
      "520000  10% (  10m 4s)   0.307   |   1.64: P&W -> p and an (✗: p and w) \n",
      "530000  15% (  15m 8s)   0.373   |   0.00: in -> in (✓) \n",
      "540000  20% ( 20m 11s)   0.326   |   0.00: Snails -> snails (✓) \n",
      "550000  25% ( 25m 16s)   0.324   |   0.00: vol -> volume (✓) (forcing)\n",
      "Saved model to data/models/whole_gen_13_2_only_chars_smaller/550000_(EncoderRNN/DecoderRNN)\n",
      "Accuracy: 88.07% (    8807/   10000)\n",
      "560000  30% (  32m 6s)   0.269   |   0.00: V. -> v (✓) \n",
      "570000  35% (  37m 6s)   0.398   |   4.18: D.C.'s -> d c '' (✗: d c's) \n",
      "580000  40% (  42m 8s)   0.295   |   0.00: Sweitzer -> sweitzer (✓) (forcing)\n",
      "590000  45% (  47m 6s)   0.305   |   0.00: & -> and (✓) \n",
      "600000  50% ( 52m 14s)   0.281   |   0.00: programme -> program (✓) \n",
      "Saved model to data/models/whole_gen_13_2_only_chars_smaller/600000_(EncoderRNN/DecoderRNN)\n",
      "Accuracy: 88.45% (    8845/   10000)\n",
      "610000  55% ( 58m 54s)   0.243   |   1.51: www.completelyretail.co.uk -> w w w dot c o m l l o l c l o l d l o l c l o l o l o l o  (✗: w w w dot c o m p l e t e l y r e t a i l dot c o dot u k) \n",
      "620000  60% (  64m 9s)   0.304   |   2.49: 3000 -> thirty hund (✗: three thousand) \n",
      "630000  65% (  69m 7s)   0.198   |   0.00: - -> to (✓) \n",
      "640000  70% ( 74m 10s)   0.280   |   0.00: design -> design (✓) \n",
      "650000  75% ( 79m 11s)   0.244   |   0.00: Centre -> center (✓) \n",
      "Saved model to data/models/whole_gen_13_2_only_chars_smaller/650000_(EncoderRNN/DecoderRNN)\n",
      "Accuracy: 89.02% (    8902/   10000)\n",
      "660000  80% ( 85m 48s)   0.289   |   0.00: in -> in (✓) \n",
      "670000  85% ( 90m 48s)   0.291   |   0.00: help -> help (✓) \n",
      "680000  90% ( 95m 45s)   0.228   |   0.00: had -> had (✓) (forcing)\n",
      "690000  95% (100m 44s)   0.224   |   0.00: & -> and (✓) \n",
      "700000 100% (105m 45s)   0.259   |   1.48: 17 January 1971 -> the selenttenth of junu  eetent neeteeteeteeteet (✗: the seventeenth of january nineteen seventy one) \n",
      "Saved model to data/models/whole_gen_13_2_only_chars_smaller/700000_(EncoderRNN/DecoderRNN)\n",
      "Accuracy: 89.67% (    8967/   10000)\n"
     ]
    }
   ],
   "source": [
    "train_iterations(n_iters=200000, print_every=10000, teacher_forcing_ratio=0.1, lr=0.0005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "$32,163        => thirty thosh shosh shosh shosh sand t shr shrshrsd || thirty two thousand one hundred sixty three dollars \n",
      "                  ['the', 'median', 'income', 'for', 'a', 'household', 'in', 'the', 'town', 'was', '$28', ',', '370', ',', 'and', 'the', 'median', 'income', 'for', 'a', 'family', 'was', '<SAMPLE>', '.']\n",
      "Simosaurus     => simoaarass     || simosaurus \n",
      "                  ['<SAMPLE>', 'also', 'differs', 'from', 'other', 'nothosaurs', 'in', 'that', 'it', 'has', 'blunt', 'teeth', 'that', 'were', 'probably', 'used', 'for', 'crushing', 'hard', 'shelled', 'organisms', '.']\n",
      "OO             => on             || oxygen monoxide \n",
      "                  ['\"', '<SAMPLE>', 'reference', 'desk', ':', 'real', 'names', 'list', '\"', '.']\n",
      "mr             => mister         || m r \n",
      "                  ['in', 'the', 'poem', 'thrymskvitha', 'of', 'the', 'poetic', 'edda', ',', 'thry', '<SAMPLE>', ',', 'the', 'king', 'of', 'the', 'jotuns', ',', 'steals', 'thor', \"'s\", 'hammer', ',', 'mjolnir', '.']\n",
      "58.8%          => fifty eighth hixt eighth e || fifty eight point eight percent \n",
      "                  ['matteo', 'renzi', 'in', 'palazzo', 'medici', 'riccardi', 'con', 'il', '<SAMPLE>', 'dei', 'votimonrifnet', '.']\n",
      "pvt            => p vvtrt        || private \n",
      "                  ['carmen', 'ibanezjake', 'busey', 'as', '<SAMPLE>']\n",
      "Bewu           => bewu           || b e w u \n",
      "                  ['his', 'first', 'significant', 'hit', 'he', 'produced', 'was', 'kwawkese', \"'s\", 'killa', '<SAMPLE>', 'last', 'show', 'in', '2010', '.']\n",
      "http://www.mercurynews.com/movies/ci_28578922/rebecca-ferguson-describes-her-big-leap-into-missionMission: => h t t p colon slash slash w w w w w a w h m a w s  || h t t p colon slash slash w w w dot m e r c u r y n e w s dot com slash m o v i e s slash c i u n d e r s c o r e t w o e i g h t f i v e s e v e n e i g h t n i n e t w o t w o slash r e b e c c a dash f e r g u s o n dash d e s c r i b e s dash h e r dash b i g dash l e a p dash i n t o dash m i s s i o n m i s s i o n colon \n",
      "                  ['retrieved', 'from', '<SAMPLE>', 'impossible', '5', 'has', 'found', 'its', 'new', 'female', 'lead', '.']\n",
      "5 April 2011   => the fifth of ppcleelww etttt eeeet i || the fifth of april twenty eleven \n",
      "                  ['reilly', ',', 'michael', '(', '<SAMPLE>', ')', '.']\n",
      "Tuesday, 10 March 1931 => tuesday firth twenty eeeenetnene || tuesday the tenth of march nineteen thirty one \n",
      "                  ['alfred', 'rouse', '—', 'hanged', '<SAMPLE>', ',', 'for', 'the', 'blazing', 'car', 'murder', 'at', 'hardingstone', 'which', 'attracted', 'sensational', 'national', 'interest', '.']\n"
     ]
    }
   ],
   "source": [
    "print_local_wrong_predictions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "710000   3% (   5m 2s)   0.280   |   0.00: in -> in (✓) \n",
      "720000   7% (  9m 58s)   0.206   |   0.00: M. -> m (✓) \n",
      "730000  10% (  15m 4s)   0.205   |   0.00: - -> to (✓) (forcing)\n",
      "740000  13% (  20m 6s)   0.209   |   0.00: analogue -> analog (✓) \n",
      "750000  17% (  25m 9s)   0.165   |   0.00: H. -> h (✓) \n",
      "Saved model to data/models/whole_gen_13_2_only_chars_smaller/750000_(EncoderRNN/DecoderRNN)\n",
      "Accuracy: 91.12% (    9112/   10000)\n",
      "760000  20% ( 31m 41s)   0.161   |   0.31: NO -> n tr (✗: nitrogen monoxide) \n",
      "770000  23% ( 36m 40s)   0.143   |   0.00: - -> to (✓) \n",
      "780000  27% ( 41m 46s)   0.217   |   0.00: Akademischer -> akademischer (✓) \n",
      "790000  30% ( 46m 44s)   0.210   |   3.27: 12/16 -> the sixth of smay  (✗: twelve sixteenths) \n",
      "800000  33% ( 51m 48s)   0.202   |   0.00: it -> it (✓) (forcing)\n",
      "Saved model to data/models/whole_gen_13_2_only_chars_smaller/800000_(EncoderRNN/DecoderRNN)\n",
      "Accuracy: 91.75% (    9175/   10000)\n",
      "810000  37% ( 58m 36s)   0.168   |   0.00: UK -> u k (✓) \n",
      "820000  40% ( 63m 40s)   0.197   |   0.00: mt -> mount (✓) \n",
      "830000  43% ( 68m 41s)   0.175   |   0.00: F- -> f (✓) (forcing)\n",
      "840000  47% ( 73m 55s)   0.196   |   2.33: 69,498 -> sixty nineh of four eheeree eeeeeneh ehhree (✗: sixty nine thousand four hundred ninety eight) \n",
      "850000  50% (  79m 0s)   0.210   |   0.00: Pearson -> pearson (✓) \n",
      "Saved model to data/models/whole_gen_13_2_only_chars_smaller/850000_(EncoderRNN/DecoderRNN)\n",
      "Accuracy: 92.13% (    9213/   10000)\n",
      "860000  53% ( 85m 40s)   0.162   |   0.00: & -> and (✓) \n",
      "870000  57% ( 90m 49s)   0.192   |   0.00: Road -> road (✓) \n",
      "880000  60% ( 95m 55s)   0.183   |   0.00: for -> for (✓) (forcing)\n",
      "890000  63% (100m 57s)   0.200   |   0.00: behaviour -> behavior (✓) \n",
      "900000  67% ( 106m 8s)   0.162   |   0.00: metre -> meter (✓) \n",
      "Saved model to data/models/whole_gen_13_2_only_chars_smaller/900000_(EncoderRNN/DecoderRNN)\n",
      "Accuracy: 92.01% (    9201/   10000)\n",
      "910000  70% (112m 51s)   0.186   |   0.00: provided -> provided (✓) (forcing)\n",
      "920000  73% (117m 50s)   0.142   |   0.00: MS- -> m s (✓) \n",
      "930000  77% (122m 53s)   0.189   |   0.00: who -> who (✓) \n",
      "940000  80% (127m 54s)   0.153   |   0.00: Home -> home (✓) \n",
      "950000  83% (132m 51s)   0.161   |   0.00: to -> to (✓) \n",
      "Saved model to data/models/whole_gen_13_2_only_chars_smaller/950000_(EncoderRNN/DecoderRNN)\n",
      "Accuracy: 92.92% (    9292/   10000)\n",
      "960000  87% (139m 27s)   0.153   |   0.00: f -> f (✓) \n",
      "970000  90% (144m 32s)   0.126   |   0.00: LMP -> l m p (✓) \n",
      "980000  93% (149m 29s)   0.211   |   0.00: play -> play (✓) \n",
      "990000  97% (154m 36s)   0.141   |   0.00: - -> to (✓) \n",
      "1000000 100% (159m 38s)   0.177   |   0.00: FIH -> f i h (✓) \n",
      "Saved model to data/models/whole_gen_13_2_only_chars_smaller/1000000_(EncoderRNN/DecoderRNN)\n",
      "Accuracy: 92.90% (    9290/   10000)\n"
     ]
    }
   ],
   "source": [
    "train_iterations(n_iters=300000, print_every=10000, teacher_forcing_ratio=0.1, lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 May 2008     => the fifth of mary  two th iiine eieei t || the fifth of may two thousand eight \n",
      "                  ['retrieved', '<SAMPLE>', ',', 'from', 'encyclopaedia', 'britannica', 'online', ':', 'http', ':', '/', '/', 'www', '.', 'britannica', '.', 'com', '/', 'eb', '/', 'article', '-', '28200', '.']\n",
      ".1870          => point eigh  eee  eeeeeeeeeee || point one eight seven o \n",
      "                  ['level', 'added', ',', 'altered', 'and', 'extended', 'c', '<SAMPLE>', '-', '5', 'by', 'architect', 'edward', 'blore', 'for', 'the', '4th', 'earl', '.']\n",
      "WHO            => w h o          || who \n",
      "                  ['data', 'for', 'water', 'and', 'sanitation', 'based', 'on', 'the', '<SAMPLE>', 'world', 'health', 'survey', '(', '2003', ')', '.']\n",
      "7 May 2011     => the seventh of may twenty ten || the seventh of may twenty eleven \n",
      "                  ['haond', ',', 'patrick', '(', '<SAMPLE>', ')', '.']\n",
      ".23            => point twe te   || point two three \n",
      "                  ['3', '/', '2011', ',', 'p', '<SAMPLE>', '-', '24', '(', 'romanian', ')', 'delavardar', ',', '\"', 'raiul', 'aromanilor', '\"', ',', 'in', 'cultura', 'poporului', ',', 'nr', '.']\n",
      ".323           => point three tteee ee || point three two three \n",
      "                  ['gateways', 'are', 'also', 'used', 'in', 'order', 'to', 'enable', 'videoconferencing', 'devices', 'based', 'on', 'h', '.', '320', 'and', 'h', '.', '324', 'to', 'communicate', 'with', 'h', '<SAMPLE>', 'systems', '.']\n",
      "40th           => forth          || fortieth \n",
      "                  ['pennsylvania', 'ranked', '<SAMPLE>', 'among', 'states', 'with', 'sat', 'scores', ':', 'verbal', '-', '493', ',', 'math', '-', '501', ',', 'writing', '-', '479', '.']\n",
      "interferometer => interferomete  || interferometer \n",
      "                  ['they', 'are', 'part', 'of', 'a', 'project', 'to', 'build', 'an', 'astronomical', '<SAMPLE>', '.']\n",
      "Rochefoucauld  => rochefoucaulld || rochefoucauld \n",
      "                  ['as', 'early', 'as', '1784', 'la', '<SAMPLE>', 'noted', 'that', '\"', 'throughout', 'the', 'whole', 'of', 'england', 'the', 'drinking', 'of', 'tea', 'is', 'general', '\"', '.']\n",
      "US$50 million  => u i ill ile    || fifty million dollars \n",
      "                  ['to', 'date', ',', 'the', 'world', 'bank', 'has', 'given', '<SAMPLE>', 'to', 'finance', 'this', 'project', '.']\n"
     ]
    }
   ],
   "source": [
    "print_local_wrong_predictions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1010000   3% (  4m 57s)   0.229   |   0.00: for -> for (✓) \n",
      "1020000   7% (  10m 2s)   0.275   |   0.00: and -> and (✓) \n",
      "1030000  10% (  15m 2s)   0.240   |   0.00: the -> the (✓) \n",
      "1040000  13% (  20m 0s)   0.273   |   0.00: was -> was (✓) \n",
      "1050000  17% ( 24m 57s)   0.254   |   0.00: etc -> etcetera (✓) \n",
      "Saved model to data/models/whole_gen_13_2_only_chars_smaller/1050000_(EncoderRNN/DecoderRNN)\n",
      "Accuracy: 90.15% (    9015/   10000)\n",
      "1060000  20% ( 31m 34s)   0.278   |   0.00: final -> final (✓) \n",
      "1070000  23% ( 36m 33s)   0.196   |   1.92: 10 September 1948 -> the tinlh of seveeeeeeeeeeeeeeeeeeeeeeeeeeee (✗: the tenth of september nineteen forty eight) \n",
      "1080000  27% ( 41m 37s)   0.222   |   0.00: A. -> a (✓) \n",
      "1090000  30% ( 46m 33s)   0.295   |   1.57: 1 July 1889 -> thh fifth of juu eet eeeeeeeennen (✗: the first of july eighteen eighty nine) \n",
      "1100000  33% ( 51m 37s)   0.299   |   0.00: ATF -> a t f (✓) \n",
      "Saved model to data/models/whole_gen_13_2_only_chars_smaller/1100000_(EncoderRNN/DecoderRNN)\n",
      "Accuracy: 90.07% (    9007/   10000)\n",
      "1110000  37% ( 58m 18s)   0.257   |   1.72: 1,040.1 -> one thousand onnnnn  nnnnn  n (✗: one thousand forty point one) \n",
      "1120000  40% ( 63m 15s)   0.240   |   0.00: since -> since (✓) \n",
      "1130000  43% ( 68m 15s)   0.221   |   0.00: - -> to (✓) \n",
      "1140000  47% ( 73m 18s)   0.251   |   0.00: available -> available (✓) \n",
      "1150000  50% ( 78m 20s)   0.242   |   0.00: HR -> h r (✓) \n",
      "Saved model to data/models/whole_gen_13_2_only_chars_smaller/1150000_(EncoderRNN/DecoderRNN)\n",
      "Accuracy: 89.48% (    8948/   10000)\n",
      "1160000  53% (  85m 0s)   0.217   |   0.00: O. -> o (✓) \n",
      "1170000  57% (  90m 3s)   0.267   |   2.68: (2005) 73-87 -> the sin                                       (✗: two o o five sil seven three sil eight seven) \n",
      "1180000  60% (  95m 3s)   0.264   |   0.00: first -> first (✓) \n",
      "1190000  63% ( 100m 2s)   0.263   |   0.00: Rule -> rule (✓) \n",
      "1200000  67% (104m 55s)   0.278   |   0.00: 1,000 -> one thousand (✓) \n",
      "Saved model to data/models/whole_gen_13_2_only_chars_smaller/1200000_(EncoderRNN/DecoderRNN)\n",
      "Accuracy: 89.42% (    8942/   10000)\n",
      "1210000  70% (111m 35s)   0.307   |   0.00: appearing -> appearing (✓) \n",
      "1220000  73% (116m 48s)   0.328   |   0.00: 2010 -> twenty ten (✓) \n",
      "1230000  77% (121m 53s)   0.264   |   0.00: age -> age (✓) \n",
      "1240000  80% (126m 57s)   0.252   |   0.00: made -> made (✓) \n",
      "1250000  83% (131m 55s)   0.292   |   0.00: FDP -> f d p (✓) \n",
      "Saved model to data/models/whole_gen_13_2_only_chars_smaller/1250000_(EncoderRNN/DecoderRNN)\n",
      "Accuracy: 89.95% (    8995/   10000)\n",
      "1260000  87% (138m 30s)   0.275   |   0.00: NBA -> n b a (✓) \n",
      "1270000  90% (143m 37s)   0.253   |   0.00: # -> number (✓) \n",
      "1280000  93% (148m 40s)   0.231   |   0.00: U.S. -> u s (✓) \n",
      "1290000  97% (153m 40s)   0.278   |   0.00: KKT -> k k t (✓) \n",
      "1300000 100% (158m 37s)   0.260   |   0.00: theories -> theories (✓) \n",
      "Saved model to data/models/whole_gen_13_2_only_chars_smaller/1300000_(EncoderRNN/DecoderRNN)\n",
      "Accuracy: 89.66% (    8966/   10000)\n"
     ]
    }
   ],
   "source": [
    "train_iterations(n_iters=300000, print_every=10000, teacher_forcing_ratio=0, lr=0.0005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lom            => lom            || l o m \n",
      "                  ['\"', '<SAMPLE>', '\"', 'is', 'scots', 'gaelic', 'for', '\"', 'bald', '\"', 'or', '\"', 'bare', '\"', '(', 'lom', 'a', '.', 'luime', ',', 'bare', ',', 'bald', ',', 'shaven', ',', 'cropped', ')', ',', 'perhaps', 'indicating', 'he', 'was', 'bald', '.']\n",
      "unfavourable   => unfavou abe    || unfavorable \n",
      "                  ['whilst', 'archer', \"'s\", 'books', 'are', 'commercially', 'successful', ',', 'critics', 'have', 'been', 'generally', '<SAMPLE>', 'towards', 'his', 'writing', '.']\n",
      "107.3          => one hundred seven ee eee ee || one hundred seven point three \n",
      "                  ['for', 'every', '100', 'females', 'age', '18', 'and', 'over', ',', 'there', 'were', '<SAMPLE>', 'males', '.']\n",
      "11 Jan 2014    => the fiven h ff jane  wenty uune || the eleventh of january twenty fourteen \n",
      "                  ['retrieved', '<SAMPLE>', '.']\n",
      "533.9          => fifty thirtyithie  t nee nee  enee  ee  ee eeee || five hundred thirty three point nine \n",
      "                  ['at', 'the', '2010', 'united', 'states', 'census', ',', 'there', 'were', '1', ',', '879', 'people', ',', '675', 'households', ',', 'and', '<SAMPLE>', 'families', 'residing', 'in', 'the', 'cdp', '.']\n",
      "0.49%          => zer poiii     ee  eeeeeeeeeeeeeeee  || zero point four nine percent \n",
      "                  ['the', 'racial', 'makeup', 'of', 'the', 'village', 'was', '99', '.', '51%', 'white', ',', 'and', '<SAMPLE>', 'from', 'two', 'or', 'more', 'races', '.']\n",
      "November 14, 1870 => november foureenththd eigheen || november fourteenth eighteen seventy \n",
      "                  ['bichler', 'was', 'born', 'on', '<SAMPLE>', 'in', 'holland', ',', 'sheboygan', 'county', 'wisconsin', '.']\n",
      "29 April 2012  => the twenty ninep  eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee || the twenty ninth of april twenty twelve \n",
      "                  ['<SAMPLE>', '.']\n",
      "kilometres     => kilometees     || kilometers \n",
      "                  ['the', 'total', 'distance', 'of', 'the', 'road', 'is', '4', '<SAMPLE>', '(', '2', '.', '5', 'mi', ')', '.']\n",
      "synapse.ne.jp  => s y n a p p e d d b j p e p t t t t || s y n a p s e dot n e dot j p \n",
      "                  ['\"', 'touristic', 'information', 'on', '<SAMPLE>', '\"', '.']\n"
     ]
    }
   ],
   "source": [
    "print_local_wrong_predictions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1310000   3% (   5m 6s)   0.235   |   0.00: in -> in (✓) \n",
      "1320000   7% (  10m 2s)   0.318   |   0.00: & -> and (✓) \n",
      "1330000  10% (  15m 9s)   0.255   |   0.00: vol -> volume (✓) \n",
      "1340000  13% ( 20m 10s)   0.265   |   0.00: two -> two (✓) \n",
      "1350000  17% (  25m 8s)   0.284   |   0.00: _ -> underscore (✓) \n",
      "Saved model to data/models/whole_gen_13_2_only_chars_smaller/1350000_(EncoderRNN/DecoderRNN)\n",
      "Accuracy: 89.10% (    8910/   10000)\n",
      "1360000  20% ( 31m 47s)   0.259   |   0.00: IDF -> i d f (✓) \n",
      "1370000  23% ( 36m 37s)   0.262   |   0.00: Brooks -> brooks (✓) \n",
      "1380000  27% ( 41m 35s)   0.300   |   0.00: the -> the (✓) \n",
      "1390000  30% ( 46m 42s)   0.297   |   0.00: civil -> civil (✓) \n",
      "1400000  33% ( 51m 48s)   0.245   |   0.00: 1 -> one (✓) \n",
      "Saved model to data/models/whole_gen_13_2_only_chars_smaller/1400000_(EncoderRNN/DecoderRNN)\n",
      "Accuracy: 89.14% (    8914/   10000)\n",
      "1410000  37% ( 58m 24s)   0.241   |   0.00: vol -> volume (✓) \n",
      "1420000  40% ( 63m 22s)   0.327   |   5.09: Dec. 2014 -> d e c dot ntt t tttttttte (✗: december twenty fourteen) \n",
      "1430000  43% ( 68m 28s)   0.250   |   0.00: Energy -> energy (✓) \n",
      "1440000  47% ( 73m 31s)   0.224   |   0.00: the -> the (✓) \n",
      "1450000  50% ( 78m 35s)   0.292   |   0.00: acres -> acres (✓) \n",
      "Saved model to data/models/whole_gen_13_2_only_chars_smaller/1450000_(EncoderRNN/DecoderRNN)\n",
      "Accuracy: 88.73% (    8873/   10000)\n",
      "1460000  53% ( 85m 10s)   0.247   |   0.00: HMS -> h m s (✓) \n",
      "1470000  57% ( 90m 22s)   0.315   |   0.00: painter -> painter (✓) \n",
      "1480000  60% ( 95m 18s)   0.308   |   0.00: that -> that (✓) \n",
      "1490000  63% (100m 18s)   0.208   |   0.00: 3 -> three (✓) \n",
      "1500000  67% (105m 19s)   0.266   |   0.00: mr -> mister (✓) \n",
      "Saved model to data/models/whole_gen_13_2_only_chars_smaller/1500000_(EncoderRNN/DecoderRNN)\n",
      "Accuracy: 89.40% (    8940/   10000)\n",
      "1510000  70% (111m 55s)   0.305   |   0.00: Classic -> classic (✓) \n",
      "1520000  73% ( 117m 3s)   0.331   |   0.00: - -> to (✓) \n",
      "1530000  77% (121m 58s)   0.285   |   0.00: & -> and (✓) \n",
      "1540000  80% ( 127m 1s)   0.289   |   0.00: - -> to (✓) \n",
      "1550000  83% ( 132m 9s)   0.318   |   0.00: eds -> e d s (✓) \n",
      "Saved model to data/models/whole_gen_13_2_only_chars_smaller/1550000_(EncoderRNN/DecoderRNN)\n",
      "Accuracy: 88.36% (    8836/   10000)\n",
      "1560000  87% (138m 59s)   0.318   |   0.00: x -> by (✓) \n",
      "1570000  90% (143m 59s)   0.340   |   0.00: Taking -> taking (✓) \n",
      "1580000  93% ( 149m 8s)   0.333   |   0.00: Award -> award (✓) \n",
      "1590000  97% (154m 17s)   0.292   |   0.00: knowledge -> knowledge (✓) \n",
      "1600000 100% (159m 17s)   0.199   |   0.00: SW -> s w (✓) \n",
      "Saved model to data/models/whole_gen_13_2_only_chars_smaller/1600000_(EncoderRNN/DecoderRNN)\n",
      "Accuracy: 88.86% (    8886/   10000)\n"
     ]
    }
   ],
   "source": [
    "train_iterations(n_iters=300000, print_every=10000, teacher_forcing_ratio=0, lr=0.0005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "March 8, 2013  => march eighth tttttttetteetteeteetee || march eighth twenty thirteen \n",
      "                  ['eakin', ',', 'marah', '(', '<SAMPLE>', ')', '.']\n",
      "19 June 2007   => the eightt nfh of    eeeeeeeent eeeeeeeeeeeeeeeeee || the nineteenth of june two thousand seven \n",
      "                  ['retrieved', '<SAMPLE>', '.']\n",
      "November 30, 2009 => november thirt tttwontttttsnsene || november thirtieth two thousand nine \n",
      "                  ['leonard', ',', 'tod', '(', '<SAMPLE>', ')', '.']\n",
      "NINJA          => n i n j a      || ninja \n",
      "                  ['\"', '<SAMPLE>', ':', 'hero', 'or', 'master', 'fake', '?']\n",
      "2nd            => secon          || second \n",
      "                  ['the', '<SAMPLE>', 'battalion', 'returned', 'to', 'britain', 'where', 'it', 'was', 'absorbed', 'by', 'the', '1st', 'battalion', 'in', '1819', '.']\n",
      "2011-01-28     => twe tiety einth          tteeeeeeeeeeeeeeeeeeeeeee || the twenty eighth of january twenty eleven \n",
      "                  ['retrieved', 'on', '<SAMPLE>', '.']\n",
      "February 2006  => february two thoottosan || february two thousand six \n",
      "                  ['jones', ',', 'preston', ';', 'wanex', ',', 'l', '.', 'f', '.', '(', '<SAMPLE>', ')', '.']\n",
      "August 15, 2008 => august fifthet tweetettttteeeeeeeeeeeeeeeeeeeeeeee || august fifteenth two thousand eight \n",
      "                  ['\"', 'spd', 'and', 'salym', 'project', ':', 'major', 'events', 'and', 'milestones', ',', 'salym', 'petroleum', 'development', 'corporation', ',', 'viewed', '<SAMPLE>', '\"', '.']\n",
      "February 19, 1987 => february ninert ninent nineneen h nine nninene nin || february nineteenth nineteen eighty seven \n",
      "                  ['<SAMPLE>', '.']\n",
      "44.5           => forty four fidtfive || forty four point five \n",
      "                  ['the', 'median', 'age', 'was', '<SAMPLE>', 'years', '.']\n"
     ]
    }
   ],
   "source": [
    "print_local_wrong_predictions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "balanced_data_last_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "state_dict_path = 'data/models/whole_gen_13_1_only_chars_and_attn/100000_'\n",
    "\n",
    "decoder_rnn.load_state_dict(torch.load(state_dict_path + 'DecoderRNN'))\n",
    "encoder_rnn.load_state_dict(torch.load(state_dict_path + 'EncoderRNN'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iterations(n_iters=100000, print_every=10000, teacher_forcing_ratio=0.5, lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Updated target_arr to include eos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_local_wrong_predictions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iterations(n_iters=50000, print_every=10000, teacher_forcing_ratio=0.5, lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "char_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "state_dict_path = 'data/models/whole_gen_13_1_only_chars_and_attn/100000_'\n",
    "\n",
    "decoder_rnn.load_state_dict(torch.load(state_dict_path + 'DecoderRNN'))\n",
    "encoder_rnn.load_state_dict(torch.load(state_dict_path + 'EncoderRNN'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iterations(n_iters=100000, print_every=10000, teacher_forcing_ratio=0.5, lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "state_dict_path = 'data/models/whole_gen_13_1_only_chars_and_attn/250000_'\n",
    "\n",
    "decoder_rnn.load_state_dict(torch.load(state_dict_path + 'DecoderRNN'))\n",
    "encoder_rnn.load_state_dict(torch.load(state_dict_path + 'EncoderRNN'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iterations(n_iters=100000, print_every=10000, teacher_forcing_ratio=0.5, lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "state_dict_path = 'data/models/whole_gen_13_1_only_chars_and_attn/300000_'\n",
    "\n",
    "decoder_rnn.load_state_dict(torch.load(state_dict_path + 'DecoderRNN'))\n",
    "encoder_rnn.load_state_dict(torch.load(state_dict_path + 'EncoderRNN'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_iterations(n_iters=200000, print_every=10000, teacher_forcing_ratio=0.2, lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print_local_wrong_predictions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_iterations(n_iters=500000, print_every=10000, teacher_forcing_ratio=0, lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print_local_wrong_predictions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_iterations(n_iters=500000, print_every=10000, teacher_forcing_ratio=0, lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print_local_wrong_predictions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_iterations(n_iters=400000, print_every=10000, teacher_forcing_ratio=0, lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_iterations(n_iters=10000, lr=0.001, print_every=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print_local_wrong_predictions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_iterations(n_iters=200000, print_every=10000, teacher_forcing_ratio=0.3, lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "state_dict_path = 'data/models/whole_gen_13_only_chars_and_attn/10_'\n",
    "#state_dict_path = 'data/models/whole_gen_13_only_chars_and_attn/250000_'\n",
    "\n",
    "decoder_rnn.load_state_dict(torch.load(state_dict_path + 'DecoderRNN'))\n",
    "encoder_rnn.load_state_dict(torch.load(state_dict_path + 'EncoderRNN'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "balanced_data.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "balanced_data.groupby('class')['class'].count()\n",
    "len(balanced_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def balanced_data_randomize_long():\n",
    "    global balanced_data, balanced_data_length, balanced_data_accessed_counter, balanced_data_randomize_freq\n",
    "    \n",
    "    bal_data = pd.concat([v.sample(min(2000, len(v))) for k, v in balanced_data_classes_select])\n",
    "    long_data = sample_data[sample_data['before'].str.len()>8].sample(4000)\n",
    "    elec_data = sample_data[sample_data['class']=='ELECTRONIC']\n",
    "    let_long_data = sample_data[(sample_data['class'] == 'LETTERS') & (sample_data['before'].str.len() > 5)]\n",
    "    balanced_data = pd.concat([bal_data, long_data, elec_data, let_long_data])#.drop_duplicates()\n",
    "    balanced_data = balanced_data[~balanced_data.index.duplicated(keep='first')]\n",
    "    \n",
    "    balanced_data_length = len(balanced_data)\n",
    "    balanced_data_randomize_freq = balanced_data_length * 0.5\n",
    "    balanced_data_accessed_counter = 0\n",
    "\n",
    "balanced_data_randomize = balanced_data_randomize_long\n",
    "balanced_data_randomize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input:   1,366\n",
      "output:  ['e', 'i', 'g', 'h', 't', ' ', 't', 'h', 'h', 'u', 'e', 'd', 'n', 't', 'e', 'e', ' ', 't', 'e']\n",
      "target:  one thousand three hundred sixty six\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlYAAAFpCAYAAABeYWb6AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n0fv9KQM1AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f001da622b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def debug_show_attention(input_sentence, output_words, attentions):\n",
    "    # Set up figure with colorbar\n",
    "    fig = plt.figure(figsize=(15,6))\n",
    "    ax = fig.add_subplot(111)\n",
    "    #cax = ax.matshow(attentions.numpy(), cmap='bone')\n",
    "    cax = ax.matshow(attentions, cmap='bone')\n",
    "    fig.colorbar(cax)\n",
    "    # Set up axes\n",
    "    #ax.set_xticklabels([''] + input_sentence.split(' ') + ['<EOS>'], rotation=90)\n",
    "    #ax.set_xticklabels([''] + input_sentence + ['<EOS>'], rotation=90)\n",
    "    ax.set_yticklabels([''] + output_words)\n",
    "    \n",
    "    input_sentence = input_sentence + ['<EOS>']\n",
    "    #inp_arr = [\"{}\\n{}\".format(input_sentence[i], input_sentence[-1-i]) for i in range(len(input_sentence))]\n",
    "    inp_arr = input_sentence\n",
    "    ax.set_xticklabels([''] + inp_arr, rotation=0)\n",
    "\n",
    "    # Show label at every tick\n",
    "    ax.xaxis.set_major_locator(matplotlib.ticker.MultipleLocator(1))\n",
    "    ax.yaxis.set_major_locator(matplotlib.ticker.MultipleLocator(1))\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "def debug_eval_sample_show_attention():\n",
    "    \n",
    "    sample_row = balanced_data_sample_row()\n",
    "    #sample_row = balanced_data[balanced_data['before'].str.len()>15].sample(1).iloc[0]\n",
    "    sample = sample_row['before'], sample_row['a_word_ind'], sample_row['class'], sample_row['sentence'].split(' ')\n",
    "    #sample = 'www.google.com', '', '', 'here goes'.split(' ')\n",
    "\n",
    "    output, decoded_output, decoder_attns_arr, sample = test_model_single_sample(None, \n",
    "                                                            return_more=True, sample=sample)\n",
    "    print('input:  ', sample[0])\n",
    "    print('output: ', decoded_output)\n",
    "    print('target: ', sample_row['after'])\n",
    "\n",
    "    attns = np.array([arr.data[0].cpu().numpy() for arr in decoder_attns_arr])\n",
    "\n",
    "    debug_show_attention(list(sample[0]), decoded_output, attns)\n",
    "    #plt.matshow(attns)\n",
    "\n",
    "debug_eval_sample_show_attention()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "balanced_data.groupby('class')['class'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test_in_categories(iter_len = 1000):\n",
    "    wrong_preds = {}\n",
    "    for cat in categories_all:\n",
    "        tmp_data = sample_data[sample_data['class'] == cat].sample(iter_len)\n",
    "        correct_n = 0\n",
    "        wrong_preds_arr = []\n",
    "\n",
    "        for _ in range(iter_len):\n",
    "            sample_row = tmp_data.iloc[_]\n",
    "            sample = sample_row['before'], sample_row['a_word_ind'], sample_row['class'], sample_row['sentence']\n",
    "\n",
    "            output, t1, sample_target, t2 = test_model_single_sample(None, sample=sample)\n",
    "            if output == sample_target:\n",
    "                correct_n += 1\n",
    "            else:\n",
    "                wrong_preds_arr.append([sample_target, output])\n",
    "\n",
    "        print(\"{:>10}: {:>5d}/{:>5d} ({:>4.0%})\".format(cat, correct_n, iter_len, correct_n/iter_len))\n",
    "        wrong_preds[cat] = wrong_preds_arr\n",
    "    return wrong_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wrong_preds = test_in_categories(3000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wrong_preds['LETTERS']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# With training longer words\n",
    "wrong_preds = test_in_categories()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:py3_pytorch_2]",
   "language": "python",
   "name": "conda-env-py3_pytorch_2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
