{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pytorch utils oh: pytorch_utils_oh_2.py\n",
      "Pytorch: 0.2.0_4\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import importlib\n",
    "from pytorch_utils_oh_2 import *\n",
    "import IPython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MODEL_SAVE_PATH = 'electronic_gen_5_testing'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pytorch utils oh: pytorch_utils_oh_2.py\n",
      "Pytorch: 0.2.0_4\n"
     ]
    }
   ],
   "source": [
    "import pytorch_utils_oh_2; importlib.reload(pytorch_utils_oh_2); from pytorch_utils_oh_2 import *;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# all_data = pickle.load(open(\"data/en_train_fixed_4_sentences.pkl\", \"rb\" ))\n",
    "all_data = pickle.load(open(\"data/en_train_fixed_5_manual.pkl\", \"rb\" ))\n",
    "# all_data_sentence_index = all_data.set_index('sentence_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>token_id</th>\n",
       "      <th>class</th>\n",
       "      <th>before</th>\n",
       "      <th>after</th>\n",
       "      <th>class_org</th>\n",
       "      <th>a_word_ind</th>\n",
       "      <th>sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9635208</th>\n",
       "      <td>727208</td>\n",
       "      <td>12</td>\n",
       "      <td>LETTERS</td>\n",
       "      <td>Eora</td>\n",
       "      <td>e o r a</td>\n",
       "      <td>LETTERS</td>\n",
       "      <td>[28, 25, 35, 22, 0]</td>\n",
       "      <td>clark was also quite friendly with local abori...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2720491</th>\n",
       "      <td>210686</td>\n",
       "      <td>5</td>\n",
       "      <td>ELECTRONIC</td>\n",
       "      <td>WebMineral.com</td>\n",
       "      <td>w e b m i n e r a l dot c o m</td>\n",
       "      <td>ELECTRONIC</td>\n",
       "      <td>[52, 28, 36, 32, 31, 29, 28, 35, 22, 42, 74, 2...</td>\n",
       "      <td>alum ( na ) , &lt;SAMPLE&gt; , retrieved 2009 - 11 -...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         sentence_id  token_id       class          before  \\\n",
       "9635208       727208        12     LETTERS            Eora   \n",
       "2720491       210686         5  ELECTRONIC  WebMineral.com   \n",
       "\n",
       "                                 after   class_org  \\\n",
       "9635208                        e o r a     LETTERS   \n",
       "2720491  w e b m i n e r a l dot c o m  ELECTRONIC   \n",
       "\n",
       "                                                a_word_ind  \\\n",
       "9635208                                [28, 25, 35, 22, 0]   \n",
       "2720491  [52, 28, 36, 32, 31, 29, 28, 35, 22, 42, 74, 2...   \n",
       "\n",
       "                                                  sentence  \n",
       "9635208  clark was also quite friendly with local abori...  \n",
       "2720491  alum ( na ) , <SAMPLE> , retrieved 2009 - 11 -...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "32992"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data = all_data[(all_data['class'] == 'LETTERS') | (all_data['class'] == 'ELECTRONIC')]\n",
    "all_data = all_data[all_data['after'].str.len() > 5]\n",
    "all_data.sample(2)\n",
    "len(all_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sample_data = all_data.copy()\n",
    "sample_data = sample_data.reset_index(drop=True)\n",
    "del(all_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sample_data = all_data.copy()\n",
    "sample_data = sample_data[sample_data['class'] == 'ELECTRONIC']\n",
    "print(\"Data rows: {},  (dropped rows: {})\".format(len(sample_data), len(all_data)-len(sample_data)))\n",
    "sample_data = sample_data.reset_index(drop=True)\n",
    "del(all_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ELECTRONIC', 'LETTERS']\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "categories_all = sorted(sample_data[\"class\"].unique())\n",
    "print(categories_all)\n",
    "print(len(categories_all))\n",
    "categories_index = dict((c, i) for i, c in enumerate(categories_all))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>token_id</th>\n",
       "      <th>class</th>\n",
       "      <th>before</th>\n",
       "      <th>after</th>\n",
       "      <th>class_org</th>\n",
       "      <th>a_word_ind</th>\n",
       "      <th>sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14581</th>\n",
       "      <td>339016</td>\n",
       "      <td>5</td>\n",
       "      <td>LETTERS</td>\n",
       "      <td>CFAC</td>\n",
       "      <td>c f a c</td>\n",
       "      <td>LETTERS</td>\n",
       "      <td>[21, 37, 22, 21, 0]</td>\n",
       "      <td>since its opening , the &lt;SAMPLE&gt; has hosted ov...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12241</th>\n",
       "      <td>282249</td>\n",
       "      <td>3</td>\n",
       "      <td>ELECTRONIC</td>\n",
       "      <td>apl.de.ap</td>\n",
       "      <td>a p l dot d e dot a p</td>\n",
       "      <td>ELECTRONIC</td>\n",
       "      <td>[22, 24, 42, 74, 26, 28, 74, 22, 24, 0]</td>\n",
       "      <td>\" look : &lt;SAMPLE&gt; returns as ' voice ph ' coac...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       sentence_id  token_id       class     before                  after  \\\n",
       "14581       339016         5     LETTERS       CFAC                c f a c   \n",
       "12241       282249         3  ELECTRONIC  apl.de.ap  a p l dot d e dot a p   \n",
       "\n",
       "        class_org                               a_word_ind  \\\n",
       "14581     LETTERS                      [21, 37, 22, 21, 0]   \n",
       "12241  ELECTRONIC  [22, 24, 42, 74, 26, 28, 74, 22, 24, 0]   \n",
       "\n",
       "                                                sentence  \n",
       "14581  since its opening , the <SAMPLE> has hosted ov...  \n",
       "12241  \" look : <SAMPLE> returns as ' voice ph ' coac...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_data.sample(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utils stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<SOS><EOS>☒ !\"#$%&'(),-./0123456789:;ABCDEFGHIJKLMNOPQRSTUVWXYZ_abcdefghijklmnopqrstuvwxyz~£¥ª²³µº¼½¾éɒʻˈΩμ—€⅓⅔⅛\n"
     ]
    }
   ],
   "source": [
    "chars_normal, chars_normal_index = load_characters_pkl('data/en_features/chars_normal.pkl')\n",
    "print(''.join(chars_normal))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "arr = list(sample_data['after'])\n",
    "arr = [s.split(' ') for s in arr]\n",
    "words_after = [EOS_TOKEN, SOS_TOKEN, UNKNOWN_WORD_TOKEN, NUMBER_WORD_TOKEN, SAMPLE_WORD_TOKEN]\n",
    "words_after = words_after + sorted(list(set(np.concatenate(arr))))\n",
    "words_after_index = dict((c, i) for i, c in enumerate(words_after))\n",
    "words_after_by_length = sorted(words_after, key=len, reverse=True)\n",
    "words_after_regex = re.compile('(' + ')|('.join(words_after_by_length) + ')')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "152"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(words_after)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "chars_after = [EOS_TOKEN, SOS_TOKEN] + sorted(list(set(list(''.join(list(sample_data['after']))))))\n",
    "chars_after_index = dict((c, i) for i, c in enumerate(chars_after))\n",
    "''.join(chars_after)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[32, 26, 92, 19, 0]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "['dot', 'd', 'o', 'c', '<EOS>']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def after_sentence_to_word_indexes(sentence, include_eos=True):\n",
    "    reg = re.finditer(words_after_regex, sentence)\n",
    "    arr = [words_after_index[s[0]] for s in reg]\n",
    "    if include_eos:\n",
    "        arr += [words_after_index[EOS_TOKEN]]\n",
    "    return arr\n",
    "tmp = after_sentence_to_word_indexes('dot d o c')\n",
    "tmp\n",
    "[words_after[t] for t in tmp]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 152])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sos_tensor = torch.zeros(1, 1, len(words_after_index))\n",
    "sos_tensor[0, 0, words_after_index[SOS_TOKEN]] = 1\n",
    "sos_tensor.size()\n",
    "#del(onehot_sos)\n",
    "\n",
    "# sos_tensor = torch.LongTensor([words_after_index[SOS_TOKEN]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RPGs -> r p g's <EOS> [109, 100, 53, 0]\n",
      "torch.Size([1, 5, 104])\n"
     ]
    }
   ],
   "source": [
    "balanced_data_length = len(sample_data)\n",
    "def get_random_sample():\n",
    "    #sample_row = balanced_data_sample_row()\n",
    "    sample_row = balanced_data_last_sample = sample_data.iloc[random.randint(1, balanced_data_length-1)]\n",
    "    \n",
    "    a_words_ind = after_sentence_to_word_indexes(sample_row['after'], include_eos=True)\n",
    "    return sample_row['before'], a_words_ind\n",
    "            \n",
    "def tmp():\n",
    "    s_bef, s_aft = get_random_sample()\n",
    "    s_aft_str = ' '.join([words_after[i] for i in s_aft])\n",
    "    print(s_bef, '->', s_aft_str, s_aft)\n",
    "    print(string_to_tensor(s_bef, chars_normal_index).shape)\n",
    "tmp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "249 µs ± 8.73 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "get_random_sample()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "use_cuda = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MAX_ATTENTION_LENGTH = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "498"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>token_id</th>\n",
       "      <th>class</th>\n",
       "      <th>before</th>\n",
       "      <th>after</th>\n",
       "      <th>class_org</th>\n",
       "      <th>a_word_ind</th>\n",
       "      <th>sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18870</th>\n",
       "      <td>440736</td>\n",
       "      <td>3</td>\n",
       "      <td>ELECTRONIC</td>\n",
       "      <td>http://tvbythenumbers.zap2it.com/2010/09/07/sy...</td>\n",
       "      <td>h t t p colon slash slash t v b y t h e n u m ...</td>\n",
       "      <td>ELECTRONIC</td>\n",
       "      <td>[45, 30, 30, 24, 129, 101, 101, 30, 54, 36, 86...</td>\n",
       "      <td>retrieved 2010 - 09 - 07 . &lt;SAMPLE&gt; , stuart (...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2047</th>\n",
       "      <td>52595</td>\n",
       "      <td>8</td>\n",
       "      <td>ELECTRONIC</td>\n",
       "      <td>https://www.eastleigh.gov.uk/the-council/mayor...</td>\n",
       "      <td>h t t p s colon slash slash w w w dot e a s t ...</td>\n",
       "      <td>ELECTRONIC</td>\n",
       "      <td>[45, 30, 30, 24, 17, 129, 101, 101, 52, 52, 52...</td>\n",
       "      <td>memoirs of the american academy in rome 12 &lt;SA...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       sentence_id  token_id       class  \\\n",
       "18870       440736         3  ELECTRONIC   \n",
       "2047         52595         8  ELECTRONIC   \n",
       "\n",
       "                                                  before  \\\n",
       "18870  http://tvbythenumbers.zap2it.com/2010/09/07/sy...   \n",
       "2047   https://www.eastleigh.gov.uk/the-council/mayor...   \n",
       "\n",
       "                                                   after   class_org  \\\n",
       "18870  h t t p colon slash slash t v b y t h e n u m ...  ELECTRONIC   \n",
       "2047   h t t p s colon slash slash w w w dot e a s t ...  ELECTRONIC   \n",
       "\n",
       "                                              a_word_ind  \\\n",
       "18870  [45, 30, 30, 24, 129, 101, 101, 30, 54, 36, 86...   \n",
       "2047   [45, 30, 30, 24, 17, 129, 101, 101, 52, 52, 52...   \n",
       "\n",
       "                                                sentence  \n",
       "18870  retrieved 2010 - 09 - 07 . <SAMPLE> , stuart (...  \n",
       "2047   memoirs of the american academy in rome 12 <SA...  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>token_id</th>\n",
       "      <th>class</th>\n",
       "      <th>before</th>\n",
       "      <th>after</th>\n",
       "      <th>class_org</th>\n",
       "      <th>a_word_ind</th>\n",
       "      <th>sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21453</th>\n",
       "      <td>491251</td>\n",
       "      <td>1</td>\n",
       "      <td>ELECTRONIC</td>\n",
       "      <td>StoneDeadline.comDeadline.comDeadline.comDeadl...</td>\n",
       "      <td>s t o n e d e a d l i n e dot c o m d e a d l ...</td>\n",
       "      <td>ELECTRONIC</td>\n",
       "      <td>[17, 30, 25, 29, 28, 26, 28, 22, 26, 42, 31, 2...</td>\n",
       "      <td>deadline . comdeadline . comvarietydeadline . ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11533</th>\n",
       "      <td>265794</td>\n",
       "      <td>3</td>\n",
       "      <td>ELECTRONIC</td>\n",
       "      <td>2000Myspace.comTempleofschlock.blogpsot.comBil...</td>\n",
       "      <td>t w o o o o m y s p a c e dot c o m t e m p l ...</td>\n",
       "      <td>ELECTRONIC</td>\n",
       "      <td>[30, 52, 25, 25, 25, 25, 32, 86, 17, 24, 22, 2...</td>\n",
       "      <td>7th edn , &lt;SAMPLE&gt; vol 89 # 8 ( 26 february 19...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       sentence_id  token_id       class  \\\n",
       "21453       491251         1  ELECTRONIC   \n",
       "11533       265794         3  ELECTRONIC   \n",
       "\n",
       "                                                  before  \\\n",
       "21453  StoneDeadline.comDeadline.comDeadline.comDeadl...   \n",
       "11533  2000Myspace.comTempleofschlock.blogpsot.comBil...   \n",
       "\n",
       "                                                   after   class_org  \\\n",
       "21453  s t o n e d e a d l i n e dot c o m d e a d l ...  ELECTRONIC   \n",
       "11533  t w o o o o m y s p a c e dot c o m t e m p l ...  ELECTRONIC   \n",
       "\n",
       "                                              a_word_ind  \\\n",
       "21453  [17, 30, 25, 29, 28, 26, 28, 22, 26, 42, 31, 2...   \n",
       "11533  [30, 52, 25, 25, 25, 25, 32, 86, 17, 24, 22, 2...   \n",
       "\n",
       "                                                sentence  \n",
       "21453  deadline . comdeadline . comvarietydeadline . ...  \n",
       "11533  7th edn , <SAMPLE> vol 89 # 8 ( 26 february 19...  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp = sample_data[sample_data['before'].str.len()>MAX_ATTENTION_LENGTH]\n",
    "len(tmp)\n",
    "tmp.sample(2)\n",
    "tmp[~tmp['before'].str.contains('/')].sample(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EncoderRNN (\n",
       "  (rnn_chars): GRU(104, 128, batch_first=True, bidirectional=True)\n",
       ")"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, chars_input_size, chars_hidden_size, chars_layers=1):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        \n",
    "        self.chars_layers = chars_layers\n",
    "        self.chars_hidden_size = chars_hidden_size\n",
    "\n",
    "        #self.rnn_chars = nn.LSTM(chars_input_size, chars_hidden_size//2, chars_layers,\n",
    "        #                         # batch_first=True, bidirectional=False)\n",
    "        #                         batch_first=True, bidirectional=True)\n",
    "        \n",
    "        self.rnn_chars = nn.GRU(chars_input_size, chars_hidden_size//2, chars_layers,\n",
    "                         # batch_first=True, bidirectional=False)\n",
    "                         batch_first=True, bidirectional=True)\n",
    "        \n",
    "    def forward(self, string_tensor, hidden = None, init_hidden = True):\n",
    "        if init_hidden:\n",
    "            hidden_chars = self.init_hidden()\n",
    "        \n",
    "        #all_outputs_chars, hidden_chars = self.rnn_chars(string_tensor, hidden_chars)\n",
    "        \n",
    "        all_outputs_chars, hidden_chars = self.rnn_chars(string_tensor, hidden_chars[0])\n",
    "        \n",
    "        return all_outputs_chars, hidden_chars\n",
    "        output_chars = all_outputs_chars[:, -1]\n",
    "        \n",
    "        hidden_states_cat = Variable(torch.zeros(MAX_ATTENTION_LENGTH, self.chars_hidden_size)).cuda()\n",
    "        for ei in range(min(MAX_ATTENTION_LENGTH, len(string_tensor[0]))):\n",
    "            hidden_states_cat[ei] = all_outputs_chars[0, ei]\n",
    "                \n",
    "        #return output, all_outputs_chars\n",
    "        return output_chars[0], hidden_states_cat\n",
    "\n",
    "    def init_hidden(self):\n",
    "        var2_1 = Variable(torch.zeros(2 * self.chars_layers, 1, self.chars_hidden_size//2))\n",
    "        var2_2 = Variable(torch.zeros(2 * self.chars_layers, 1, self.chars_hidden_size//2))\n",
    "        \n",
    "        var2_1 = var2_1.cuda(); var2_2 = var2_2.cuda()\n",
    "        return (var2_1, var2_2)\n",
    "    \n",
    "    \n",
    "encoder_rnn = EncoderRNN(chars_input_size=len(chars_normal),\n",
    "                         chars_hidden_size=256, chars_layers=1).cuda()\n",
    "encoder_rnn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 5, 104])"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string_t.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_chars = encoder_rnn.rnn_chars\n",
    "hidden = Variable(torch.zeros(2, 1, 256//2)).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 304,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden = Variable(torch.zeros(2, 1, 256//2)).cuda()\n",
    "hidden_2 = Variable(torch.zeros(2, 1, 256//2)).cuda()\n",
    "arr = [] \n",
    "arr2 = [] \n",
    "for i in range(1):#range(len(s_bef)):\n",
    "    rnn_result, hidden = rnn_chars(string_t[:,i].unsqueeze(0), hidden)\n",
    "    arr.append(rnn_result)\n",
    "    \n",
    "    rnn_result_2, hidden_2 = rnn_chars(string_t[:,-i].unsqueeze(0), hidden_2)\n",
    "    arr2.append(rnn_result_2)\n",
    "len(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 256])"
      ]
     },
     "execution_count": 305,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr[0].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 1, 128])"
      ]
     },
     "execution_count": 306,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 308,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 308,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(arr[-1][0,0,:128] == hidden[0,0]).data.all()\n",
    "(arr[-1][0,0,128:] == hidden[1,0]).data.all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 0\n",
       "[torch.cuda.ByteTensor of size 128 (GPU 0)]"
      ]
     },
     "execution_count": 267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnn_result[0,0,:128] == rnn_result[0,0,128:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hidden[0,0] == tmp_b[0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 104])"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string_t[:,0].unsqueeze(0).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 256])"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 1, 128])"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a,b = rnn_chars(string_t[:,0].unsqueeze(0), hidden)\n",
    "a.size()\n",
    "b.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(a[0, -1][:128] == b[0][0]).data.all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(a[0, -1][128:] == b[1][0]).data.all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(tmp_a[0, -1][:128] == tmp_b[0][0]).data.all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(tmp_a[0, 0][128:] == tmp_b[1][0]).data.all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(a==tmp_a).data.all()\n",
    "(b==tmp_b).data.all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ISBN'"
      ]
     },
     "execution_count": 313,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 4, 256])"
      ]
     },
     "execution_count": 313,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#s_bef, s_aft = get_random_sample()\n",
    "s_bef\n",
    "string_t = string_to_tensor(s_bef, chars_normal_index, include_eos=False)\n",
    "string_t = Variable(string_t).cuda()\n",
    " \n",
    "tmp_a, tmp_b = encoder_rnn(string_t)\n",
    "tmp_a.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 1, 128])"
      ]
     },
     "execution_count": 314,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp_b.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 128])"
      ]
     },
     "execution_count": 315,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 128])"
      ]
     },
     "execution_count": 315,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp_b[0].size()\n",
    "tmp_b[1].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 4, 256])"
      ]
     },
     "execution_count": 316,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp_a.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 317,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.eq(tmp_a[0, -1][:128], tmp_b[0][0]).data.all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 318,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.eq(tmp_a[0, 0][128:], tmp_b[1][0]).data.all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 256])"
      ]
     },
     "execution_count": 320,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp_b.view(1,-1).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 1  1  1  1  1\n",
       "[torch.FloatTensor of size 1x5]"
      ]
     },
     "execution_count": 322,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ten = torch.ones(1,5)\n",
    "ten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'torch.nn' has no attribute 'Padding'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-323-1076dd91b062>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPadding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mndim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: module 'torch.nn' has no attribute 'Padding'"
     ]
    }
   ],
   "source": [
    "nn.Padding(30, pad, ndim, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.eq(tmp_a[0, -1][128:], tmp_b[0][0]).data.all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 1 is out of range for dimension 0 (of size 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-95-692aec0cb25d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtmp_a\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtmp_b\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/py3_pytorch_2/lib/python3.6/site-packages/torch/autograd/variable.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m     74\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mIndexSelect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m             \u001b[0;31m# else fall through and raise an error in Index\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mIndex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py3_pytorch_2/lib/python3.6/site-packages/torch/autograd/_functions/tensor.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(ctx, i, index)\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madvanced_indexing\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_advanced_indexing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madvanced_indexing\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 1 is out of range for dimension 0 (of size 1)"
     ]
    }
   ],
   "source": [
    "#torch.eq(tmp_a[0, 0][128:], tmp_b[0][1]).data.all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [],
   "source": [
    "var = Variable(torch.zeros(10, 256)).cuda() \n",
    "var[0:4, :] = tmp_a[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       "[torch.cuda.ByteTensor of size 256 (GPU 0)]"
      ]
     },
     "execution_count": 340,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var[3] == tmp_a[0, 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 4, 256])"
      ]
     },
     "execution_count": 326,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp_a.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       "( 0 ,.,.) = \n",
       "\n",
       "Columns 0 to 5 \n",
       "  -3.5901e-02  3.3424e-02  2.1086e-02  2.6456e-02  3.2424e-03 -2.8453e-02\n",
       "\n",
       "Columns 6 to 11 \n",
       "  -3.9658e-03  2.9822e-03 -9.1939e-03 -4.9068e-02 -5.9038e-02 -3.0173e-03\n",
       "\n",
       "Columns 12 to 17 \n",
       "   1.4003e-02  5.4032e-02 -2.7449e-02 -2.0977e-02 -3.9236e-02  1.7325e-02\n",
       "\n",
       "Columns 18 to 23 \n",
       "  -1.7254e-02  6.0257e-02 -4.1839e-02 -2.7712e-02  9.0128e-02 -2.7616e-02\n",
       "\n",
       "Columns 24 to 29 \n",
       "  -2.8029e-02  2.4453e-02 -2.6970e-02 -5.7464e-02 -6.2279e-02 -1.7502e-04\n",
       "\n",
       "Columns 30 to 35 \n",
       "  -1.7628e-02  3.1261e-02  3.3015e-02  5.2114e-02 -5.2699e-02  3.3634e-02\n",
       "\n",
       "Columns 36 to 41 \n",
       "   3.8681e-03  1.1507e-02  1.7050e-02 -1.2760e-02 -1.7624e-02  1.0668e-02\n",
       "\n",
       "Columns 42 to 47 \n",
       "   6.3007e-02  6.3538e-02  7.1745e-02 -2.5703e-02 -6.8111e-02  3.3389e-02\n",
       "\n",
       "Columns 48 to 53 \n",
       "   1.0935e-02  4.9186e-02  5.2750e-02  1.3243e-02 -6.2038e-02 -2.4470e-02\n",
       "\n",
       "Columns 54 to 59 \n",
       "  -3.3816e-02 -5.6037e-02 -6.7744e-02 -1.0007e-02  4.5078e-03 -5.5131e-03\n",
       "\n",
       "Columns 60 to 65 \n",
       "   4.6660e-02 -3.5627e-02  4.5711e-02  1.9766e-03 -3.8702e-02 -2.1316e-02\n",
       "\n",
       "Columns 66 to 71 \n",
       "  -8.7357e-02  5.6672e-02  6.1361e-03 -6.1340e-02  5.6640e-03 -1.3068e-02\n",
       "\n",
       "Columns 72 to 77 \n",
       "   1.9688e-02 -1.1813e-01 -1.2725e-02 -2.2661e-02 -5.3302e-02  1.7122e-02\n",
       "\n",
       "Columns 78 to 83 \n",
       "  -7.5270e-02 -1.3934e-02 -7.4152e-05  2.0420e-02 -3.1153e-02  4.0402e-02\n",
       "\n",
       "Columns 84 to 89 \n",
       "  -2.2235e-02  2.0444e-02  2.5485e-02  3.6986e-02  1.2221e-02 -2.6381e-02\n",
       "\n",
       "Columns 90 to 95 \n",
       "   3.7217e-03 -1.4112e-02 -3.9542e-02 -1.5713e-02  7.9135e-02 -1.1064e-02\n",
       "\n",
       "Columns 96 to 101 \n",
       "  -3.2909e-02 -7.5597e-02  1.3956e-02  6.2413e-02 -3.2539e-02  1.4519e-02\n",
       "\n",
       "Columns 102 to 107 \n",
       "   9.6275e-03 -5.8208e-02 -3.4781e-02 -1.4591e-02 -9.5014e-03  5.8637e-02\n",
       "\n",
       "Columns 108 to 113 \n",
       "   5.3477e-03 -1.2680e-02  2.0561e-02 -6.9032e-02 -1.0237e-02  4.7858e-06\n",
       "\n",
       "Columns 114 to 119 \n",
       "  -3.4343e-03  4.2207e-02  2.2400e-02 -1.4554e-03 -2.3912e-02 -2.3251e-02\n",
       "\n",
       "Columns 120 to 125 \n",
       "  -1.6727e-02  6.4070e-02 -2.1184e-02 -6.9502e-02 -2.8880e-02 -2.3649e-02\n",
       "\n",
       "Columns 126 to 127 \n",
       "   4.5562e-02 -1.2684e-02\n",
       "\n",
       "( 1 ,.,.) = \n",
       "\n",
       "Columns 0 to 5 \n",
       "  -3.0912e-02 -4.0258e-02 -6.2033e-02 -1.6648e-02  5.0707e-02 -1.0352e-02\n",
       "\n",
       "Columns 6 to 11 \n",
       "   1.3204e-02  8.4592e-02 -2.5230e-02  4.1885e-02 -2.2709e-02  6.5163e-02\n",
       "\n",
       "Columns 12 to 17 \n",
       "   8.9312e-02 -4.4066e-03  2.0713e-02 -2.0696e-02  7.2510e-02 -8.6485e-03\n",
       "\n",
       "Columns 18 to 23 \n",
       "  -2.0958e-02 -2.7877e-02 -4.0005e-02  2.7601e-02 -1.0749e-02 -3.9201e-03\n",
       "\n",
       "Columns 24 to 29 \n",
       "   3.6592e-02  1.2551e-02 -1.9579e-02 -1.7485e-02  9.6945e-02 -6.6776e-03\n",
       "\n",
       "Columns 30 to 35 \n",
       "  -6.2473e-02 -6.2297e-02  9.4886e-03 -3.0980e-02 -2.0361e-03  5.0677e-03\n",
       "\n",
       "Columns 36 to 41 \n",
       "   6.0793e-02  4.1997e-03  3.4739e-02  4.2318e-02  2.0856e-02  7.0418e-02\n",
       "\n",
       "Columns 42 to 47 \n",
       "  -1.6521e-02  3.9221e-02  2.0258e-02  2.8662e-02 -5.8168e-04  1.8025e-02\n",
       "\n",
       "Columns 48 to 53 \n",
       "  -1.2615e-02 -5.7555e-02  9.3107e-02 -5.5103e-02 -1.1423e-02 -2.9827e-02\n",
       "\n",
       "Columns 54 to 59 \n",
       "   1.2346e-03 -4.6271e-02  3.6955e-02 -1.3041e-03  6.8550e-03  6.0299e-02\n",
       "\n",
       "Columns 60 to 65 \n",
       "   1.6848e-02  3.3201e-03  2.1647e-02  2.8079e-02 -7.5872e-02  2.2479e-02\n",
       "\n",
       "Columns 66 to 71 \n",
       "  -1.9418e-02  1.3306e-02 -6.3134e-02  1.0690e-02  1.9444e-02  1.6035e-02\n",
       "\n",
       "Columns 72 to 77 \n",
       "   7.6217e-02  1.2250e-02  2.8250e-02  1.8441e-02 -3.1792e-02 -1.4903e-02\n",
       "\n",
       "Columns 78 to 83 \n",
       "   4.1293e-02 -3.1115e-02  1.2878e-03  6.0540e-02 -2.2344e-02  1.3762e-02\n",
       "\n",
       "Columns 84 to 89 \n",
       "   9.3446e-03 -7.8066e-02  4.4177e-02 -8.3463e-03  3.3526e-02 -4.6281e-02\n",
       "\n",
       "Columns 90 to 95 \n",
       "  -1.6819e-02  1.5654e-02 -5.3463e-02 -5.0829e-02  4.3720e-02  1.9899e-02\n",
       "\n",
       "Columns 96 to 101 \n",
       "  -2.8656e-02  9.0908e-03 -3.1197e-02  9.6349e-03 -1.7994e-02 -3.7176e-03\n",
       "\n",
       "Columns 102 to 107 \n",
       "   4.5669e-02 -3.8736e-02  1.1821e-02 -5.2786e-02  6.3437e-03 -3.0847e-02\n",
       "\n",
       "Columns 108 to 113 \n",
       "  -1.9243e-02  8.8510e-02  6.3294e-03 -5.6640e-02  5.5979e-03 -4.7910e-03\n",
       "\n",
       "Columns 114 to 119 \n",
       "  -3.4346e-02 -2.4570e-02 -1.8498e-02  1.0589e-02 -3.7351e-02 -4.3559e-02\n",
       "\n",
       "Columns 120 to 125 \n",
       "  -5.0522e-02  1.7838e-02  2.9122e-02 -3.9293e-02 -5.6007e-02  3.3665e-02\n",
       "\n",
       "Columns 126 to 127 \n",
       "  -9.6576e-03 -2.1012e-02\n",
       "[torch.cuda.FloatTensor of size 2x1x128 (GPU 0)]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp_b[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       "-3.5901e-02\n",
       " 3.3424e-02\n",
       " 2.1086e-02\n",
       " 2.6456e-02\n",
       " 3.2424e-03\n",
       "-2.8453e-02\n",
       "-3.9658e-03\n",
       " 2.9822e-03\n",
       "-9.1939e-03\n",
       "-4.9068e-02\n",
       "-5.9038e-02\n",
       "-3.0173e-03\n",
       " 1.4003e-02\n",
       " 5.4032e-02\n",
       "-2.7449e-02\n",
       "-2.0977e-02\n",
       "-3.9236e-02\n",
       " 1.7325e-02\n",
       "-1.7254e-02\n",
       " 6.0257e-02\n",
       "-4.1839e-02\n",
       "-2.7712e-02\n",
       " 9.0128e-02\n",
       "-2.7616e-02\n",
       "-2.8029e-02\n",
       " 2.4453e-02\n",
       "-2.6970e-02\n",
       "-5.7464e-02\n",
       "-6.2279e-02\n",
       "-1.7502e-04\n",
       "-1.7628e-02\n",
       " 3.1261e-02\n",
       " 3.3015e-02\n",
       " 5.2114e-02\n",
       "-5.2699e-02\n",
       " 3.3634e-02\n",
       " 3.8681e-03\n",
       " 1.1507e-02\n",
       " 1.7050e-02\n",
       "-1.2760e-02\n",
       "-1.7624e-02\n",
       " 1.0668e-02\n",
       " 6.3007e-02\n",
       " 6.3538e-02\n",
       " 7.1745e-02\n",
       "-2.5703e-02\n",
       "-6.8111e-02\n",
       " 3.3389e-02\n",
       " 1.0935e-02\n",
       " 4.9186e-02\n",
       " 5.2750e-02\n",
       " 1.3243e-02\n",
       "-6.2038e-02\n",
       "-2.4470e-02\n",
       "-3.3816e-02\n",
       "-5.6037e-02\n",
       "-6.7744e-02\n",
       "-1.0007e-02\n",
       " 4.5078e-03\n",
       "-5.5131e-03\n",
       " 4.6660e-02\n",
       "-3.5627e-02\n",
       " 4.5711e-02\n",
       " 1.9766e-03\n",
       "-3.8702e-02\n",
       "-2.1316e-02\n",
       "-8.7357e-02\n",
       " 5.6672e-02\n",
       " 6.1361e-03\n",
       "-6.1340e-02\n",
       " 5.6640e-03\n",
       "-1.3068e-02\n",
       " 1.9688e-02\n",
       "-1.1813e-01\n",
       "-1.2725e-02\n",
       "-2.2661e-02\n",
       "-5.3302e-02\n",
       " 1.7122e-02\n",
       "-7.5270e-02\n",
       "-1.3934e-02\n",
       "-7.4152e-05\n",
       " 2.0420e-02\n",
       "-3.1153e-02\n",
       " 4.0402e-02\n",
       "-2.2235e-02\n",
       " 2.0444e-02\n",
       " 2.5485e-02\n",
       " 3.6986e-02\n",
       " 1.2221e-02\n",
       "-2.6381e-02\n",
       " 3.7217e-03\n",
       "-1.4112e-02\n",
       "-3.9542e-02\n",
       "-1.5713e-02\n",
       " 7.9135e-02\n",
       "-1.1064e-02\n",
       "-3.2909e-02\n",
       "-7.5597e-02\n",
       " 1.3956e-02\n",
       " 6.2413e-02\n",
       "-3.2539e-02\n",
       " 1.4519e-02\n",
       " 9.6275e-03\n",
       "-5.8208e-02\n",
       "-3.4781e-02\n",
       "-1.4591e-02\n",
       "-9.5014e-03\n",
       " 5.8637e-02\n",
       " 5.3477e-03\n",
       "-1.2680e-02\n",
       " 2.0561e-02\n",
       "-6.9032e-02\n",
       "-1.0237e-02\n",
       " 4.7858e-06\n",
       "-3.4343e-03\n",
       " 4.2207e-02\n",
       " 2.2400e-02\n",
       "-1.4554e-03\n",
       "-2.3912e-02\n",
       "-2.3251e-02\n",
       "-1.6727e-02\n",
       " 6.4070e-02\n",
       "-2.1184e-02\n",
       "-6.9502e-02\n",
       "-2.8880e-02\n",
       "-2.3649e-02\n",
       " 4.5562e-02\n",
       "-1.2684e-02\n",
       " 4.9375e-03\n",
       "-4.7012e-03\n",
       "-5.5076e-02\n",
       "-1.0560e-02\n",
       " 1.4598e-03\n",
       "-1.6792e-02\n",
       "-2.3876e-02\n",
       " 4.3038e-02\n",
       "-2.3378e-02\n",
       " 1.1673e-02\n",
       " 2.7456e-04\n",
       " 4.8757e-04\n",
       " 2.1486e-02\n",
       "-1.9040e-02\n",
       " 1.1402e-03\n",
       "-4.0552e-02\n",
       " 5.5258e-02\n",
       "-1.8961e-02\n",
       "-1.9053e-02\n",
       " 5.6796e-03\n",
       "-5.0403e-03\n",
       " 8.4492e-03\n",
       "-1.7661e-02\n",
       " 5.4510e-03\n",
       " 3.8909e-02\n",
       " 2.4950e-02\n",
       " 3.3163e-02\n",
       " 1.8890e-03\n",
       " 1.0956e-02\n",
       " 5.4320e-03\n",
       "-1.0937e-02\n",
       "-6.3206e-03\n",
       " 1.6995e-02\n",
       "-2.8307e-03\n",
       " 1.4832e-02\n",
       "-6.3282e-03\n",
       " 1.0680e-02\n",
       "-2.7545e-04\n",
       " 1.6730e-02\n",
       "-3.3540e-03\n",
       " 3.6241e-02\n",
       " 3.3751e-02\n",
       "-2.4511e-02\n",
       " 1.4259e-02\n",
       " 9.7360e-04\n",
       "-4.3306e-03\n",
       "-2.1068e-02\n",
       " 6.2844e-03\n",
       "-2.8431e-02\n",
       "-1.8835e-02\n",
       " 1.9112e-02\n",
       "-1.3320e-02\n",
       "-3.4318e-03\n",
       "-1.6139e-02\n",
       "-2.1378e-02\n",
       "-9.4938e-03\n",
       " 2.3348e-02\n",
       "-1.1931e-02\n",
       " 1.3317e-02\n",
       "-2.7766e-03\n",
       "-5.2449e-03\n",
       " 4.8690e-03\n",
       " 2.8887e-02\n",
       " 7.1182e-04\n",
       "-5.8433e-02\n",
       " 5.4855e-03\n",
       "-9.9707e-03\n",
       " 2.9380e-03\n",
       "-1.5279e-02\n",
       "-1.3653e-02\n",
       " 4.9569e-03\n",
       " 3.2921e-04\n",
       " 1.6951e-02\n",
       " 1.1988e-02\n",
       "-1.4704e-02\n",
       " 3.1388e-02\n",
       "-3.2311e-02\n",
       "-2.2905e-03\n",
       " 1.8891e-02\n",
       "-2.7340e-02\n",
       "-3.3687e-03\n",
       " 1.6950e-02\n",
       "-2.0086e-02\n",
       "-1.4801e-02\n",
       " 1.6975e-02\n",
       "-4.3027e-02\n",
       " 2.5880e-02\n",
       " 5.6017e-03\n",
       " 2.6985e-03\n",
       " 5.3306e-04\n",
       "-4.6207e-03\n",
       " 1.2704e-02\n",
       "-2.1694e-02\n",
       "-2.5122e-02\n",
       " 7.9484e-03\n",
       " 1.1178e-02\n",
       "-3.8780e-02\n",
       " 2.5600e-03\n",
       "-1.1539e-02\n",
       " 1.2425e-02\n",
       "-3.7602e-02\n",
       " 2.8916e-02\n",
       " 1.4795e-02\n",
       "-1.1913e-02\n",
       " 1.9302e-02\n",
       "-4.9577e-02\n",
       " 1.6328e-02\n",
       " 1.1161e-02\n",
       " 2.2294e-02\n",
       " 2.7743e-02\n",
       " 1.4491e-02\n",
       "-2.5037e-02\n",
       " 2.4302e-02\n",
       " 1.1746e-02\n",
       " 6.7717e-03\n",
       "-2.7167e-03\n",
       "-2.7089e-03\n",
       " 1.9703e-02\n",
       "-2.2980e-02\n",
       "-3.1334e-02\n",
       "-4.8332e-02\n",
       "-1.2770e-03\n",
       " 1.1032e-02\n",
       "-1.6147e-02\n",
       "-2.0935e-02\n",
       "-1.9253e-02\n",
       "-7.4688e-03\n",
       "-4.1327e-04\n",
       "[torch.cuda.FloatTensor of size 256 (GPU 0)]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp_a[0, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 6, 104])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string_t.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6, 128])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp[0,:,:tmp.size()[2]//2].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NAZARETHANA'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([256])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([50, 256])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def test_encoder_single_sample():\n",
    "    s_bef, s_aft = get_random_sample()\n",
    "\n",
    "    string_t = string_to_tensor(s_bef, chars_normal_index)\n",
    "    string_t = Variable(string_t).cuda()\n",
    "    \n",
    "    return encoder_rnn(string_t), s_bef\n",
    "    \n",
    "(encoder_output, encoder_outputs), tmp = test_encoder_single_sample()\n",
    "tmp\n",
    "encoder_output.size()\n",
    "encoder_outputs.size()\n",
    "torch.eq(encoder_output, encoder_outputs[len(tmp)]).data.all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecoderRNN (\n",
       "  (emb_lin): Linear (152 -> 256)\n",
       "  (attn): Linear (512 -> 50)\n",
       "  (attn_combine): Linear (512 -> 256)\n",
       "  (dropout): Dropout (p = 0.1)\n",
       "  (rnn): GRU(256, 256, batch_first=True)\n",
       "  (lin_out): Linear (256 -> 152)\n",
       ")"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class DecoderRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, n_layers=1, dropout_p=0.1, max_length=MAX_ATTENTION_LENGTH):\n",
    "        super(DecoderRNN, self).__init__()\n",
    "        self.n_layers = n_layers\n",
    "        self.hidden_size = hidden_size\n",
    "        self.max_length = max_length\n",
    "        \n",
    "        self.emb_lin = nn.Linear(input_size, hidden_size)\n",
    "        self.attn = nn.Linear(hidden_size*2, self.max_length)\n",
    "        self.attn_combine = nn.Linear(self.hidden_size * 2, self.hidden_size)\n",
    "        self.dropout = nn.Dropout(dropout_p)\n",
    "        \n",
    "        self.rnn = nn.GRU(hidden_size, hidden_size, n_layers, batch_first=True, bidirectional=False)\n",
    "        self.lin_out = nn.Linear(hidden_size, input_size)\n",
    "        \n",
    "    #def forward(self, char, hidden):\n",
    "    def forward(self, last_input, hidden, encoder_outputs):\n",
    "        embedded = self.emb_lin(last_input).view(1, 1, -1)\n",
    "        embedded = self.dropout(embedded)\n",
    "\n",
    "        attn_weights = F.softmax(self.attn(torch.cat((embedded[0], hidden[0]), 1)))\n",
    "        attn_applied = torch.bmm(attn_weights.unsqueeze(0), encoder_outputs.unsqueeze(0))\n",
    "        \n",
    "        rnn_input = torch.cat((embedded[0], attn_applied[0]), 1)\n",
    "        rnn_input = self.attn_combine(rnn_input).unsqueeze(0)\n",
    "        rnn_input = F.relu(rnn_input)\n",
    "        \n",
    "        output, hidden = self.rnn(rnn_input, hidden)\n",
    "        output = F.log_softmax(self.lin_out(output[0]))\n",
    "        \n",
    "        return output, hidden, attn_weights\n",
    "    \n",
    "    def init_rest_hidden(self, input_var):\n",
    "        if self.n_layers > 1:\n",
    "            hid_var = Variable(torch.zeros(self.n_layers - 1, 1, self.hidden_size)).cuda()\n",
    "            res = torch.cat((input_var, hid_var), 0)\n",
    "            return res\n",
    "        else:\n",
    "            return input_var\n",
    "        \n",
    "\n",
    "decoder_rnn = DecoderRNN(input_size=len(words_after), hidden_size=encoder_output.size()[0], n_layers=1)\n",
    "decoder_rnn = decoder_rnn.cuda()\n",
    "decoder_rnn\n",
    "\n",
    "tmp_outputs = Variable(torch.zeros(MAX_ATTENTION_LENGTH, encoder_output.size()[0])).cuda()\n",
    "tmp_hiddens = decoder_rnn.init_rest_hidden(encoder_output.view(1,1,-1))\n",
    "tmp = decoder_rnn(Variable(sos_tensor).cuda(), tmp_hiddens, tmp_outputs)\n",
    "#[v.size() for v in tmp]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 152])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 256])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([50, 256])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sos_tensor.size()\n",
    "tmp_hiddens.size()\n",
    "tmp_outputs.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[torch.Size([1, 152]), torch.Size([1, 1, 256]), torch.Size([1, 50])]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      " 103\n",
      "[torch.cuda.LongTensor of size 1x1 (GPU 0)]\n",
      "\n",
      "plus\n"
     ]
    }
   ],
   "source": [
    "tmp_outputs = Variable(torch.zeros(MAX_ATTENTION_LENGTH, encoder_output.size()[0])).cuda()\n",
    "tmp_hiddens = decoder_rnn.init_rest_hidden(encoder_output.view(1,1,-1))\n",
    "tmp = decoder_rnn(Variable(sos_tensor).cuda(), tmp_hiddens, tmp_outputs)\n",
    "[v.size() for v in tmp]\n",
    "print(tmp[0].topk(1)[1])\n",
    "print(words_after[tmp[0].topk(1)[1].data[0][0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training etc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('plus plus plus plus plus plus plus plus plus plus plus plus plus plus plus plus plus plus plus plus',\n",
       " 'plus plus plus plus plus plus plus plus plus plus plus plus plus plus plus plus plus plus plus plus',\n",
       " 'g e r d a b dot i r',\n",
       " ('gerdab.ir', [52, 33, 109, 26, 5, 13, 32, 65, 109, 0]))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def test_model_single_sample(model=None, return_more=False, sample=False):\n",
    "    decoder_rnn.eval()\n",
    "    encoder_rnn.eval()\n",
    "    \n",
    "    if not sample:\n",
    "        sample = get_random_sample()\n",
    "    s_bef, s_aft = sample\n",
    "    \n",
    "    string_t = string_to_tensor(s_bef, chars_normal_index)\n",
    "    string_t = Variable(string_t).cuda()\n",
    "    \n",
    "    encoder_output, encoder_outputs = encoder_rnn(string_t)\n",
    "        \n",
    "    decoder_hidden = decoder_rnn.init_rest_hidden(encoder_outputs[0].view(1,1,-1))\n",
    "    decoder_input = Variable(sos_tensor).cuda()\n",
    "\n",
    "    decoded_output = []\n",
    "    decoder_attns_arr = []\n",
    "    max_length = 20\n",
    "    for _ in range(max_length):\n",
    "        decoder_output, decoder_hidden, decoder_attns = decoder_rnn(decoder_input, decoder_hidden, encoder_outputs)\n",
    "        decoder_attns_arr.append(decoder_attns)\n",
    "        #return decoder_output\n",
    "\n",
    "        topv, topi = decoder_output.data.topk(1)\n",
    "        word_index = topi[0][0]\n",
    "        word = words_after[word_index] # Use own prediction as next input\n",
    "                \n",
    "        if word == EOS_TOKEN:\n",
    "            break\n",
    "\n",
    "        decoded_output.append(word)\n",
    "        \n",
    "        #decoder_input = Variable(torch.LongTensor([word_index])).cuda()\n",
    "        \n",
    "        decoder_input = torch.zeros(1, 1, len(words_after_index))\n",
    "        decoder_input[0, 0, word_index] = 1\n",
    "        decoder_input = Variable(decoder_input).cuda()\n",
    "    \n",
    "    output = ' '.join(decoded_output)\n",
    "    sample_target = ' '.join([words_after[w] for w in s_aft][:-1])\n",
    "    \n",
    "    decoder_rnn.train()\n",
    "    encoder_rnn.train()\n",
    "    \n",
    "    if return_more:\n",
    "        return output, decoded_output, decoder_attns_arr, sample\n",
    "    \n",
    "    return output, output, sample_target, sample\n",
    "    \n",
    "tmp = test_model_single_sample(None)\n",
    "tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NHPTV          => plus plus plus plus plus plus plus plus plus plus plus plus plus plus plus plus plus plus plus plus || [87, 59, 100, 124, 138, 0] \n",
      "                  \n",
      "ISTE           => plus plus plus plus plus plus plus plus plus plus plus plus plus plus plus plus plus plus plus plus || [65, 113, 124, 33, 0] \n",
      "                  \n"
     ]
    }
   ],
   "source": [
    "def print_local_wrong_predictions(max_results=10):\n",
    "    arr = get_some_wrong_predictions(None, test_model_single_sample, max_iterations=10000, max_results=max_results)\n",
    "    for sample, predict, output in arr:\n",
    "        s_bef, s_aft = sample\n",
    "        print(\"{:<14} => {:<14} || {} \\n{:>17} {}\".format(s_bef, predict, s_aft, '', '' ))\n",
    "print_local_wrong_predictions(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.00% (       0/     100)\n",
      "CPU times: user 2.02 s, sys: 0 ns, total: 2.02 s\n",
      "Wall time: 2.02 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "test_model_accuracy(encoder_rnn, test_model_single_sample, n_sample=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train(s_bef, s_aft, s_sentence, encoder_optimizer, decoder_optimizer, loss_function,\n",
    "          use_teacher_forcing, max_length=20):\n",
    "    \n",
    "    string_t = string_to_tensor(s_bef, chars_normal_index)\n",
    "    string_t = Variable(string_t).cuda()\n",
    "    \n",
    "    encoder_output, encoder_outputs = encoder_rnn(string_t)\n",
    "    \n",
    "    #encoder_output = encoder_output.view(1,1,-1)\n",
    "    \n",
    "    decoder_hidden = decoder_rnn.init_rest_hidden(encoder_outputs[0].view(1,1,-1))\n",
    "    decoder_input = Variable(sos_tensor).cuda()\n",
    "    \n",
    "    ###\n",
    "    target_arr = s_aft\n",
    "    #target_arr = after_sentence_to_word_indexes(s_aft, include_eos=True)\n",
    "    \n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "    loss = 0\n",
    "    \n",
    "    decoded_output = []\n",
    "    for i in range(len(target_arr)):\n",
    "        decoder_output, decoder_hidden, decoder_attns = decoder_rnn(decoder_input, decoder_hidden, encoder_outputs)\n",
    "\n",
    "        #decoder_target_i = chars_after_index[target_arr[i]]\n",
    "        decoder_target_i = target_arr[i]\n",
    "        decoder_target_i = Variable(torch.LongTensor([decoder_target_i])).cuda()\n",
    "        loss += loss_function(decoder_output, decoder_target_i)\n",
    "        \n",
    "        topv, topi = decoder_output.data.topk(1)\n",
    "        word_index = topi[0][0]\n",
    "        word = words_after[word_index] # Use own prediction as next input\n",
    "        decoded_output.append(word)\n",
    "        \n",
    "        if use_teacher_forcing:\n",
    "            word_index = target_arr[i] # replace input with right target\n",
    "        else:\n",
    "            # use output normally as input \n",
    "            if word == EOS_TOKEN:\n",
    "                break\n",
    "                \n",
    "        decoder_input = torch.zeros(1, 1, len(words_after_index))\n",
    "        decoder_input[0, 0, word_index] = 1\n",
    "        decoder_input = Variable(decoder_input).cuda()\n",
    "        #decoder_input = Variable(torch.LongTensor([word_index])).cuda()\n",
    "        \n",
    "    if decoded_output[-1] == EOS_TOKEN:\n",
    "        decoded_output = decoded_output[:-1]\n",
    "        \n",
    "    loss.backward()\n",
    "\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "\n",
    "    return ' '.join(decoded_output), (loss.data[0] / len(target_arr))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_iterations(n_iters=100000, lr=0.001, teacher_forcing_ratio=0.5,\n",
    "                     print_every=10000, plot_every=1000):\n",
    "\n",
    "    start = time.time()\n",
    "    \n",
    "    decoder_rnn.train()\n",
    "    encoder_rnn.train()\n",
    "\n",
    "    current_loss = 0\n",
    "    current_loss_iter = 0\n",
    "\n",
    "    encoder_optimizer = torch.optim.Adam(encoder_rnn.parameters(), lr=lr)\n",
    "    decoder_optimizer = torch.optim.Adam(decoder_rnn.parameters(), lr=lr)\n",
    "    loss_function = nn.NLLLoss()\n",
    "    \n",
    "    for iteration in range(1, n_iters + 1):\n",
    "        model_training.iterations += 1\n",
    "        \n",
    "        use_teacher_forcing = random.random() < teacher_forcing_ratio\n",
    "        \n",
    "        s_bef, s_aft = get_random_sample()\n",
    "        s_sentence=''\n",
    "        \n",
    "        result, loss = train(s_bef=s_bef, s_aft=s_aft, s_sentence=s_sentence,\n",
    "                             encoder_optimizer=encoder_optimizer, decoder_optimizer=decoder_optimizer,\n",
    "                             loss_function=nn.NLLLoss(), use_teacher_forcing=use_teacher_forcing,\n",
    "                             max_length=40 )\n",
    "        \n",
    "        current_loss += loss\n",
    "        current_loss_iter += 1\n",
    "\n",
    "        # Print iter number, loss, name and guess\n",
    "        if iteration % print_every == 0:\n",
    "            teacher_forcing_str = \"\"\n",
    "            if use_teacher_forcing:\n",
    "                teacher_forcing_str = \"(forcing)\"\n",
    "            s_aft_sentence = ' '.join([words_after[w] for w in s_aft][:-1])\n",
    "            correct = '✓' if result == s_aft_sentence else \"✗: {}\".format(s_aft_sentence)\n",
    "            \n",
    "            print(\"{:>6d} {:>4.0%} ({:>8}) {:>7.3f}   | {:>6.2f}: {} -> {} ({}) {}\".format(\n",
    "                      model_training.iterations, iteration/n_iters, time_since(start),\n",
    "                      current_loss/current_loss_iter, loss,\n",
    "                      s_bef, result, correct, teacher_forcing_str))\n",
    "\n",
    "        # Add current loss avg to list of losses\n",
    "        if iteration % plot_every == 0:\n",
    "            model_training.losses.append(current_loss / plot_every)\n",
    "            model_training.learning_rates.append(lr)\n",
    "            current_loss = 0\n",
    "            current_loss_iter = 0\n",
    "            \n",
    "        if model_training.iterations % 50000 == 0 or model_training.iterations == 10:\n",
    "            model_training.save_models()\n",
    "            acc = test_model_accuracy(encoder_rnn, test_model_single_sample)\n",
    "            model_training.accuracy.append(acc)\n",
    "    \n",
    "    # test_model_accuracy(model, n_sample=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Save path: data/models/electronic_gen_4_testing_no_words\n"
     ]
    }
   ],
   "source": [
    "model_training = ModelTraining(MODEL_SAVE_PATH, [encoder_rnn, decoder_rnn])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     9  18% (   0m 0s)   5.024   |   5.00: NARSTIE -> plus plus plus plus plus plus plus plus (✗: n a r s t i e) \n",
      "Saved model to data/models/electronic_gen_4_testing_no_words/10_(EncoderRNN/DecoderRNN)\n",
      "Accuracy: 0.00% (       0/   10000)\n",
      "    18  36% (  3m 34s)   4.399   |   4.97: IRRI -> <EOS> <EOS> <EOS> <EOS> (✗: i r r i) (forcing)\n",
      "    27  54% (  3m 34s)   4.143   |   4.93: ISBN -> <EOS> <EOS> <EOS> <EOS> (✗: i s b n) (forcing)\n",
      "    36  72% (  3m 35s)   3.791   |   1.00: PFLP ->  (✗: p f l p) \n",
      "    45  90% (  3m 35s)   3.547   |   0.29: ThisIsKent.co.uk ->  (✗: t h i s i s k e n t dot c o dot u k) \n"
     ]
    }
   ],
   "source": [
    "train_iterations(n_iters=50, print_every=9, lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   550  53% (   0m 8s)   2.351   |   2.63: ISBN -> i s <EOS> <EOS> (✗: i s b n) (forcing)\n"
     ]
    }
   ],
   "source": [
    "train_iterations(n_iters=(1000-model_training.iterations), print_every=500, lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 11000  10% (  4m 28s)   0.225   |   1.33: Browseinside.harpercollins.com -> b r o w s e i n s i d e dot h r m <EOS> p s dot o r a s s h h c o m (✗: b r o w s e i n s i d e dot h a r p e r c o l l i n s dot c o m) (forcing)\n",
      " 21000  20% (   9m 4s)   0.140   |   0.00: Ofie -> o f i e (✓) \n",
      " 31000  30% ( 13m 29s)   0.118   |   0.01: é -> e acute (✓) \n",
      " 41000  40% ( 17m 58s)   0.141   |   0.02: Iida's -> i i d a's (✓) (forcing)\n",
      "Saved model to data/models/electronic_gen_4_testing_no_words/50000_(EncoderRNN/DecoderRNN)\n",
      "Accuracy: 92.51% (    9251/   10000)\n",
      " 51000  51% ( 23m 39s)   0.119   |   0.01: srpskih -> s r p s k i h (✓) \n",
      " 61000  61% (  28m 7s)   0.139   |   2.73: U.T.O.P.I.A. -> u l t p o m m (✗: u t o p i a) \n",
      " 71000  71% ( 32m 26s)   0.354   |   0.03: TNA's -> t n a's (✓) \n",
      " 81000  81% ( 36m 46s)   0.189   |   0.02: NGOs -> n g o's (✓) \n",
      " 91000  91% (  41m 4s)   0.688   |   0.98: WHYN's -> w h y n (✗: w h y n's) \n",
      "Saved model to data/models/electronic_gen_4_testing_no_words/100000_(EncoderRNN/DecoderRNN)\n",
      "Accuracy: 58.95% (    5895/   10000)\n"
     ]
    }
   ],
   "source": [
    "train_iterations(n_iters=99000, print_every=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "110000  10% (  4m 15s)   0.425   |   0.01: ISBN -> i s b n (✓) (forcing)\n",
      "120000  20% (  8m 36s)   0.662   |   0.05: E&M -> e and m (✓) (forcing)\n",
      "130000  30% (  13m 1s)   0.725   |   0.03: WJLA -> w j l a (✓) \n",
      "140000  40% ( 17m 19s)   0.549   |   0.02: SBAO -> s b a o (✓) \n",
      "150000  50% ( 21m 40s)   0.489   |   0.01: ADMN -> a d m n (✓) \n",
      "Saved model to data/models/electronic_gen_4_testing_no_words/150000_(EncoderRNN/DecoderRNN)\n",
      "Accuracy: 75.45% (    7545/   10000)\n",
      "160000  60% ( 27m 27s)   0.467   |   0.07: DFAT -> d f a t (✓) \n",
      "170000  70% (  32m 7s)   0.878   |   0.11: Lidl -> l i d l (✓) (forcing)\n",
      "180000  80% ( 36m 28s)   0.713   |   0.05: WDSE -> w d s e (✓) \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-42-ac23592386f6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_iterations\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_iters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprint_every\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-37-37d440257daf>\u001b[0m in \u001b[0;36mtrain_iterations\u001b[0;34m(n_iters, lr, teacher_forcing_ratio, print_every, plot_every)\u001b[0m\n\u001b[1;32m     25\u001b[0m                              \u001b[0mencoder_optimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoder_optimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder_optimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdecoder_optimizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m                              \u001b[0mloss_function\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNLLLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_teacher_forcing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_teacher_forcing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m                              max_length=40 )\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0mcurrent_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-36-71d079fa1e0a>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(s_bef, s_aft, s_sentence, encoder_optimizer, decoder_optimizer, loss_function, use_teacher_forcing, max_length)\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0mdecoded_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecoded_output\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mencoder_optimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py3_pytorch_2/lib/python3.6/site-packages/torch/autograd/variable.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, retain_variables)\u001b[0m\n\u001b[1;32m    154\u001b[0m                 \u001b[0mVariable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m         \"\"\"\n\u001b[0;32m--> 156\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py3_pytorch_2/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(variables, grad_variables, retain_graph, create_graph, retain_variables)\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[0;32m---> 98\u001b[0;31m         variables, grad_variables, retain_graph)\n\u001b[0m\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_iterations(n_iters=100000, print_every=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input:   DHAMOIRHAT\n",
      "output:  d h a t h d t h h h h h h e\n",
      "target:    dhamoirhat\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAwoAAAFeCAYAAAAluOjpAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fad50e3a240>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def debug_show_attention(input_sentence, output_words, attentions):\n",
    "    # Set up figure with colorbar\n",
    "    fig = plt.figure(figsize=(15,6))\n",
    "    ax = fig.add_subplot(111)\n",
    "    #cax = ax.matshow(attentions.numpy(), cmap='bone')\n",
    "    cax = ax.matshow(attentions, cmap='bone')\n",
    "    fig.colorbar(cax)\n",
    "    # Set up axes\n",
    "    #ax.set_xticklabels([''] + input_sentence.split(' ') + ['<EOS>'], rotation=90)\n",
    "    #ax.set_xticklabels([''] + input_sentence + ['<EOS>'], rotation=90)\n",
    "    ax.set_yticklabels([''] + output_words)\n",
    "    \n",
    "    input_sentence = input_sentence + ['<EOS>']\n",
    "    inp_arr = [\"{}\\n{}\".format(input_sentence[i], input_sentence[-1-i]) for i in range(len(input_sentence))]\n",
    "    ax.set_xticklabels([''] + inp_arr, rotation=0)\n",
    "\n",
    "    # Show label at every tick\n",
    "    ax.xaxis.set_major_locator(matplotlib.ticker.MultipleLocator(1))\n",
    "    ax.yaxis.set_major_locator(matplotlib.ticker.MultipleLocator(1))\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "def debug_eval_sample_show_attention():\n",
    "    \n",
    "    output, decoded_output, decoder_attns_arr, sample = test_model_single_sample(None, return_more=True)\n",
    "    print('input:  ', sample[0])\n",
    "    print('output: ', ' '.join(decoded_output))\n",
    "    print('target:   ', ''.join([words_after[w] for w in sample[1][:-1]]))\n",
    "\n",
    "    attns = np.array([arr.data[0].cpu().numpy() for arr in decoder_attns_arr])\n",
    "\n",
    "    debug_show_attention(list(sample[0]), decoded_output, attns)\n",
    "    #plt.matshow(attns)\n",
    "\n",
    "debug_eval_sample_show_attention()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "1+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:py3_pytorch_2]",
   "language": "python",
   "name": "conda-env-py3_pytorch_2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
