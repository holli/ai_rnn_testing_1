{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-1-6288e39d62f2>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-1-6288e39d62f2>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    THIS WAS ERROR. SENTENCE IS SINGLE LETTERS INSTEAD OF WORDS\u001b[0m\n\u001b[0m           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "    THIS WAS ERROR. SENTENCE IS SINGLE LETTERS INSTEAD OF WORDS\n",
    "    THIS WAS ERROR. SENTENCE IS SINGLE LETTERS INSTEAD OF WORDS\n",
    "    THIS WAS ERROR. SENTENCE IS SINGLE LETTERS INSTEAD OF WORDS\n",
    "    THIS WAS ERROR. SENTENCE IS SINGLE LETTERS INSTEAD OF WORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pytorch utils oh: pytorch_utils_oh_2.py\n",
      "Pytorch: 0.2.0_4\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import importlib\n",
    "from pytorch_utils_oh_2 import *\n",
    "import IPython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MODEL_SAVE_PATH = 'whole_gen_11_fixes'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pytorch utils oh: pytorch_utils_oh_2.py\n",
      "Pytorch: 0.2.0_4\n"
     ]
    }
   ],
   "source": [
    "import pytorch_utils_oh_2; importlib.reload(pytorch_utils_oh_2); from pytorch_utils_oh_2 import *;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# all_data = pickle.load(open(\"data/en_train_fixed_4_sentences.pkl\", \"rb\" ))\n",
    "all_data = pickle.load(open(\"data/en_train_fixed_5_manual.pkl\", \"rb\" ))\n",
    "# all_data_sentence_index = all_data.set_index('sentence_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data rows: 649369,  (dropped rows: 9268823)\n"
     ]
    }
   ],
   "source": [
    "sample_data = all_data.copy()\n",
    "sample_data = sample_data[sample_data['class'] != 'NOT_CHANGED']\n",
    "sample_data = sample_data[sample_data['class'] != 'MANUAL']\n",
    "sample_data = sample_data[sample_data['class'] != 'ELECTRONIC']\n",
    "print(\"Data rows: {},  (dropped rows: {})\".format(len(sample_data), len(all_data)-len(sample_data)))\n",
    "sample_data = sample_data.reset_index(drop=True)\n",
    "del(all_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['LETTERS', 'NUMBERS', 'PLAIN', 'VERBATIM']\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "categories_all = sorted(sample_data[\"class\"].unique())\n",
    "print(categories_all)\n",
    "print(len(categories_all))\n",
    "categories_index = dict((c, i) for i, c in enumerate(categories_all))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utils stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<SOS><EOS>☒ !\"#$%&'(),-./0123456789:;ABCDEFGHIJKLMNOPQRSTUVWXYZ_abcdefghijklmnopqrstuvwxyz~£¥ª²³µº¼½¾éɒʻˈΩμ—€⅓⅔⅛\n"
     ]
    }
   ],
   "source": [
    "chars_normal, chars_normal_index = load_characters_pkl('data/en_features/chars_normal.pkl')\n",
    "print(''.join(chars_normal))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "common_words, common_words_index = load_common_words_10k()\n",
    "len(common_words)\n",
    "common_words[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wv_vecs, wv_words, wv_idx = load_glove('/home/ohu/koodi/data/glove_wordvec/glove.6B.50d.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### After words handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<EOS>', '<SOS>', '<UNK>', '<0000>', '<SAMPLE>', 'two', 'twenty']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "1351"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_after_common = pickle.load(open(\"data/en_features/words_after_ext.pkl\", 'rb'))\n",
    "words_after_index = dict((c, i) for i, c in enumerate(words_after_common))\n",
    "words_after_common[0:7]\n",
    "len(words_after_common)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 1351])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sos_tensor = torch.zeros(1, 1, len(words_after_index))\n",
    "sos_tensor[0, 0, words_after_index[SOS_TOKEN]] = 1\n",
    "sos_tensor.size()\n",
    "#del(onehot_sos)\n",
    "\n",
    "# sos_tensor = torch.LongTensor([words_after_index[SOS_TOKEN]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### More balanced sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "balanced_data_classes_select = list(sample_data.groupby('class'))\n",
    "\n",
    "balanced_data_accessed_counter = 0 \n",
    "balanced_data_randomize_freq = False\n",
    "balanced_data_length = 0\n",
    "\n",
    "def balanced_data_randomize_org(max_len=20000):\n",
    "    global balanced_data, balanced_data_length, balanced_data_accessed_counter, balanced_data_randomize_freq\n",
    "    balanced_data = pd.concat([v.sample(min(max_len, len(v))) for k, v in balanced_data_classes_select])\n",
    "    balanced_data_length = len(balanced_data)\n",
    "    balanced_data_randomize_freq = balanced_data_length * 0.2\n",
    "    balanced_data_accessed_counter = 0\n",
    "balanced_data_randomize = balanced_data_randomize_org\n",
    "\n",
    "def balanced_data_sample_row():\n",
    "    global balanced_data_accessed_counter\n",
    "    global balanced_data_last_sample\n",
    "    balanced_data_accessed_counter += 1\n",
    "    if balanced_data_randomize_freq and balanced_data_accessed_counter > balanced_data_randomize_freq:\n",
    "        balanced_data_randomize()\n",
    "    balanced_data_last_sample = balanced_data.iloc[random.randint(1, balanced_data_length-1)]\n",
    "    return balanced_data_last_sample\n",
    "    \n",
    "balanced_data_randomize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "class\n",
       "LETTERS     20000\n",
       "NUMBERS     20000\n",
       "PLAIN       20000\n",
       "VERBATIM    11741\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#all_data.groupby('class')['class'].count()\n",
    "#sample_data.groupby('class')['class'].count()\n",
    "balanced_data.groupby('class')['class'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentence_id                                               301006\n",
       "token_id                                                       6\n",
       "class                                                      PLAIN\n",
       "before                                                  baptised\n",
       "after                                                   baptized\n",
       "class_org                                                  PLAIN\n",
       "a_word_ind                                              [418, 0]\n",
       "sentence       as george wished , she was <SAMPLE> before the...\n",
       "Name: 259802, dtype: object"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "balanced_data_sample_row()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LETTERS : HK -> h k <EOS> [45, 59, 0]\n",
      "jarrahy r , shahinian <SAMPLE> : surgical management of pituitary tumors .\n",
      "torch.Size([1, 3, 104])\n"
     ]
    }
   ],
   "source": [
    "def get_random_sample():\n",
    "    sample_row = balanced_data_sample_row()   \n",
    "    return sample_row['before'], sample_row['a_word_ind'], sample_row['class'], sample_row['sentence']\n",
    "            \n",
    "def tmp():\n",
    "    s_bef, s_aft, s_class, s_sentence = get_random_sample()\n",
    "    s_aft_str = ' '.join([words_after_common[i] for i in s_aft])\n",
    "    print(s_class, ':', s_bef, '->', s_aft_str, s_aft)\n",
    "    print(s_sentence)\n",
    "    print(string_to_tensor(s_bef, chars_normal_index).shape)\n",
    "tmp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "159 µs ± 4.11 µs per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "get_random_sample()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "use_cuda = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MAX_ATTENTION_LENGTH = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>token_id</th>\n",
       "      <th>class</th>\n",
       "      <th>before</th>\n",
       "      <th>after</th>\n",
       "      <th>class_org</th>\n",
       "      <th>a_word_ind</th>\n",
       "      <th>sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>251131</th>\n",
       "      <td>290739</td>\n",
       "      <td>9</td>\n",
       "      <td>NUMBERS</td>\n",
       "      <td>21 80 38 30 31 38 30 32 33 30 30</td>\n",
       "      <td>two one sil eight o sil three eight sil three ...</td>\n",
       "      <td>TELEPHONE</td>\n",
       "      <td>[5, 9, 58, 16, 25, 58, 13, 16, 58, 13, 25, 58,...</td>\n",
       "      <td>0010 a 9 83 85 6 c 0 c &lt;SAMPLE&gt; .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500384</th>\n",
       "      <td>577146</td>\n",
       "      <td>7</td>\n",
       "      <td>NUMBERS</td>\n",
       "      <td>0-333-73432-7 ISBN 1-56159-228-5</td>\n",
       "      <td>o sil three three three sil seven three four t...</td>\n",
       "      <td>TELEPHONE</td>\n",
       "      <td>[25, 58, 13, 13, 13, 58, 18, 13, 19, 13, 5, 58...</td>\n",
       "      <td>london : macmillan publishers , inc isbn &lt;SAMP...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        sentence_id  token_id    class                            before  \\\n",
       "251131       290739         9  NUMBERS  21 80 38 30 31 38 30 32 33 30 30   \n",
       "500384       577146         7  NUMBERS  0-333-73432-7 ISBN 1-56159-228-5   \n",
       "\n",
       "                                                    after  class_org  \\\n",
       "251131  two one sil eight o sil three eight sil three ...  TELEPHONE   \n",
       "500384  o sil three three three sil seven three four t...  TELEPHONE   \n",
       "\n",
       "                                               a_word_ind  \\\n",
       "251131  [5, 9, 58, 16, 25, 58, 13, 16, 58, 13, 25, 58,...   \n",
       "500384  [25, 58, 13, 13, 13, 58, 18, 13, 19, 13, 5, 58...   \n",
       "\n",
       "                                                 sentence  \n",
       "251131                  0010 a 9 83 85 6 c 0 c <SAMPLE> .  \n",
       "500384  london : macmillan publishers , inc isbn <SAMP...  "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>token_id</th>\n",
       "      <th>class</th>\n",
       "      <th>before</th>\n",
       "      <th>after</th>\n",
       "      <th>class_org</th>\n",
       "      <th>a_word_ind</th>\n",
       "      <th>sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>251131</th>\n",
       "      <td>290739</td>\n",
       "      <td>9</td>\n",
       "      <td>NUMBERS</td>\n",
       "      <td>21 80 38 30 31 38 30 32 33 30 30</td>\n",
       "      <td>two one sil eight o sil three eight sil three ...</td>\n",
       "      <td>TELEPHONE</td>\n",
       "      <td>[5, 9, 58, 16, 25, 58, 13, 16, 58, 13, 25, 58,...</td>\n",
       "      <td>0010 a 9 83 85 6 c 0 c &lt;SAMPLE&gt; .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271272</th>\n",
       "      <td>314363</td>\n",
       "      <td>1</td>\n",
       "      <td>NUMBERS</td>\n",
       "      <td>981-232-423-2 ISBN 978-9812324238</td>\n",
       "      <td>nine eight one sil two three two sil four two ...</td>\n",
       "      <td>TELEPHONE</td>\n",
       "      <td>[15, 16, 9, 58, 5, 13, 5, 58, 19, 5, 13, 58, 5...</td>\n",
       "      <td>isbn &lt;SAMPLE&gt; abdulgani , ruslan .</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        sentence_id  token_id    class                             before  \\\n",
       "251131       290739         9  NUMBERS   21 80 38 30 31 38 30 32 33 30 30   \n",
       "271272       314363         1  NUMBERS  981-232-423-2 ISBN 978-9812324238   \n",
       "\n",
       "                                                    after  class_org  \\\n",
       "251131  two one sil eight o sil three eight sil three ...  TELEPHONE   \n",
       "271272  nine eight one sil two three two sil four two ...  TELEPHONE   \n",
       "\n",
       "                                               a_word_ind  \\\n",
       "251131  [5, 9, 58, 16, 25, 58, 13, 16, 58, 13, 25, 58,...   \n",
       "271272  [15, 16, 9, 58, 5, 13, 5, 58, 19, 5, 13, 58, 5...   \n",
       "\n",
       "                                  sentence  \n",
       "251131   0010 a 9 83 85 6 c 0 c <SAMPLE> .  \n",
       "271272  isbn <SAMPLE> abdulgani , ruslan .  "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp = sample_data[sample_data['before'].str.len()>MAX_ATTENTION_LENGTH]\n",
    "len(tmp)\n",
    "tmp.sample(2)\n",
    "tmp[~tmp['before'].str.contains('/')].sample(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EncoderRNN (\n",
       "  (rnn_words): LSTM(50, 128, batch_first=True, bidirectional=True)\n",
       "  (rnn_chars): LSTM(104, 192, batch_first=True, bidirectional=True)\n",
       ")"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, words_input_size, chars_input_size, words_hidden_size, chars_hidden_size,\n",
    "                 words_layers=1, chars_layers=1):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        \n",
    "        self.words_layers = words_layers\n",
    "        self.chars_layers = chars_layers\n",
    "        self.words_hidden_size = words_hidden_size\n",
    "        self.chars_hidden_size = chars_hidden_size\n",
    "        self.hidden_size = words_hidden_size + chars_hidden_size\n",
    "\n",
    "        self.rnn_words = nn.LSTM(words_input_size, words_hidden_size // 2, words_layers,\n",
    "                                 batch_first=True, bidirectional=True)\n",
    "\n",
    "        self.rnn_chars = nn.LSTM(chars_input_size, chars_hidden_size // 2, chars_layers,\n",
    "                                batch_first=True, bidirectional=True)\n",
    "        \n",
    "    def forward(self, word_vectors, string_tensor, hidden = None, init_hidden = True):\n",
    "        if init_hidden:\n",
    "            hidden_words, hidden_chars = self.init_hidden()\n",
    "        \n",
    "        all_outputs_words, hidden_words = self.rnn_words(word_vectors, hidden_words)\n",
    "        output_words = all_outputs_words[:, -1]\n",
    "        \n",
    "        all_outputs_chars, hidden_chars = self.rnn_chars(string_tensor, hidden_chars)\n",
    "        output_chars = all_outputs_chars[:, -1]\n",
    "        \n",
    "        hidden_states_cat = Variable(torch.zeros(MAX_ATTENTION_LENGTH, self.hidden_size)).cuda()\n",
    "        for ei in range(min(MAX_ATTENTION_LENGTH, len(string_tensor[0]))):\n",
    "            hidden_states_cat[ei] = torch.cat((output_words, all_outputs_chars[0, ei].view(1,-1)), 1)\n",
    "                \n",
    "        output = torch.cat((output_words[0], output_chars[0]), 0)\n",
    "\n",
    "        #output = torch.cat((output_words, output_chars), 1)\n",
    "        \n",
    "        #return output, all_outputs_chars\n",
    "        return output, hidden_states_cat\n",
    "\n",
    "    def init_hidden(self):\n",
    "        var1_1 = Variable(torch.zeros(2 * self.words_layers, 1, self.words_hidden_size // 2))\n",
    "        var1_2 = Variable(torch.zeros(2 * self.words_layers, 1, self.words_hidden_size // 2))\n",
    "        var2_1 = Variable(torch.zeros(2 * self.chars_layers, 1, self.chars_hidden_size // 2))\n",
    "        var2_2 = Variable(torch.zeros(2 * self.chars_layers, 1, self.chars_hidden_size // 2))\n",
    "        \n",
    "        var1_1 = var1_1.cuda(); var1_2 = var1_2.cuda()\n",
    "        var2_1 = var2_1.cuda(); var2_2 = var2_2.cuda()\n",
    "        return ((var1_1, var1_2), (var2_1, var2_2))\n",
    "    \n",
    "    \n",
    "encoder_rnn = EncoderRNN(words_input_size=wv_vecs.shape[-1], chars_input_size=len(chars_normal),\n",
    "                         words_hidden_size=256, chars_hidden_size=384,\n",
    "                         words_layers=1, chars_layers=1).cuda()\n",
    "encoder_rnn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'42'"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([640])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([30, 640])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def test_encoder_single_sample():\n",
    "    s_bef, s_aft, s_class, s_sentence = get_random_sample()\n",
    "    print(s_bef)\n",
    "    \n",
    "    words_t = Variable(words_to_word_vectors_tensor(list(s_sentence), wv_vecs, wv_idx)).cuda()\n",
    "    \n",
    "    string_t = string_to_tensor(s_bef, chars_normal_index)\n",
    "    string_t = Variable(string_t).cuda()\n",
    "    \n",
    "    return encoder_rnn(words_t, string_t), s_bef\n",
    "    \n",
    "(encoder_output, encoder_outputs), tmp = test_encoder_single_sample()\n",
    "tmp\n",
    "encoder_output.size()\n",
    "encoder_outputs.size()\n",
    "torch.eq(encoder_output, encoder_outputs[len(tmp)]).data.all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecoderRNN (\n",
       "  (rnn): GRU(640, 640, batch_first=True)\n",
       "  (lin_out): Linear (640 -> 1351)\n",
       "  (emb_lin): Linear (1351 -> 640)\n",
       "  (attn): Linear (1280 -> 30)\n",
       "  (attn_combine): Linear (1280 -> 640)\n",
       "  (dropout): Dropout (p = 0.1)\n",
       ")"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[torch.Size([1, 1351]), torch.Size([1, 1, 640]), torch.Size([1, 30])]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class DecoderRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, n_layers=1, dropout_p=0.1, max_length=MAX_ATTENTION_LENGTH):\n",
    "        super(DecoderRNN, self).__init__()\n",
    "        self.n_layers = n_layers\n",
    "        self.hidden_size = hidden_size\n",
    "        \n",
    "        #self.rnn = nn.GRU(input_size, hidden_size, n_layers,\n",
    "        self.rnn = nn.GRU(hidden_size, hidden_size, n_layers,\n",
    "                                 batch_first=True, bidirectional=False)\n",
    "        \n",
    "        self.lin_out = nn.Linear(hidden_size, input_size)\n",
    "        #self.softmax = nn.LogSoftmax()\n",
    "        \n",
    "        #self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        self.emb_lin = nn.Linear(input_size, hidden_size)\n",
    "        self.max_length = max_length\n",
    "        self.attn = nn.Linear(hidden_size*2, self.max_length)\n",
    "        self.attn_combine = nn.Linear(self.hidden_size * 2, self.hidden_size)\n",
    "        self.dropout = nn.Dropout(dropout_p)\n",
    "        \n",
    "    #def forward(self, char, hidden):\n",
    "    def forward(self, last_input, hidden, encoder_outputs):\n",
    "        #embedded = self.embedding(last_input).view(1, 1, -1)\n",
    "        embedded = self.emb_lin(last_input).view(1, 1, -1)\n",
    "        embedded = self.dropout(embedded)\n",
    "        #IPython.core.debugger.Pdb().set_trace()\n",
    "        #attn_weights = F.softmax(self.attn(torch.cat((char[0], hidden[0]), 1)))\n",
    "        attn_weights = F.softmax(self.attn(torch.cat((embedded[0], hidden[0]), 1)))\n",
    "        attn_applied = torch.bmm(attn_weights.unsqueeze(0), encoder_outputs.unsqueeze(0))\n",
    "        \n",
    "        output = torch.cat((embedded[0], attn_applied[0]), 1)\n",
    "        output = self.attn_combine(output).unsqueeze(0)\n",
    "\n",
    "        \n",
    "        output = F.relu(output)\n",
    "        output, hidden = self.rnn(output, hidden)\n",
    "\n",
    "        output = F.log_softmax(self.lin_out(output[0]))\n",
    "        return output, hidden, attn_weights\n",
    "    \n",
    "    def init_rest_hidden(self, input_var):\n",
    "        if self.n_layers > 1:\n",
    "            hid_var = Variable(torch.zeros(self.n_layers - 1, 1, self.hidden_size)).cuda()\n",
    "            res = torch.cat((input_var, hid_var), 0)\n",
    "            return res\n",
    "        else:\n",
    "            return input_var\n",
    "        \n",
    "\n",
    "decoder_rnn = DecoderRNN(input_size=len(words_after_common), hidden_size=encoder_output.size()[0], n_layers=1)\n",
    "decoder_rnn = decoder_rnn.cuda()\n",
    "decoder_rnn\n",
    "\n",
    "tmp_outputs = Variable(torch.zeros(MAX_ATTENTION_LENGTH, encoder_output.size()[0])).cuda()\n",
    "tmp_hiddens = decoder_rnn.init_rest_hidden(encoder_output.view(1,1,-1))\n",
    "tmp = decoder_rnn(Variable(sos_tensor).cuda(), tmp_hiddens, tmp_outputs)\n",
    "[v.size() for v in tmp]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "(0 ,.,.) = \n",
       "  1.2000  2.4000  3.6000  4.8000\n",
       "[torch.FloatTensor of size 1x1x4]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.bmm(torch.FloatTensor([1,0.1,0.1]).view(1,1,-1), torch.arange(0, 12).view(1,3,-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[torch.Size([1, 1351]), torch.Size([1, 1, 640]), torch.Size([1, 30])]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      " 789\n",
      "[torch.cuda.LongTensor of size 1x1 (GPU 0)]\n",
      "\n",
      "gamergate\n"
     ]
    }
   ],
   "source": [
    "tmp_outputs = Variable(torch.zeros(MAX_ATTENTION_LENGTH, encoder_output.size()[0])).cuda()\n",
    "tmp_hiddens = decoder_rnn.init_rest_hidden(encoder_output.view(1,1,-1))\n",
    "tmp = decoder_rnn(Variable(sos_tensor).cuda(), tmp_hiddens, tmp_outputs)\n",
    "[v.size() for v in tmp]\n",
    "print(tmp[0].topk(1)[1])\n",
    "print(words_after_common[tmp[0].topk(1)[1].data[0][0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training etc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('caribbean license license license license license license license license license license license license license license license license license license license',\n",
       " 'caribbean license license license license license license license license license license license license license license license license license license license',\n",
       " 'dollar',\n",
       " ('$',\n",
       "  [231, 0],\n",
       "  'VERBATIM',\n",
       "  'mccoy made his appearance in viva la bam , bam margera presents : where the # <SAMPLE> & % is santa ?'))"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def test_model_single_sample(model=None, return_more=False, sample=False):\n",
    "    decoder_rnn.eval()\n",
    "    encoder_rnn.eval()\n",
    "    \n",
    "    if not sample:\n",
    "        sample = get_random_sample()\n",
    "    s_bef, s_aft, s_class, s_sentence = sample\n",
    "        \n",
    "    words_t = Variable(words_to_word_vectors_tensor(list(s_sentence), wv_vecs, wv_idx)).cuda()\n",
    "    \n",
    "    string_t = string_to_tensor(s_bef, chars_normal_index)\n",
    "    string_t = Variable(string_t).cuda()\n",
    "    \n",
    "    encoder_output, encoder_outputs = encoder_rnn(words_t, string_t)\n",
    "    \n",
    "    #encoder_output = encoder_output.view(1,1,-1)\n",
    "    \n",
    "    decoder_hidden = decoder_rnn.init_rest_hidden(encoder_outputs[0].view(1,1,-1))\n",
    "    decoder_input = Variable(sos_tensor).cuda()\n",
    "\n",
    "    decoded_output = []\n",
    "    decoder_attns_arr = []\n",
    "    max_length = 20\n",
    "    for _ in range(max_length):\n",
    "        decoder_output, decoder_hidden, decoder_attns = decoder_rnn(decoder_input, decoder_hidden, encoder_outputs)\n",
    "        decoder_attns_arr.append(decoder_attns)\n",
    "        #return decoder_output\n",
    "\n",
    "        topv, topi = decoder_output.data.topk(1)\n",
    "        word_index = topi[0][0]\n",
    "        word = words_after_common[word_index] # Use own prediction as next input\n",
    "                \n",
    "        if word == EOS_TOKEN:\n",
    "            break\n",
    "\n",
    "        decoded_output.append(word)\n",
    "        \n",
    "        #decoder_input = Variable(torch.LongTensor([word_index])).cuda()\n",
    "        \n",
    "        decoder_input = torch.zeros(1, 1, len(words_after_index))\n",
    "        decoder_input[0, 0, word_index] = 1\n",
    "        decoder_input = Variable(decoder_input).cuda()\n",
    "    \n",
    "    output = ' '.join(decoded_output)\n",
    "    sample_target = ' '.join([words_after_common[w] for w in s_aft][:-1])\n",
    "    \n",
    "    decoder_rnn.train()\n",
    "    encoder_rnn.train()\n",
    "    \n",
    "    if return_more:\n",
    "        return output, decoded_output, decoder_attns_arr, sample\n",
    "    \n",
    "    return output, output, sample_target, sample\n",
    "    \n",
    "tmp = test_model_single_sample(None)\n",
    "tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metres         => theaters license license license license license license license license license license license license license license license license license license license || [108, 0] \n",
      "                  completed in 1985 , it has a main span of 876 <SAMPLE> ( 2 , 874 ft ) .\n",
      "IRIB's         => theaters license license license license license license license license license license license license license license license license license license license || [31, 35, 31, 240, 0] \n",
      "                  <SAMPLE> central documents archive on simorgh ( irib national channel 1 ) .\n"
     ]
    }
   ],
   "source": [
    "def print_local_wrong_predictions(max_results=10):\n",
    "    arr = get_some_wrong_predictions(None, test_model_single_sample, max_iterations=10000, max_results=max_results)\n",
    "    for sample, predict, output in arr:\n",
    "        s_bef, s_aft, s_class, s_sentence = sample\n",
    "        print(\"{:<14} => {:<14} || {} \\n{:>17} {}\".format(s_bef, predict, s_aft, '', s_sentence, ))\n",
    "print_local_wrong_predictions(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.00% (       0/     100)\n",
      "CPU times: user 3.39 s, sys: 144 ms, total: 3.53 s\n",
      "Wall time: 3.53 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "test_model_accuracy(encoder_rnn, test_model_single_sample, n_sample=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train(s_bef, s_aft, s_sentence, encoder_optimizer, decoder_optimizer, loss_function,\n",
    "          use_teacher_forcing, max_length=20):\n",
    "    \n",
    "    words_t = Variable(words_to_word_vectors_tensor(list(s_sentence), wv_vecs, wv_idx)).cuda()\n",
    "    \n",
    "    THIS WAS ERROR. SENTENCE IS SINGLE LETTERS INSTEAD OF WORDS\n",
    "    THIS WAS ERROR. SENTENCE IS SINGLE LETTERS INSTEAD OF WORDS\n",
    "    THIS WAS ERROR. SENTENCE IS SINGLE LETTERS INSTEAD OF WORDS\n",
    "    THIS WAS ERROR. SENTENCE IS SINGLE LETTERS INSTEAD OF WORDS\n",
    "    THIS WAS ERROR. SENTENCE IS SINGLE LETTERS INSTEAD OF WORDS\n",
    "    \n",
    "    \n",
    "    string_t = string_to_tensor(s_bef, chars_normal_index)\n",
    "    string_t = Variable(string_t).cuda()\n",
    "    \n",
    "    encoder_output, encoder_outputs = encoder_rnn(words_t, string_t)\n",
    "    \n",
    "    #encoder_output = encoder_output.view(1,1,-1)\n",
    "    \n",
    "    decoder_hidden = decoder_rnn.init_rest_hidden(encoder_outputs[0].view(1,1,-1))\n",
    "    decoder_input = Variable(sos_tensor).cuda()\n",
    "    \n",
    "    ###\n",
    "    target_arr = s_aft\n",
    "    #target_arr = after_sentence_to_word_indexes(s_aft, include_eos=True)\n",
    "    \n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "    loss = 0\n",
    "    \n",
    "    decoded_output = []\n",
    "    for i in range(len(target_arr)):\n",
    "        decoder_output, decoder_hidden, decoder_attns = decoder_rnn(decoder_input, decoder_hidden, encoder_outputs)\n",
    "\n",
    "        #decoder_target_i = chars_after_index[target_arr[i]]\n",
    "        decoder_target_i = target_arr[i]\n",
    "        decoder_target_i = Variable(torch.LongTensor([decoder_target_i])).cuda()\n",
    "        loss += loss_function(decoder_output, decoder_target_i)\n",
    "        \n",
    "        topv, topi = decoder_output.data.topk(1)\n",
    "        word_index = topi[0][0]\n",
    "        word = words_after_common[word_index] # Use own prediction as next input\n",
    "        decoded_output.append(word)\n",
    "        \n",
    "        if use_teacher_forcing:\n",
    "            word_index = target_arr[i] # replace input with right target\n",
    "        else:\n",
    "            # use output normally as input \n",
    "            if word == EOS_TOKEN:\n",
    "                break\n",
    "                \n",
    "        decoder_input = torch.zeros(1, 1, len(words_after_index))\n",
    "        decoder_input[0, 0, word_index] = 1\n",
    "        decoder_input = Variable(decoder_input).cuda()\n",
    "        #decoder_input = Variable(torch.LongTensor([word_index])).cuda()\n",
    "        \n",
    "    if decoded_output[-1] == EOS_TOKEN:\n",
    "        decoded_output = decoded_output[:-1]\n",
    "        \n",
    "    loss.backward()\n",
    "\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "\n",
    "    return ' '.join(decoded_output), (loss.data[0] / len(target_arr))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_iterations(n_iters=100000, lr=0.001, teacher_forcing_ratio=0.5,\n",
    "                     print_every=10000, plot_every=1000):\n",
    "\n",
    "    start = time.time()\n",
    "    \n",
    "    decoder_rnn.train()\n",
    "    encoder_rnn.train()\n",
    "\n",
    "    current_loss = 0\n",
    "    current_loss_iter = 0\n",
    "\n",
    "    encoder_optimizer = torch.optim.Adam(encoder_rnn.parameters(), lr=lr)\n",
    "    decoder_optimizer = torch.optim.Adam(decoder_rnn.parameters(), lr=lr)\n",
    "    loss_function = nn.NLLLoss()\n",
    "    \n",
    "    for iteration in range(1, n_iters + 1):\n",
    "        model_training.iterations += 1\n",
    "        \n",
    "        use_teacher_forcing = random.random() < teacher_forcing_ratio\n",
    "        \n",
    "        s_bef, s_aft, s_class, s_sentence = get_random_sample()\n",
    "        \n",
    "        result, loss = train(s_bef=s_bef, s_aft=s_aft, s_sentence=s_sentence,\n",
    "                             encoder_optimizer=encoder_optimizer, decoder_optimizer=decoder_optimizer,\n",
    "                             loss_function=nn.NLLLoss(), use_teacher_forcing=use_teacher_forcing,\n",
    "                             max_length=40 )\n",
    "        \n",
    "        current_loss += loss\n",
    "        current_loss_iter += 1\n",
    "\n",
    "        # Print iter number, loss, name and guess\n",
    "        if iteration % print_every == 0:\n",
    "            teacher_forcing_str = \"\"\n",
    "            if use_teacher_forcing:\n",
    "                teacher_forcing_str = \"(forcing)\"\n",
    "            s_aft_sentence = ' '.join([words_after_common[w] for w in s_aft][:-1])\n",
    "            correct = '✓' if result == s_aft_sentence else \"✗: {}\".format(s_aft_sentence)\n",
    "            \n",
    "            print(\"{:>6d} {:>4.0%} ({:>8}) {:>7.3f}   | {:>6.2f}: {} -> {} ({}) {}\".format(\n",
    "                      model_training.iterations, iteration/n_iters, time_since(start),\n",
    "                      current_loss/current_loss_iter, loss,\n",
    "                      s_bef, result, correct, teacher_forcing_str))\n",
    "\n",
    "        # Add current loss avg to list of losses\n",
    "        if iteration % plot_every == 0:\n",
    "            model_training.losses.append(current_loss / plot_every)\n",
    "            model_training.learning_rates.append(lr)\n",
    "            current_loss = 0\n",
    "            current_loss_iter = 0\n",
    "            \n",
    "        if model_training.iterations % 50000 == 0 or model_training.iterations == 10:\n",
    "            model_training.save_models()\n",
    "            acc = test_model_accuracy(encoder_rnn, test_model_single_sample)\n",
    "            model_training.accuracy.append(acc)\n",
    "    \n",
    "    # test_model_accuracy(model, n_sample=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Save path: data/models/whole_gen_11_fixes\n"
     ]
    }
   ],
   "source": [
    "model_training = ModelTraining(MODEL_SAVE_PATH, [encoder_rnn, decoder_rnn])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     9  18% (   0m 0s)   6.288   |   3.59: 2006 -> theaters (✗: two thousand six) \n",
      "Saved model to data/models/whole_gen_11_fixes/10_(EncoderRNN/DecoderRNN)\n",
      "Accuracy: 0.00% (       0/   10000)\n",
      "    18  36% (  1m 19s)   6.001   |   3.62: organised ->  (✗: organized) \n",
      "    27  54% (  1m 19s)   6.104   |   7.14: 85% -> <EOS> <EOS> <EOS> (✗: eighty five percent) (forcing)\n",
      "    36  72% (  1m 20s)   5.871   |   6.90: & -> <EOS> (✗: and) (forcing)\n",
      "    45  90% (  1m 20s)   5.541   |   6.71: & -> <EOS> (✗: and) (forcing)\n"
     ]
    }
   ],
   "source": [
    "train_iterations(n_iters=50, print_every=9, lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "time.sleep(60*60*3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   665  60% (  0m 12s)   2.884   |   5.47: st -> and (✗: street) (forcing)\n"
     ]
    }
   ],
   "source": [
    "train_iterations(n_iters=(1000-model_training.iterations), print_every=500, lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  2000  11% (  0m 25s)   2.539   |   1.68: SRRA -> two (✗: s r r a) \n",
      "  3000  22% (  0m 51s)   2.378   |   2.21: etc -> p (✗: etcetera) \n",
      "  4000  33% (  1m 17s)   2.185   |   2.06: J. -> p (✗: j) \n",
      "  5000  44% (  1m 44s)   1.975   |   0.34: - -> to (✓) (forcing)\n",
      "  6000  56% (  2m 10s)   1.903   |   2.02: 383 -> two hundred (✗: three hundred eighty three) \n",
      "  7000  67% (  2m 37s)   1.811   |   0.02: & -> and (✓) \n",
      "  8000  78% (   3m 4s)   1.724   |   2.44: September 4, 2008 -> november twenty twenty twenty (✗: september fourth two thousand eight) \n",
      "  9000  89% (  3m 31s)   1.715   |   1.44: A. -> r (✗: a) \n",
      " 10000 100% (  3m 58s)   1.626   |   2.80: TB -> i (✗: t b) \n"
     ]
    }
   ],
   "source": [
    "train_iterations(n_iters=9000, lr=0.0001, print_every=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 20000  11% (  3m 58s)   0.815   |   2.17: January 15, 2008 -> june twenty twenty thousand (✗: january fifteenth two thousand eight) \n",
      " 30000  22% (  6m 47s)   0.585   |   1.09: synagogue -> dialog (✗: synagog) \n",
      " 40000  33% (  9m 37s)   0.545   |   0.00: J. -> j (✓) \n",
      " 50000  44% ( 12m 27s)   0.399   |   0.00: & -> and (✓) (forcing)\n",
      "Saved model to data/models/whole_gen_11_fixes/50000_(EncoderRNN/DecoderRNN)\n",
      "Accuracy: 80.58% (    8058/   10000)\n",
      " 60000  56% ( 16m 19s)   0.390   |   0.00: & -> and (✓) (forcing)\n",
      " 70000  67% ( 19m 10s)   0.416   |   0.00: - -> to (✓) \n",
      " 80000  78% (  22m 1s)   0.333   |   0.00: & -> and (✓) \n",
      " 90000  89% ( 24m 52s)   0.299   |   0.13: NCEL -> n c e l (✓) (forcing)\n",
      "100000 100% ( 27m 42s)   0.298   |   0.01: 2009 -> two thousand nine (✓) \n",
      "Saved model to data/models/whole_gen_11_fixes/100000_(EncoderRNN/DecoderRNN)\n",
      "Accuracy: 85.15% (    8515/   10000)\n"
     ]
    }
   ],
   "source": [
    "train_iterations(n_iters=90000, print_every=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "110000   5% (  2m 52s)   0.344   |   0.00: dr -> doctor (✓) (forcing)\n",
      "120000  10% (  5m 42s)   0.278   |   0.25: bros -> brothers (✓) (forcing)\n",
      "130000  15% (  8m 31s)   0.311   |   0.00: - -> to (✓) \n",
      "140000  20% ( 11m 22s)   0.353   |   0.00: honour -> honor (✓) \n",
      "150000  25% ( 14m 13s)   0.289   |   0.00: & -> and (✓) \n",
      "Saved model to data/models/whole_gen_11_fixes/150000_(EncoderRNN/DecoderRNN)\n",
      "Accuracy: 88.37% (    8837/   10000)\n",
      "160000  30% (  18m 5s)   0.249   |   0.00: BACC -> b a c c (✓) \n",
      "170000  35% ( 20m 55s)   0.271   |   0.00: & -> and (✓) (forcing)\n",
      "180000  40% ( 23m 45s)   0.365   |   0.00: 69 -> sixty nine (✓) \n",
      "190000  45% ( 26m 36s)   0.257   |   0.74: agli -> a s l l (✗: a g l i) (forcing)\n",
      "200000  50% ( 29m 26s)   0.281   |   0.18: CDs -> c d's (✓) \n",
      "Saved model to data/models/whole_gen_11_fixes/200000_(EncoderRNN/DecoderRNN)\n",
      "Accuracy: 87.71% (    8771/   10000)\n",
      "210000  55% ( 33m 20s)   0.300   |   1.55: I -> the (✗: one) \n",
      "220000  60% ( 36m 10s)   0.257   |   0.00: & -> and (✓) \n",
      "230000  65% (  39m 1s)   0.216   |   0.00: reorganisation -> reorganization (✓) \n",
      "240000  70% ( 41m 53s)   0.234   |   0.87: 12 ft -> twelve two (✗: twelve feet) (forcing)\n",
      "250000  75% ( 44m 43s)   0.263   |   0.00: - -> to (✓) (forcing)\n",
      "Saved model to data/models/whole_gen_11_fixes/250000_(EncoderRNN/DecoderRNN)\n",
      "Accuracy: 89.21% (    8921/   10000)\n",
      "260000  80% ( 48m 34s)   0.153   |   0.00: November 2010 -> november twenty ten (✓) \n",
      "270000  85% ( 51m 26s)   0.246   |   0.02: 1847 -> eighteen forty seven (✓) (forcing)\n",
      "280000  90% ( 54m 18s)   0.214   |   0.01: OK -> okay (✓) \n",
      "290000  95% ( 57m 10s)   0.240   |   4.45: 18 November 1924 -> the twenty eighth of november nineteen thirty four (✗: the eighteenth of november nineteen twenty four) \n",
      "300000 100% (  60m 0s)   0.229   |   0.00: theatre -> theater (✓) \n",
      "Saved model to data/models/whole_gen_11_fixes/300000_(EncoderRNN/DecoderRNN)\n",
      "Accuracy: 88.58% (    8858/   10000)\n"
     ]
    }
   ],
   "source": [
    "train_iterations(n_iters=200000, print_every=10000, teacher_forcing_ratio=0.5, lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hypothesised   => summarized     || [732, 0] \n",
      "                  it has been <SAMPLE> that niche partitioning enabled several species of crocodyliforms to co exist .\n",
      "1995-12-31     => the thirty first of ninety nineteen ninety five || [11, 34, 56, 12, 65, 7, 23, 14, 0] \n",
      "                  g . c . shekhar ( <SAMPLE> ) .\n",
      "Wednesday March 6, 2013 => august sixth twenty thirteen || [236, 62, 79, 6, 49, 0] \n",
      "                  <SAMPLE> .\n",
      "VII            => the million    || [18, 0] \n",
      "                  \" parts v , vi , <SAMPLE> , viii and ix of the bar council of india rules \" .\n",
      "Landstrasse    => strasse        || [766, 241, 0] \n",
      "                  the escalators down to the platform are located in offenbacher <SAMPLE> .\n",
      "AFI            => a f            || [22, 37, 31, 0] \n",
      "                  the following list is limited to <SAMPLE> awards , logie and / or awgie awards winners .\n",
      "ADSL           => a d l          || [22, 26, 17, 42, 0] \n",
      "                  <SAMPLE> became available in montenegro in 2005 .\n",
      "2.5%           => two point five five percent || [5, 46, 14, 83, 0] \n",
      "                  <SAMPLE> of the population were hispanic or latino of any race .\n",
      "DAGBO          => d a d b o b    || [26, 22, 53, 36, 25, 0] \n",
      "                  english m buko / french m buko dictionaries on project <SAMPLE> by jolomerichard gravina .\n",
      "Decentralised  => twenty         || [830, 0] \n",
      "                  \" national commission for <SAMPLE> cooperation \" .\n"
     ]
    }
   ],
   "source": [
    "print_local_wrong_predictions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "310000   5% (  2m 49s)   0.228   |   0.00: BA -> b a (✓) \n",
      "320000  10% (  5m 39s)   0.238   |   0.00: DNA -> d n a (✓) \n",
      "330000  15% (  8m 30s)   0.232   |   0.00: IPO -> i p o (✓) \n",
      "340000  20% ( 11m 21s)   0.248   |   0.00: & -> and (✓) \n",
      "350000  25% ( 14m 10s)   0.211   |   0.00: : -> to (✓) \n",
      "Saved model to data/models/whole_gen_11_fixes/350000_(EncoderRNN/DecoderRNN)\n",
      "Accuracy: 88.41% (    8841/   10000)\n",
      "360000  30% (  18m 4s)   0.244   |   0.00: & -> and (✓) \n",
      "370000  35% ( 20m 55s)   0.246   |   0.01: # -> number (✓) \n",
      "380000  40% ( 23m 47s)   0.221   |   0.00: - -> to (✓) (forcing)\n",
      "390000  45% ( 26m 39s)   0.179   |   0.00: - -> to (✓) \n",
      "400000  50% ( 29m 29s)   0.177   |   0.01: 1954 -> nineteen fifty four (✓) \n",
      "Saved model to data/models/whole_gen_11_fixes/400000_(EncoderRNN/DecoderRNN)\n",
      "Accuracy: 89.60% (    8960/   10000)\n",
      "410000  55% ( 33m 22s)   0.196   |   0.00: & -> and (✓) \n",
      "420000  60% ( 36m 12s)   0.180   |   0.00: T.I. -> t i (✓) \n",
      "430000  65% (  39m 2s)   0.200   |   0.00: 2004 -> two thousand four (✓) \n",
      "440000  70% ( 41m 53s)   0.251   |   0.02: 29 October 2011 -> the twenty ninth of october twenty eleven (✓) \n",
      "450000  75% ( 44m 44s)   0.184   |   0.00: sr -> senior (✓) \n",
      "Saved model to data/models/whole_gen_11_fixes/450000_(EncoderRNN/DecoderRNN)\n",
      "Accuracy: 91.61% (    9161/   10000)\n",
      "460000  80% ( 48m 37s)   0.168   |   3.16: harbours -> humor (✗: harbors) (forcing)\n",
      "470000  85% ( 51m 26s)   0.166   |   0.00: 22 -> twenty two (✓) \n",
      "480000  90% ( 54m 17s)   0.176   |   0.00: PKK -> p k k (✓) \n",
      "490000  95% (  57m 7s)   0.200   |   0.00: I.P. -> i p (✓) \n",
      "500000 100% ( 59m 59s)   0.189   |   0.00: 235 -> two hundred thirty five (✓) \n",
      "Saved model to data/models/whole_gen_11_fixes/500000_(EncoderRNN/DecoderRNN)\n",
      "Accuracy: 92.12% (    9212/   10000)\n"
     ]
    }
   ],
   "source": [
    "train_iterations(n_iters=200000, print_every=10000, teacher_forcing_ratio=0.3, lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2003-12-24     => the twenty fourth of december two thousand four || [11, 6, 77, 12, 65, 5, 8, 13, 0] \n",
      "                  sisario , ben ( <SAMPLE> ) .\n",
      "59 percent     => fifty five percent || [38, 15, 83, 0] \n",
      "                  in 1973 the turnover topped the 200 million dm limit ; the export share climbed to <SAMPLE> .\n",
      "mrs            => mister         || [32, 35, 17, 0] \n",
      "                  for a list of all moravac <SAMPLE> tane players with a wikipedia article , please see : category : fk moravac mrs tane players .\n",
      "978-0-87930-892-6 => nine seven sil sil sil sil sil sil sil sil sil sil sil sil sil sil sil sil sil sil || [15, 18, 16, 58, 25, 58, 16, 18, 15, 13, 25, 58, 16, 15, 5, 58, 20, 0] \n",
      "                  richie unterberger , the unreleased beatles : music & film , backbeat books ( san francisco , ca , 2006 ; isbn <SAMPLE> ) .\n",
      "Langebaanweg   => ten            || [1021, 315, 0] \n",
      "                  it is the location of the air force base afb <SAMPLE> .\n",
      "normalisation  => nationalization || [745, 0] \n",
      "                  as oii commented , <SAMPLE> surgery is more than physical reconstruction .\n",
      ".296           => point two six nine || [46, 5, 15, 20, 0] \n",
      "                  over the rest of the season , flynn batted <SAMPLE> with twenty rbi .\n",
      "Sunday, April 6 => april the april || [166, 71, 79, 0] \n",
      "                  \" first performers announced : feist , finger eleven and michael bublé to rock the 2008 juno awards , <SAMPLE> on ctv \" .\n",
      "utilise        => utilizing      || [639, 0] \n",
      "                  mac os x does not hide this account , but users with limited rights can still fully <SAMPLE> the system .\n",
      "1014           => one fourteen   || [44, 50, 0] \n",
      "                  new york : church publishing inc isbn 978 - 0 - 89869 - 888 - 6 , p . <SAMPLE> .\n"
     ]
    }
   ],
   "source": [
    "print_local_wrong_predictions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "510000  10% (  2m 52s)   0.173   |   0.00: _ -> underscore (✓) (forcing)\n",
      "520000  20% (  5m 44s)   0.137   |   8.75: ostracised -> subsidized (✗: ostracized) \n",
      "530000  30% (  8m 34s)   0.113   |   0.00: & -> and (✓) \n",
      "540000  40% ( 11m 25s)   0.138   |   0.00: A. J. -> a j (✓) \n",
      "550000  50% ( 14m 17s)   0.098   |   0.00: & -> and (✓) (forcing)\n",
      "Saved model to data/models/whole_gen_11_fixes/550000_(EncoderRNN/DecoderRNN)\n",
      "Accuracy: 94.64% (    9464/   10000)\n",
      "560000  60% ( 18m 12s)   0.087   |   0.07: 2012 -> twenty twelve (✓) (forcing)\n",
      "570000  70% (  21m 3s)   0.101   |   0.00: advertising -> advertizing (✓) \n",
      "580000  80% ( 23m 54s)   0.107   |   0.00: gp -> g p (✓) (forcing)\n",
      "590000  90% ( 26m 44s)   0.151   |   0.00: GP -> g p (✓) \n",
      "600000 100% ( 29m 35s)   0.107   |   0.00: AP -> a p (✓) \n",
      "Saved model to data/models/whole_gen_11_fixes/600000_(EncoderRNN/DecoderRNN)\n",
      "Accuracy: 95.00% (    9500/   10000)\n"
     ]
    }
   ],
   "source": [
    "train_iterations(n_iters=100000, print_every=10000, teacher_forcing_ratio=0.5, lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CEGIN          => c i g e i      || [21, 28, 53, 31, 29, 0] \n",
      "                  hypolito won the brazilian national championships again in 2014 ; her club , <SAMPLE> , took second in the team event .\n",
      "4092           => four thousand o two || [19, 8, 23, 5, 0] \n",
      "                  \" cbo — h . r . <SAMPLE> \" .\n",
      "BMedSc         => b e e e e      || [36, 32, 28, 26, 17, 21, 0] \n",
      "                  in 1927 he was the first student to graduate bachelor of medical science ( <SAMPLE> ) .\n",
      "18464          => fourteen thousand four hundred sixty four || [40, 8, 19, 10, 39, 19, 0] \n",
      "                  it operates as train number 18463 from bhubaneswar to bangalore and as train number <SAMPLE> between bangalore and bhubaneswar .\n",
      "A29091         => a thousand o o || [22, 5, 15, 25, 15, 9, 0] \n",
      "                  1991 <SAMPLE> : hsk 0491 ( 1990334 s 08078 ) .\n",
      "TPK            => t p k          || [1138, 0] \n",
      "                  <SAMPLE> 3 8 2 0 6 12 29 69 .\n",
      "localiser      => localized      || [1227, 0] \n",
      "                  the starboard wing impacted the concrete socket of the instrument landing system <SAMPLE> antenna , rendering it unusable .\n",
      "127.2          => one hundred twenty two point two || [9, 10, 6, 18, 46, 5, 0] \n",
      "                  for every 100 females age 18 and over , there were <SAMPLE> males .\n",
      "WowTV          => w w t w v      || [52, 25, 52, 30, 54, 0] \n",
      "                  <SAMPLE> ( in korean ) .\n",
      "#              => number         || [175, 0] \n",
      "                  code 08 203 , as amended by the amendment <SAMPLE> 259 / 2014 of december 12 , 2014 .\n"
     ]
    }
   ],
   "source": [
    "print_local_wrong_predictions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "610000  10% (  2m 50s)   0.201   |   0.00: 2008 -> two thousand eight (✓) \n",
      "620000  20% (  5m 41s)   0.173   |   0.00: centre -> center (✓) \n",
      "630000  30% (  8m 32s)   0.238   |   0.00: & -> and (✓) \n",
      "640000  40% ( 11m 24s)   0.148   |   0.00: TVN -> t v n (✓) (forcing)\n",
      "650000  50% ( 14m 14s)   0.170   |   0.00: & -> and (✓) \n",
      "Saved model to data/models/whole_gen_11_fixes/650000_(EncoderRNN/DecoderRNN)\n",
      "Accuracy: 92.40% (    9240/   10000)\n",
      "660000  60% (  18m 7s)   0.169   |   0.77: GSCAS -> g s a s s (✗: g s c a s) \n",
      "670000  70% ( 20m 58s)   0.170   |   0.01: 1994 -> nineteen ninety four (✓) \n",
      "680000  80% ( 23m 51s)   0.135   |   0.00: Kou -> k o u (✓) \n",
      "690000  90% ( 26m 41s)   0.194   |   0.00: & -> and (✓) \n",
      "700000 100% ( 29m 33s)   0.157   |   0.00: cf -> c f (✓) \n",
      "Saved model to data/models/whole_gen_11_fixes/700000_(EncoderRNN/DecoderRNN)\n",
      "Accuracy: 92.34% (    9234/   10000)\n"
     ]
    }
   ],
   "source": [
    "train_iterations(n_iters=100000, print_every=10000, teacher_forcing_ratio=0.1, lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HDOBD          => h b d d d      || [45, 26, 25, 36, 26, 0] \n",
      "                  2010 : <SAMPLE> ( heavy duty ) specification is made mandatory for selected commercial ( non passenger car ) engines sold in the united states .\n",
      "Moj            => m o l          || [32, 25, 60, 0] \n",
      "                  example sentences : <SAMPLE> bog pravi drugace !\n",
      "2015           => twenty fifteen || [5, 8, 51, 0] \n",
      "                  rok military weapon systems 2014 - <SAMPLE> .\n",
      "Récits         => e i acute i t  || [35, 28, 121, 21, 31, 221, 0] \n",
      "                  naklad gebethnera i wolffa \" les <SAMPLE> d' un vieux gentilhomme polonais \" , mickiewicz wladyslaw , paris 1866 .\n",
      "Feb 2, 2015    => february second twenty || [72, 73, 6, 51, 0] \n",
      "                  retrieved <SAMPLE> .\n",
      "$81,000        => eighty one thousand dollars dollars dollars || [27, 9, 8, 85, 0] \n",
      "                  \" news of the stage ; <SAMPLE> in grants for colon theater \" , the new york times , february 24 , 1974 .\n",
      "WOMEX          => w e m e x      || [52, 25, 32, 28, 97, 0] \n",
      "                  the band had their showcase concert at the <SAMPLE> 2015 festival in budapest .\n",
      "IQOLA          => i o l l a      || [31, 111, 25, 42, 22, 0] \n",
      "                  \" overview of the sf - 36 health survey and the international quality of life assessment ( <SAMPLE> ) project \" .\n",
      "14.5 km        => fourteen point four kilometers || [50, 46, 14, 89, 0] \n",
      "                  it currently has 19 stations and it runs <SAMPLE> from reumannplatz to leopoldau .\n",
      "BSGs           => b s b's        || [36, 17, 264, 0] \n",
      "                  blue supergiants ( <SAMPLE> ) are hot luminous stars , referred to scientifically as ob supergiants .\n"
     ]
    }
   ],
   "source": [
    "print_local_wrong_predictions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "710000   5% (  2m 50s)   0.119   |   0.00: UK -> u k (✓) \n",
      "720000  10% (  5m 43s)   0.155   |   0.00: October 5, 2015 -> october fifth twenty fifteen (✓) \n",
      "730000  15% (  8m 34s)   0.139   |   0.02: 2008-05-08 -> the eighth of may two thousand eight (✓) \n",
      "740000  20% ( 11m 24s)   0.129   |   0.00: vol -> volume (✓) \n",
      "750000  25% ( 14m 15s)   0.089   |   0.01: Rih -> r i h (✓) \n",
      "Saved model to data/models/whole_gen_11_fixes/750000_(EncoderRNN/DecoderRNN)\n",
      "Accuracy: 94.85% (    9485/   10000)\n",
      "760000  30% (  18m 8s)   0.104   |   0.00: AI -> a i (✓) \n",
      "770000  35% ( 20m 59s)   0.103   |   0.00: & -> and (✓) \n",
      "780000  40% ( 23m 49s)   0.114   |   0.06: 2011 -> twenty eleven (✓) \n",
      "790000  45% ( 26m 42s)   0.111   |   0.00: thC -> t h c (✓) \n",
      "800000  50% ( 29m 33s)   0.125   |   0.00: - -> to (✓) \n",
      "Saved model to data/models/whole_gen_11_fixes/800000_(EncoderRNN/DecoderRNN)\n",
      "Accuracy: 94.36% (    9436/   10000)\n",
      "810000  55% ( 33m 27s)   0.061   |   0.00: NBA -> n b a (✓) \n",
      "820000  60% ( 36m 18s)   0.121   |   0.00: R. -> r (✓) \n",
      "830000  65% (  39m 9s)   0.100   |   0.03: 2010 -> twenty ten (✓) \n",
      "840000  70% (  42m 0s)   0.130   |   0.00: EPA -> e p a (✓) \n",
      "850000  75% ( 44m 51s)   0.070   |   0.00: - -> to (✓) \n",
      "Saved model to data/models/whole_gen_11_fixes/850000_(EncoderRNN/DecoderRNN)\n",
      "Accuracy: 95.50% (    9550/   10000)\n",
      "860000  80% ( 48m 45s)   0.121   |   0.00: & -> and (✓) \n",
      "870000  85% ( 51m 36s)   0.084   |   0.00: W. -> w (✓) \n",
      "880000  90% ( 54m 28s)   0.100   |   0.00: ISBN -> i s b n (✓) \n",
      "890000  95% ( 57m 19s)   0.121   |   0.00: etc -> etcetera (✓) \n",
      "900000 100% ( 60m 10s)   0.125   |   0.01: 60 -> sixty (✓) \n",
      "Saved model to data/models/whole_gen_11_fixes/900000_(EncoderRNN/DecoderRNN)\n",
      "Accuracy: 94.65% (    9465/   10000)\n"
     ]
    }
   ],
   "source": [
    "train_iterations(n_iters=200000, print_every=10000, teacher_forcing_ratio=0.1, lr=0.0005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12,800         => twelve thousand thousand || [47, 8, 16, 10, 0] \n",
      "                  \" evidence for deposition of 10 million tonnes of impact spherules across four continents <SAMPLE> y ago . \"\n",
      "07             => o seven        || [18, 0] \n",
      "                  belle vernon area school district administration did not apply to participate in 2006 - <SAMPLE> nor in 2007 - 08 .\n",
      "armées         => a r r r acute acute e's || [22, 35, 32, 28, 121, 173, 0] \n",
      "                  biographie des célébrités militaires des <SAMPLE> de terre et de mer de 1789 a 1850 ( in french ) .\n",
      "PlaqueIII-     => p i i i i i i i || [24, 42, 22, 111, 43, 28, 31, 31, 31, 0] \n",
      "                  exploring niagara : jordan , ontarioontario <SAMPLE> 24 the first mennonite church ( vineland , ont .\n",
      "RECIST         => r c c i s t    || [35, 28, 21, 31, 17, 30, 0] \n",
      "                  today , the majority of clinical trials evaluating cancer treatments for objective response in solid tumors use <SAMPLE> .\n",
      "1924           => nineteen twenty four || [9, 8, 15, 10, 6, 19, 0] \n",
      "                  the <SAMPLE> - 25 squad played only eight games , finishing 6 - 2 , and played a single road game , against navy at annapolis .\n",
      "1996 B         => one ninety six || [7, 23, 20, 0] \n",
      "                  \" deuterated water in comet c / <SAMPLE> 2 ( hyakutake ) and its implications for the origin of comets \" .\n",
      "#              => number         || [175, 0] \n",
      "                  2 , <SAMPLE> 3 / 100 ( feb . 2006 , the 100th issue of all the various she hulk series ) .\n",
      "Grimmstrasse   => six strasse    || [1135, 241, 0] \n",
      "                  originally on the kemperplatz , it is now at the corner of urbanstrasse and <SAMPLE> in berlin kreuzberg .\n",
      "1-4051-6260-0  => one sil six sil sil sil sil sil sil sil sil sil || [9, 58, 19, 25, 14, 9, 58, 20, 5, 20, 25, 58, 25, 0] \n",
      "                  making social worlds : a communication perspective , wiley blackwell , january , 2008 , isbn <SAMPLE> stone , douglas ; patton , bruce and heen , sheila .\n"
     ]
    }
   ],
   "source": [
    "print_local_wrong_predictions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "910000   3% (  2m 52s)   0.070   |   0.11: 2014-02-20 -> the second of february twenty fourteen (✗: the twentieth of february twenty fourteen) \n",
      "920000   7% (  5m 44s)   0.107   |   0.00: finalise -> finalize (✓) \n",
      "930000  10% (  8m 35s)   0.064   |   0.00: January 2013 -> january twenty thirteen (✓) \n",
      "940000  13% ( 11m 26s)   0.126   |   0.00: μ -> mu (✓) \n",
      "950000  17% ( 14m 19s)   0.136   |   0.00: & -> and (✓) (forcing)\n",
      "Saved model to data/models/whole_gen_11_fixes/950000_(EncoderRNN/DecoderRNN)\n",
      "Accuracy: 95.99% (    9599/   10000)\n",
      "960000  20% ( 18m 12s)   0.095   |   0.00: 2004 -> two thousand four (✓) \n",
      "970000  23% (  21m 4s)   0.119   |   0.20: 222 million -> two hundred twenty two million (✓) \n",
      "980000  27% ( 23m 55s)   0.064   |   0.01: # -> number (✓) \n",
      "990000  30% ( 26m 48s)   0.094   |   0.00: & -> and (✓) \n",
      "1000000  33% ( 29m 40s)   0.064   |   0.02: 1983 -> nineteen eighty three (✓) \n",
      "Saved model to data/models/whole_gen_11_fixes/1000000_(EncoderRNN/DecoderRNN)\n",
      "Accuracy: 96.01% (    9601/   10000)\n",
      "1010000  37% ( 33m 36s)   0.074   |   0.00: $ -> dollar (✓) \n",
      "1020000  40% ( 36m 28s)   0.075   |   0.00: etc -> etcetera (✓) \n",
      "1030000  43% ( 39m 19s)   0.076   |   0.00: - -> to (✓) \n",
      "1040000  47% ( 42m 11s)   0.055   |   0.00: - -> to (✓) \n",
      "1050000  50% (  45m 3s)   0.084   |   0.00: 135 -> one hundred thirty five (✓) \n",
      "Saved model to data/models/whole_gen_11_fixes/1050000_(EncoderRNN/DecoderRNN)\n",
      "Accuracy: 96.10% (    9610/   10000)\n",
      "1060000  53% ( 48m 58s)   0.073   |   0.00: & -> and (✓) \n",
      "1070000  57% ( 51m 50s)   0.111   |   0.09: Uniao -> u n i a o (✓) \n",
      "1080000  60% ( 54m 41s)   0.059   |   0.00: Franchise -> franchize (✓) \n",
      "1090000  63% ( 57m 32s)   0.071   |   0.00: & -> and (✓) \n",
      "1100000  67% ( 60m 23s)   0.071   |   0.00: J. -> j (✓) \n",
      "Saved model to data/models/whole_gen_11_fixes/1100000_(EncoderRNN/DecoderRNN)\n",
      "Accuracy: 95.92% (    9592/   10000)\n",
      "1110000  70% ( 64m 18s)   0.092   |   0.00: THSR -> t h s r (✓) \n",
      "1120000  73% (  67m 9s)   0.111   |   0.00: 44, -> forty four (✓) \n",
      "1130000  77% (  70m 1s)   0.064   |   0.00: 17 -> seventeen (✓) \n",
      "1140000  80% ( 72m 52s)   0.056   |   0.00: Centre -> center (✓) \n",
      "1150000  83% ( 75m 45s)   0.063   |   0.00: 25 September 1940 -> the twenty fifth of september nineteen forty (✓) \n",
      "Saved model to data/models/whole_gen_11_fixes/1150000_(EncoderRNN/DecoderRNN)\n",
      "Accuracy: 96.13% (    9613/   10000)\n",
      "1160000  87% ( 79m 39s)   0.067   |   0.00: - -> to (✓) \n",
      "1170000  90% ( 82m 31s)   0.093   |   0.00: 87 -> eighty seven (✓) \n",
      "1180000  93% ( 85m 23s)   0.069   |   0.00: 2 -> two (✓) \n",
      "1190000  97% ( 88m 14s)   0.070   |   0.00: & -> and (✓) \n",
      "1200000 100% (  91m 8s)   0.054   |   0.00: - -> to (✓) \n",
      "Saved model to data/models/whole_gen_11_fixes/1200000_(EncoderRNN/DecoderRNN)\n",
      "Accuracy: 96.06% (    9606/   10000)\n"
     ]
    }
   ],
   "source": [
    "train_iterations(n_iters=300000, print_every=10000, teacher_forcing_ratio=0.1, lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16.5m          => sixteen point five five || [75, 46, 14, 108, 0] \n",
      "                  tv viewership was <SAMPLE> on espn , and 5 . 1m on univision .\n",
      ".926           => point nine nine six || [46, 15, 5, 20, 0] \n",
      "                  koch 2006 , p <SAMPLE> .\n",
      "£56,030        => fifty six thousand six pounds || [38, 20, 8, 34, 124, 0] \n",
      "                  the attendance was 19 , 202 and receipts were <SAMPLE> .\n",
      "ST             => street         || [102, 0] \n",
      "                  undergoing overhaul or restorationandrew barclay 0 - 4 - 0 <SAMPLE> no 22 built in 1952 .\n",
      "FGBMFI         => f i f m f i    || [37, 53, 36, 32, 37, 31, 0] \n",
      "                  the plan was supported by oral roberts , and under his leadership , the <SAMPLE> had chapters in over 190 countries .\n",
      "Mittelstrasse  => twelve strasse || [773, 241, 0] \n",
      "                  led by chief editor bruno schonlank , in the lvz 's early years it was edited and printed on <SAMPLE> in leipzig .\n",
      "44601-         => four thousand six thousand o o || [19, 19, 20, 25, 9, 0] \n",
      "                  isbn 0 - 679 - <SAMPLE> x . \" myxine mcmillanae \" .\n",
      ".523           => point five five three || [46, 14, 5, 13, 0] \n",
      "                  hull , p <SAMPLE> caption .\n",
      "#              => number         || [175, 0] \n",
      "                  code 70 228 513 , as amended by the amendment <SAMPLE> 243 / 2014 of april 18 , 2014 .\n",
      "RAIDRS         => r i i r r s    || [35, 22, 31, 26, 35, 17, 0] \n",
      "                  the 380 spcs will operate the rb - 10 central operating location , five <SAMPLE> deployable ground segments .\n"
     ]
    }
   ],
   "source": [
    "print_local_wrong_predictions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1210000   3% (  2m 51s)   0.092   |   0.00: & -> and (✓) \n",
      "1220000   7% (  5m 42s)   0.137   |   0.00: B. -> b (✓) \n",
      "1230000  10% (  8m 35s)   0.162   |   0.00: 1793 -> seventeen ninety three (✓) \n",
      "1240000  13% ( 11m 27s)   0.086   |   0.00: 1000 -> one thousand (✓) \n",
      "1250000  17% ( 14m 19s)   0.144   |   0.00: & -> and (✓) \n",
      "Saved model to data/models/whole_gen_11_fixes/1250000_(EncoderRNN/DecoderRNN)\n",
      "Accuracy: 94.90% (    9490/   10000)\n",
      "1260000  20% ( 18m 13s)   0.108   |   0.00: CBS -> c b s (✓) \n",
      "1270000  23% (  21m 3s)   0.096   |   0.06: st -> saint (✓) \n",
      "1280000  27% ( 23m 53s)   0.114   |   0.02: 115 -> one hundred fifteen (✓) \n",
      "1290000  30% ( 26m 44s)   0.123   |   0.35: I -> one (✓) \n",
      "1300000  33% ( 29m 34s)   0.100   |   0.00: D.S. -> d s (✓) \n",
      "Saved model to data/models/whole_gen_11_fixes/1300000_(EncoderRNN/DecoderRNN)\n",
      "Accuracy: 94.85% (    9485/   10000)\n",
      "1310000  37% ( 33m 28s)   0.096   |   0.00: TKI -> t k i (✓) \n",
      "1320000  40% ( 36m 18s)   0.121   |   0.00: & -> and (✓) \n",
      "1330000  43% ( 39m 10s)   0.088   |   0.00: 53 -> fifty three (✓) \n",
      "1340000  47% (  42m 0s)   0.094   |   0.00: 2008 -> two thousand eight (✓) \n",
      "1350000  50% ( 44m 50s)   0.161   |   0.00: min -> minute (✓) \n",
      "Saved model to data/models/whole_gen_11_fixes/1350000_(EncoderRNN/DecoderRNN)\n",
      "Accuracy: 94.57% (    9457/   10000)\n",
      "1360000  53% ( 48m 45s)   0.139   |   4.76: Sun. January 21, 1919 -> january twenty first nineteen nineteen (✗: sunday january twenty first nineteen nineteen) \n",
      "1370000  57% ( 51m 37s)   0.072   |   0.00: 1956 -> nineteen fifty six (✓) \n",
      "1380000  60% ( 54m 28s)   0.101   |   0.00: PDF -> p d f (✓) \n",
      "1390000  63% ( 57m 18s)   0.109   |   0.00: & -> and (✓) \n",
      "1400000  67% ( 60m 10s)   0.138   |   0.00: 2 -> two (✓) \n",
      "Saved model to data/models/whole_gen_11_fixes/1400000_(EncoderRNN/DecoderRNN)\n",
      "Accuracy: 94.96% (    9496/   10000)\n",
      "1410000  70% (  64m 5s)   0.088   |   0.00: centre -> center (✓) \n",
      "1420000  73% ( 66m 57s)   0.086   |   0.00: & -> and (✓) \n",
      "1430000  77% ( 69m 47s)   0.089   |   0.03: 87 -> eighty seven (✓) \n",
      "1440000  80% ( 72m 38s)   0.080   |   0.00: & -> and (✓) \n",
      "1450000  83% ( 75m 31s)   0.061   |   0.00: st -> saint (✓) \n",
      "Saved model to data/models/whole_gen_11_fixes/1450000_(EncoderRNN/DecoderRNN)\n",
      "Accuracy: 95.63% (    9563/   10000)\n",
      "1460000  87% ( 79m 25s)   0.130   |   0.00: criticised -> criticized (✓) \n",
      "1470000  90% ( 82m 16s)   0.120   |   0.00: Labour -> labor (✓) \n",
      "1480000  93% (  85m 6s)   0.085   |   0.00: & -> and (✓) \n",
      "1490000  97% ( 87m 57s)   0.073   |   0.00: A. -> a (✓) \n",
      "1500000 100% ( 90m 49s)   0.093   |   0.00: glamour -> glamor (✓) \n",
      "Saved model to data/models/whole_gen_11_fixes/1500000_(EncoderRNN/DecoderRNN)\n",
      "Accuracy: 95.50% (    9550/   10000)\n"
     ]
    }
   ],
   "source": [
    "train_iterations(n_iters=300000, print_every=10000, teacher_forcing_ratio=0, lr=0.0005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2011           => twenty eleven  || [5, 8, 48, 0] \n",
      "                  <SAMPLE> - 60% ( 20% below basic ) .\n",
      "500Nm          => five hundred b meters || [14, 10, 712, 108, 0] \n",
      "                  \" extra length <SAMPLE> tcvj \" .\n",
      "NFL            => n f e          || [29, 37, 42, 0] \n",
      "                  he was then allocated to <SAMPLE> europa for the 2005 season .\n",
      "Acua           => a c u c        || [22, 21, 43, 22, 0] \n",
      "                  the most important hills are : cerro cora , located in the national park , <SAMPLE> , lorito , guasu , muralle and sarambi .\n",
      "CRK            => c r k          || [799, 0] \n",
      "                  in august 2000 , <SAMPLE> members called for reopening the discussion about the monarchy .\n",
      "neutralises    => f              || [869, 0] \n",
      "                  the resulting alkaline fluid mix <SAMPLE> the gastric acid which would damage the lining of the intestine .\n",
      "7,960,000      => seven million sixty hundred sixty hundred sixty || [18, 90, 15, 10, 39, 8, 0] \n",
      "                  6 , 037 , 537 of the country 's <SAMPLE> registered voters ( 75 . 84% ) took part in the election .\n",
      "20 cm          => twenty twenty  || [6, 141, 0] \n",
      "                  the lamina is linear , lanceolate or spathulate lanceolate in form and up to <SAMPLE> long by 5 cm wide .\n",
      "GZVH           => g z a h        || [53, 105, 54, 45, 0] \n",
      "                  they were de havilland canada dhc - 6 twin otter c - <SAMPLE> , beechcraft king air c - ghoc and beechcraft 99 c - gkkb .\n",
      "$272           => two two seventy two twelve || [5, 10, 33, 5, 85, 0] \n",
      "                  \" dubai properties sees portfolio doubling to <SAMPLE> bln \" .\n"
     ]
    }
   ],
   "source": [
    "print_local_wrong_predictions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1510000   5% (  2m 52s)   0.060   |   0.00: February 15, 2005 -> february fifteenth two thousand five (✓) \n",
      "1520000  10% (  5m 45s)   0.085   |   0.00: & -> and (✓) \n",
      "1530000  15% (  8m 38s)   0.072   |   0.00: honour -> honor (✓) \n",
      "1540000  20% ( 11m 29s)   0.118   |   0.00: PDF -> p d f (✓) \n",
      "1550000  25% ( 14m 21s)   0.058   |   0.00: & -> and (✓) \n",
      "Saved model to data/models/whole_gen_11_fixes/1550000_(EncoderRNN/DecoderRNN)\n",
      "Accuracy: 96.36% (    9636/   10000)\n",
      "1560000  30% ( 18m 16s)   0.108   |   0.00: & -> and (✓) \n",
      "1570000  35% (  21m 6s)   0.067   |   0.00: ltd -> limited (✓) \n",
      "1580000  40% ( 23m 58s)   0.054   |   0.01: # -> number (✓) \n",
      "1590000  45% ( 26m 49s)   0.078   |   0.00: kilometres -> kilometers (✓) \n",
      "1600000  50% ( 29m 40s)   0.068   |   0.00: kilometres -> kilometers (✓) \n",
      "Saved model to data/models/whole_gen_11_fixes/1600000_(EncoderRNN/DecoderRNN)\n",
      "Accuracy: 96.62% (    9662/   10000)\n",
      "1610000  55% ( 33m 36s)   0.119   |   0.93: EADGBEA -> e a d b b e a (✗: e a d g b e a) \n",
      "1620000  60% ( 36m 26s)   0.086   |   0.01: dr -> doctor (✓) \n",
      "1630000  65% ( 39m 19s)   0.065   |   0.00: ~ -> tilde (✓) \n",
      "1640000  70% ( 42m 13s)   0.075   |   0.00: 869 -> eight hundred sixty nine (✓) \n",
      "1650000  75% (  45m 5s)   0.054   |   0.00: & -> and (✓) \n",
      "Saved model to data/models/whole_gen_11_fixes/1650000_(EncoderRNN/DecoderRNN)\n",
      "Accuracy: 96.73% (    9673/   10000)\n",
      "1660000  80% (  49m 1s)   0.097   |   0.00: & -> and (✓) \n",
      "1670000  85% ( 51m 53s)   0.063   |   0.00: & -> and (✓) \n",
      "1680000  90% ( 54m 44s)   0.082   |   0.00: - -> to (✓) \n",
      "1690000  95% ( 57m 35s)   0.079   |   0.00: 1883 -> eighteen eighty three (✓) \n",
      "1700000 100% ( 60m 28s)   0.048   |   0.00: 1888 -> eighteen eighty eight (✓) \n",
      "Saved model to data/models/whole_gen_11_fixes/1700000_(EncoderRNN/DecoderRNN)\n",
      "Accuracy: 96.28% (    9628/   10000)\n"
     ]
    }
   ],
   "source": [
    "train_iterations(n_iters=200000, print_every=10000, teacher_forcing_ratio=0, lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "$13,859        => thirteen thousand three hundred fifty nine dollars || [49, 8, 16, 10, 38, 15, 85, 0] \n",
      "                  the per capita income for the village was <SAMPLE> .\n",
      "$7,824         => twenty seven thousand four hundred twenty four || [18, 8, 16, 10, 6, 19, 85, 0] \n",
      "                  according to the u . s . census bureau , pennsylvania spent <SAMPLE> per pupil in the year 2000 .\n",
      "978-0-7022-1485-1 => nine seven eight sil sil sil sil sil two sil two sil two sil four sil || [15, 18, 16, 58, 25, 58, 18, 25, 5, 5, 58, 9, 19, 16, 14, 58, 9, 0] \n",
      "                  isbn <SAMPLE> mehl , margaret .\n",
      "504 kHz        => five hundred four || [14, 10, 19, 289, 0] \n",
      "                  ireland has allowed individuals to apply for test licenses in the 501 to <SAMPLE> frequency range .\n",
      "GS&CS          => g s c c c      || [53, 17, 55, 21, 17, 0] \n",
      "                  knox , hugh foss and alastair denniston represented <SAMPLE> at the first polish french british meeting at paris in january 1939 .\n",
      "favouritism    => a              || [848, 0] \n",
      "                  unlike his father , wenceslaus relied on <SAMPLE> , which made him abhorrent to many nobles and led to increasing isolation .\n",
      "11/03/2015     => the thirteenth of may twenty fifteen || [11, 76, 12, 69, 6, 51, 0] \n",
      "                  83 milford mill to north avenue , new pdf version l <SAMPLE> no\n",
      "20½            => two o          || [6, 55, 22, 199, 0] \n",
      "                  egyptian alabaster with glass and stone inlays ; h . <SAMPLE> in .\n",
      "60532          => sixty thousand five hundred two || [39, 8, 14, 10, 34, 5, 0] \n",
      "                  <SAMPLE> blue peter .\n",
      "39917-         => three nine nine nine nine || [13, 15, 15, 9, 18, 0] \n",
      "                  isbn 0 - 333 - <SAMPLE> x . st clement 's church website .\n"
     ]
    }
   ],
   "source": [
    "print_local_wrong_predictions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1710000   2% (  2m 53s)   0.067   |   0.01: st -> saint (✓) \n",
      "1720000   4% (  5m 44s)   0.048   |   0.00: 1 September 2014 -> the first of september twenty fourteen (✓) \n",
      "1730000   6% (  8m 34s)   0.065   |   0.00: & -> and (✓) \n",
      "1740000   8% ( 11m 26s)   0.096   |   0.00: 1854 -> eighteen fifty four (✓) \n",
      "1750000  10% ( 14m 19s)   0.088   |   0.26: PROGET -> p r o g e t (✓) \n",
      "Saved model to data/models/whole_gen_11_fixes/1750000_(EncoderRNN/DecoderRNN)\n",
      "Accuracy: 96.66% (    9666/   10000)\n",
      "1760000  12% ( 18m 13s)   0.057   |   0.00: - -> to (✓) \n",
      "1770000  14% (  21m 4s)   0.084   |   0.00: 1975 -> nineteen seventy five (✓) \n",
      "1780000  16% ( 23m 56s)   0.063   |   0.00: 1998 -> nineteen ninety eight (✓) \n",
      "1790000  18% ( 26m 48s)   0.050   |   0.00: & -> and (✓) \n",
      "1800000  20% ( 29m 40s)   0.106   |   0.00: Vol -> volume (✓) \n",
      "Saved model to data/models/whole_gen_11_fixes/1800000_(EncoderRNN/DecoderRNN)\n",
      "Accuracy: 96.42% (    9642/   10000)\n",
      "1810000  22% ( 33m 34s)   0.085   |   0.00: mr -> mister (✓) \n",
      "1820000  24% ( 36m 26s)   0.073   |   0.00: NTSB -> n t s b (✓) \n",
      "1830000  26% ( 39m 18s)   0.083   |   0.00: colour -> color (✓) \n",
      "1840000  28% ( 42m 11s)   0.065   |   1.82: 60488 -> six thousand eight eight eight eight (✗: six o four eight eight) \n",
      "1850000  30% (  45m 3s)   0.051   |   0.00: J.A. -> j a (✓) \n",
      "Saved model to data/models/whole_gen_11_fixes/1850000_(EncoderRNN/DecoderRNN)\n",
      "Accuracy: 96.56% (    9656/   10000)\n",
      "1860000  32% ( 48m 56s)   0.090   |   0.00: 5 -> five (✓) \n",
      "1870000  34% ( 51m 47s)   0.091   |   0.00: etc -> etcetera (✓) \n",
      "1880000  36% ( 54m 40s)   0.068   |   0.00: No -> number (✓) \n",
      "1890000  38% ( 57m 32s)   0.086   |   0.00: 1883 -> eighteen eighty three (✓) \n",
      "1900000  40% ( 60m 25s)   0.094   |   0.00: 23rd -> twenty third (✓) \n",
      "Saved model to data/models/whole_gen_11_fixes/1900000_(EncoderRNN/DecoderRNN)\n",
      "Accuracy: 96.30% (    9630/   10000)\n",
      "1910000  42% ( 64m 18s)   0.052   |   0.00: 1 -> one (✓) \n",
      "1920000  44% ( 67m 11s)   0.076   |   0.00: pp -> p p (✓) \n",
      "1930000  46% (  70m 3s)   0.101   |   3.38: exorcise -> x (✗: exorcize) \n",
      "1940000  48% ( 72m 56s)   0.060   |   0.00: Organisation -> organization (✓) \n",
      "1950000  50% ( 75m 47s)   0.085   |   0.00: & -> and (✓) \n",
      "Saved model to data/models/whole_gen_11_fixes/1950000_(EncoderRNN/DecoderRNN)\n",
      "Accuracy: 96.22% (    9622/   10000)\n",
      "1960000  52% ( 79m 42s)   0.083   |   0.00: W. C. -> w c (✓) \n",
      "1970000  54% ( 82m 35s)   0.063   |   0.00: 1986 -> nineteen eighty six (✓) \n",
      "1980000  56% ( 85m 28s)   0.066   |   0.00: MTD -> m t d (✓) \n",
      "1990000  58% ( 88m 20s)   0.073   |   0.00: st -> saint (✓) \n",
      "2000000  60% ( 91m 12s)   0.072   |   0.00: VF- -> v f (✓) \n",
      "Saved model to data/models/whole_gen_11_fixes/2000000_(EncoderRNN/DecoderRNN)\n",
      "Accuracy: 96.28% (    9628/   10000)\n",
      "2010000  62% (  95m 7s)   0.059   |   0.00: & -> and (✓) \n",
      "2020000  64% ( 97m 57s)   0.074   |   0.00: PDF -> p d f (✓) \n",
      "2030000  66% (100m 49s)   0.068   |   0.00: - -> to (✓) \n",
      "2040000  68% (103m 41s)   0.092   |   0.00: 40 -> forty (✓) \n",
      "2050000  70% (106m 32s)   0.075   |   0.00: organisations -> organizations (✓) \n",
      "Saved model to data/models/whole_gen_11_fixes/2050000_(EncoderRNN/DecoderRNN)\n",
      "Accuracy: 96.51% (    9651/   10000)\n",
      "2060000  72% (110m 27s)   0.038   |   0.00: é -> e acute (✓) \n",
      "2070000  74% (113m 18s)   0.095   |   0.00: PDF -> p d f (✓) \n",
      "2080000  76% (116m 10s)   0.090   |   0.02: st -> saint (✓) \n",
      "2090000  78% ( 119m 0s)   0.078   |   0.01: st -> saint (✓) \n",
      "2100000  80% (121m 53s)   0.088   |   0.00: NCL -> n c l (✓) \n",
      "Saved model to data/models/whole_gen_11_fixes/2100000_(EncoderRNN/DecoderRNN)\n",
      "Accuracy: 96.02% (    9602/   10000)\n",
      "2110000  82% (125m 47s)   0.101   |   0.00: _ -> underscore (✓) \n",
      "2120000  84% (128m 40s)   0.079   |   0.01: pl -> place (✓) \n",
      "2130000  86% (131m 33s)   0.100   |   0.03: st -> saint (✓) \n",
      "2140000  88% (134m 25s)   0.069   |   0.00: U.S. -> u s (✓) \n",
      "2150000  90% (137m 18s)   0.117   |   0.01: 11 -> eleven (✓) \n",
      "Saved model to data/models/whole_gen_11_fixes/2150000_(EncoderRNN/DecoderRNN)\n",
      "Accuracy: 96.39% (    9639/   10000)\n",
      "2160000  92% (141m 14s)   0.075   |   0.00: 8 -> eight (✓) \n",
      "2170000  94% ( 144m 6s)   0.095   |   0.00: 8 -> eight (✓) \n",
      "2180000  96% (146m 59s)   0.061   |   0.01: 1998 -> nineteen ninety eight (✓) \n",
      "2190000  98% (149m 51s)   0.087   |   0.00: 3 -> three (✓) \n",
      "2200000 100% (152m 45s)   0.098   |   0.00: - -> to (✓) \n",
      "Saved model to data/models/whole_gen_11_fixes/2200000_(EncoderRNN/DecoderRNN)\n",
      "Accuracy: 96.59% (    9659/   10000)\n"
     ]
    }
   ],
   "source": [
    "train_iterations(n_iters=500000, print_every=10000, teacher_forcing_ratio=0, lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "416.4          => four hundred sixteen point six four || [19, 10, 75, 46, 19, 0] \n",
      "                  there were 59 housing units at an average density of <SAMPLE> per square mile ( 162 . 7 / km² ) .\n",
      "sr             => senior         || [17, 35, 0] \n",
      "                  republika <SAMPLE> bija , republicki zavod za statistiku beograd 2003 .\n",
      ".1740          => point one seven four || [46, 9, 18, 19, 25, 0] \n",
      "                  this article incorporates text from a publication now in the public domain : \" anderson , george ( florida <SAMPLE> ) \" .\n",
      "RSDLP          => r s d p p      || [35, 17, 26, 42, 24, 0] \n",
      "                  stalin continued to use koba as his party name in the underground world of the <SAMPLE> .\n",
      "II             => two            || [11, 73, 0] \n",
      "                  the title 's \" uncommon reader \" ( queen elizabeth <SAMPLE> ) becomes obsessed with books after a chance encounter with a mobile library .\n",
      "AUDELCO        => a l c c c o l  || [22, 43, 26, 28, 42, 21, 25, 0] \n",
      "                  the play received eleven <SAMPLE> nominations .\n",
      "1065-08-12     => the twelfth of august nineteen eighty five || [11, 95, 12, 70, 44, 39, 14, 0] \n",
      "                  mckee , kenneth ( <SAMPLE> ) .\n",
      "191729         => one hundred ninety nine thousand nine hundred twenty nine || [9, 10, 23, 9, 8, 18, 10, 6, 15, 0] \n",
      "                  orrin d . bleakley ( r ) , until april 3 , 1917 ( resigned ) earl hanley beshlin ( d ) , from november 6 , <SAMPLE> .\n",
      "#              => number         || [175, 0] \n",
      "                  his guitars are tuned to d # and a <SAMPLE> standard .\n",
      "APRIL 2009     => april two o o  || [71, 5, 8, 15, 0] \n",
      "                  the collected edition was published by idw in <SAMPLE> collecting all 8 issues that were first published in 2002 .\n"
     ]
    }
   ],
   "source": [
    "print_local_wrong_predictions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2210000   2% (  2m 54s)   0.082   |   0.00: GB -> g b (✓) \n",
      "2220000   4% (  5m 46s)   0.066   |   0.00: A- -> a (✓) \n",
      "2230000   6% (  8m 37s)   0.098   |   0.00: Phra -> p h r a (✓) \n",
      "2240000   8% ( 11m 30s)   0.070   |   0.00: 18 -> eighteen (✓) \n",
      "2250000  10% ( 14m 20s)   0.078   |   0.00: C. -> c (✓) \n",
      "Saved model to data/models/whole_gen_11_fixes/2250000_(EncoderRNN/DecoderRNN)\n",
      "Accuracy: 96.85% (    9685/   10000)\n",
      "2260000  12% ( 18m 15s)   0.061   |   0.00: BBC -> b b c (✓) \n",
      "2270000  14% (  21m 7s)   0.061   |   0.00: labour -> labor (✓) \n",
      "2280000  16% ( 23m 59s)   0.046   |   0.00: jr -> junior (✓) \n",
      "2290000  18% ( 26m 51s)   0.084   |   0.00: criticised -> criticized (✓) \n",
      "2300000  20% ( 29m 43s)   0.066   |   0.00: & -> and (✓) \n",
      "Saved model to data/models/whole_gen_11_fixes/2300000_(EncoderRNN/DecoderRNN)\n",
      "Accuracy: 96.54% (    9654/   10000)\n",
      "2310000  22% ( 33m 35s)   0.083   |   0.00: 4 -> four (✓) \n",
      "2320000  24% ( 36m 26s)   0.043   |   0.02: WGNY -> w g n y (✓) \n",
      "2330000  26% ( 39m 17s)   0.072   |   0.01: 2011 -> twenty eleven (✓) \n",
      "2340000  28% (  42m 9s)   0.098   |   0.00: advertising -> advertizing (✓) \n",
      "2350000  30% (  45m 1s)   0.066   |   0.00: ITT -> i t t (✓) \n",
      "Saved model to data/models/whole_gen_11_fixes/2350000_(EncoderRNN/DecoderRNN)\n",
      "Accuracy: 97.11% (    9711/   10000)\n",
      "2360000  32% ( 48m 57s)   0.077   |   0.00: & -> and (✓) \n",
      "2370000  34% ( 51m 51s)   0.075   |   0.00: & -> and (✓) \n",
      "2380000  36% ( 54m 43s)   0.078   |   0.00: pg -> p g (✓) \n",
      "2390000  38% ( 57m 35s)   0.114   |   0.00: centre -> center (✓) \n",
      "2400000  40% ( 60m 26s)   0.077   |   0.00: - -> to (✓) \n",
      "Saved model to data/models/whole_gen_11_fixes/2400000_(EncoderRNN/DecoderRNN)\n",
      "Accuracy: 96.77% (    9677/   10000)\n",
      "2410000  42% ( 64m 20s)   0.061   |   0.00: etc -> etcetera (✓) \n",
      "2420000  44% ( 67m 12s)   0.057   |   0.00: S. G. -> s g (✓) \n",
      "2430000  46% (  70m 4s)   0.064   |   0.01: 2001 -> two thousand one (✓) \n",
      "2440000  48% ( 72m 54s)   0.066   |   0.01: st -> saint (✓) \n",
      "2450000  50% ( 75m 47s)   0.069   |   0.00: 4 -> four (✓) \n",
      "Saved model to data/models/whole_gen_11_fixes/2450000_(EncoderRNN/DecoderRNN)\n",
      "Accuracy: 97.00% (    9700/   10000)\n",
      "2460000  52% ( 79m 42s)   0.060   |   0.00: G. -> g (✓) \n",
      "2470000  54% ( 82m 34s)   0.069   |   0.00: Asz -> a s z (✓) \n",
      "2480000  56% ( 85m 24s)   0.078   |   0.00: US -> u s (✓) \n",
      "2490000  58% ( 88m 15s)   0.047   |   0.00: CD- -> c d (✓) \n",
      "2500000  60% (  91m 8s)   0.059   |   0.00: March 16, 2004 -> march sixteenth two thousand four (✓) \n",
      "Saved model to data/models/whole_gen_11_fixes/2500000_(EncoderRNN/DecoderRNN)\n",
      "Accuracy: 96.61% (    9661/   10000)\n",
      "2510000  62% (  95m 2s)   0.062   |   0.00: : -> to (✓) \n",
      "2520000  64% ( 97m 54s)   0.041   |   0.00: FC -> f c (✓) \n",
      "2530000  66% (100m 46s)   0.069   |   0.00: centre -> center (✓) \n",
      "2540000  68% (103m 37s)   0.065   |   0.00: & -> and (✓) \n",
      "2550000  70% (106m 30s)   0.042   |   0.00: & -> and (✓) \n",
      "Saved model to data/models/whole_gen_11_fixes/2550000_(EncoderRNN/DecoderRNN)\n",
      "Accuracy: 96.91% (    9691/   10000)\n",
      "2560000  72% (110m 24s)   0.050   |   0.00: kilometres -> kilometers (✓) \n",
      "2570000  74% (113m 15s)   0.062   |   0.00: 3 -> three (✓) \n",
      "2580000  76% ( 116m 7s)   0.059   |   0.00: 15 -> fifteen (✓) \n",
      "2590000  78% ( 119m 0s)   0.085   |   0.00: WF -> w f (✓) \n",
      "2600000  80% (121m 52s)   0.075   |   0.51: NHANES -> n n a n h s (✗: n h a n e s) \n",
      "Saved model to data/models/whole_gen_11_fixes/2600000_(EncoderRNN/DecoderRNN)\n",
      "Accuracy: 97.22% (    9722/   10000)\n",
      "2610000  82% (125m 46s)   0.080   |   1.28: III -> the third (✗: three) \n",
      "2620000  84% (128m 39s)   0.073   |   0.00: etc -> etcetera (✓) \n",
      "2630000  86% (131m 31s)   0.084   |   0.03: 2016 -> twenty sixteen (✓) \n",
      "2640000  88% (134m 27s)   0.051   |   0.06: 2012 -> twenty twelve (✓) \n",
      "2650000  90% (138m 17s)   0.080   |   0.00: centre -> center (✓) \n",
      "Saved model to data/models/whole_gen_11_fixes/2650000_(EncoderRNN/DecoderRNN)\n",
      "Accuracy: 96.91% (    9691/   10000)\n",
      "2660000  92% (144m 43s)   0.059   |   0.00: QVT -> q v t (✓) \n",
      "2670000  94% (149m 30s)   0.090   |   0.00: mr -> mister (✓) \n",
      "2680000  96% (153m 21s)   0.097   |   0.00: theatre -> theater (✓) \n",
      "2690000  98% (156m 22s)   0.061   |   0.00: centimetres -> centimeters (✓) \n",
      "2700000 100% (159m 23s)   0.072   |   0.00: March 7, 2011 -> march seventh twenty eleven (✓) \n",
      "Saved model to data/models/whole_gen_11_fixes/2700000_(EncoderRNN/DecoderRNN)\n",
      "Accuracy: 97.12% (    9712/   10000)\n"
     ]
    }
   ],
   "source": [
    "train_iterations(n_iters=500000, print_every=10000, teacher_forcing_ratio=0, lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cléron         => c l e e e o o  || [21, 42, 28, 121, 35, 25, 29, 0] \n",
      "                  de <SAMPLE> represented seine et marne in the national assembly ( 1871 ) and voted with the right centre .\n",
      "recolonisation => road           || [1005, 0] \n",
      "                  urbanization and road building have sometimes fragmented communities and prevented <SAMPLE> of empty sites .\n",
      "0-912301-32-5  => o sil one one one sil sil sil two sil one sil three || [25, 58, 15, 9, 5, 13, 25, 9, 58, 13, 5, 58, 14, 0] \n",
      "                  first books inc isbn <SAMPLE> .\n",
      "eulogise       => kilogram       || [1315, 0] \n",
      "                  \" relatives of may 9 disaster victims <SAMPLE> herbert mensah \" , accra , 08 may 2015 .\n",
      "811            => eight hundred one || [16, 10, 48, 0] \n",
      "                  from <SAMPLE> , the territory of the ljubljana archdiocese was part of the ecclesiastical territory of the patriarch of aquileia .\n",
      "1973           => nineteen seventy three || [9, 8, 15, 10, 33, 13, 0] \n",
      "                  anthony was also runner up to orchard in 1972 - <SAMPLE> school year and the 1973 - 1974 school year .\n",
      "US$30 billion  => thirty billion dollars dollars || [34, 125, 85, 0] \n",
      "                  india hopes to reach the level of <SAMPLE> by 2007 .\n",
      "Catechising    =>                || [1284, 0] \n",
      "                  the ministry of <SAMPLE> .\n",
      "4459           => four thousand five hundred fifty nine || [19, 8, 19, 10, 38, 15, 0] \n",
      "                  it lies at an altitude of <SAMPLE> metres ( 14 , 632 feet ) .\n",
      "086            => o six six      || [25, 16, 20, 0] \n",
      "                  startupdoscstrt <SAMPLE> . asm code \" c99 compliance in open watcom \" .\n"
     ]
    }
   ],
   "source": [
    "print_local_wrong_predictions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2710000   2% (   3m 2s)   0.043   |   0.00: dr -> doctor (✓) \n",
      "2720000   5% (   6m 1s)   0.065   |   0.00: March 29, 2016 -> march twenty ninth twenty sixteen (✓) \n",
      "2730000   8% (  8m 58s)   0.052   |   0.01: ELOY -> e l o y (✓) \n",
      "2740000  10% ( 11m 54s)   0.057   |   0.00: 3 -> three (✓) \n",
      "2750000  12% ( 14m 55s)   0.063   |   0.00: ltd -> limited (✓) \n",
      "Saved model to data/models/whole_gen_11_fixes/2750000_(EncoderRNN/DecoderRNN)\n",
      "Accuracy: 96.90% (    9690/   10000)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-100-1b5470835d99>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_iterations\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_iters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m400000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprint_every\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mteacher_forcing_ratio\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0001\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-70-27807fc3707c>\u001b[0m in \u001b[0;36mtrain_iterations\u001b[0;34m(n_iters, lr, teacher_forcing_ratio, print_every, plot_every)\u001b[0m\n\u001b[1;32m     24\u001b[0m                              \u001b[0mencoder_optimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoder_optimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder_optimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdecoder_optimizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m                              \u001b[0mloss_function\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNLLLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_teacher_forcing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_teacher_forcing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m                              max_length=40 )\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0mcurrent_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-69-95336e4ebf15>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(s_bef, s_aft, s_sentence, encoder_optimizer, decoder_optimizer, loss_function, use_teacher_forcing, max_length)\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0mdecoded_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecoded_output\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0mencoder_optimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py3_pytorch_2/lib/python3.6/site-packages/torch/autograd/variable.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, retain_variables)\u001b[0m\n\u001b[1;32m    154\u001b[0m                 \u001b[0mVariable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m         \"\"\"\n\u001b[0;32m--> 156\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py3_pytorch_2/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(variables, grad_variables, retain_graph, create_graph, retain_variables)\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[0;32m---> 98\u001b[0;31m         variables, grad_variables, retain_graph)\n\u001b[0m\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_iterations(n_iters=400000, print_every=10000, teacher_forcing_ratio=0, lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#state_dict_path = 'data/models/whole_gen_10_after_words_attention_no_embd/2450000_'\n",
    "#state_dict_path = 'data/models/whole_gen_10_after_words_attention_no_embd/2250000_'\n",
    "state_dict_path = 'data/models/whole_gen_11_fixes/500000_'\n",
    "#state_dict_path = 'data/models/whole_gen_11_fixes/2750000_'\n",
    "decoder_rnn.load_state_dict(torch.load(state_dict_path + 'DecoderRNN'))\n",
    "encoder_rnn.load_state_dict(torch.load(state_dict_path + 'EncoderRNN'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "balanced_data.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "balanced_data.groupby('class')['class'].count()\n",
    "len(balanced_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def balanced_data_randomize_long():\n",
    "    global balanced_data, balanced_data_length, balanced_data_accessed_counter, balanced_data_randomize_freq\n",
    "    \n",
    "    bal_data = pd.concat([v.sample(min(2000, len(v))) for k, v in balanced_data_classes_select])\n",
    "    long_data = sample_data[sample_data['before'].str.len()>8].sample(4000)\n",
    "    elec_data = sample_data[sample_data['class']=='ELECTRONIC']\n",
    "    let_long_data = sample_data[(sample_data['class'] == 'LETTERS') & (sample_data['before'].str.len() > 5)]\n",
    "    balanced_data = pd.concat([bal_data, long_data, elec_data, let_long_data])#.drop_duplicates()\n",
    "    balanced_data = balanced_data[~balanced_data.index.duplicated(keep='first')]\n",
    "    \n",
    "    balanced_data_length = len(balanced_data)\n",
    "    balanced_data_randomize_freq = balanced_data_length * 0.5\n",
    "    balanced_data_accessed_counter = 0\n",
    "\n",
    "balanced_data_randomize = balanced_data_randomize_long\n",
    "balanced_data_randomize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input:   Harbour\n",
      "output:  ['harbor']\n",
      "target:    harbor\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAyUAAAFeCAYAAACb7rC0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nwicPAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f8744a76550>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def debug_show_attention(input_sentence, output_words, attentions):\n",
    "    # Set up figure with colorbar\n",
    "    fig = plt.figure(figsize=(15,6))\n",
    "    ax = fig.add_subplot(111)\n",
    "    #cax = ax.matshow(attentions.numpy(), cmap='bone')\n",
    "    cax = ax.matshow(attentions, cmap='bone')\n",
    "    fig.colorbar(cax)\n",
    "    # Set up axes\n",
    "    #ax.set_xticklabels([''] + input_sentence.split(' ') + ['<EOS>'], rotation=90)\n",
    "    #ax.set_xticklabels([''] + input_sentence + ['<EOS>'], rotation=90)\n",
    "    ax.set_yticklabels([''] + output_words)\n",
    "    \n",
    "    input_sentence = input_sentence + ['<EOS>']\n",
    "    inp_arr = [\"{}\\n{}\".format(input_sentence[i], input_sentence[-1-i]) for i in range(len(input_sentence))]\n",
    "    ax.set_xticklabels([''] + inp_arr, rotation=0)\n",
    "\n",
    "    # Show label at every tick\n",
    "    ax.xaxis.set_major_locator(matplotlib.ticker.MultipleLocator(1))\n",
    "    ax.yaxis.set_major_locator(matplotlib.ticker.MultipleLocator(1))\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "def debug_eval_sample_show_attention():\n",
    "    \n",
    "    sample_row = balanced_data_sample_row()\n",
    "    #sample_row = balanced_data[balanced_data['before'].str.len()>15].sample(1).iloc[0]\n",
    "    sample = sample_row['before'], sample_row['a_word_ind'], sample_row['class'], sample_row['sentence']\n",
    "\n",
    "    output, decoded_output, decoder_attns_arr, sample = test_model_single_sample(None, \n",
    "                                                            return_more=True, sample=sample)\n",
    "    print('input:  ', sample[0])\n",
    "    print('output: ', decoded_output)\n",
    "    print('target:   ', ' '.join([words_after_common[w] for w in sample[1][:-1]]))\n",
    "\n",
    "    attns = np.array([arr.data[0].cpu().numpy() for arr in decoder_attns_arr])\n",
    "\n",
    "    debug_show_attention(list(sample[0]), decoded_output, attns)\n",
    "    #plt.matshow(attns)\n",
    "\n",
    "debug_eval_sample_show_attention()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "balanced_data.groupby('class')['class'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test_in_categories(iter_len = 1000):\n",
    "    wrong_preds = {}\n",
    "    for cat in categories_all:\n",
    "        tmp_data = sample_data[sample_data['class'] == cat].sample(iter_len)\n",
    "        correct_n = 0\n",
    "        wrong_preds_arr = []\n",
    "\n",
    "        for _ in range(iter_len):\n",
    "            sample_row = tmp_data.iloc[_]\n",
    "            sample = sample_row['before'], sample_row['a_word_ind'], sample_row['class'], sample_row['sentence']\n",
    "\n",
    "            output, t1, sample_target, t2 = test_model_single_sample(None, sample=sample)\n",
    "            if output == sample_target:\n",
    "                correct_n += 1\n",
    "            else:\n",
    "                wrong_preds_arr.append([sample_target, output])\n",
    "\n",
    "        print(\"{:>10}: {:>5d}/{:>5d} ({:>4.0%})\".format(cat, correct_n, iter_len, correct_n/iter_len))\n",
    "        wrong_preds[cat] = wrong_preds_arr\n",
    "    return wrong_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wrong_preds = test_in_categories(3000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wrong_preds['LETTERS']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# With training longer words\n",
    "wrong_preds = test_in_categories()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:py3_pytorch_2]",
   "language": "python",
   "name": "conda-env-py3_pytorch_2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
