{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pytorch utils oh: pytorch_utils_oh_1.py\n",
      "Pytorch: 0.2.0_4\n",
      "Loadig pytorch_utils_oh defaults\n",
      "Pytorch utils oh: pytorch_utils_oh_1.py\n",
      "Pytorch: 0.2.0_4\n",
      "Loadig pytorch_utils_oh defaults\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import importlib\n",
    "import pytorch_utils_oh_1; importlib.reload(pytorch_utils_oh_1); from pytorch_utils_oh_1 import *;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_data_org = pd.read_csv('data/en_train_org.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data rows: 9918390,  (dropped none rows: 51)\n"
     ]
    }
   ],
   "source": [
    "all_data_org[pd.isnull(all_data_org['before'])][:3]\n",
    "all_data = all_data_org.dropna()\n",
    "print(\"Data rows: {},  (dropped none rows: {})\".format(len(all_data), len(all_data_org)-len(all_data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data rows: 9840282,  (dropped (verbatim) rows: 78159)\n"
     ]
    }
   ],
   "source": [
    "all_data = all_data[all_data['class'] != 'VERBATIM']\n",
    "print(\"Data rows: {},  (dropped (verbatim) rows: {})\".format(len(all_data), len(all_data_org)-len(all_data)))\n",
    "all_data = all_data.reset_index(drop=True)\n",
    "# Note we dropped VERBATIM class. Thats because it had so many weird characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_data_sentence_index = all_data.set_index('sentence_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "number_classes = ['DATE','CARDINAL','MEASURE','ORDINAL','DECIMAL','MONEY', 'DIGIT', 'TELEPHONE', 'TIME', 'FRACTION', 'ADDRESS']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data rows: 448176,  (dropped rows: 9470265)\n"
     ]
    }
   ],
   "source": [
    "number_data = all_data[all_data['class'].isin(number_classes)]\n",
    "print(\"Data rows: {},  (dropped rows: {})\".format(len(number_data), len(all_data_org)-len(number_data)))\n",
    "number_data = number_data.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### More balanced sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "balanced_data_classes_select = list(number_data.groupby('class'))\n",
    "def balanced_data_randomize(max_len=10000):\n",
    "    global balanced_data\n",
    "    balanced_data = pd.concat([v.sample(min(max_len, len(v))) for k, v in balanced_data_classes_select])\n",
    "balanced_data_randomize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Letters all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<EOS><SOS> \"$%'(),-./0123456789:ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz£¥ª²³µº¼½¾Ωμ€⅓⅔⅛⅝⅞\n",
      "94\n"
     ]
    }
   ],
   "source": [
    "tmp = sorted(list(set(''.join(number_data['before']))))\n",
    "letters_all = ['<EOS>', '<SOS>'] + sorted(list(set(tmp)))\n",
    "letters_all_index = dict((c, i) for i, c in enumerate(letters_all))\n",
    "print(''.join(letters_all))\n",
    "print(len(letters_all))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "546"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr = list(set(list(number_data['after'])))\n",
    "arr = [s.split(' ') for s in arr]\n",
    "arr = np.concatenate(arr)\n",
    "arr = list(set(arr))\n",
    "number_words = ['<EOS>', '<SOS>'] + arr\n",
    "number_words_index = dict((c, i) for i, c in enumerate(number_words))\n",
    "len(number_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 3, 546)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def number_words_to_tensor(words, include_eos=True):\n",
    "    return words_to_tensor(words, words_lookup_index=number_words_index, include_eos=include_eos)\n",
    "number_words_to_tensor(['one', 'first']).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 546])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "number_words_onehot_sos = number_words_to_tensor([SOS_TOKEN], include_eos=False)\n",
    "number_words_onehot_sos = Variable(torch.from_numpy(number_words_onehot_sos)).cuda()\n",
    "number_words_onehot_sos.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ORDINAL : 8th -> eighth\n",
      "Pierre Gallo Sex : Male Age : 18 Position : The 6th section of the <SAMPLE> experiment division's aviation unit .\n",
      "(1, 21, 50)\n",
      "(1, 2, 546)\n"
     ]
    }
   ],
   "source": [
    "def get_random_sample():\n",
    "    sample_row = balanced_data.iloc[random.randint(1, len(balanced_data)-1)]\n",
    "    sentence_id = sample_row['class']\n",
    "\n",
    "    rows = all_data_sentence_index.loc[sample_row['sentence_id']]\n",
    "    befores = rows.before.values\n",
    "        \n",
    "    token_id_idx = list(rows['token_id']).index(sample_row['token_id'])\n",
    "    befores[token_id_idx] = SAMPLE_WORD_TOKEN\n",
    "\n",
    "    return sample_row['before'], sample_row['after'], sample_row['class'], befores\n",
    "            \n",
    "def tmp():\n",
    "    s_bef, s_aft, s_class, s_sentence = get_random_sample()\n",
    "    print(s_class, ':', s_bef, '->', s_aft)\n",
    "    print(' '.join(s_sentence))\n",
    "    print(sentence_word_vectorize(s_sentence).shape)\n",
    "    print(number_words_to_tensor(s_aft.split(' ')).shape)\n",
    "tmp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sentence_word_vectorize_no_defaults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "419 µs ± 5.16 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "get_random_sample()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "use_cuda = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, wordvect_size, chars_input_size, words_hidden_size, chars_hidden_size,\n",
    "                 words_layers=1, chars_layers=1):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        \n",
    "        self.words_layers = words_layers\n",
    "        self.chars_layers = chars_layers\n",
    "        self.words_hidden_size = words_hidden_size\n",
    "        self.chars_hidden_size = chars_hidden_size\n",
    "\n",
    "        #self.rnn_words = nn.LSTM(wordvect_size, words_hidden_size // 2, words_layers,\n",
    "        #                         batch_first=True, bidirectional=True)\n",
    "\n",
    "        self.rnn_chars = nn.LSTM(chars_input_size, chars_hidden_size // 2, chars_layers,\n",
    "                                batch_first=True, bidirectional=True)\n",
    "        \n",
    "    def forward(self, word_vectors, string_tensor, hidden = None, init_hidden = True):\n",
    "        if init_hidden:\n",
    "            hidden_words, hidden_chars = self.init_hidden()\n",
    "        \n",
    "        #all_outputs_words, hidden_words = self.rnn_words(word_vectors, hidden_words)\n",
    "        #output_words = all_outputs_words[:, -1]\n",
    "        \n",
    "        all_outputs_chars, hidden_chars = self.rnn_chars(string_tensor, hidden_chars)\n",
    "        output_chars = all_outputs_chars[:, -1]\n",
    "        \n",
    "        # output = torch.cat((output_words, output_chars), 1)\n",
    "        # output = torch.cat((output_chars), 1)\n",
    "        output = output_chars\n",
    "        \n",
    "        return output\n",
    "\n",
    "    def init_hidden(self):\n",
    "        var1_1 = Variable(torch.zeros(2 * self.words_layers, 1, self.words_hidden_size // 2))\n",
    "        var1_2 = Variable(torch.zeros(2 * self.words_layers, 1, self.words_hidden_size // 2))\n",
    "        var2_1 = Variable(torch.zeros(2 * self.chars_layers, 1, self.chars_hidden_size // 2))\n",
    "        var2_2 = Variable(torch.zeros(2 * self.chars_layers, 1, self.chars_hidden_size // 2))\n",
    "        if use_cuda:\n",
    "            var1_1 = var1_1.cuda(); var1_2 = var1_2.cuda()\n",
    "            var2_1 = var2_1.cuda(); var2_2 = var2_2.cuda()\n",
    "        return ((var1_1, var1_2), (var2_1, var2_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word vect size: (1, 21, 50) . String vector size: torch.Size([1, 5, 94])\n",
      "Output: torch.Size([1, 128])\n"
     ]
    }
   ],
   "source": [
    "def get_encoder(debug=False):\n",
    "    # s_bef, s_aft, s_class, s_word_vs = get_random_sample()\n",
    "    s_bef, s_aft, s_class, s_sentence = get_random_sample()\n",
    "    \n",
    "    s_word_vs = sentence_word_vectorize(s_sentence)\n",
    "    s_string = string_to_tensor(s_bef, letters_all_index)\n",
    "    target = number_words_to_tensor(s_aft.split(' '))\n",
    "    \n",
    "    encoder_rnn = EncoderRNN(wordvect_size=s_word_vs.shape[-1], chars_input_size=len(letters_all),\n",
    "                                      words_hidden_size=128, chars_hidden_size=128,\n",
    "                                      words_layers=2, chars_layers=2).cuda()\n",
    "    \n",
    "    output_encoded = encoder_rnn(Variable(torch.from_numpy(s_word_vs)).cuda(), Variable(s_string).cuda())\n",
    "    if debug:\n",
    "        print('Word vect size:', s_word_vs.shape, '. String vector size:', s_string.size())\n",
    "        print('Output:', output_encoded.size())\n",
    "    return encoder_rnn, output_encoded;\n",
    "encoder_rnn, output_encoded = get_encoder(debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecoderRNN (\n",
       "  (rnn): GRU(546, 128, batch_first=True)\n",
       "  (lin_out): Linear (128 -> 546)\n",
       ")"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class DecoderRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, n_layers=1):\n",
    "        super(DecoderRNN, self).__init__()\n",
    "        self.n_layers = n_layers\n",
    "        self.hidden_size = hidden_size\n",
    "        \n",
    "        self.rnn = nn.GRU(input_size, hidden_size, n_layers,\n",
    "                                 batch_first=True, bidirectional=False)\n",
    "                         # LSTM would require own hidden included\n",
    "        \n",
    "        self.lin_out = nn.Linear(hidden_size, input_size)\n",
    "        #self.softmax = nn.LogSoftmax()\n",
    "\n",
    "    def forward(self, char, hidden):\n",
    "        #char = char.view(1,1,-1)\n",
    "        #hidden = hidden.view(1,1,-1)\n",
    "        output, hidden = self.rnn(char, hidden)\n",
    "        output = output[:, -1] # view(1,-1)\n",
    "        output = self.lin_out(output)\n",
    "        output = F.log_softmax(output)\n",
    "        return output, hidden\n",
    "\n",
    "decoder_rnn = DecoderRNN(input_size=len(number_words), hidden_size=output_encoded.size()[-1], n_layers=1)\n",
    "decoder_rnn = decoder_rnn.cuda()\n",
    "decoder_rnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 546])\n",
      "Variable containing:\n",
      "-6.1598\n",
      "[torch.cuda.FloatTensor of size 1x1 (GPU 0)]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tmp_a, tmp_b = decoder_rnn(number_words_onehot_sos, output_encoded.view(1,1,-1))\n",
    "print(tmp_a.size())\n",
    "print(tmp_a.topk(1)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[torch.Size([1, 546]), torch.Size([1, 1, 128])]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp_input = number_words_to_tensor([number_words[tmp_a.topk(1)[1].data[0][0]]])\n",
    "tmp_input = Variable(torch.from_numpy(tmp_input)).cuda()\n",
    "tmp = decoder_rnn(tmp_input, tmp_b)\n",
    "[t.size() for t in tmp]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training etc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'rupiahs rupiahs rupiahs rupiahs rupiahs rupiahs rupiahs rupiahs rupiahs rupiahs rupiahs rupiahs rupiahs rupiahs rupiahs rupiahs rupiahs rupiahs rupiahs rupiahs'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def evaluate(encoder, decoder, s_bef, s_sentence, max_length=20):\n",
    "    encoder.eval()\n",
    "    decoder.eval()\n",
    "    #s_word_vs = sentence_word_vectorize(s_sentence)\n",
    "    s_bef_string = string_to_tensor(s_bef, letters_all_index, include_eos=True)\n",
    "\n",
    "    #encoder_output = encoder(Variable(torch.from_numpy(s_word_vs)).cuda(), Variable(s_bef_string).cuda())\n",
    "    encoder_output = encoder(None, Variable(s_bef_string).cuda())\n",
    "    encoder_output = encoder_output.view(1,1,-1)\n",
    "    \n",
    "    decoder_hidden = encoder_output\n",
    "    decoder_input = number_words_onehot_sos\n",
    "\n",
    "    decoded_output = []\n",
    "    for _ in range(max_length):\n",
    "        decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden)\n",
    "\n",
    "        topv, topi = decoder_output.data.topk(1)\n",
    "        word_index = topi[0][0]\n",
    "        word = number_words[word_index] # Use own prediction as next input\n",
    "                \n",
    "        if word == '<EOS>':\n",
    "            break\n",
    "\n",
    "        decoded_output.append(word)\n",
    "        \n",
    "        decoder_input = number_words_to_tensor([word], include_eos=False)\n",
    "        decoder_input = Variable(torch.from_numpy(decoder_input)).cuda()\n",
    "\n",
    "    return ' '.join(decoded_output)\n",
    "\n",
    "evaluate(encoder_rnn, decoder_rnn, '12th', 'he was <SAMPLE>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".78                  -> rupiahs rupiahs rupiahs rupiahs rupiahs rupiahs rupiahs rupiahs rupiahs rupiahs rupiahs rupiahs rupiahs rupiahs rupiahs rupiahs rupiahs rupiahs rupiahs rupiahs \n",
      "                     != point seven eight\n",
      "19th                 -> rupiahs rupiahs rupiahs rupiahs rupiahs rupiahs rupiahs rupiahs rupiahs rupiahs rupiahs rupiahs rupiahs rupiahs rupiahs rupiahs rupiahs rupiahs rupiahs rupiahs \n",
      "                     != nineteenth\n",
      "25%                  -> rupiahs rupiahs rupiahs rupiahs rupiahs rupiahs rupiahs rupiahs rupiahs rupiahs rupiahs rupiahs rupiahs rupiahs rupiahs rupiahs rupiahs rupiahs rupiahs rupiahs \n",
      "                     != twenty five percent\n",
      "102.9                -> rupiahs rupiahs rupiahs rupiahs rupiahs rupiahs rupiahs rupiahs rupiahs rupiahs rupiahs rupiahs rupiahs rupiahs rupiahs rupiahs rupiahs rupiahs rupiahs rupiahs \n",
      "                     != one hundred two point nine\n",
      "Accuracy: 0.00% (       0/       4)\n"
     ]
    }
   ],
   "source": [
    "def test_model_accuracy(n_sample=10000, print_wrongs=False):\n",
    "    balanced_data_randomize()\n",
    "    n_correct = 0\n",
    "    for iteration in range(n_sample):\n",
    "        s_bef, s_aft, s_class, s_sentence = get_random_sample()\n",
    "        output = evaluate(encoder_rnn, decoder_rnn, s_bef, s_sentence)\n",
    "        if s_aft == output:\n",
    "            n_correct += 1\n",
    "        else:\n",
    "            if print_wrongs:\n",
    "                print(\"{:<20} -> {} \\n{:<20} != {}\".format(s_bef, output, '', s_aft))\n",
    "                \n",
    "\n",
    "    print(\"Accuracy: {:>4.2%} ({:>8d}/{:>8d})\".format(\n",
    "            n_correct/n_sample, n_correct, n_sample))\n",
    "\n",
    "test_model_accuracy(4, print_wrongs=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%timeit\n",
    "test_model_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train(s_bef, s_aft, s_sentence, encoder, decoder, encoder_optimizer, decoder_optimizer, loss_function,\n",
    "          use_teacher_forcing, max_length=20):\n",
    "\n",
    "    #s_word_vs = sentence_word_vectorize(s_sentence)\n",
    "    s_bef_string = string_to_tensor(s_bef, letters_all_index, include_eos=True)\n",
    "    target_arr = s_aft.split(' ') + ['<EOS>']\n",
    "    \n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "    loss = 0\n",
    "\n",
    "    #encoder_output = encoder(Variable(torch.from_numpy(s_word_vs)).cuda(), Variable(s_bef_string).cuda())\n",
    "    encoder_output = encoder(None, Variable(s_bef_string).cuda())\n",
    "    encoder_output = encoder_output.view(1,1,-1)\n",
    "    decoder_hidden = encoder_output\n",
    "\n",
    "    decoder_input = number_words_onehot_sos\n",
    "\n",
    "    decoded_output = []\n",
    "    for i in range(len(target_arr)):\n",
    "        decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden)\n",
    "\n",
    "        decoder_target = number_words_index[target_arr[i]]\n",
    "        #print(decoder_target)\n",
    "        decoder_target = Variable(torch.LongTensor([decoder_target])).cuda()\n",
    "        \n",
    "        # import IPython; IPython.core.debugger.set_trace()\n",
    "        \n",
    "        loss += loss_function(decoder_output, decoder_target)\n",
    "\n",
    "        topv, topi = decoder_output.data.topk(1)\n",
    "        word_index = topi[0][0]\n",
    "        word = number_words[word_index] # Use own prediction as next input\n",
    "        decoded_output.append(word)\n",
    "        \n",
    "        if use_teacher_forcing:\n",
    "            word = target_arr[i] # replace input with right target\n",
    "        else:\n",
    "            # use output normally as input \n",
    "            if word == '<EOS>':\n",
    "                break\n",
    "\n",
    "        decoder_input = number_words_to_tensor([word], include_eos=False)\n",
    "        decoder_input = Variable(torch.from_numpy(decoder_input)).cuda()\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "\n",
    "    return((loss.data[0] / len(target_arr)), ' '.join(decoded_output))\n",
    "#print(train())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_train_iterations = 0\n",
    "model_train_history = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_iterations(n_iters=100000, lr=0.001, teacher_forcing_ratio=0.5,\n",
    "                     print_every=10000, plot_every=1000):\n",
    "    global model_train_iterations\n",
    "    global model_train_history\n",
    "    start = time.time()\n",
    "    decoder_rnn.train()\n",
    "    encoder_rnn.train()\n",
    "\n",
    "    current_loss = 0\n",
    "    current_loss_iter = 0\n",
    "\n",
    "    encoder_optimizer = torch.optim.Adam(encoder_rnn.parameters(), lr=lr)\n",
    "    decoder_optimizer = torch.optim.Adam(decoder_rnn.parameters(), lr=lr)\n",
    "    loss_function = nn.NLLLoss()\n",
    "    \n",
    "    for iteration in range(1, n_iters + 1):\n",
    "        model_train_iterations += 1\n",
    "\n",
    "        use_teacher_forcing = random.random() < teacher_forcing_ratio\n",
    "        \n",
    "        s_bef, s_aft, s_class, s_sentence = get_random_sample()\n",
    "        \n",
    "        loss, result = train(s_bef=s_bef, s_aft=s_aft, s_sentence=s_sentence,\n",
    "                             encoder=encoder_rnn, decoder=decoder_rnn,\n",
    "                             encoder_optimizer=encoder_optimizer, decoder_optimizer=decoder_optimizer,\n",
    "                             loss_function=nn.NLLLoss(), use_teacher_forcing=use_teacher_forcing,\n",
    "                             max_length=40 )\n",
    "\n",
    "        current_loss += loss\n",
    "        current_loss_iter += 1\n",
    "\n",
    "        # Print iter number, loss, name and guess\n",
    "        if iteration % print_every == 0:\n",
    "            teacher_forcing_str = \"\"\n",
    "            if use_teacher_forcing:\n",
    "                teacher_forcing_str = \"(forcing)\"\n",
    "            print(\"{:>6d} {:>4.0%} ({:>8}) {:>7.3f}   | {:>6.2f}: {} -> {} {} ({})\".format(\n",
    "                      model_train_iterations, iteration/n_iters, time_since(start),\n",
    "                      current_loss/current_loss_iter, loss,\n",
    "                      s_bef, teacher_forcing_str, result, s_aft))\n",
    "\n",
    "        # Add current loss avg to list of losses\n",
    "        if iteration % plot_every == 0:\n",
    "            model_train_history.append((current_loss / plot_every, lr))\n",
    "            current_loss = 0\n",
    "            current_loss_iter = 0\n",
    "            \n",
    "        if model_train_iterations % 10000 == 0:\n",
    "            balanced_data_randomize()\n",
    "            \n",
    "        if model_train_iterations % 50000 == 0:\n",
    "            test_model_accuracy()\n",
    "            save_model('numbers_gen_3', encoder_rnn, decoder_rnn, model_train_iterations)\n",
    "    \n",
    "    # test_model_accuracy(model, n_sample=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     5  50% (   0m 0s)   6.291   |   6.23: 13th -> (forcing) rupiahs rupiahs (thirteenth)\n",
      "    10 100% (   0m 0s)   6.272   |   6.21: 20th -> (forcing) <EOS> <EOS> (twentieth)\n"
     ]
    }
   ],
   "source": [
    "train_iterations(n_iters=10, print_every=5, teacher_forcing_ratio=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  1010  10% (   0m 9s)   2.768   |   1.35: 3 -> (forcing) two <EOS> (three)\n",
      "  2010  20% (  0m 18s)   2.741   |   2.10: 1900 -> (forcing) two <EOS> <EOS> (nineteen hundred)\n",
      "  3010  30% (  0m 28s)   2.564   |   5.11: 57/100 ->  one hundred thousand five <EOS> (fifty seven one hundredths)\n",
      "  4010  40% (  0m 38s)   2.400   |   1.49: 2.9% ->  one point one <EOS> (two point nine percent)\n",
      "  5010  50% (  0m 48s)   2.280   |   1.69: 1.50 ->  two point five <EOS> (one point five o)\n",
      "  6010  60% (  0m 58s)   2.150   |   2.40: 3.05 mm -> (forcing) one point one five <EOS> <EOS> (three point o five millimeters)\n",
      "  7010  70% (   1m 9s)   2.064   |   0.78: 125 ->  one hundred <EOS> (one hundred twenty five)\n",
      "  8010  80% (  1m 19s)   1.886   |   1.83: 70.3 ->  zero point five <EOS> (seventy point three)\n",
      "  9010  90% (  1m 29s)   1.765   |   0.77: 10 -> (forcing) one <EOS> (ten)\n"
     ]
    }
   ],
   "source": [
    "train_iterations(n_iters=(10000-model_train_iterations), print_every=1000, teacher_forcing_ratio=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 20000  20% (  1m 43s)   1.120   |   0.61: 109 ->  one hundred ninety <EOS> (one hundred nine)\n",
      " 30000  40% (  3m 26s)   0.772   |   0.16: 15th -> (forcing) fifteenth <EOS> (fifteenth)\n",
      " 40000  60% (  5m 11s)   0.573   |   0.13: 275 ->  two hundred seventy five <EOS> (two hundred seventy five)\n",
      " 50000  80% (  6m 56s)   0.531   |   0.08: 2004 ->  two thousand four <EOS> (two thousand four)\n",
      "Accuracy: 65.30% (    6530/   10000)\n",
      "Saving: data/models/numbers_gen_3/50000 (encoder/decoder)\n",
      " 60000 100% (  9m 16s)   0.446   |   0.02: 94.5% -> (forcing) ninety four point five percent <EOS> (ninety four point five percent)\n"
     ]
    }
   ],
   "source": [
    "train_iterations(n_iters=50000, teacher_forcing_ratio=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12am                 -> twelve millimeters \n",
      "                     != twelve a m\n",
      "1018.1               -> one thousand one hundred eighteen \n",
      "                     != one thousand eighteen point one\n",
      "¥4,000               -> four thousand pounds \n",
      "                     != four thousand yen\n",
      "300                  -> three o o \n",
      "                     != three hundred\n",
      "10 December 1969     -> the tenth of september nineteen ninety six nine \n",
      "                     != the tenth of december nineteen sixty nine\n",
      "Accuracy: 50.00% (       5/      10)\n"
     ]
    }
   ],
   "source": [
    "test_model_accuracy(10, print_wrongs=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 70000  20% (  1m 44s)   0.475   |   0.08: 1891 ->  eighteen ninety one <EOS> (eighteen ninety one)\n",
      " 80000  40% (  3m 29s)   0.406   |   0.02: 500 ->  five hundred <EOS> (five hundred)\n",
      " 90000  60% (  5m 14s)   0.372   |   0.02: 18.50 -> (forcing) eighteen point five o <EOS> (eighteen point five o)\n",
      "100000  80% (  6m 58s)   0.350   |   0.01: 40 million -> (forcing) forty million <EOS> (forty million)\n",
      "Accuracy: 75.85% (    7585/   10000)\n",
      "Saving: data/models/numbers_gen_3/100000 (encoder/decoder)\n",
      "110000 100% (  9m 20s)   0.334   |   0.00: 2 ->  two <EOS> (two)\n"
     ]
    }
   ],
   "source": [
    "train_iterations(n_iters=50000, teacher_forcing_ratio=0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1991/94              -> one thousand nine hundred ninety nine forty \n",
      "                     != one thousand nine hundred ninety one ninety fourths\n",
      "0-7018-1330          -> o sil eight seven one one sil one one three three \n",
      "                     != o sil seven o one eight sil one three three o\n",
      "Accuracy: 80.00% (       8/      10)\n"
     ]
    }
   ],
   "source": [
    "test_model_accuracy(10, print_wrongs=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120000  20% (  1m 44s)   0.342   |   2.25: 1996 ->  one ninety nine six (nineteen ninety six)\n",
      "130000  40% (  3m 28s)   0.336   |   0.01: 15th ->  fifteenth <EOS> (fifteenth)\n",
      "140000  60% (  5m 12s)   0.307   |   0.20: 2011 ->  twenty eleven <EOS> (twenty eleven)\n",
      "150000  80% (  6m 57s)   0.267   |   0.58: 2013 ->  twenty o <EOS> (two o one three)\n",
      "Accuracy: 79.22% (    7922/   10000)\n",
      "Saving: data/models/numbers_gen_3/150000 (encoder/decoder)\n",
      "160000 100% (  9m 19s)   0.267   |   0.00: 3 ->  three <EOS> (three)\n"
     ]
    }
   ],
   "source": [
    "train_iterations(n_iters=50000, teacher_forcing_ratio=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2009                 -> two thousand nine \n",
      "                     != two o o nine\n",
      "2001                 -> two thousand one \n",
      "                     != two o o one\n",
      "508                  -> five hundred eight \n",
      "                     != five o eight\n",
      "Accuracy: 85.00% (      17/      20)\n"
     ]
    }
   ],
   "source": [
    "test_model_accuracy(20, print_wrongs=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "170000  20% (  1m 43s)   0.296   |   0.01: 5.7 ->  five point seven <EOS> (five point seven)\n",
      "180000  40% (  3m 27s)   0.290   |   0.01: 15 ->  fifteen <EOS> (fifteen)\n",
      "190000  60% (  5m 12s)   0.245   |   0.01: 2.1 m ->  two point one meters <EOS> (two point one meters)\n",
      "200000  80% (  6m 56s)   0.249   |   0.02: 100 ->  one hundred <EOS> (one hundred)\n",
      "Accuracy: 81.87% (    8187/   10000)\n",
      "Saving: data/models/numbers_gen_3/200000 (encoder/decoder)\n",
      "210000 100% (  9m 17s)   0.251   |   0.10: 1978 ->  nineteen seventy eight <EOS> (nineteen seventy eight)\n"
     ]
    }
   ],
   "source": [
    "train_iterations(n_iters=50000, teacher_forcing_ratio=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0-86358-084          -> o sil eight six eight eight eight sil eight o four \n",
      "                     != o sil eight six three five eight sil o eight four\n",
      "1997                 -> nineteen ninety seven \n",
      "                     != one nine nine seven\n",
      "Accuracy: 90.00% (      18/      20)\n"
     ]
    }
   ],
   "source": [
    "test_model_accuracy(20, print_wrongs=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "220000  20% (  1m 44s)   0.244   |   0.00: $25,000 ->  twenty five thousand dollars <EOS> (twenty five thousand dollars)\n",
      "230000  40% (  3m 28s)   0.231   |   0.00: 3 -> (forcing) three <EOS> (three)\n",
      "240000  60% (  5m 13s)   0.175   |   0.00: 4th ->  fourth <EOS> (fourth)\n",
      "250000  80% (  6m 58s)   0.244   |   0.00: 3rd ->  third <EOS> (third)\n",
      "Accuracy: 85.49% (    8549/   10000)\n",
      "Saving: data/models/numbers_gen_3/250000 (encoder/decoder)\n",
      "260000 100% (  9m 18s)   0.243   |   0.09: 2007 ->  two thousand seven <EOS> (two thousand seven)\n"
     ]
    }
   ],
   "source": [
    "train_iterations(n_iters=50000, teacher_forcing_ratio=0.2, lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14.00 pm             -> fourteen p m \n",
      "                     != two p m\n",
      "1895                 -> eighteen ninety five \n",
      "                     != one eight nine five\n",
      "Accuracy: 90.00% (      18/      20)\n"
     ]
    }
   ],
   "source": [
    "test_model_accuracy(20, print_wrongs=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "270000  20% (  1m 44s)   0.210   |   0.23: I -> (forcing) the first <EOS> (the first)\n",
      "280000  40% (  3m 29s)   0.171   |   0.00: 0.83% ->  zero point eight three percent <EOS> (zero point eight three percent)\n",
      "290000  60% (  5m 14s)   0.190   |   0.00: 1.0 -> (forcing) one point zero <EOS> (one point zero)\n",
      "300000  80% (   7m 0s)   0.176   |   0.04: 818th ->  eight hundred eighteenth <EOS> (eight hundred eighteenth)\n",
      "Accuracy: 86.56% (    8656/   10000)\n",
      "Saving: data/models/numbers_gen_3/300000 (encoder/decoder)\n",
      "310000 100% (  9m 22s)   0.156   |   0.02: $458,000 ->  four hundred fifty eight thousand dollars <EOS> (four hundred fifty eight thousand dollars)\n"
     ]
    }
   ],
   "source": [
    "train_iterations(n_iters=50000, teacher_forcing_ratio=0.4, lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "088 127 085          -> o eight eight one sil two eight seven eight five \n",
      "                     != o eight eight sil one two seven sil o eight five\n",
      "Accuracy: 95.00% (      19/      20)\n"
     ]
    }
   ],
   "source": [
    "test_model_accuracy(20, print_wrongs=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "320000  20% (  1m 45s)   0.245   |   0.04: 54/1 ->  fifty four over one <EOS> (fifty four over one)\n",
      "330000  40% (  3m 30s)   0.293   |   0.05: 1942 -> (forcing) nineteen forty two <EOS> (nineteen forty two)\n",
      "340000  60% (  5m 15s)   0.268   |   0.00: .67 ->  point six seven <EOS> (point six seven)\n",
      "350000  80% (   7m 0s)   0.260   |   0.72: 3000 ->  three thousand <EOS> (three o o o)\n",
      "Accuracy: 82.48% (    8248/   10000)\n",
      "Saving: data/models/numbers_gen_3/350000 (encoder/decoder)\n",
      "360000 100% (  9m 21s)   0.286   |   0.03: 1995 ->  nineteen ninety five <EOS> (nineteen ninety five)\n"
     ]
    }
   ],
   "source": [
    "train_iterations(n_iters=50000, teacher_forcing_ratio=0.2, lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2010                 -> twenty ten \n",
      "                     != two thousand ten\n",
      "Accuracy: 95.00% (      19/      20)\n"
     ]
    }
   ],
   "source": [
    "test_model_accuracy(20, print_wrongs=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "370000  10% (  1m 44s)   0.223   |   0.01: 03 ->  o three <EOS> (o three)\n",
      "380000  20% (  3m 29s)   0.248   |   0.00: 12% ->  twelve percent <EOS> (twelve percent)\n",
      "390000  30% (  5m 13s)   0.197   |   0.03: 04 ->  o four <EOS> (o four)\n",
      "400000  40% (  6m 56s)   0.212   |   0.16: (2009)22 ->  two o o nine sil two two <EOS> (two o o nine sil two two)\n",
      "Accuracy: 86.92% (    8692/   10000)\n",
      "Saving: data/models/numbers_gen_3/400000 (encoder/decoder)\n",
      "410000  50% (  9m 16s)   0.190   |   0.13: 598 ->  five hundred ninety eight <EOS> (five hundred ninety eight)\n",
      "420000  60% (  11m 0s)   0.186   |   0.02: $19,105 ->  nineteen thousand one hundred five dollars <EOS> (nineteen thousand one hundred five dollars)\n",
      "430000  70% ( 12m 44s)   0.206   |   0.02: 35 ->  thirty five <EOS> (thirty five)\n",
      "440000  80% ( 14m 28s)   0.194   |   0.00: £100,000 ->  one hundred thousand pounds <EOS> (one hundred thousand pounds)\n",
      "450000  90% ( 16m 12s)   0.184   |   0.00: 3 ->  three <EOS> (three)\n",
      "Accuracy: 87.62% (    8762/   10000)\n",
      "Saving: data/models/numbers_gen_3/450000 (encoder/decoder)\n",
      "460000 100% ( 18m 33s)   0.189   |   0.00: 2nd ->  second <EOS> (second)\n"
     ]
    }
   ],
   "source": [
    "train_iterations(n_iters=100000, teacher_forcing_ratio=0.1, lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "978-0-8493-4258-5    -> nine seven eight sil o sil eight four nine four sil three three two five sil five \n",
      "                     != nine seven eight sil o sil eight four nine three sil four two five eight sil five\n",
      "2011-04-13           -> the first of april twenty thirteen \n",
      "                     != the thirteenth of april twenty eleven\n",
      "16                   -> sixteen \n",
      "                     != one six\n",
      "Accuracy: 85.00% (      17/      20)\n"
     ]
    }
   ],
   "source": [
    "test_model_accuracy(20, print_wrongs=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "470000   5% (  1m 43s)   0.189   |   0.00: 125th ->  one hundred twenty fifth <EOS> (one hundred twenty fifth)\n",
      "480000  10% (  3m 28s)   0.185   |   0.00: $10 billion ->  ten billion dollars <EOS> (ten billion dollars)\n",
      "490000  15% (  5m 12s)   0.174   |   0.02: 5 km2 ->  five square kilometers <EOS> (five square kilometers)\n",
      "500000  20% (  6m 56s)   0.152   |   0.08: 2009 ->  two thousand nine <EOS> (two thousand nine)\n",
      "Accuracy: 87.50% (    8750/   10000)\n",
      "Saving: data/models/numbers_gen_3/500000 (encoder/decoder)\n",
      "510000  25% (  9m 17s)   0.170   |   0.04: 8.022 ->  eight point o two two <EOS> (eight point o two two)\n",
      "520000  30% (  11m 1s)   0.181   |   0.00: 3- ->  three <EOS> (three)\n",
      "530000  35% ( 12m 46s)   0.194   |   0.04: 1877 ->  eighteen seventy seven <EOS> (eighteen seventy seven)\n",
      "540000  40% ( 14m 31s)   0.180   |   0.00: 2.5 ->  two point five <EOS> (two point five)\n",
      "550000  45% ( 16m 15s)   0.173   |   0.00: 1st ->  first <EOS> (first)\n",
      "Accuracy: 87.55% (    8755/   10000)\n",
      "Saving: data/models/numbers_gen_3/550000 (encoder/decoder)\n",
      "560000  50% ( 18m 35s)   0.167   |   0.38: 31.1 km/h ->  thirty one point one kilometers <EOS> (thirty one point one kilometers per hour)\n",
      "570000  55% ( 20m 18s)   0.157   |   0.10: 12:45 pm -> (forcing) twelve forty five p m <EOS> (twelve forty five p m)\n",
      "580000  60% (  22m 3s)   0.196   |   0.29: 1652 ->  sixteen fifty two <EOS> (sixteen fifty two)\n",
      "590000  65% ( 23m 47s)   0.172   |   0.01: 1 January 1999 ->  the first of january nineteen ninety nine <EOS> (the first of january nineteen ninety nine)\n",
      "600000  70% ( 25m 31s)   0.156   |   2.40: 1456 ->  one four five six (fourteen fifty six)\n",
      "Accuracy: 87.24% (    8724/   10000)\n",
      "Saving: data/models/numbers_gen_3/600000 (encoder/decoder)\n",
      "610000  75% ( 27m 53s)   0.137   |   0.01: 11 September 2006 ->  the eleventh of september two thousand six <EOS> (the eleventh of september two thousand six)\n",
      "620000  80% ( 29m 38s)   0.150   |   0.00: 9th ->  ninth <EOS> (ninth)\n",
      "630000  85% ( 31m 22s)   0.171   |   0.00: 175.5 -> (forcing) one hundred seventy five point five <EOS> (one hundred seventy five point five)\n",
      "640000  90% (  33m 6s)   0.173   |   0.00: 20.8% ->  twenty point eight percent <EOS> (twenty point eight percent)\n",
      "650000  95% ( 34m 51s)   0.197   |   1.74: I ->  the first (one)\n",
      "Accuracy: 87.98% (    8798/   10000)\n",
      "Saving: data/models/numbers_gen_3/650000 (encoder/decoder)\n",
      "660000 100% ( 37m 10s)   0.219   |   0.21: 18 ->  eighteen <EOS> (eighteen)\n"
     ]
    }
   ],
   "source": [
    "train_iterations(n_iters=200000, teacher_forcing_ratio=0.1, lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44-9-SIM             -> four four sil nine sil p a \n",
      "                     != four four sil nine sil sim\n",
      "978-2723467049       -> nine seven eight sil two seven seven six six four four o four nine \n",
      "                     != nine seven eight sil two seven two three four six seven o four nine\n",
      "Accuracy: 90.00% (      18/      20)\n"
     ]
    }
   ],
   "source": [
    "test_model_accuracy(20, print_wrongs=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "670000   5% (  1m 45s)   0.154   |   0.01: C11 ->  c eleven <EOS> (c eleven)\n",
      "680000  10% (  3m 28s)   0.204   |   0.00: 1 ->  one <EOS> (one)\n",
      "690000  15% (  5m 13s)   0.150   |   0.00: 001 ->  o o one <EOS> (o o one)\n",
      "700000  20% (  6m 58s)   0.139   |   0.00: .5 ->  point five <EOS> (point five)\n",
      "Accuracy: 88.43% (    8843/   10000)\n",
      "Saving: data/models/numbers_gen_3/700000 (encoder/decoder)\n",
      "710000  25% (  9m 18s)   0.140   |   0.03: $11,667 ->  eleven thousand six hundred sixty seven dollars <EOS> (eleven thousand six hundred sixty seven dollars)\n",
      "720000  30% (  11m 3s)   0.156   |   0.00: 2 ->  two <EOS> (two)\n",
      "730000  35% ( 12m 47s)   0.191   |   0.58: 25 July 1712 ->  the twenty fifth of july twenty twelve <EOS> (the twenty fifth of july seventeen twelve)\n",
      "740000  40% ( 14m 31s)   0.168   |   0.00: $3M ->  three million dollars <EOS> (three million dollars)\n",
      "750000  45% ( 16m 15s)   0.184   |   0.15: 0.45 V ->  zero point four five volts <EOS> (zero point four five volts)\n",
      "Accuracy: 88.84% (    8884/   10000)\n",
      "Saving: data/models/numbers_gen_3/750000 (encoder/decoder)\n",
      "760000  50% ( 18m 35s)   0.171   |   0.00: 2.77 ->  two point seven seven <EOS> (two point seven seven)\n",
      "770000  55% ( 20m 20s)   0.170   |   0.00: C4 ->  c four <EOS> (c four)\n",
      "780000  60% (  22m 4s)   0.172   |   6.26: 2PW ->  two megawatts <EOS> (two peta watts)\n",
      "790000  65% ( 23m 47s)   0.157   |   0.00: 2.0 ->  two point zero <EOS> (two point zero)\n",
      "800000  70% ( 25m 31s)   0.136   |   0.00: 46th ->  forty sixth <EOS> (forty sixth)\n",
      "Accuracy: 88.47% (    8847/   10000)\n",
      "Saving: data/models/numbers_gen_3/800000 (encoder/decoder)\n",
      "810000  75% ( 27m 52s)   0.168   |   0.00: 25% ->  twenty five percent <EOS> (twenty five percent)\n",
      "820000  80% ( 29m 38s)   0.156   |   0.09: 1989 ->  nineteen eighty nine <EOS> (nineteen eighty nine)\n",
      "830000  85% ( 31m 22s)   0.149   |   0.46: 978-1-55876-463-7 ->  nine seven eight sil one sil five five five eight six sil six six three sil seven <EOS> (nine seven eight sil one sil five five eight seven six sil four six three sil seven)\n",
      "840000  90% (  33m 7s)   0.176   |   0.36: 1939-1945 4 ->  one nine three nine sil one nine four sil four four <EOS> (one nine three nine sil one nine four five sil four)\n",
      "850000  95% ( 34m 52s)   0.161   |   0.00: 10.6/km² ->  ten point six per square kilometers <EOS> (ten point six per square kilometers)\n",
      "Accuracy: 88.90% (    8890/   10000)\n",
      "Saving: data/models/numbers_gen_3/850000 (encoder/decoder)\n",
      "860000 100% ( 37m 12s)   0.144   |   0.49: 0-910313-98-9 ->  o sil nine one three o one three sil nine nine sil nine <EOS> (o sil nine one o three one three sil nine eight sil nine)\n"
     ]
    }
   ],
   "source": [
    "train_iterations(n_iters=200000, teacher_forcing_ratio=0.1, lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "604-606 DOI          -> six o four sil six six six sil sixty \n",
      "                     != six o four sil six o six sil doi\n",
      "0500 700 700         -> o five o sil seven seven o sil o \n",
      "                     != o five hundred sil seven hundred sil seven hundred\n",
      "0-87195-109-6        -> o sil eight seven one five nine sil one nine nine sil six \n",
      "                     != o sil eight seven one nine five sil one o nine sil six\n",
      "Accuracy: 85.00% (      17/      20)\n"
     ]
    }
   ],
   "source": [
    "test_model_accuracy(20, print_wrongs=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "870000   5% (  1m 44s)   0.136   |   0.00: 2.35 ->  two point three five <EOS> (two point three five)\n",
      "880000  10% (  3m 30s)   0.167   |   0.27: 0-521-78220-1 ->  o sil five two one sil two seven two two o sil one <EOS> (o sil five two one sil seven eight two two o sil one)\n",
      "890000  15% (  5m 15s)   0.209   |   0.02: 22 -> (forcing) twenty two <EOS> (twenty two)\n",
      "900000  20% (   7m 0s)   0.164   |   0.12: 10 ->  ten <EOS> (ten)\n",
      "Accuracy: 88.93% (    8893/   10000)\n",
      "Saving: data/models/numbers_gen_3/900000 (encoder/decoder)\n",
      "910000  25% (  9m 21s)   0.141   |   0.00: 5.7% ->  five point seven percent <EOS> (five point seven percent)\n",
      "920000  30% (  11m 7s)   0.149   |   0.01: 5-1-2 ->  five sil one sil two <EOS> (five sil one sil two)\n",
      "930000  35% ( 12m 53s)   0.140   |   0.01: 80 hp ->  eighty horsepower <EOS> (eighty horsepower)\n",
      "940000  40% ( 14m 37s)   0.147   |   0.00: 2.14 ->  two point one four <EOS> (two point one four)\n",
      "950000  45% ( 16m 22s)   0.153   |   0.00: 2 ->  two <EOS> (two)\n",
      "Accuracy: 88.33% (    8833/   10000)\n",
      "Saving: data/models/numbers_gen_3/950000 (encoder/decoder)\n",
      "960000  50% ( 18m 43s)   0.167   |   0.00: 5th ->  fifth <EOS> (fifth)\n",
      "970000  55% ( 20m 26s)   0.140   |   0.06: 1978 ->  nineteen seventy eight <EOS> (nineteen seventy eight)\n",
      "980000  60% ( 22m 11s)   0.152   |   0.00: 770.8 ->  seven hundred seventy point eight <EOS> (seven hundred seventy point eight)\n",
      "990000  65% ( 23m 56s)   0.164   |   0.00: 20th ->  twentieth <EOS> (twentieth)\n",
      "1000000  70% ( 25m 40s)   0.134   |   0.02: 464 hp ->  four hundred sixty four horsepower <EOS> (four hundred sixty four horsepower)\n",
      "Accuracy: 89.37% (    8937/   10000)\n",
      "Saving: data/models/numbers_gen_3/1000000 (encoder/decoder)\n",
      "1010000  75% (  28m 0s)   0.170   |   0.00: $24,694 ->  twenty four thousand six hundred ninety four dollars <EOS> (twenty four thousand six hundred ninety four dollars)\n",
      "1020000  80% ( 29m 44s)   0.174   |   0.02: June 27 ->  june twenty seventh <EOS> (june twenty seventh)\n",
      "1030000  85% ( 31m 28s)   0.166   |   0.00: 2,000 ->  two thousand <EOS> (two thousand)\n",
      "1040000  90% ( 33m 12s)   0.154   |   0.00: 95.7 ->  ninety five point seven <EOS> (ninety five point seven)\n",
      "1050000  95% ( 34m 57s)   0.155   |   0.02: 15.542 ->  fifteen point five four two <EOS> (fifteen point five four two)\n",
      "Accuracy: 89.45% (    8945/   10000)\n",
      "Saving: data/models/numbers_gen_3/1050000 (encoder/decoder)\n",
      "1060000 100% ( 37m 20s)   0.127   |   0.00: 70 mm ->  seventy millimeters <EOS> (seventy millimeters)\n"
     ]
    }
   ],
   "source": [
    "train_iterations(n_iters=200000, teacher_forcing_ratio=0.1, lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 100.00% (      20/      20)\n"
     ]
    }
   ],
   "source": [
    "test_model_accuracy(20, print_wrongs=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1070000   5% (  1m 51s)   0.174   |   0.00: 7 ->  seven <EOS> (seven)\n",
      "1080000  10% (  3m 38s)   0.136   |   0.00: 3 million ->  three million <EOS> (three million)\n",
      "1090000  15% (  5m 28s)   0.159   |   0.95: 49 ->  forty nine <EOS> (four nine)\n",
      "1100000  20% (  7m 18s)   0.173   |   0.00: 6th ->  sixth <EOS> (sixth)\n",
      "Accuracy: 89.33% (    8933/   10000)\n",
      "Saving: data/models/numbers_gen_3/1100000 (encoder/decoder)\n",
      "1110000  25% (  9m 45s)   0.123   |   0.09: 2009 ->  two thousand nine <EOS> (two thousand nine)\n",
      "1120000  30% ( 11m 36s)   0.131   |   0.00: 2 ->  two <EOS> (two)\n",
      "1130000  35% ( 13m 24s)   0.146   |   0.04: 22 ->  twenty two <EOS> (twenty two)\n",
      "1140000  40% ( 15m 13s)   0.138   |   0.00: 64.2 ->  sixty four point two <EOS> (sixty four point two)\n",
      "1150000  45% (  17m 2s)   0.168   |   0.00: 10th ->  tenth <EOS> (tenth)\n",
      "Accuracy: 89.73% (    8973/   10000)\n",
      "Saving: data/models/numbers_gen_3/1150000 (encoder/decoder)\n",
      "1160000  50% ( 19m 29s)   0.139   |   0.15: 1991 ->  nineteen ninety one <EOS> (nineteen ninety one)\n",
      "1170000  55% ( 21m 20s)   0.146   |   0.00: 4 km ->  four kilometers <EOS> (four kilometers)\n",
      "1180000  60% ( 23m 18s)   0.128   |   0.00: 12% ->  twelve percent <EOS> (twelve percent)\n",
      "1190000  65% ( 25m 11s)   0.148   |   0.01: $22,237 ->  twenty two thousand two hundred thirty seven dollars <EOS> (twenty two thousand two hundred thirty seven dollars)\n",
      "1200000  70% (  27m 6s)   0.141   |   0.00: 8th ->  eighth <EOS> (eighth)\n",
      "Accuracy: 88.71% (    8871/   10000)\n",
      "Saving: data/models/numbers_gen_3/1200000 (encoder/decoder)\n",
      "1210000  75% ( 29m 37s)   0.136   |   0.03: £5,337 ->  five thousand three hundred thirty seven pounds <EOS> (five thousand three hundred thirty seven pounds)\n",
      "1220000  80% ( 31m 31s)   0.148   |   0.79: 2126 ->  two one two six <EOS> (two thousand one hundred twenty six)\n",
      "1230000  85% ( 33m 22s)   0.141   |   0.00: 18:00 ->  eighteen hundred <EOS> (eighteen hundred)\n",
      "1240000  90% ( 35m 11s)   0.141   |   0.00: 2.39% ->  two point three nine percent <EOS> (two point three nine percent)\n",
      "1250000  95% (  37m 4s)   0.186   |   0.11: 3472  ->  three four seven two <EOS> (three four seven two)\n",
      "Accuracy: 89.20% (    8920/   10000)\n",
      "Saving: data/models/numbers_gen_3/1250000 (encoder/decoder)\n",
      "1260000 100% ( 39m 36s)   0.135   |   0.05: 012523- ->  o one two five two three <EOS> (o one two five two three)\n"
     ]
    }
   ],
   "source": [
    "train_iterations(n_iters=200000, teacher_forcing_ratio=0, lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1966 MATS            -> one thousand nine hundred sixty six million fifty \n",
      "                     != one thousand nine hundred sixty six million austrian schillings\n",
      "978-3-540-77758-8    -> nine seven eight sil three sil five seven o sil seven seven seven five eight sil eight \n",
      "                     != nine seven eight sil three sil five four o sil seven seven seven five eight sil eight\n",
      "2012                 -> twenty twelve \n",
      "                     != two o one two\n",
      "Accuracy: 85.00% (      17/      20)\n"
     ]
    }
   ],
   "source": [
    "test_model_accuracy(20, print_wrongs=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1270000   2% (  1m 51s)   0.126   |   0.87: 0156029081 ->  o one six five o two o o eight eight one (o one five six o two nine o eight one)\n",
      "1280000   5% (  3m 43s)   0.131   |   0.05: 1999 ->  nineteen ninety nine <EOS> (nineteen ninety nine)\n",
      "1290000   8% (  5m 35s)   0.146   |   0.32: 978-0-570-01306-8 ->  nine seven eight sil o sil five seven o sil one one o three six sil eight <EOS> (nine seven eight sil o sil five seven o sil o one three o six sil eight)\n",
      "1300000  10% (  7m 28s)   0.136   |   0.00: 2.3 million ->  two point three million <EOS> (two point three million)\n",
      "Accuracy: 89.60% (    8960/   10000)\n",
      "Saving: data/models/numbers_gen_3/1300000 (encoder/decoder)\n",
      "1310000  12% (  9m 53s)   0.139   |   0.08: 607.5 KB ->  six hundred seven point five kilobytes <EOS> (six hundred seven point five kilobytes)\n",
      "1320000  15% ( 11m 42s)   0.132   |   0.01: 0.54% ->  zero point five four percent <EOS> (zero point five four percent)\n",
      "1330000  18% ( 13m 32s)   0.171   |   0.00: 8.78 ->  eight point seven eight <EOS> (eight point seven eight)\n",
      "1340000  20% ( 15m 27s)   0.105   |   0.00: 512 m ->  five hundred twelve meters <EOS> (five hundred twelve meters)\n",
      "1350000  22% ( 17m 20s)   0.130   |   0.08: 1982 ->  nineteen eighty two <EOS> (nineteen eighty two)\n",
      "Accuracy: 89.45% (    8945/   10000)\n",
      "Saving: data/models/numbers_gen_3/1350000 (encoder/decoder)\n",
      "1360000  25% ( 19m 43s)   0.152   |   0.14: I ->  the first <EOS> (the first)\n",
      "1370000  28% ( 21m 29s)   0.136   |   0.02: 01 ->  o one <EOS> (o one)\n",
      "1380000  30% ( 23m 18s)   0.132   |   0.00: 102.5 ->  one hundred two point five <EOS> (one hundred two point five)\n",
      "1390000  32% (  25m 7s)   0.153   |   0.06: 19 ->  nineteen <EOS> (nineteen)\n",
      "1400000  35% ( 26m 55s)   0.120   |   0.01: 46 ->  forty six <EOS> (forty six)\n",
      "Accuracy: 89.37% (    8937/   10000)\n",
      "Saving: data/models/numbers_gen_3/1400000 (encoder/decoder)\n",
      "1410000  38% ( 29m 22s)   0.148   |   0.01: $28,021 ->  twenty eight thousand twenty one dollars <EOS> (twenty eight thousand twenty one dollars)\n",
      "1420000  40% ( 31m 10s)   0.162   |   0.00: .264 ->  point two six four <EOS> (point two six four)\n",
      "1430000  42% ( 32m 58s)   0.151   |   0.00: 56th ->  fifty sixth <EOS> (fifty sixth)\n",
      "1440000  45% ( 34m 45s)   0.182   |   0.00: 3 ->  three <EOS> (three)\n",
      "1450000  48% ( 36m 33s)   0.151   |   0.00: 11% ->  eleven percent <EOS> (eleven percent)\n",
      "Accuracy: 90.41% (    9041/   10000)\n",
      "Saving: data/models/numbers_gen_3/1450000 (encoder/decoder)\n",
      "1460000  50% (  39m 1s)   0.134   |   0.05: 32 ->  thirty two <EOS> (thirty two)\n",
      "1470000  52% ( 40m 50s)   0.131   |   0.35: 2011 ->  twenty eleven <EOS> (twenty eleven)\n",
      "1480000  55% ( 42m 36s)   0.125   |   0.05: 99 ->  ninety nine <EOS> (ninety nine)\n",
      "1490000  57% ( 44m 25s)   0.152   |   0.00: 3000 m ->  three thousand meters <EOS> (three thousand meters)\n",
      "1500000  60% ( 46m 11s)   0.131   |   0.03: 90.70 ->  ninety point seven o <EOS> (ninety point seven o)\n",
      "Accuracy: 89.76% (    8976/   10000)\n",
      "Saving: data/models/numbers_gen_3/1500000 (encoder/decoder)\n",
      "1510000  62% ( 48m 36s)   0.142   |   0.02: (2004) 81 ->  two o o four sil eight one <EOS> (two o o four sil eight one)\n",
      "1520000  65% ( 50m 24s)   0.159   |   0.00: 0.91 m ->  zero point nine one meters <EOS> (zero point nine one meters)\n",
      "1530000  68% ( 52m 12s)   0.143   |   0.00: 2.91 ->  two point nine one <EOS> (two point nine one)\n",
      "1540000  70% ( 53m 59s)   0.137   |   0.00: January 1979 ->  january nineteen seventy nine <EOS> (january nineteen seventy nine)\n",
      "1550000  72% ( 55m 47s)   0.147   |   0.68: 5280 ->  five two eight hundred eighty <EOS> (five thousand two hundred eighty)\n",
      "Accuracy: 90.11% (    9011/   10000)\n",
      "Saving: data/models/numbers_gen_3/1550000 (encoder/decoder)\n",
      "1560000  75% ( 58m 12s)   0.128   |   0.05: VI ->  the sixth <EOS> (the sixth)\n",
      "1570000  78% ( 59m 59s)   0.101   |   0.00: 56.6% ->  fifty six point six percent <EOS> (fifty six point six percent)\n",
      "1580000  80% ( 61m 46s)   0.141   |   0.00: 22 May 2012 ->  the twenty second of may twenty twelve <EOS> (the twenty second of may twenty twelve)\n",
      "1590000  82% ( 63m 33s)   0.132   |   0.00: 2 million ->  two million <EOS> (two million)\n",
      "1600000  85% ( 65m 21s)   0.157   |   0.12: I ->  the first <EOS> (the first)\n",
      "Accuracy: 89.34% (    8934/   10000)\n",
      "Saving: data/models/numbers_gen_3/1600000 (encoder/decoder)\n",
      "1610000  88% ( 67m 47s)   0.146   |   0.00: 16th ->  sixteenth <EOS> (sixteenth)\n",
      "1620000  90% ( 69m 36s)   0.134   |   0.00: $100,000 ->  one hundred thousand dollars <EOS> (one hundred thousand dollars)\n",
      "1630000  92% ( 71m 25s)   0.165   |   0.01: 2-2-2 ->  two sil two sil two <EOS> (two sil two sil two)\n",
      "1640000  95% ( 73m 13s)   0.129   |   0.40: 1574 ->  fifteen seventy four <EOS> (fifteen seventy four)\n",
      "1650000  98% (  75m 0s)   0.118   |   0.02: 5:27 ->  five twenty seven <EOS> (five twenty seven)\n",
      "Accuracy: 89.98% (    8998/   10000)\n",
      "Saving: data/models/numbers_gen_3/1650000 (encoder/decoder)\n",
      "1660000 100% ( 77m 25s)   0.148   |   0.21: 1995 ->  nineteen ninety five <EOS> (nineteen ninety five)\n"
     ]
    }
   ],
   "source": [
    "train_iterations(n_iters=400000, teacher_forcing_ratio=0, lr=0.0001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "1+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X                    -> the tenth \n",
      "                     != tenth\n",
      "0-415-30779-1        -> o sil four one five sil three seven seven seven nine sil one \n",
      "                     != o sil four one five sil three o seven seven nine sil one\n",
      "74321 41064 2        -> seven four two three sil one one one four o o sil two \n",
      "                     != seven four three two one sil four one o six four sil two\n",
      "107.5 KZL            -> one hundred seven point five thousand fifteen \n",
      "                     != one hundred seven point five thousand zlotys\n",
      "0-7190-6122-9        -> o sil seven one o nine sil one six two two sil nine \n",
      "                     != o sil seven one nine o sil six one two two sil nine\n",
      "214/209PN            -> two hundred fourteen two hundred ten hundred forty \n",
      "                     != two hundred fourteen two hundred ninths of a peta newton\n",
      "1969                 -> nineteen sixty nine \n",
      "                     != one nine six nine\n",
      "1994                 -> nineteen ninety nine four \n",
      "                     != nineteen ninety four\n",
      "III                  -> the third \n",
      "                     != three\n",
      "113                  -> one hundred three \n",
      "                     != one hundred thirteen\n",
      "83564-               -> eight six six five four \n",
      "                     != eight three five six four\n",
      "1994                 -> nineteen ninety nine four \n",
      "                     != nineteen ninety four\n",
      "978-1-901447-61-3    -> nine seven eight sil one sil nine o one four four seven sil four one sil three \n",
      "                     != nine seven eight sil one sil nine o one four four seven sil six one sil three\n",
      "978-3-942130-57-8    -> nine seven eight sil three sil nine three two one o o sil five five sil eight \n",
      "                     != nine seven eight sil three sil nine four two one three o sil five seven sil eight\n",
      "16 6 6 4 31-21 18 5  -> one six six six sil three sil six sil two one sil one one sil eight \n",
      "                     != one six sil six sil six sil four sil three one sil two one sil one eight sil five\n",
      "Accuracy: 92.50% (     185/     200)\n"
     ]
    }
   ],
   "source": [
    "test_model_accuracy(200, print_wrongs=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1670000   2% (  1m 48s)   0.158   |   0.00: 3:50 ->  three fifty <EOS> (three fifty)\n",
      "1680000   3% (  3m 39s)   0.146   |   0.01: March 20, 2016 ->  march twentieth twenty sixteen <EOS> (march twentieth twenty sixteen)\n",
      "1690000   5% (  5m 25s)   0.106   |   0.00: 0.26% ->  zero point two six percent <EOS> (zero point two six percent)\n",
      "1700000   7% (  7m 14s)   0.134   |   0.00: 3rd ->  third <EOS> (third)\n",
      "Accuracy: 89.56% (    8956/   10000)\n",
      "Saving: data/models/numbers_gen_3/1700000 (encoder/decoder)\n",
      "1710000   8% (  9m 36s)   0.134   |   0.00: 135 mph ->  one hundred thirty five miles per hour <EOS> (one hundred thirty five miles per hour)\n",
      "1720000  10% ( 11m 20s)   0.147   |   0.00: 1,377.9 ->  one thousand three hundred seventy seven point nine <EOS> (one thousand three hundred seventy seven point nine)\n",
      "1730000  12% (  13m 5s)   0.121   |   0.27: 0-87972-474-9 ->  o sil eight seven nine seven two sil seven four four sil nine <EOS> (o sil eight seven nine seven two sil four seven four sil nine)\n",
      "1740000  13% ( 14m 50s)   0.112   |   0.00: 4.9 ->  four point nine <EOS> (four point nine)\n",
      "1750000  15% ( 16m 34s)   0.138   |   0.00: 0.12% ->  zero point one two percent <EOS> (zero point one two percent)\n",
      "Accuracy: 90.64% (    9064/   10000)\n",
      "Saving: data/models/numbers_gen_3/1750000 (encoder/decoder)\n",
      "1760000  17% ( 18m 56s)   0.130   |   0.19: $0.28 ->  twenty eight cents <EOS> (twenty eight cents)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-67-3766c596bb2c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_iterations\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_iters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m600000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mteacher_forcing_ratio\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0001\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-33-f60f52e03567>\u001b[0m in \u001b[0;36mtrain_iterations\u001b[0;34m(n_iters, lr, teacher_forcing_ratio, print_every, plot_every)\u001b[0m\n\u001b[1;32m     25\u001b[0m                              \u001b[0mencoder_optimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoder_optimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder_optimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdecoder_optimizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m                              \u001b[0mloss_function\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNLLLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_teacher_forcing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_teacher_forcing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m                              max_length=40 )\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0mcurrent_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-31-66cb3a25eab0>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(s_bef, s_aft, s_sentence, encoder, decoder, encoder_optimizer, decoder_optimizer, loss_function, use_teacher_forcing, max_length)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;31m#encoder_output = encoder(Variable(torch.from_numpy(s_word_vs)).cuda(), Variable(s_bef_string).cuda())\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mencoder_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms_bef_string\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0mencoder_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mdecoder_hidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder_output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py3_pytorch_2/lib/python3.6/site-packages/torch/autograd/variable.py\u001b[0m in \u001b[0;36mcuda\u001b[0;34m(self, device_id, async)\u001b[0m\n\u001b[1;32m    277\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0masync\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 279\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mCudaTransfer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0masync\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    280\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    281\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py3_pytorch_2/lib/python3.6/site-packages/torch/autograd/_functions/tensor.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(ctx, i, device_id, async)\u001b[0m\n\u001b[1;32m    149\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0masync\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0masync\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 151\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0masync\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0masync\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py3_pytorch_2/lib/python3.6/site-packages/torch/_utils.py\u001b[0m in \u001b[0;36m_cuda\u001b[0;34m(self, device, async)\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0mnew_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mnew_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0masync\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_iterations(n_iters=600000, teacher_forcing_ratio=0, lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_model_accuracy(20, print_wrongs=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_iterations(n_iters=600000, teacher_forcing_ratio=0, lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_model_accuracy(20, print_wrongs=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_iterations(n_iters=600000, teacher_forcing_ratio=0, lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_model_accuracy(1000, print_wrongs=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_data[all_data['sentence_id'].isin(all_data[all_data['after'] == \"two o one o\"].sample(1)['sentence_id'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_data[all_data['sentence_id'].isin(all_data[all_data['after'] == \"twenty ten\"].sample(1)['sentence_id'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:py3_pytorch_2]",
   "language": "python",
   "name": "conda-env-py3_pytorch_2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
