{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker\n",
    "import numpy as np\n",
    "import random\n",
    "import time\n",
    "import os\n",
    "import pandas as pd\n",
    "import math\n",
    "import bcolz\n",
    "import pickle\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pytorch: 0.2.0_4\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "print(\"Pytorch: {}\".format(torch.__version__))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_data_org = pd.read_csv('data/en_train_org.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>token_id</th>\n",
       "      <th>class</th>\n",
       "      <th>before</th>\n",
       "      <th>after</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>616107</th>\n",
       "      <td>49226</td>\n",
       "      <td>17</td>\n",
       "      <td>LETTERS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>n a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>684691</th>\n",
       "      <td>54634</td>\n",
       "      <td>1</td>\n",
       "      <td>PLAIN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>965529</th>\n",
       "      <td>76612</td>\n",
       "      <td>7</td>\n",
       "      <td>PLAIN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        sentence_id  token_id    class before after\n",
       "616107        49226        17  LETTERS    NaN   n a\n",
       "684691        54634         1    PLAIN    NaN   NaN\n",
       "965529        76612         7    PLAIN    NaN   NaN"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data_org[pd.isnull(all_data_org['before'])][:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data rows: 9918390,  (dropped none rows: 51)\n",
      "Data rows: 9840282,  (dropped rows: 78159)\n"
     ]
    }
   ],
   "source": [
    "all_data = all_data_org.dropna()\n",
    "print(\"Data rows: {},  (dropped none rows: {})\".format(len(all_data), len(all_data_org)-len(all_data)))\n",
    "all_data = all_data[all_data['class'] != 'VERBATIM']\n",
    "print(\"Data rows: {},  (dropped rows: {})\".format(len(all_data), len(all_data_org)-len(all_data)))\n",
    "all_data = all_data.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note we dropped VERBATIM class. Thats because it had so many weird characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_data_sentence_index = all_data.set_index('sentence_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### More balanced sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "class\n",
       "ADDRESS           522\n",
       "CARDINAL       133744\n",
       "DATE           258348\n",
       "DECIMAL          9821\n",
       "DIGIT            5442\n",
       "ELECTRONIC       5162\n",
       "FRACTION         1196\n",
       "LETTERS        152790\n",
       "MEASURE         14783\n",
       "MONEY            6128\n",
       "ORDINAL         12703\n",
       "PLAIN         7353647\n",
       "PUNCT         1880507\n",
       "TELEPHONE        4024\n",
       "TIME             1465\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data.groupby(\"class\")[\"class\"].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_data_classes = list(all_data.groupby('class'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_balanced_classes = pd.concat([v.sample(min(50000, len(v))) for k, v in all_data_classes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "class\n",
       "ADDRESS         522\n",
       "CARDINAL      50000\n",
       "DATE          50000\n",
       "DECIMAL        9821\n",
       "DIGIT          5442\n",
       "ELECTRONIC     5162\n",
       "FRACTION       1196\n",
       "LETTERS       50000\n",
       "MEASURE       14783\n",
       "MONEY          6128\n",
       "ORDINAL       12703\n",
       "PLAIN         50000\n",
       "PUNCT         50000\n",
       "TELEPHONE      4024\n",
       "TIME           1465\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_balanced_classes.groupby(\"class\")[\"class\"].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>token_id</th>\n",
       "      <th>class</th>\n",
       "      <th>before</th>\n",
       "      <th>after</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8357127</th>\n",
       "      <td>637485</td>\n",
       "      <td>5</td>\n",
       "      <td>LETTERS</td>\n",
       "      <td>SZMC</td>\n",
       "      <td>s z m c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8212270</th>\n",
       "      <td>626664</td>\n",
       "      <td>18</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>,</td>\n",
       "      <td>,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9120105</th>\n",
       "      <td>694197</td>\n",
       "      <td>2</td>\n",
       "      <td>CARDINAL</td>\n",
       "      <td>1</td>\n",
       "      <td>one</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2937813</th>\n",
       "      <td>228965</td>\n",
       "      <td>4</td>\n",
       "      <td>DECIMAL</td>\n",
       "      <td>1,222.5</td>\n",
       "      <td>one thousand two hundred twenty two point five</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7780130</th>\n",
       "      <td>594330</td>\n",
       "      <td>2</td>\n",
       "      <td>PLAIN</td>\n",
       "      <td>is</td>\n",
       "      <td>is</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8649206</th>\n",
       "      <td>659202</td>\n",
       "      <td>0</td>\n",
       "      <td>PLAIN</td>\n",
       "      <td>Smith</td>\n",
       "      <td>Smith</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3066540</th>\n",
       "      <td>238748</td>\n",
       "      <td>5</td>\n",
       "      <td>CARDINAL</td>\n",
       "      <td>2</td>\n",
       "      <td>two</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8060409</th>\n",
       "      <td>615294</td>\n",
       "      <td>0</td>\n",
       "      <td>DECIMAL</td>\n",
       "      <td>3.48</td>\n",
       "      <td>three point four eight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9003905</th>\n",
       "      <td>685569</td>\n",
       "      <td>11</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>,</td>\n",
       "      <td>,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49542</th>\n",
       "      <td>4013</td>\n",
       "      <td>9</td>\n",
       "      <td>ELECTRONIC</td>\n",
       "      <td>ilpalermocalcio.it</td>\n",
       "      <td>i l p a l e r m o c a l c i o dot i t</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         sentence_id  token_id       class              before  \\\n",
       "8357127       637485         5     LETTERS                SZMC   \n",
       "8212270       626664        18       PUNCT                   ,   \n",
       "9120105       694197         2    CARDINAL                   1   \n",
       "2937813       228965         4     DECIMAL             1,222.5   \n",
       "7780130       594330         2       PLAIN                  is   \n",
       "8649206       659202         0       PLAIN               Smith   \n",
       "3066540       238748         5    CARDINAL                   2   \n",
       "8060409       615294         0     DECIMAL                3.48   \n",
       "9003905       685569        11       PUNCT                   ,   \n",
       "49542           4013         9  ELECTRONIC  ilpalermocalcio.it   \n",
       "\n",
       "                                                  after  \n",
       "8357127                                         s z m c  \n",
       "8212270                                               ,  \n",
       "9120105                                             one  \n",
       "2937813  one thousand two hundred twenty two point five  \n",
       "7780130                                              is  \n",
       "8649206                                           Smith  \n",
       "3066540                                             two  \n",
       "8060409                          three point four eight  \n",
       "9003905                                               ,  \n",
       "49542             i l p a l e r m o c a l c i o dot i t  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_balanced_classes.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_balanced_classes_matrix = data_balanced_classes.as_matrix()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_glove(name):\n",
    "    with open(name, 'r') as f: lines = [line.split() for line in f]\n",
    "    words = [d[0] for d in lines]\n",
    "    vecs = np.stack(np.array(d[1:], dtype=np.float32) for d in lines)\n",
    "    wordidx = {o:i for i,o in enumerate(words)}\n",
    "    return vecs, words, wordidx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wv_vecs, wv_words, wv_idx = load_glove('/home/ohu/koodi/data/glove_wordvec/glove.6B.50d.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['asdf', \"'s\", 'asdf', '-', 'testaaa']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re_apos = re.compile(r\"(\\w)'s\\b\")         # make 's a separate word\n",
    "re_mw_punc = re.compile(r\"(\\w[’'])(\\w)\")  # other ' in a word creates 2 words\n",
    "re_punc = re.compile(\"([\\\"().,;:/_?!—])\") # add spaces around punctuation\n",
    "re_mult_space = re.compile(r\"  *\")        # replace multiple spaces with just one\n",
    "\n",
    "def simple_tokeniser(sent):\n",
    "    sent = re_apos.sub(r\"\\1 's\", sent)\n",
    "    sent = re_mw_punc.sub(r\"\\1 \\2\", sent)\n",
    "    sent = re_punc.sub(r\" \\1 \", sent).replace('-', ' - ')\n",
    "    sent = re_punc.sub(r\" \\1 \", sent)\n",
    "    sent = re_mult_space.sub(' ', sent)\n",
    "    return sent.lower().split()\n",
    "simple_tokeniser(\"asdf's   asdf   -testaaa\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "arr = [simple_tokeniser(s_)[0] for s_ in list(all_data.sample(1000)['before'])]\n",
    "[s in wv_idx for s in arr].count(True) / 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DECIMAL : 380.5 -> three hundred eighty point five : (1, 17, 50) <class 'numpy.float32'>\n"
     ]
    }
   ],
   "source": [
    "def get_random_sample():\n",
    "    sample_row = data_balanced_classes.iloc[random.randint(1, len(data_balanced_classes)-1)]\n",
    "    sentence_id = sample_row['class']\n",
    "\n",
    "    #rows = all_data[all_data['sentence_id']==sample_row['sentence_id']]\n",
    "    rows = all_data_sentence_index.loc[sample_row['sentence_id']]\n",
    "    befores = rows.before.values\n",
    "        \n",
    "    token_id_idx = list(rows['token_id']).index(sample_row['token_id'])\n",
    "    befores[token_id_idx] = '*****'\n",
    "    str_list = simple_tokeniser(' '.join(befores))\n",
    "    \n",
    "    word_vect = np.zeros((1, len(str_list), wv_vecs.shape[1]), dtype=np.float32)\n",
    "    # var = np.zeros((1, len(str_list), wv_vecs.shape[1]+1))\n",
    "    for i, w in enumerate(str_list):\n",
    "        if w=='*****':\n",
    "            word_vect[0][i] = np.zeros((1, wv_vecs.shape[1]))\n",
    "        else:\n",
    "            try:\n",
    "                word_vect[0][i] = wv_vecs[wv_idx[w]]\n",
    "            except KeyError:\n",
    "                word_vect[0][i] = np.random.rand(1, wv_vecs.shape[1])\n",
    "    return sample_row['before'], sample_row['after'], sample_row['class'], word_vect\n",
    "            \n",
    "# get_random_sample()\n",
    "s_bef, s_aft, s_class, s_word_v = get_random_sample()\n",
    "print(s_class, ':', s_bef, '->', s_aft, ':', s_word_v.shape, type(s_word_v[0,0,0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "511 µs ± 11.2 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "get_random_sample()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categories and Chars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['PLAIN' 'PUNCT' 'DATE' 'LETTERS' 'CARDINAL' 'DECIMAL' 'MEASURE' 'MONEY'\n",
      " 'ORDINAL' 'TIME' 'ELECTRONIC' 'DIGIT' 'FRACTION' 'TELEPHONE' 'ADDRESS']\n",
      "15\n"
     ]
    }
   ],
   "source": [
    "categories_all = all_data[\"class\"].unique()\n",
    "print(categories_all)\n",
    "print(len(categories_all))\n",
    "categories_index = dict((c, i) for i, c in enumerate(categories_all))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " !\"#$%&'()+,-./0123456789:;?ABCDEFGHIJKLMNOPQRSTUVWXYZ[]_abcdefghijklmnopqrstuvwxyz|~¡£¥ª«²³µº»¼½¾¿éɒʻˈΩμ—€⅓⅔⅛⅝⅞\n",
      "112\n"
     ]
    }
   ],
   "source": [
    "letters_all = sorted(list(set(''.join(all_data['before']))))\n",
    "letters_index = dict((c, i) for i, c in enumerate(letters_all))\n",
    "letters_n = len(letters_all)\n",
    "print(''.join(letters_all))\n",
    "print(len(letters_all))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 6, 112])\n"
     ]
    }
   ],
   "source": [
    "def string_to_tensor(line):\n",
    "    tensor = torch.zeros(1, len(line), letters_n)\n",
    "    for li, letter in enumerate(line):\n",
    "        tensor[0, li, letters_index[letter]] = 1\n",
    "    return tensor\n",
    "print(string_to_tensor('wordup').size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "use_cuda = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word vect size: (1, 22, 50) . String vector size: torch.Size([1, 4, 112])\n",
      "Output: torch.Size([1, 15])\n"
     ]
    }
   ],
   "source": [
    "class RNN_WORDS_CHARS_CLASS(nn.Module):\n",
    "    def __init__(self, wordvect_size, letters_size, hidden_size, output_size, n_layers=1):\n",
    "        super(RNN_WORDS_CHARS_CLASS, self).__init__()\n",
    "\n",
    "        self.train_iterations = 0\n",
    "        self.train_history = []\n",
    "        \n",
    "        self.n_layers = n_layers\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "\n",
    "        self.rnn_words = nn.LSTM(wordvect_size, hidden_size // 2, n_layers,\n",
    "                                 batch_first=True, bidirectional=True)\n",
    "\n",
    "        self.rnn_chars = nn.LSTM(letters_size, hidden_size // 2, n_layers,\n",
    "                                 batch_first=True, bidirectional=True)\n",
    "        \n",
    "        #self.lin_1 = nn.Linear(hidden_size*2, 1024)\n",
    "        self.lin_output = nn.Linear(hidden_size*2, output_size)\n",
    "\n",
    "    def forward(self, word_vectors, string_tensor, hidden = None, init_hidden = True):\n",
    "        if init_hidden:\n",
    "            hidden_words, hidden_chars = self.init_hidden()\n",
    "        \n",
    "        all_outputs_words, hidden_words = self.rnn_words(word_vectors, hidden_words)\n",
    "        output_words = all_outputs_words[:, -1]\n",
    "        \n",
    "        all_outputs_chars, hidden_chars = self.rnn_chars(string_tensor, hidden_chars)\n",
    "        output_chars = all_outputs_chars[:, -1]\n",
    "        \n",
    "        output = torch.cat((output_words, output_chars), 1)\n",
    "        \n",
    "        #output = self.lin_1(output)\n",
    "        output = self.lin_output(output)\n",
    "        output = F.log_softmax(output)\n",
    "        return output\n",
    "\n",
    "    def init_hidden(self):\n",
    "        var1_1 = Variable(torch.zeros(2, self.n_layers, self.hidden_size // 2))\n",
    "        var1_2 = Variable(torch.zeros(2, self.n_layers, self.hidden_size // 2))\n",
    "        var2_1 = Variable(torch.zeros(2, self.n_layers, self.hidden_size // 2))\n",
    "        var2_2 = Variable(torch.zeros(2, self.n_layers, self.hidden_size // 2))\n",
    "        if use_cuda:\n",
    "            var1_1 = var1_1.cuda(); var1_2 = var1_2.cuda()\n",
    "            var2_1 = var2_1.cuda(); var2_2 = var2_2.cuda()\n",
    "        return ((var1_1, var1_2), (var2_1, var2_2))\n",
    "\n",
    "use_cuda = False\n",
    "s_bef, s_aft, s_class, s_word_vs = get_random_sample()\n",
    "s_string = string_to_tensor(s_bef)\n",
    "model_tmp = RNN_WORDS_CHARS_CLASS(wordvect_size=s_word_vs.shape[-1], letters_size=letters_n,\n",
    "                              hidden_size=128, output_size=len(categories_all))\n",
    "print('Word vect size:', s_word_vs.shape, '. String vector size:', s_string.size())\n",
    "output = model_tmp(Variable(torch.from_numpy(s_word_vs)), Variable(s_string))\n",
    "print('Output:', output.size())\n",
    "use_cuda = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tmp = use_cuda\n",
    "use_cuda = True\n",
    "model_tmp.cuda()\n",
    "output = model_tmp(Variable(torch.from_numpy(s_word_vs)).cuda(), Variable(s_string).cuda())\n",
    "use_cuda = tmp\n",
    "type(output.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('ORDINAL', 8)\n"
     ]
    }
   ],
   "source": [
    "def category_from_output(output):\n",
    "    top_n, top_i = output.data.topk(1)\n",
    "    category_i = top_i[0][0]\n",
    "    return categories_all[category_i], category_i\n",
    "\n",
    "print(category_from_output(output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test_model_accuracy(model, n_sample=10000):\n",
    "    model.eval()\n",
    "    n_correct = 0\n",
    "    for iteration in range(n_sample):\n",
    "        s_bef, s_aft, s_class, s_word_vs = get_random_sample()\n",
    "        s_string = Variable(string_to_tensor(s_bef))\n",
    "        s_word_vs = Variable(torch.from_numpy(s_word_vs))\n",
    "        if use_cuda:\n",
    "            s_word_vs = s_word_vs.cuda()\n",
    "            s_string = s_string.cuda()\n",
    "        output = model(s_word_vs, s_string)\n",
    "        if s_class == category_from_output(output)[0]:\n",
    "            n_correct += 1\n",
    "\n",
    "    print(\"Accuracy: {:>4.2%} ({:>8d}/{:>8d})\".format(\n",
    "            n_correct/n_sample, n_correct, n_sample))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "%%time\n",
    "test_model_accuracy(model_tmp.cuda(), n_sample=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train(model, category, word_vectors, string, loss_function, optimizer):\n",
    "    category_tensor = Variable(torch.LongTensor([categories_index[category]]))\n",
    "    word_vectors = Variable(torch.from_numpy(word_vectors))\n",
    "    string = Variable(string_to_tensor(string))\n",
    "    if use_cuda:\n",
    "        category_tensor = category_tensor.cuda()\n",
    "        word_vectors = word_vectors.cuda()\n",
    "        string = string.cuda()\n",
    "\n",
    "    output = model(word_vectors, string)\n",
    "    loss = loss_function(output, category_tensor)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    return output, loss.data[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "loss_function = nn.NLLLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "s_bef, s_aft, s_class, s_word_vs = get_random_sample()\n",
    "train(model, s_class, s_word_vs, s_bef)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def timeSince(since):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_iterations(n_iters=100000, lr=0.001, print_every=25000, plot_every=1000):\n",
    "    model.train()\n",
    "    start = time.time()\n",
    "    \n",
    "    loss_function = nn.NLLLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    \n",
    "    current_loss = 0\n",
    "    current_loss_iter = 0\n",
    "\n",
    "    for iteration in range(1, n_iters + 1):\n",
    "        model.train_iterations += 1\n",
    "        s_bef, s_aft, s_class, s_word_vs = get_random_sample()\n",
    "\n",
    "        output, loss = train(model, s_class, s_word_vs, s_bef, loss_function, optimizer)\n",
    "        current_loss += loss\n",
    "        current_loss_iter += 1\n",
    "\n",
    "        # Print iter number, loss, name and guess\n",
    "        if iteration % print_every == 0:\n",
    "            guess, guess_i = category_from_output(output)\n",
    "            correct = '✓' if guess == s_class else \"✗ ({})\".format(s_class)\n",
    "            print(\"{:>6d} {:>4.0%} ({:>8}) {:>7.3f}   | {:>6.2f}: {} -> {} {}\".format(\n",
    "                model.train_iterations, iteration/n_iters, timeSince(start),\n",
    "                current_loss/current_loss_iter, loss,\n",
    "                s_bef, guess, correct ))\n",
    "\n",
    "        # Add current loss avg to list of losses\n",
    "        if iteration % plot_every == 0:\n",
    "            model.train_history.append((current_loss / plot_every, lr))\n",
    "            current_loss = 0\n",
    "            current_loss_iter = 0\n",
    "            \n",
    "        if iteration % 50000 == 0:\n",
    "            data_balance_randomize_classes()\n",
    "    \n",
    "    test_model_accuracy(model, n_sample=10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = RNN_WORDS_CHARS_CLASS(wordvect_size=s_word_vs.shape[-1], letters_size=letters_n,\n",
    "                              hidden_size=128, output_size=len(categories_all)).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  5000  50% (  0m 33s)   0.355   |   0.79: W -> LETTERS ✓\n",
      " 10000 100% (   1m 6s)   0.288   |   0.07: 54 -> CARDINAL ✓\n",
      "Accuracy: 93.29% (    9329/   10000)\n"
     ]
    }
   ],
   "source": [
    "train_iterations(n_iters=10000, print_every=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 30000  10% (   2m 5s)   0.164   |   0.00: , -> PUNCT ✓\n",
      " 50000  20% (  4m 10s)   0.137   |   0.00: 6 ft -> MEASURE ✓\n",
      " 70000  30% (  6m 18s)   0.132   |   0.00: to -> PLAIN ✓\n",
      " 90000  40% (  8m 21s)   0.097   |   0.00: . -> PUNCT ✓\n",
      "110000  50% ( 10m 26s)   0.108   |   0.00: PDF -> LETTERS ✓\n",
      "130000  60% ( 12m 34s)   0.104   |   0.00: 88th -> ORDINAL ✓\n",
      "150000  70% ( 14m 41s)   0.072   |   0.01: US -> LETTERS ✓\n",
      "170000  80% ( 16m 47s)   0.072   |   0.04: H -> LETTERS ✓\n",
      "190000  90% ( 18m 56s)   0.079   |   0.00: D. -> LETTERS ✓\n",
      "210000 100% (  21m 5s)   0.078   |   0.00: 21 -> CARDINAL ✓\n",
      "Accuracy: 97.46% (    9746/   10000)\n"
     ]
    }
   ],
   "source": [
    "train_iterations(n_iters=200000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "235000  13% (  2m 33s)   0.102   |   0.00: October 1998 -> DATE ✓\n",
      "260000  26% (   5m 7s)   0.060   |   0.00: CBM -> LETTERS ✓\n",
      "285000  39% (  7m 36s)   0.056   |   0.03: 2007 -> DATE ✓\n",
      "310000  53% (  9m 57s)   0.063   |   0.02: 1 -> CARDINAL ✓\n",
      "335000  66% ( 12m 31s)   0.097   |   0.00: 10 May 2011 -> DATE ✓\n",
      "360000  79% (  15m 2s)   0.055   |   0.00: , -> PUNCT ✓\n",
      "385000  92% ( 17m 35s)   0.052   |   0.00: 822.1 -> DECIMAL ✓\n",
      "Accuracy: 97.73% (    9773/   10000)\n"
     ]
    }
   ],
   "source": [
    "train_iterations(n_iters=190000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "625000  12% (  2m 27s)   0.053   |   0.01: zones -> PLAIN ✓\n",
      "650000  25% (  4m 44s)   0.056   |   0.00: 1 -> CARDINAL ✓\n",
      "675000  38% (   7m 3s)   0.062   |   0.01: T -> LETTERS ✓\n",
      "700000  50% (  9m 19s)   0.053   |   0.00: ' -> PUNCT ✓\n",
      "725000  62% ( 11m 35s)   0.041   |   0.00: 22 December 2008 -> DATE ✓\n",
      "750000  75% ( 13m 50s)   0.050   |   0.00: M. -> LETTERS ✓\n",
      "775000  88% (  16m 5s)   0.073   |   0.00: . -> PUNCT ✓\n",
      "800000 100% ( 18m 24s)   0.052   |   0.00: . -> PUNCT ✓\n",
      "Accuracy: 98.68% (    9868/   10000)\n"
     ]
    }
   ],
   "source": [
    "train_iterations(n_iters=200000, lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "825000  12% (  2m 17s)   0.058   |   0.00: . -> PUNCT ✓\n",
      "850000  25% (  4m 32s)   0.037   |   0.00: MD -> LETTERS ✓\n",
      "875000  38% (  6m 47s)   0.036   |   0.00: 21 -> CARDINAL ✓\n",
      "900000  50% (   9m 4s)   0.038   |   0.00: 15th -> ORDINAL ✓\n",
      "925000  62% ( 11m 21s)   0.043   |   0.00: 70,000 -> CARDINAL ✓\n",
      "950000  75% ( 13m 36s)   0.045   |   0.01: 77  -> CARDINAL ✓\n",
      "975000  88% ( 15m 52s)   0.026   |   0.00: Stars -> PLAIN ✓\n",
      "1000000 100% (  18m 7s)   0.045   |   0.00: 1997 -> DATE ✓\n",
      "Accuracy: 98.61% (    9861/   10000)\n"
     ]
    }
   ],
   "source": [
    "train_iterations(n_iters=200000, lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def data_balance_randomize_classes(max_len=10000):\n",
    "    global data_balanced_classes\n",
    "    data_balanced_classes = pd.concat([v.sample(min(max_len, len(v))) for k, v in all_data_classes])\n",
    "data_balance_randomize_classes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1025000  12% (  2m 33s)   0.033   |   0.00: 1st -> ORDINAL ✓\n",
      "1050000  25% (   5m 2s)   0.070   |   0.00: 0-89774-991 -> TELEPHONE ✓\n",
      "1075000  38% (  7m 36s)   0.057   |   0.00: 30 -> CARDINAL ✓\n",
      "1100000  50% (  10m 8s)   0.067   |   0.00: 76% -> MEASURE ✓\n",
      "1125000  62% ( 12m 32s)   0.040   |   0.00: . -> PUNCT ✓\n",
      "1150000  75% ( 14m 52s)   0.061   |   0.00: 100 million -> DECIMAL ✓\n",
      "1175000  88% ( 17m 16s)   0.047   |   0.00: 79% -> MEASURE ✓\n",
      "1200000 100% ( 19m 39s)   0.069   |   0.00: 21 km -> MEASURE ✓\n",
      "Accuracy: 98.40% (    9840/   10000)\n"
     ]
    }
   ],
   "source": [
    "train_iterations(n_iters=200000, lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1225000  12% (  2m 34s)   0.035   |   0.00: 1812 -> DATE ✓\n",
      "1250000  25% (  5m 14s)   0.042   |   0.00: 4\" -> MEASURE ✓\n",
      "1275000  38% (  7m 52s)   0.056   |   0.00: 1998 -> DATE ✓\n",
      "1300000  50% ( 10m 36s)   0.033   |   0.22: 2010 -> DIGIT ✓\n",
      "1325000  62% ( 13m 24s)   0.071   |   0.00: 2:00.8 -> TIME ✓\n",
      "1350000  75% (  16m 2s)   0.071   |   0.00: 1800autopsy.comPBS -> ELECTRONIC ✓\n",
      "1375000  88% ( 18m 37s)   0.043   |   0.00: 2GB -> MEASURE ✓\n",
      "1400000 100% (  21m 1s)   0.034   |   0.00: US$90 Million -> MONEY ✓\n",
      "Accuracy: 98.35% (    9835/   10000)\n"
     ]
    }
   ],
   "source": [
    "train_iterations(n_iters=200000, lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 97.92% (    9792/   10000)\n"
     ]
    }
   ],
   "source": [
    "data_balance_randomize_classes(100000)\n",
    "test_model_accuracy(model, n_sample=10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Keep track of correct guesses in a confusion matrix\n",
    "confusion = torch.zeros(len(categories_all), len(categories_all))\n",
    "n_confusion = 100000\n",
    "\n",
    "# Go through a bunch of examples and record which are correctly guessed\n",
    "for i in range(n_confusion):\n",
    "    s_bef, s_aft, s_class, s_word_vs = get_random_sample()\n",
    "    word_vectors = Variable(torch.from_numpy(s_word_vs))\n",
    "    string = Variable(string_to_tensor(s_bef))\n",
    "    if use_cuda:\n",
    "        word_vectors = word_vectors.cuda()\n",
    "        string = string.cuda()\n",
    "    output = model(word_vects, string)\n",
    "    guess, guess_i = category_from_output(output)\n",
    "    category_i = categories_index[s_class]\n",
    "    confusion[category_i][guess_i] += 1\n",
    "\n",
    "# Normalize by dividing every row by its sum\n",
    "for i in range(len(categories_all)):\n",
    "    confusion[i] = confusion[i] / confusion[i].sum()\n",
    "\n",
    "# Set up plot\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "cax = ax.matshow(confusion.numpy())\n",
    "fig.colorbar(cax)\n",
    "\n",
    "# Set up axes\n",
    "ax.set_xticklabels([''] + list(categories_all), rotation=90)\n",
    "ax.set_yticklabels([''] + list(categories_all))\n",
    "\n",
    "# Force label at every tick\n",
    "ax.xaxis.set_major_locator(matplotlib.ticker.MultipleLocator(1))\n",
    "ax.yaxis.set_major_locator(matplotlib.ticker.MultipleLocator(1))\n",
    "\n",
    "# sphinx_gallery_thumbnail_number = 2\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f7503976cf8>]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAD8CAYAAABw1c+bAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nP8MwTJzBws8wDBNn/D+wzNLp6RThVgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f7503965be0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "all_losses = [arr[0] for arr in model.train_history[10:]]\n",
    "plt.figure()\n",
    "plt.plot(all_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:py3_pytorch_2]",
   "language": "python",
   "name": "conda-env-py3_pytorch_2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
