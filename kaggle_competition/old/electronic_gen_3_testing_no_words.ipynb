{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import importlib\n",
    "from pytorch_utils_oh_2 import *\n",
    "import IPython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MODEL_SAVE_PATH = 'electronic_gen_3_testing_no_words'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pytorch utils oh: pytorch_utils_oh_2.py\n",
      "Pytorch: 0.2.0_4\n"
     ]
    }
   ],
   "source": [
    "import pytorch_utils_oh_2; importlib.reload(pytorch_utils_oh_2); from pytorch_utils_oh_2 import *;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# all_data = pickle.load(open(\"data/en_train_fixed_4_sentences.pkl\", \"rb\" ))\n",
    "all_data = pickle.load(open(\"data/en_train_fixed_5_manual.pkl\", \"rb\" ))\n",
    "# all_data_sentence_index = all_data.set_index('sentence_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>token_id</th>\n",
       "      <th>class</th>\n",
       "      <th>before</th>\n",
       "      <th>after</th>\n",
       "      <th>class_org</th>\n",
       "      <th>a_word_ind</th>\n",
       "      <th>sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6489685</th>\n",
       "      <td>493485</td>\n",
       "      <td>20</td>\n",
       "      <td>LETTERS</td>\n",
       "      <td>OPIS</td>\n",
       "      <td>o p i s</td>\n",
       "      <td>LETTERS</td>\n",
       "      <td>[25, 24, 31, 17, 0]</td>\n",
       "      <td>examples of u . s . tax shelters include : for...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7698043</th>\n",
       "      <td>583566</td>\n",
       "      <td>20</td>\n",
       "      <td>LETTERS</td>\n",
       "      <td>A.C.A.P.</td>\n",
       "      <td>a c a p</td>\n",
       "      <td>LETTERS</td>\n",
       "      <td>[22, 21, 22, 24, 0]</td>\n",
       "      <td>within the first two years of his career in 19...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         sentence_id  token_id    class    before    after class_org  \\\n",
       "6489685       493485        20  LETTERS      OPIS  o p i s   LETTERS   \n",
       "7698043       583566        20  LETTERS  A.C.A.P.  a c a p   LETTERS   \n",
       "\n",
       "                  a_word_ind  \\\n",
       "6489685  [25, 24, 31, 17, 0]   \n",
       "7698043  [22, 21, 22, 24, 0]   \n",
       "\n",
       "                                                  sentence  \n",
       "6489685  examples of u . s . tax shelters include : for...  \n",
       "7698043  within the first two years of his career in 19...  "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "32992"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data = all_data[(all_data['class'] == 'LETTERS') | (all_data['class'] == 'ELECTRONIC')]\n",
    "all_data = all_data[all_data['after'].str.len() > 5]\n",
    "all_data.sample(2)\n",
    "len(all_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sample_data = all_data.copy()\n",
    "sample_data = sample_data.reset_index(drop=True)\n",
    "del(all_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sample_data = all_data.copy()\n",
    "sample_data = sample_data[sample_data['class'] == 'ELECTRONIC']\n",
    "print(\"Data rows: {},  (dropped rows: {})\".format(len(sample_data), len(all_data)-len(sample_data)))\n",
    "sample_data = sample_data.reset_index(drop=True)\n",
    "del(all_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ELECTRONIC', 'LETTERS']\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "categories_all = sorted(sample_data[\"class\"].unique())\n",
    "print(categories_all)\n",
    "print(len(categories_all))\n",
    "categories_index = dict((c, i) for i, c in enumerate(categories_all))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>token_id</th>\n",
       "      <th>class</th>\n",
       "      <th>before</th>\n",
       "      <th>after</th>\n",
       "      <th>class_org</th>\n",
       "      <th>a_word_ind</th>\n",
       "      <th>sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11099</th>\n",
       "      <td>255315</td>\n",
       "      <td>20</td>\n",
       "      <td>ELECTRONIC</td>\n",
       "      <td>mlive.com</td>\n",
       "      <td>m l i v e dot c o m</td>\n",
       "      <td>ELECTRONIC</td>\n",
       "      <td>[32, 42, 31, 54, 28, 74, 21, 25, 32, 0]</td>\n",
       "      <td>\" meet michigan 's next house speaker : kevin ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28044</th>\n",
       "      <td>633799</td>\n",
       "      <td>0</td>\n",
       "      <td>LETTERS</td>\n",
       "      <td>KTAV</td>\n",
       "      <td>k t a v</td>\n",
       "      <td>LETTERS</td>\n",
       "      <td>[59, 30, 22, 54, 0]</td>\n",
       "      <td>&lt;SAMPLE&gt; publishing house , p . 107 .</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       sentence_id  token_id       class     before                after  \\\n",
       "11099       255315        20  ELECTRONIC  mlive.com  m l i v e dot c o m   \n",
       "28044       633799         0     LETTERS       KTAV              k t a v   \n",
       "\n",
       "        class_org                               a_word_ind  \\\n",
       "11099  ELECTRONIC  [32, 42, 31, 54, 28, 74, 21, 25, 32, 0]   \n",
       "28044     LETTERS                      [59, 30, 22, 54, 0]   \n",
       "\n",
       "                                                sentence  \n",
       "11099  \" meet michigan 's next house speaker : kevin ...  \n",
       "28044              <SAMPLE> publishing house , p . 107 .  "
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_data.sample(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utils stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<SOS><EOS>☒ !\"#$%&'(),-./0123456789:;ABCDEFGHIJKLMNOPQRSTUVWXYZ_abcdefghijklmnopqrstuvwxyz~£¥ª²³µº¼½¾éɒʻˈΩμ—€⅓⅔⅛\n"
     ]
    }
   ],
   "source": [
    "chars_normal, chars_normal_index = load_characters_pkl('data/en_features/chars_normal.pkl')\n",
    "print(''.join(chars_normal))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = list(sample_data['after'])\n",
    "arr = [s.split(' ') for s in arr]\n",
    "words_after = [EOS_TOKEN, SOS_TOKEN, UNKNOWN_WORD_TOKEN, NUMBER_WORD_TOKEN, SAMPLE_WORD_TOKEN]\n",
    "words_after = words_after + sorted(list(set(np.concatenate(arr))))\n",
    "words_after_index = dict((c, i) for i, c in enumerate(words_after))\n",
    "words_after_by_length = sorted(words_after, key=len, reverse=True)\n",
    "words_after_regex = re.compile('(' + ')|('.join(words_after_by_length) + ')')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "152"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(words_after)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "chars_after = [EOS_TOKEN, SOS_TOKEN] + sorted(list(set(list(''.join(list(sample_data['after']))))))\n",
    "chars_after_index = dict((c, i) for i, c in enumerate(chars_after))\n",
    "''.join(chars_after)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[32, 26, 92, 19, 0]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "['dot', 'd', 'o', 'c', '<EOS>']"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def after_sentence_to_word_indexes(sentence, include_eos=True):\n",
    "    reg = re.finditer(words_after_regex, sentence)\n",
    "    arr = [words_after_index[s[0]] for s in reg]\n",
    "    if include_eos:\n",
    "        arr += [words_after_index[EOS_TOKEN]]\n",
    "    return arr\n",
    "tmp = after_sentence_to_word_indexes('dot d o c')\n",
    "tmp\n",
    "[words_after[t] for t in tmp]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 152])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sos_tensor = torch.zeros(1, 1, len(words_after_index))\n",
    "sos_tensor[0, 0, words_after_index[SOS_TOKEN]] = 1\n",
    "sos_tensor.size()\n",
    "#del(onehot_sos)\n",
    "\n",
    "# sos_tensor = torch.LongTensor([words_after_index[SOS_TOKEN]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NYtimes.com -> n y t i m e s dot c o m <EOS> [87, 147, 124, 65, 82, 33, 113, 32, 19, 92, 82, 0]\n",
      "torch.Size([1, 12, 104])\n"
     ]
    }
   ],
   "source": [
    "balanced_data_length = len(sample_data)\n",
    "def get_random_sample():\n",
    "    #sample_row = balanced_data_sample_row()\n",
    "    sample_row = balanced_data_last_sample = sample_data.iloc[random.randint(1, balanced_data_length-1)]\n",
    "    \n",
    "    a_words_ind = after_sentence_to_word_indexes(sample_row['after'], include_eos=True)\n",
    "    return sample_row['before'], a_words_ind\n",
    "            \n",
    "def tmp():\n",
    "    s_bef, s_aft = get_random_sample()\n",
    "    s_aft_str = ' '.join([words_after[i] for i in s_aft])\n",
    "    print(s_bef, '->', s_aft_str, s_aft)\n",
    "    print(string_to_tensor(s_bef, chars_normal_index).shape)\n",
    "tmp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "137 µs ± 1.53 µs per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "get_random_sample()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "use_cuda = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MAX_ATTENTION_LENGTH = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "498"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>token_id</th>\n",
       "      <th>class</th>\n",
       "      <th>before</th>\n",
       "      <th>after</th>\n",
       "      <th>class_org</th>\n",
       "      <th>a_word_ind</th>\n",
       "      <th>sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19487</th>\n",
       "      <td>453003</td>\n",
       "      <td>7</td>\n",
       "      <td>ELECTRONIC</td>\n",
       "      <td>http://www.verfassungen.de/de/de33-45/wehrmach...</td>\n",
       "      <td>h t t p colon slash slash w w w dot v e r f a ...</td>\n",
       "      <td>ELECTRONIC</td>\n",
       "      <td>[45, 30, 30, 24, 129, 101, 101, 52, 52, 52, 74...</td>\n",
       "      <td>52 , p . 609 see : &lt;SAMPLE&gt; , telford .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28222</th>\n",
       "      <td>637870</td>\n",
       "      <td>7</td>\n",
       "      <td>ELECTRONIC</td>\n",
       "      <td>http://chesstournamentservices.com/cca/2009/04...</td>\n",
       "      <td>h t t p colon slash slash c h e s s t o u r n ...</td>\n",
       "      <td>ELECTRONIC</td>\n",
       "      <td>[45, 30, 30, 24, 129, 101, 101, 21, 45, 28, 17...</td>\n",
       "      <td>\" sadvakasov sneaks past shulman \" ( &lt;SAMPLE&gt; .</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       sentence_id  token_id       class  \\\n",
       "19487       453003         7  ELECTRONIC   \n",
       "28222       637870         7  ELECTRONIC   \n",
       "\n",
       "                                                  before  \\\n",
       "19487  http://www.verfassungen.de/de/de33-45/wehrmach...   \n",
       "28222  http://chesstournamentservices.com/cca/2009/04...   \n",
       "\n",
       "                                                   after   class_org  \\\n",
       "19487  h t t p colon slash slash w w w dot v e r f a ...  ELECTRONIC   \n",
       "28222  h t t p colon slash slash c h e s s t o u r n ...  ELECTRONIC   \n",
       "\n",
       "                                              a_word_ind  \\\n",
       "19487  [45, 30, 30, 24, 129, 101, 101, 52, 52, 52, 74...   \n",
       "28222  [45, 30, 30, 24, 129, 101, 101, 21, 45, 28, 17...   \n",
       "\n",
       "                                              sentence  \n",
       "19487          52 , p . 609 see : <SAMPLE> , telford .  \n",
       "28222  \" sadvakasov sneaks past shulman \" ( <SAMPLE> .  "
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>token_id</th>\n",
       "      <th>class</th>\n",
       "      <th>before</th>\n",
       "      <th>after</th>\n",
       "      <th>class_org</th>\n",
       "      <th>a_word_ind</th>\n",
       "      <th>sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11533</th>\n",
       "      <td>265794</td>\n",
       "      <td>3</td>\n",
       "      <td>ELECTRONIC</td>\n",
       "      <td>2000Myspace.comTempleofschlock.blogpsot.comBil...</td>\n",
       "      <td>t w o o o o m y s p a c e dot c o m t e m p l ...</td>\n",
       "      <td>ELECTRONIC</td>\n",
       "      <td>[30, 52, 25, 25, 25, 25, 32, 86, 17, 24, 22, 2...</td>\n",
       "      <td>7th edn , &lt;SAMPLE&gt; vol 89 # 8 ( 26 february 19...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21453</th>\n",
       "      <td>491251</td>\n",
       "      <td>1</td>\n",
       "      <td>ELECTRONIC</td>\n",
       "      <td>StoneDeadline.comDeadline.comDeadline.comDeadl...</td>\n",
       "      <td>s t o n e d e a d l i n e dot c o m d e a d l ...</td>\n",
       "      <td>ELECTRONIC</td>\n",
       "      <td>[17, 30, 25, 29, 28, 26, 28, 22, 26, 42, 31, 2...</td>\n",
       "      <td>deadline . comdeadline . comvarietydeadline . ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       sentence_id  token_id       class  \\\n",
       "11533       265794         3  ELECTRONIC   \n",
       "21453       491251         1  ELECTRONIC   \n",
       "\n",
       "                                                  before  \\\n",
       "11533  2000Myspace.comTempleofschlock.blogpsot.comBil...   \n",
       "21453  StoneDeadline.comDeadline.comDeadline.comDeadl...   \n",
       "\n",
       "                                                   after   class_org  \\\n",
       "11533  t w o o o o m y s p a c e dot c o m t e m p l ...  ELECTRONIC   \n",
       "21453  s t o n e d e a d l i n e dot c o m d e a d l ...  ELECTRONIC   \n",
       "\n",
       "                                              a_word_ind  \\\n",
       "11533  [30, 52, 25, 25, 25, 25, 32, 86, 17, 24, 22, 2...   \n",
       "21453  [17, 30, 25, 29, 28, 26, 28, 22, 26, 42, 31, 2...   \n",
       "\n",
       "                                                sentence  \n",
       "11533  7th edn , <SAMPLE> vol 89 # 8 ( 26 february 19...  \n",
       "21453  deadline . comdeadline . comvarietydeadline . ...  "
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp = sample_data[sample_data['before'].str.len()>MAX_ATTENTION_LENGTH]\n",
    "len(tmp)\n",
    "tmp.sample(2)\n",
    "tmp[~tmp['before'].str.contains('/')].sample(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EncoderRNN (\n",
       "  (rnn_chars): LSTM(104, 256, batch_first=True)\n",
       ")"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, chars_input_size, chars_hidden_size, chars_layers=1):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        \n",
    "        self.chars_layers = chars_layers\n",
    "        self.chars_hidden_size = chars_hidden_size\n",
    "\n",
    "        self.rnn_chars = nn.LSTM(chars_input_size, chars_hidden_size, chars_layers,\n",
    "                                 batch_first=True, bidirectional=False)\n",
    "                                #batch_first=True, bidirectional=True)\n",
    "        \n",
    "    def forward(self, string_tensor, hidden = None, init_hidden = True):\n",
    "        if init_hidden:\n",
    "            hidden_chars = self.init_hidden()\n",
    "        \n",
    "        all_outputs_chars, hidden_chars = self.rnn_chars(string_tensor, hidden_chars)\n",
    "        output_chars = all_outputs_chars[:, -1]\n",
    "        \n",
    "        hidden_states_cat = Variable(torch.zeros(MAX_ATTENTION_LENGTH, self.chars_hidden_size)).cuda()\n",
    "        for ei in range(min(MAX_ATTENTION_LENGTH, len(string_tensor[0]))):\n",
    "            hidden_states_cat[ei] = all_outputs_chars[0, ei]\n",
    "                \n",
    "        #return output, all_outputs_chars\n",
    "        return output_chars[0], hidden_states_cat\n",
    "\n",
    "    def init_hidden(self):\n",
    "        var2_1 = Variable(torch.zeros(1 * self.chars_layers, 1, self.chars_hidden_size))\n",
    "        var2_2 = Variable(torch.zeros(1 * self.chars_layers, 1, self.chars_hidden_size))\n",
    "        \n",
    "        var2_1 = var2_1.cuda(); var2_2 = var2_2.cuda()\n",
    "        return (var2_1, var2_2)\n",
    "    \n",
    "    \n",
    "encoder_rnn = EncoderRNN(chars_input_size=len(chars_normal),\n",
    "                         chars_hidden_size=256, chars_layers=1).cuda()\n",
    "encoder_rnn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'SUPW'"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([256])"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([50, 256])"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def test_encoder_single_sample():\n",
    "    s_bef, s_aft = get_random_sample()\n",
    "\n",
    "    string_t = string_to_tensor(s_bef, chars_normal_index)\n",
    "    string_t = Variable(string_t).cuda()\n",
    "    \n",
    "    return encoder_rnn(string_t), s_bef\n",
    "    \n",
    "(encoder_output, encoder_outputs), tmp = test_encoder_single_sample()\n",
    "tmp\n",
    "encoder_output.size()\n",
    "encoder_outputs.size()\n",
    "torch.eq(encoder_output, encoder_outputs[len(tmp)]).data.all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecoderRNN (\n",
       "  (emb_lin): Linear (152 -> 256)\n",
       "  (attn): Linear (512 -> 50)\n",
       "  (attn_combine): Linear (512 -> 256)\n",
       "  (dropout): Dropout (p = 0.1)\n",
       "  (rnn): GRU(256, 256, batch_first=True)\n",
       "  (lin_out): Linear (256 -> 152)\n",
       ")"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class DecoderRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, n_layers=1, dropout_p=0.1, max_length=MAX_ATTENTION_LENGTH):\n",
    "        super(DecoderRNN, self).__init__()\n",
    "        self.n_layers = n_layers\n",
    "        self.hidden_size = hidden_size\n",
    "        self.max_length = max_length\n",
    "        \n",
    "        self.emb_lin = nn.Linear(input_size, hidden_size)\n",
    "        self.attn = nn.Linear(hidden_size*2, self.max_length)\n",
    "        self.attn_combine = nn.Linear(self.hidden_size * 2, self.hidden_size)\n",
    "        self.dropout = nn.Dropout(dropout_p)\n",
    "        \n",
    "        self.rnn = nn.GRU(hidden_size, hidden_size, n_layers, batch_first=True, bidirectional=False)\n",
    "        self.lin_out = nn.Linear(hidden_size, input_size)\n",
    "        \n",
    "    #def forward(self, char, hidden):\n",
    "    def forward(self, last_input, hidden, encoder_outputs):\n",
    "        embedded = self.emb_lin(last_input).view(1, 1, -1)\n",
    "        embedded = self.dropout(embedded)\n",
    "\n",
    "        attn_weights = F.softmax(self.attn(torch.cat((embedded[0], hidden[0]), 1)))\n",
    "        attn_applied = torch.bmm(attn_weights.unsqueeze(0), encoder_outputs.unsqueeze(0))\n",
    "        \n",
    "        rnn_input = torch.cat((embedded[0], attn_applied[0]), 1)\n",
    "        rnn_input = self.attn_combine(rnn_input).unsqueeze(0)\n",
    "        rnn_input = F.relu(rnn_input)\n",
    "        \n",
    "        output, hidden = self.rnn(rnn_input, hidden)\n",
    "        output = F.log_softmax(self.lin_out(output[0]))\n",
    "        \n",
    "        return output, hidden, attn_weights\n",
    "    \n",
    "    def init_rest_hidden(self, input_var):\n",
    "        if self.n_layers > 1:\n",
    "            hid_var = Variable(torch.zeros(self.n_layers - 1, 1, self.hidden_size)).cuda()\n",
    "            res = torch.cat((input_var, hid_var), 0)\n",
    "            return res\n",
    "        else:\n",
    "            return input_var\n",
    "        \n",
    "\n",
    "decoder_rnn = DecoderRNN(input_size=len(words_after), hidden_size=encoder_output.size()[0], n_layers=1)\n",
    "decoder_rnn = decoder_rnn.cuda()\n",
    "decoder_rnn\n",
    "\n",
    "tmp_outputs = Variable(torch.zeros(MAX_ATTENTION_LENGTH, encoder_output.size()[0])).cuda()\n",
    "tmp_hiddens = decoder_rnn.init_rest_hidden(encoder_output.view(1,1,-1))\n",
    "tmp = decoder_rnn(Variable(sos_tensor).cuda(), tmp_hiddens, tmp_outputs)\n",
    "#[v.size() for v in tmp]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 152])"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 256])"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([50, 256])"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sos_tensor.size()\n",
    "tmp_hiddens.size()\n",
    "tmp_outputs.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[torch.Size([1, 152]), torch.Size([1, 1, 256]), torch.Size([1, 50])]"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      " 45\n",
      "[torch.cuda.LongTensor of size 1x1 (GPU 0)]\n",
      "\n",
      "fitnesstuesday\n"
     ]
    }
   ],
   "source": [
    "tmp_outputs = Variable(torch.zeros(MAX_ATTENTION_LENGTH, encoder_output.size()[0])).cuda()\n",
    "tmp_hiddens = decoder_rnn.init_rest_hidden(encoder_output.view(1,1,-1))\n",
    "tmp = decoder_rnn(Variable(sos_tensor).cuda(), tmp_hiddens, tmp_outputs)\n",
    "[v.size() for v in tmp]\n",
    "print(tmp[0].topk(1)[1])\n",
    "print(words_after[tmp[0].topk(1)[1].data[0][0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training etc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('fitnesstuesday fitnesstuesday s s s s s s s s s s s s s s s s s s',\n",
       " 'fitnesstuesday fitnesstuesday s s s s s s s s s s s s s s s s s s',\n",
       " 'i n e g i',\n",
       " ('INEGI', [65, 87, 33, 52, 65, 0]))"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def test_model_single_sample(model=None, return_more=False, sample=False):\n",
    "    decoder_rnn.eval()\n",
    "    encoder_rnn.eval()\n",
    "    \n",
    "    if not sample:\n",
    "        sample = get_random_sample()\n",
    "    s_bef, s_aft = sample\n",
    "    \n",
    "    string_t = string_to_tensor(s_bef, chars_normal_index)\n",
    "    string_t = Variable(string_t).cuda()\n",
    "    \n",
    "    encoder_output, encoder_outputs = encoder_rnn(string_t)\n",
    "        \n",
    "    decoder_hidden = decoder_rnn.init_rest_hidden(encoder_outputs[0].view(1,1,-1))\n",
    "    decoder_input = Variable(sos_tensor).cuda()\n",
    "\n",
    "    decoded_output = []\n",
    "    decoder_attns_arr = []\n",
    "    max_length = 20\n",
    "    for _ in range(max_length):\n",
    "        decoder_output, decoder_hidden, decoder_attns = decoder_rnn(decoder_input, decoder_hidden, encoder_outputs)\n",
    "        decoder_attns_arr.append(decoder_attns)\n",
    "        #return decoder_output\n",
    "\n",
    "        topv, topi = decoder_output.data.topk(1)\n",
    "        word_index = topi[0][0]\n",
    "        word = words_after[word_index] # Use own prediction as next input\n",
    "                \n",
    "        if word == EOS_TOKEN:\n",
    "            break\n",
    "\n",
    "        decoded_output.append(word)\n",
    "        \n",
    "        #decoder_input = Variable(torch.LongTensor([word_index])).cuda()\n",
    "        \n",
    "        decoder_input = torch.zeros(1, 1, len(words_after_index))\n",
    "        decoder_input[0, 0, word_index] = 1\n",
    "        decoder_input = Variable(decoder_input).cuda()\n",
    "    \n",
    "    output = ' '.join(decoded_output)\n",
    "    sample_target = ' '.join([words_after[w] for w in s_aft][:-1])\n",
    "    \n",
    "    decoder_rnn.train()\n",
    "    encoder_rnn.train()\n",
    "    \n",
    "    if return_more:\n",
    "        return output, decoded_output, decoder_attns_arr, sample\n",
    "    \n",
    "    return output, output, sample_target, sample\n",
    "    \n",
    "tmp = test_model_single_sample(None)\n",
    "tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ECFC           => fitnesstuesday fitnesstuesday fitnesstuesday s s s s s s s s s s s s s s s s s || [33, 19, 39, 19, 0] \n",
      "                  \n",
      "CDP's          => fitnesstuesday fitnesstuesday s s s s s s s s s s s s s s s s s s || [19, 26, 101, 0] \n",
      "                  \n"
     ]
    }
   ],
   "source": [
    "def print_local_wrong_predictions(max_results=10):\n",
    "    arr = get_some_wrong_predictions(None, test_model_single_sample, max_iterations=10000, max_results=max_results)\n",
    "    for sample, predict, output in arr:\n",
    "        s_bef, s_aft = sample\n",
    "        print(\"{:<14} => {:<14} || {} \\n{:>17} {}\".format(s_bef, predict, s_aft, '', '' ))\n",
    "print_local_wrong_predictions(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.00% (       0/     100)\n",
      "CPU times: user 2.34 s, sys: 20 ms, total: 2.36 s\n",
      "Wall time: 2.35 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "test_model_accuracy(encoder_rnn, test_model_single_sample, n_sample=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train(s_bef, s_aft, s_sentence, encoder_optimizer, decoder_optimizer, loss_function,\n",
    "          use_teacher_forcing, max_length=20):\n",
    "    \n",
    "    string_t = string_to_tensor(s_bef, chars_normal_index)\n",
    "    string_t = Variable(string_t).cuda()\n",
    "    \n",
    "    encoder_output, encoder_outputs = encoder_rnn(string_t)\n",
    "    \n",
    "    #encoder_output = encoder_output.view(1,1,-1)\n",
    "    \n",
    "    decoder_hidden = decoder_rnn.init_rest_hidden(encoder_outputs[0].view(1,1,-1))\n",
    "    decoder_input = Variable(sos_tensor).cuda()\n",
    "    \n",
    "    ###\n",
    "    target_arr = s_aft\n",
    "    #target_arr = after_sentence_to_word_indexes(s_aft, include_eos=True)\n",
    "    \n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "    loss = 0\n",
    "    \n",
    "    decoded_output = []\n",
    "    for i in range(len(target_arr)):\n",
    "        decoder_output, decoder_hidden, decoder_attns = decoder_rnn(decoder_input, decoder_hidden, encoder_outputs)\n",
    "\n",
    "        #decoder_target_i = chars_after_index[target_arr[i]]\n",
    "        decoder_target_i = target_arr[i]\n",
    "        decoder_target_i = Variable(torch.LongTensor([decoder_target_i])).cuda()\n",
    "        loss += loss_function(decoder_output, decoder_target_i)\n",
    "        \n",
    "        topv, topi = decoder_output.data.topk(1)\n",
    "        word_index = topi[0][0]\n",
    "        word = words_after[word_index] # Use own prediction as next input\n",
    "        decoded_output.append(word)\n",
    "        \n",
    "        if use_teacher_forcing:\n",
    "            word_index = target_arr[i] # replace input with right target\n",
    "        else:\n",
    "            # use output normally as input \n",
    "            if word == EOS_TOKEN:\n",
    "                break\n",
    "                \n",
    "        decoder_input = torch.zeros(1, 1, len(words_after_index))\n",
    "        decoder_input[0, 0, word_index] = 1\n",
    "        decoder_input = Variable(decoder_input).cuda()\n",
    "        #decoder_input = Variable(torch.LongTensor([word_index])).cuda()\n",
    "        \n",
    "    if decoded_output[-1] == EOS_TOKEN:\n",
    "        decoded_output = decoded_output[:-1]\n",
    "        \n",
    "    loss.backward()\n",
    "\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "\n",
    "    return ' '.join(decoded_output), (loss.data[0] / len(target_arr))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_iterations(n_iters=100000, lr=0.001, teacher_forcing_ratio=0.5,\n",
    "                     print_every=10000, plot_every=1000):\n",
    "\n",
    "    start = time.time()\n",
    "    \n",
    "    decoder_rnn.train()\n",
    "    encoder_rnn.train()\n",
    "\n",
    "    current_loss = 0\n",
    "    current_loss_iter = 0\n",
    "\n",
    "    encoder_optimizer = torch.optim.Adam(encoder_rnn.parameters(), lr=lr)\n",
    "    decoder_optimizer = torch.optim.Adam(decoder_rnn.parameters(), lr=lr)\n",
    "    loss_function = nn.NLLLoss()\n",
    "    \n",
    "    for iteration in range(1, n_iters + 1):\n",
    "        model_training.iterations += 1\n",
    "        \n",
    "        use_teacher_forcing = random.random() < teacher_forcing_ratio\n",
    "        \n",
    "        s_bef, s_aft = get_random_sample()\n",
    "        s_sentence=''\n",
    "        \n",
    "        result, loss = train(s_bef=s_bef, s_aft=s_aft, s_sentence=s_sentence,\n",
    "                             encoder_optimizer=encoder_optimizer, decoder_optimizer=decoder_optimizer,\n",
    "                             loss_function=nn.NLLLoss(), use_teacher_forcing=use_teacher_forcing,\n",
    "                             max_length=40 )\n",
    "        \n",
    "        current_loss += loss\n",
    "        current_loss_iter += 1\n",
    "\n",
    "        # Print iter number, loss, name and guess\n",
    "        if iteration % print_every == 0:\n",
    "            teacher_forcing_str = \"\"\n",
    "            if use_teacher_forcing:\n",
    "                teacher_forcing_str = \"(forcing)\"\n",
    "            s_aft_sentence = ' '.join([words_after[w] for w in s_aft][:-1])\n",
    "            correct = '✓' if result == s_aft_sentence else \"✗: {}\".format(s_aft_sentence)\n",
    "            \n",
    "            print(\"{:>6d} {:>4.0%} ({:>8}) {:>7.3f}   | {:>6.2f}: {} -> {} ({}) {}\".format(\n",
    "                      model_training.iterations, iteration/n_iters, time_since(start),\n",
    "                      current_loss/current_loss_iter, loss,\n",
    "                      s_bef, result, correct, teacher_forcing_str))\n",
    "\n",
    "        # Add current loss avg to list of losses\n",
    "        if iteration % plot_every == 0:\n",
    "            model_training.losses.append(current_loss / plot_every)\n",
    "            model_training.learning_rates.append(lr)\n",
    "            current_loss = 0\n",
    "            current_loss_iter = 0\n",
    "            \n",
    "        if model_training.iterations % 50000 == 0 or model_training.iterations == 10:\n",
    "            model_training.save_models()\n",
    "            acc = test_model_accuracy(encoder_rnn, test_model_single_sample)\n",
    "            model_training.accuracy.append(acc)\n",
    "    \n",
    "    # test_model_accuracy(model, n_sample=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Save path: data/models/electronic_gen_3_testing_no_words\n"
     ]
    }
   ],
   "source": [
    "model_training = ModelTraining(MODEL_SAVE_PATH, [encoder_rnn, decoder_rnn])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     9  18% (   0m 0s)   5.008   |   5.02: RCBL -> s s s s s (✗: r c b l) (forcing)\n",
      "Saved model to data/models/electronic_gen_3_testing_no_words/10_(EncoderRNN/DecoderRNN)\n",
      "Accuracy: 0.00% (       0/   10000)\n",
      "    18  36% (  5m 17s)   4.823   |   4.94: USNO -> s s s s s (✗: u s n o) (forcing)\n",
      "    27  54% (  5m 17s)   4.626   |   1.36: /ˈmɒl.li -> s s (✗: s l a s h m l dot l i) \n",
      "    36  72% (  5m 17s)   4.089   |   0.90: ESSENTIALE -> s (✗: e s s e n t i a l e) \n",
      "    45  90% (  5m 18s)   4.175   |   4.91: UCLA -> s <EOS> <EOS> <EOS> (✗: u c l a) (forcing)\n"
     ]
    }
   ],
   "source": [
    "train_iterations(n_iters=50, print_every=9, lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   550  53% (   0m 8s)   2.415   |   1.55: ew.com -> i s (✗: e w dot c o m) \n"
     ]
    }
   ],
   "source": [
    "train_iterations(n_iters=(1000-model_training.iterations), print_every=500, lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 11000  10% (  4m 18s)   0.369   |   0.29: CEDEJ -> c e d e l (✗: c e d e j) (forcing)\n",
      " 21000  20% (  8m 45s)   0.270   |   0.01: SRJC -> s r j c (✓) (forcing)\n",
      " 31000  30% ( 12m 56s)   0.155   |   0.01: IIHF -> i i h f (✓) \n",
      " 41000  40% ( 17m 19s)   0.178   |   0.03: KTHV -> k t h v (✓) (forcing)\n",
      "Saved model to data/models/electronic_gen_3_testing_no_words/50000_(EncoderRNN/DecoderRNN)\n",
      "Accuracy: 85.02% (    8502/   10000)\n",
      " 51000  51% ( 22m 51s)   0.203   |   0.00: BSIE -> b s i e (✓) \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-140-f63a205175f9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_iterations\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_iters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m99000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprint_every\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-136-37d440257daf>\u001b[0m in \u001b[0;36mtrain_iterations\u001b[0;34m(n_iters, lr, teacher_forcing_ratio, print_every, plot_every)\u001b[0m\n\u001b[1;32m     25\u001b[0m                              \u001b[0mencoder_optimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoder_optimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder_optimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdecoder_optimizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m                              \u001b[0mloss_function\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNLLLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_teacher_forcing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_teacher_forcing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m                              max_length=40 )\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0mcurrent_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-132-71d079fa1e0a>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(s_bef, s_aft, s_sentence, encoder_optimizer, decoder_optimizer, loss_function, use_teacher_forcing, max_length)\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0mdecoder_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwords_after_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0mdecoder_input\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword_index\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m         \u001b[0mdecoder_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecoder_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m         \u001b[0;31m#decoder_input = Variable(torch.LongTensor([word_index])).cuda()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py3_pytorch_2/lib/python3.6/site-packages/torch/autograd/variable.py\u001b[0m in \u001b[0;36mcuda\u001b[0;34m(self, device_id, async)\u001b[0m\n\u001b[1;32m    277\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0masync\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 279\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mCudaTransfer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0masync\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    280\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    281\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py3_pytorch_2/lib/python3.6/site-packages/torch/autograd/_functions/tensor.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(ctx, i, device_id, async)\u001b[0m\n\u001b[1;32m    149\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0masync\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0masync\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 151\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0masync\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0masync\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py3_pytorch_2/lib/python3.6/site-packages/torch/_utils.py\u001b[0m in \u001b[0;36m_cuda\u001b[0;34m(self, device, async)\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0mnew_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mnew_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0masync\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_iterations(n_iters=99000, print_every=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_iterations(n_iters=100000, print_every=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input:   UEFA.comWebster\n",
      "output:  u e f a dot c o m w e b s t e r\n",
      "target:    uefadotcomwebster\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAxQAAAFeCAYAAAAc31myAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fe8dce04f98>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def debug_show_attention(input_sentence, output_words, attentions):\n",
    "    # Set up figure with colorbar\n",
    "    fig = plt.figure(figsize=(15,6))\n",
    "    ax = fig.add_subplot(111)\n",
    "    #cax = ax.matshow(attentions.numpy(), cmap='bone')\n",
    "    cax = ax.matshow(attentions, cmap='bone')\n",
    "    fig.colorbar(cax)\n",
    "    # Set up axes\n",
    "    #ax.set_xticklabels([''] + input_sentence.split(' ') + ['<EOS>'], rotation=90)\n",
    "    #ax.set_xticklabels([''] + input_sentence + ['<EOS>'], rotation=90)\n",
    "    ax.set_yticklabels([''] + output_words)\n",
    "    \n",
    "    input_sentence = input_sentence + ['<EOS>']\n",
    "    inp_arr = [\"{}\\n{}\".format(input_sentence[i], input_sentence[-1-i]) for i in range(len(input_sentence))]\n",
    "    ax.set_xticklabels([''] + inp_arr, rotation=0)\n",
    "\n",
    "    # Show label at every tick\n",
    "    ax.xaxis.set_major_locator(matplotlib.ticker.MultipleLocator(1))\n",
    "    ax.yaxis.set_major_locator(matplotlib.ticker.MultipleLocator(1))\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "def debug_eval_sample_show_attention():\n",
    "    \n",
    "    output, decoded_output, decoder_attns_arr, sample = test_model_single_sample(None, return_more=True)\n",
    "    print('input:  ', sample[0])\n",
    "    print('output: ', ' '.join(decoded_output))\n",
    "    print('target:   ', ''.join([words_after[w] for w in sample[1][:-1]]))\n",
    "\n",
    "    attns = np.array([arr.data[0].cpu().numpy() for arr in decoder_attns_arr])\n",
    "\n",
    "    debug_show_attention(list(sample[0]), decoded_output, attns)\n",
    "    #plt.matshow(attns)\n",
    "\n",
    "debug_eval_sample_show_attention()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:py3_pytorch_2]",
   "language": "python",
   "name": "conda-env-py3_pytorch_2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
