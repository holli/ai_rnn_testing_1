{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pytorch utils oh: pytorch_utils_oh_2.py\n",
      "Pytorch: 0.2.0_4\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import importlib\n",
    "from pytorch_utils_oh_2 import *\n",
    "import IPython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MODEL_SAVE_PATH = 'numbers_gen_9_attention_no_embedding'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pytorch utils oh: pytorch_utils_oh_2.py\n",
      "Pytorch: 0.2.0_4\n"
     ]
    }
   ],
   "source": [
    "import pytorch_utils_oh_2; importlib.reload(pytorch_utils_oh_2); from pytorch_utils_oh_2 import *;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# all_data = pickle.load(open(\"data/en_train_fixed_4_sentences.pkl\", \"rb\" ))\n",
    "all_data = pickle.load(open(\"data/en_train_fixed_5_manual.pkl\", \"rb\" ))\n",
    "# all_data_sentence_index = all_data.set_index('sentence_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data rows: 448170,  (dropped rows: 9470022)\n"
     ]
    }
   ],
   "source": [
    "sample_data = all_data.copy()\n",
    "#sample_data = sample_data[sample_data['class'] != 'NOT_CHANGED']\n",
    "#sample_data = sample_data[sample_data['class'] != 'MANUAL']\n",
    "\n",
    "sample_data =  sample_data[sample_data['class'] == 'NUMBERS']\n",
    "\n",
    "print(\"Data rows: {},  (dropped rows: {})\".format(len(sample_data), len(all_data)-len(sample_data)))\n",
    "sample_data = sample_data.reset_index(drop=True)\n",
    "del(all_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['NUMBERS']\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "categories_all = sorted(sample_data[\"class\"].unique())\n",
    "print(categories_all)\n",
    "print(len(categories_all))\n",
    "categories_index = dict((c, i) for i, c in enumerate(categories_all))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utils stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<SOS><EOS>☒ !\"#$%&'(),-./0123456789:;ABCDEFGHIJKLMNOPQRSTUVWXYZ_abcdefghijklmnopqrstuvwxyz~£¥ª²³µº¼½¾éɒʻˈΩμ—€⅓⅔⅛\n"
     ]
    }
   ],
   "source": [
    "chars_normal, chars_normal_index = load_characters_pkl('data/en_features/chars_normal.pkl')\n",
    "print(''.join(chars_normal))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "common_words, common_words_index = load_common_words_10k()\n",
    "len(common_words)\n",
    "common_words[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wv_vecs, wv_words, wv_idx = load_glove('/home/ohu/koodi/data/glove_wordvec/glove.6B.50d.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### After words handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<EOS>', '<SOS>', '<UNK>', '<0000>', '<SAMPLE>', 'two', 'twenty']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "1351"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_after_common = pickle.load(open(\"data/en_features/words_after_ext.pkl\", 'rb'))\n",
    "words_after_index = dict((c, i) for i, c in enumerate(words_after_common))\n",
    "words_after_common[0:7]\n",
    "len(words_after_common)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 1351])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sos_tensor = torch.zeros(1, 1, len(words_after_index))\n",
    "sos_tensor[0, 0, words_after_index[SOS_TOKEN]] = 1\n",
    "sos_tensor.size()\n",
    "#del(onehot_sos)\n",
    "\n",
    "#sos_tensor = torch.LongTensor([words_after_index[SOS_TOKEN]])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### More balanced sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "balanced_data_classes_select = list(sample_data.groupby('class'))\n",
    "\n",
    "balanced_data_accessed_counter = 0 \n",
    "balanced_data_length = 0\n",
    "def balanced_data_randomize(max_len=20000):\n",
    "    global balanced_data, balanced_data_length, balanced_data_accessed_counter\n",
    "    balanced_data = pd.concat([v.sample(min(max_len, len(v))) for k, v in balanced_data_classes_select])\n",
    "    balanced_data_length = len(balanced_data)\n",
    "    balanced_data_accessed_counter = 0\n",
    "\n",
    "def balanced_data_sample_row():\n",
    "    global balanced_data_accessed_counter\n",
    "    global balanced_data_last_sample\n",
    "    balanced_data_accessed_counter += 1\n",
    "    if balanced_data_accessed_counter/balanced_data_length > 0.2:\n",
    "        balanced_data_randomize()\n",
    "    balanced_data_last_sample = balanced_data.iloc[random.randint(1, balanced_data_length-1)]\n",
    "    return balanced_data_last_sample\n",
    "    \n",
    "balanced_data_randomize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "111 µs ± 1.06 µs per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "balanced_data_sample_row()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "class\n",
       "NUMBERS    20000\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#all_data.groupby('class')['class'].count()\n",
    "#sample_data.groupby('class')['class'].count()\n",
    "balanced_data.groupby('class')['class'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentence_id                                               382243\n",
       "token_id                                                       2\n",
       "class                                                    NUMBERS\n",
       "before                                                  May 2013\n",
       "after                                        may twenty thirteen\n",
       "class_org                                                   DATE\n",
       "a_word_ind                                        [66, 6, 49, 0]\n",
       "sentence       as of <SAMPLE> , georgia glastris is the reign...\n",
       "Name: 228531, dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " balanced_data_sample_row()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NUMBERS : 4 -> four <EOS> [19, 0]\n",
      "he substituted tim smolders at half time in a 2 - <SAMPLE> home defeat against sporting charleroi .\n",
      "torch.Size([1, 2, 104])\n"
     ]
    }
   ],
   "source": [
    "def get_random_sample():\n",
    "    sample_row = balanced_data_sample_row()\n",
    "    sentence_id = sample_row['class']\n",
    "    \n",
    "    return sample_row['before'], sample_row['a_word_ind'], sample_row['class'], sample_row['sentence']\n",
    "            \n",
    "def tmp():\n",
    "    s_bef, s_aft, s_class, s_sentence = get_random_sample()\n",
    "    s_aft_str = ' '.join([words_after_common[i] for i in s_aft])\n",
    "    print(s_class, ':', s_bef, '->', s_aft_str, s_aft)\n",
    "    print(s_sentence)\n",
    "    print(string_to_tensor(s_bef, chars_normal_index).shape)\n",
    "tmp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "159 µs ± 5.49 µs per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "get_random_sample()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "use_cuda = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MAX_ATTENTION_LENGTH = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EncoderRNN (\n",
       "  (rnn_words): LSTM(50, 64, batch_first=True, bidirectional=True)\n",
       "  (rnn_chars): LSTM(104, 128, batch_first=True, bidirectional=True)\n",
       ")"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, words_input_size, chars_input_size, words_hidden_size, chars_hidden_size,\n",
    "                 words_layers=1, chars_layers=1):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        \n",
    "        self.words_layers = words_layers\n",
    "        self.chars_layers = chars_layers\n",
    "        self.words_hidden_size = words_hidden_size\n",
    "        self.chars_hidden_size = chars_hidden_size\n",
    "        self.hidden_size = words_hidden_size + chars_hidden_size\n",
    "\n",
    "        self.rnn_words = nn.LSTM(words_input_size, words_hidden_size // 2, words_layers,\n",
    "                                 batch_first=True, bidirectional=True)\n",
    "\n",
    "        self.rnn_chars = nn.LSTM(chars_input_size, chars_hidden_size // 2, chars_layers,\n",
    "                                batch_first=True, bidirectional=True)\n",
    "        \n",
    "    def forward(self, word_vectors, string_tensor, hidden = None, init_hidden = True):\n",
    "        if init_hidden:\n",
    "            hidden_words, hidden_chars = self.init_hidden()\n",
    "        \n",
    "        all_outputs_words, hidden_words = self.rnn_words(word_vectors, hidden_words)\n",
    "        output_words = all_outputs_words[:, -1]\n",
    "        \n",
    "        all_outputs_chars, hidden_chars = self.rnn_chars(string_tensor, hidden_chars)\n",
    "        output_chars = all_outputs_chars[:, -1]\n",
    "        \n",
    "        hidden_states_cat = Variable(torch.zeros(MAX_ATTENTION_LENGTH, self.hidden_size)).cuda()\n",
    "        for ei in range(min(MAX_ATTENTION_LENGTH, len(string_tensor[0]))):\n",
    "            hidden_states_cat[ei] = torch.cat((output_words, all_outputs_chars[0, ei].view(1,-1)), 1)\n",
    "                \n",
    "        output = torch.cat((output_words[0], output_chars[0]), 0)\n",
    "        #output = torch.cat((output_words, output_chars), 1)\n",
    "        \n",
    "        #return output, all_outputs_chars\n",
    "        return output, hidden_states_cat\n",
    "\n",
    "    def init_hidden(self):\n",
    "        var1_1 = Variable(torch.zeros(2 * self.words_layers, 1, self.words_hidden_size // 2))\n",
    "        var1_2 = Variable(torch.zeros(2 * self.words_layers, 1, self.words_hidden_size // 2))\n",
    "        var2_1 = Variable(torch.zeros(2 * self.chars_layers, 1, self.chars_hidden_size // 2))\n",
    "        var2_2 = Variable(torch.zeros(2 * self.chars_layers, 1, self.chars_hidden_size // 2))\n",
    "        \n",
    "        var1_1 = var1_1.cuda(); var1_2 = var1_2.cuda()\n",
    "        var2_1 = var2_1.cuda(); var2_2 = var2_2.cuda()\n",
    "        return ((var1_1, var1_2), (var2_1, var2_2))\n",
    "    \n",
    "    \n",
    "encoder_rnn = EncoderRNN(words_input_size=wv_vecs.shape[-1], chars_input_size=len(chars_normal),\n",
    "                         words_hidden_size=128, chars_hidden_size=256,\n",
    "                         words_layers=1, chars_layers=1).cuda()\n",
    "encoder_rnn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2019'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([384])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([20, 384])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def test_encoder_single_sample():\n",
    "    s_bef, s_aft, s_class, s_sentence = get_random_sample()\n",
    "    \n",
    "    words_t = Variable(words_to_word_vectors_tensor(list(s_sentence), wv_vecs, wv_idx)).cuda()\n",
    "    \n",
    "    string_t = string_to_tensor(s_bef, chars_normal_index)\n",
    "    string_t = Variable(string_t).cuda()\n",
    "    \n",
    "    return encoder_rnn(words_t, string_t), s_bef\n",
    "    \n",
    "(encoder_output, encoder_outputs), tmp = test_encoder_single_sample()\n",
    "tmp\n",
    "encoder_output.size()\n",
    "encoder_outputs.size()\n",
    "list(encoder_output.data.cpu().numpy()) == list(encoder_outputs[len(tmp)].data.cpu().numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecoderRNN (\n",
       "  (rnn): GRU(384, 384, batch_first=True)\n",
       "  (lin_out): Linear (384 -> 1351)\n",
       "  (emb_lin): Linear (1351 -> 384)\n",
       "  (attn): Linear (768 -> 20)\n",
       "  (attn_combine): Linear (768 -> 384)\n",
       "  (dropout): Dropout (p = 0.1)\n",
       ")"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[torch.Size([1, 1351]), torch.Size([1, 1, 384]), torch.Size([1, 20])]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class DecoderRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, n_layers=1, dropout_p=0.1, max_length=MAX_ATTENTION_LENGTH):\n",
    "        super(DecoderRNN, self).__init__()\n",
    "        self.n_layers = n_layers\n",
    "        self.hidden_size = hidden_size\n",
    "        \n",
    "        \n",
    "        self.rnn = nn.GRU(hidden_size, hidden_size, n_layers,\n",
    "                                 batch_first=True, bidirectional=False)\n",
    "        \n",
    "        self.lin_out = nn.Linear(hidden_size, input_size)\n",
    "\n",
    "        self.emb_lin = nn.Linear(input_size, hidden_size)\n",
    "        #self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        self.max_length = max_length\n",
    "        self.attn = nn.Linear(hidden_size*2, self.max_length)\n",
    "        self.attn_combine = nn.Linear(self.hidden_size * 2, self.hidden_size)\n",
    "        self.dropout = nn.Dropout(dropout_p)\n",
    "        \n",
    "    #def forward(self, char, hidden):\n",
    "    def forward(self, last_input, hidden, encoder_outputs):\n",
    "        #embedded = self.embedding(last_input).view(1, 1, -1)\n",
    "        embedded = self.emb_lin(last_input).view(1, 1, -1)\n",
    "        embedded = self.dropout(embedded)\n",
    "        #IPython.core.debugger.Pdb().set_trace()\n",
    "        #attn_weights = F.softmax(self.attn(torch.cat((char[0], hidden[0]), 1)))\n",
    "        attn_weights = F.softmax(self.attn(torch.cat((embedded[0], hidden[0]), 1)))\n",
    "        attn_applied = torch.bmm(attn_weights.unsqueeze(0), encoder_outputs.unsqueeze(0))\n",
    "        \n",
    "        output = torch.cat((embedded[0], attn_applied[0]), 1)\n",
    "        output = self.attn_combine(output).unsqueeze(0)\n",
    "\n",
    "        \n",
    "        output = F.relu(output)\n",
    "        output, hidden = self.rnn(output, hidden)\n",
    "\n",
    "        output = F.log_softmax(self.lin_out(output[0]))\n",
    "        return output, hidden, attn_weights\n",
    "    \n",
    "    def init_rest_hidden(self, input_var):\n",
    "        if self.n_layers > 1:\n",
    "            hid_var = Variable(torch.zeros(self.n_layers - 1, 1, self.hidden_size)).cuda()\n",
    "            res = torch.cat((input_var, hid_var), 0)\n",
    "            return res\n",
    "        else:\n",
    "            return input_var\n",
    "        \n",
    "\n",
    "decoder_rnn = DecoderRNN(input_size=len(words_after_common), hidden_size=encoder_output.size()[0], n_layers=1)\n",
    "decoder_rnn = decoder_rnn.cuda()\n",
    "decoder_rnn\n",
    "\n",
    "tmp_outputs = Variable(torch.zeros(MAX_ATTENTION_LENGTH, encoder_output.size()[0])).cuda()\n",
    "tmp_hiddens = decoder_rnn.init_rest_hidden(encoder_output.view(1,1,-1))\n",
    "tmp = decoder_rnn(Variable(sos_tensor).cuda(), tmp_hiddens, tmp_outputs)\n",
    "[v.size() for v in tmp]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[torch.Size([1, 1351]), torch.Size([1, 1, 384]), torch.Size([1, 20])]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      " 219\n",
      "[torch.cuda.LongTensor of size 1x1 (GPU 0)]\n",
      "\n",
      "fiftieth\n"
     ]
    }
   ],
   "source": [
    "tmp_outputs = Variable(torch.zeros(MAX_ATTENTION_LENGTH, encoder_output.size()[0])).cuda()\n",
    "tmp_hiddens = decoder_rnn.init_rest_hidden(encoder_output.view(1,1,-1))\n",
    "tmp = decoder_rnn(Variable(sos_tensor).cuda(), tmp_hiddens, tmp_outputs)\n",
    "[v.size() for v in tmp]\n",
    "print(tmp[0].topk(1)[1])\n",
    "print(words_after_common[tmp[0].topk(1)[1].data[0][0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training etc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('sixth idealized idealized synchronize synchronize synchronize synchronize synchronize synchronize synchronize synchronize synchronize synchronize synchronize synchronize synchronize synchronize synchronize synchronize synchronize',\n",
       " 'sixth idealized idealized synchronize synchronize synchronize synchronize synchronize synchronize synchronize synchronize synchronize synchronize synchronize synchronize synchronize synchronize synchronize synchronize synchronize',\n",
       " 'two thousand three',\n",
       " ('2003',\n",
       "  [5, 8, 13, 0],\n",
       "  'NUMBERS',\n",
       "  'gathercole , s . e . , brown , l . , & pickering , s . j . ( <SAMPLE> ) .'))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def test_model_single_sample(model=None, return_more=False):\n",
    "    decoder_rnn.eval()\n",
    "    encoder_rnn.eval()\n",
    "    \n",
    "    s_bef, s_aft, s_class, s_sentence = sample = get_random_sample()\n",
    "        \n",
    "    words_t = Variable(words_to_word_vectors_tensor(list(s_sentence), wv_vecs, wv_idx)).cuda()\n",
    "    \n",
    "    string_t = string_to_tensor(s_bef, chars_normal_index)\n",
    "    string_t = Variable(string_t).cuda()\n",
    "    \n",
    "    encoder_output, encoder_outputs = encoder_rnn(words_t, string_t)\n",
    "    \n",
    "    #encoder_output = encoder_output.view(1,1,-1)\n",
    "    \n",
    "    decoder_hidden = decoder_rnn.init_rest_hidden(encoder_outputs[0].view(1,1,-1))\n",
    "    decoder_input = Variable(sos_tensor).cuda()\n",
    "\n",
    "    decoded_output = []\n",
    "    decoder_attns_arr = []\n",
    "    max_length = 20\n",
    "    for _ in range(max_length):\n",
    "        decoder_output, decoder_hidden, decoder_attns = decoder_rnn(decoder_input, decoder_hidden, encoder_outputs)\n",
    "        decoder_attns_arr.append(decoder_attns)\n",
    "        #return decoder_output\n",
    "\n",
    "        topv, topi = decoder_output.data.topk(1)\n",
    "        word_index = topi[0][0]\n",
    "        word = words_after_common[word_index] # Use own prediction as next input\n",
    "                \n",
    "        if word == EOS_TOKEN:\n",
    "            break\n",
    "\n",
    "        decoded_output.append(word)\n",
    "        \n",
    "        #decoder_intput = torch.LongTensor([word_index])\n",
    "        decoder_input = torch.zeros(1, 1, len(words_after_index))\n",
    "        decoder_input[0, 0, word_index] = 1\n",
    "        decoder_input = Variable(decoder_input).cuda()\n",
    "    \n",
    "    output = ' '.join(decoded_output)\n",
    "    sample_target = ' '.join([words_after_common[w] for w in s_aft][:-1])\n",
    "    \n",
    "    decoder_rnn.train()\n",
    "    encoder_rnn.train()\n",
    "    \n",
    "    if return_more:\n",
    "        return output, decoded_output, decoder_attns_arr, sample\n",
    "    \n",
    "    return output, output, sample_target, sample\n",
    "    \n",
    "tmp = test_model_single_sample(None)\n",
    "tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2009           => idealized idealized idealized synchronize synchronize synchronize synchronize synchronize synchronize synchronize synchronize synchronize synchronize synchronize synchronize synchronize synchronize synchronize synchronize synchronize || [5, 8, 15, 0] \n",
      "                  witte , craeybeckx & meynen <SAMPLE> , p . 306 .\n",
      "1964           => ireland idealized gamergate synchronize synchronize synchronize synchronize synchronize synchronize synchronize synchronize synchronize synchronize synchronize synchronize synchronize synchronize synchronize synchronize synchronize || [7, 39, 19, 0] \n",
      "                  initially equipped with 50 lgm - 30 b minuteman is in early <SAMPLE> , the first 90th smw icbm squadron activated .\n"
     ]
    }
   ],
   "source": [
    "def print_local_wrong_predictions(max_results=10):\n",
    "    arr = get_some_wrong_predictions(None, test_model_single_sample, max_iterations=10000, max_results=max_results)\n",
    "    for sample, predict, output in arr:\n",
    "        s_bef, s_aft, s_class, s_sentence = sample\n",
    "        print(\"{:<14} => {:<14} || {} \\n{:>17} {}\".format(s_bef, predict, s_aft, '', s_sentence, ))\n",
    "print_local_wrong_predictions(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train(s_bef, s_aft, s_sentence, encoder_optimizer, decoder_optimizer, loss_function,\n",
    "          use_teacher_forcing, max_length=20):\n",
    "    \n",
    "    words_t = Variable(words_to_word_vectors_tensor(list(s_sentence), wv_vecs, wv_idx)).cuda()\n",
    "    \n",
    "    string_t = string_to_tensor(s_bef, chars_normal_index)\n",
    "    string_t = Variable(string_t).cuda()\n",
    "    \n",
    "    encoder_output, encoder_outputs = encoder_rnn(words_t, string_t)\n",
    "    \n",
    "    #encoder_output = encoder_output.view(1,1,-1)\n",
    "    \n",
    "    decoder_hidden = decoder_rnn.init_rest_hidden(encoder_outputs[0].view(1,1,-1))\n",
    "    decoder_input = Variable(sos_tensor).cuda()\n",
    "    \n",
    "    ###\n",
    "    target_arr = s_aft\n",
    "    #target_arr = after_sentence_to_word_indexes(s_aft, include_eos=True)\n",
    "    \n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "    loss = 0\n",
    "    \n",
    "    decoded_output = []\n",
    "    for i in range(len(target_arr)):\n",
    "        decoder_output, decoder_hidden, decoder_attns = decoder_rnn(decoder_input, decoder_hidden, encoder_outputs)\n",
    "\n",
    "        #decoder_target_i = chars_after_index[target_arr[i]]\n",
    "        decoder_target_i = target_arr[i]\n",
    "        decoder_target_i = Variable(torch.LongTensor([decoder_target_i])).cuda()\n",
    "        loss += loss_function(decoder_output, decoder_target_i)\n",
    "        \n",
    "        topv, topi = decoder_output.data.topk(1)\n",
    "        word_index = topi[0][0]\n",
    "        word = words_after_common[word_index] # Use own prediction as next input\n",
    "        decoded_output.append(word)\n",
    "        \n",
    "        if use_teacher_forcing:\n",
    "            word_index = target_arr[i] # replace input with right target\n",
    "        else:\n",
    "            # use output normally as input \n",
    "            if word == EOS_TOKEN:\n",
    "                break\n",
    "                \n",
    "        decoder_input = torch.zeros(1, 1, len(words_after_index))\n",
    "        decoder_input[0, 0, word_index] = 1\n",
    "        decoder_input = Variable(decoder_input).cuda()\n",
    "        \n",
    "    if decoded_output[-1] == EOS_TOKEN:\n",
    "        decoded_output = decoded_output[:-1]\n",
    "        \n",
    "    loss.backward()\n",
    "\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "\n",
    "    return ' '.join(decoded_output), (loss.data[0] / len(target_arr))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_iterations(n_iters=100000, lr=0.001, teacher_forcing_ratio=0.5,\n",
    "                     print_every=10000, plot_every=1000):\n",
    "\n",
    "    start = time.time()\n",
    "    \n",
    "    decoder_rnn.train()\n",
    "    encoder_rnn.train()\n",
    "\n",
    "    current_loss = 0\n",
    "    current_loss_iter = 0\n",
    "\n",
    "    encoder_optimizer = torch.optim.Adam(encoder_rnn.parameters(), lr=lr)\n",
    "    decoder_optimizer = torch.optim.Adam(decoder_rnn.parameters(), lr=lr)\n",
    "    loss_function = nn.NLLLoss()\n",
    "    \n",
    "    for iteration in range(1, n_iters + 1):\n",
    "        model_training.iterations += 1\n",
    "        \n",
    "        use_teacher_forcing = random.random() < teacher_forcing_ratio\n",
    "        \n",
    "        s_bef, s_aft, s_class, s_sentence = get_random_sample()\n",
    "        \n",
    "        result, loss = train(s_bef=s_bef, s_aft=s_aft, s_sentence=s_sentence,\n",
    "                             encoder_optimizer=encoder_optimizer, decoder_optimizer=decoder_optimizer,\n",
    "                             loss_function=nn.NLLLoss(), use_teacher_forcing=use_teacher_forcing,\n",
    "                             max_length=40 )\n",
    "        \n",
    "        current_loss += loss\n",
    "        current_loss_iter += 1\n",
    "\n",
    "        # Print iter number, loss, name and guess\n",
    "        if iteration % print_every == 0:\n",
    "            teacher_forcing_str = \"\"\n",
    "            if use_teacher_forcing:\n",
    "                teacher_forcing_str = \"(forcing)\"\n",
    "            s_aft_sentence = ' '.join([words_after_common[w] for w in s_aft][:-1])\n",
    "            correct = '✓' if result == s_aft_sentence else \"✗: {}\".format(s_aft)\n",
    "            \n",
    "            print(\"{:>6d} {:>4.0%} ({:>8}) {:>7.3f}   | {:>6.2f}: {} -> {} ({}) {}\".format(\n",
    "                      model_training.iterations, iteration/n_iters, time_since(start),\n",
    "                      current_loss/current_loss_iter, loss,\n",
    "                      s_bef, result, correct, teacher_forcing_str))\n",
    "\n",
    "        # Add current loss avg to list of losses\n",
    "        if iteration % plot_every == 0:\n",
    "            model_training.losses.append(current_loss / plot_every)\n",
    "            model_training.learning_rates.append(lr)\n",
    "            current_loss = 0\n",
    "            current_loss_iter = 0\n",
    "            \n",
    "        if model_training.iterations % 50000 == 0: # or model_training.iterations == 10:\n",
    "            model_training.save_models()\n",
    "            acc = test_model_accuracy(encoder_rnn, test_model_single_sample)\n",
    "            model_training.accuracy.append(acc)\n",
    "    \n",
    "    # test_model_accuracy(model, n_sample=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Save path: data/models/numbers_gen_9_attention_no_embedding_1\n"
     ]
    }
   ],
   "source": [
    "model_training = ModelTraining(MODEL_SAVE_PATH, [encoder_rnn, decoder_rnn])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     9  18% (   0m 0s)   7.194   |   7.15: 1945 -> gallons gamergate gamergate gamergate (✗: [7, 41, 14, 0]) \n",
      "    18  36% (   0m 0s)   6.958   |   3.08: 12 June 2012 -> nineteen nineteen (✗: [11, 95, 12, 68, 6, 47, 0]) \n",
      "    27  54% (   0m 0s)   7.018   |   7.14: II -> nineteen <EOS> (✗: [11, 73, 0]) (forcing)\n",
      "    36  72% (   0m 0s)   6.729   |   4.76: 20 km -> nineteen (✗: [6, 89, 0]) \n",
      "    45  90% (   0m 1s)   6.237   |   0.51: 3-8053-2263-1 ->  (✗: [13, 58, 16, 25, 14, 13, 58, 5, 5, 20, 13, 58, 9, 0]) \n"
     ]
    }
   ],
   "source": [
    "train_iterations(n_iters=50, print_every=9, lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   550  53% (   0m 9s)   2.997   |   1.60: 1935 -> nineteen (✗: [7, 34, 14, 0]) \n"
     ]
    }
   ],
   "source": [
    "train_iterations(n_iters=(1000-model_training.iterations), print_every=500, lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  2000  11% (  0m 20s)   2.555   |   3.30: 1390 -> nineteen thousand (✗: [49, 23, 0]) \n",
      "  3000  22% (  0m 40s)   2.401   |   0.96: 2 -> two (✓) \n",
      "  4000  33% (   1m 0s)   2.291   |   1.54: 1960 -> nineteen sixty three (✗: [7, 39, 0]) \n",
      "  5000  44% (  1m 21s)   2.153   |   1.28: 3 -> one (✗: [13, 0]) \n",
      "  6000  56% (  1m 42s)   2.056   |   1.70: 29 April 2013 -> the twenty of of <EOS> twenty thousand (✗: [11, 6, 84, 12, 71, 6, 49, 0]) (forcing)\n",
      "  7000  67% (   2m 2s)   1.968   |   0.94: 1997 -> nineteen eighty seven (✗: [7, 23, 18, 0]) (forcing)\n",
      "  8000  78% (  2m 23s)   1.885   |   0.86: 1 -> one (✓) (forcing)\n",
      "  9000  89% (  2m 44s)   1.851   |   1.24: 1986 -> nineteen ninety nine (✗: [7, 27, 20, 0]) \n",
      " 10000 100% (   3m 6s)   1.810   |   1.03: 1977 -> nineteen ninety (✗: [7, 33, 18, 0]) \n"
     ]
    }
   ],
   "source": [
    "train_iterations(n_iters=9000, lr=0.0001, print_every=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 20000  11% (  3m 22s)   0.613   |   1.18: June 2013 -> june twenty twenty (✗: [68, 6, 49, 0]) (forcing)\n",
      " 30000  22% (  6m 48s)   0.389   |   0.01: 1928 -> nineteen twenty eight (✓) (forcing)\n",
      " 40000  33% ( 10m 12s)   0.360   |   0.00: 1976 -> nineteen seventy six (✓) \n",
      " 50000  44% ( 13m 43s)   0.276   |   0.01: 2011 -> twenty eleven (✓) (forcing)\n",
      "Saved model to data/models/numbers_gen_9_attention_no_embedding_1/50000_(EncoderRNN/DecoderRNN)\n",
      "Accuracy: 82.31% (    8231/   10000)\n",
      " 60000  56% ( 18m 25s)   0.352   |   1.80: 4556 -> four five fifty five (✗: [19, 8, 14, 10, 38, 20, 0]) \n",
      " 70000  67% ( 21m 53s)   0.251   |   0.03: 381 -> three hundred eighty one (✓) \n",
      " 80000  78% ( 25m 21s)   0.286   |   0.96: 2,988 m -> two thousand eight hundred eighty eight (✗: [5, 8, 15, 10, 27, 16, 108, 0]) \n",
      " 90000  89% ( 28m 48s)   0.224   |   0.08: 233 -> two hundred thirty three (✓) (forcing)\n",
      "100000 100% ( 32m 17s)   0.288   |   0.02: 1917 -> nineteen seventeen (✓) (forcing)\n",
      "Saved model to data/models/numbers_gen_9_attention_no_embedding_1/100000_(EncoderRNN/DecoderRNN)\n",
      "Accuracy: 81.91% (    8191/   10000)\n"
     ]
    }
   ],
   "source": [
    "train_iterations(n_iters=90000, print_every=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400m           => four hundred   || [19, 10, 108, 0] \n",
      "                  \" knyazyeva minenko misses medal in moscow ; israeli ends triple jump final in sixth position ; gordon , hejnova take superb <SAMPLE> hurdles golds . \"\n",
      "10460          => ten thousand sixty || [9, 25, 19, 20, 25, 0] \n",
      "                  23 hundred southern boulevard , bronx new york <SAMPLE> : wildlife conservation society .\n",
      "21 Mar 2014    => the twenty first of may twenty fourteen || [11, 6, 56, 12, 62, 6, 50, 0] \n",
      "                  retrieved <SAMPLE> .\n",
      "Friday, February 19, 2010 => february february february february february ninth twelfth || [233, 72, 87, 6, 44, 0] \n",
      "                  the washington times — <SAMPLE> retrieved 2015 - 09 - 11 .\n",
      "978-0-14-118304-6 => nine seven eight sil eight sil eight eight eight sil eight sil eight sil eight sil eight sil eight sil || [15, 18, 16, 58, 25, 58, 9, 19, 58, 9, 9, 16, 13, 25, 19, 58, 20, 0] \n",
      "                  isbn <SAMPLE> le livre de l' intranquillité de bernardo soares .\n",
      "October 2007   => october two seventh two || [61, 5, 8, 18, 0] \n",
      "                  tom wood ( <SAMPLE> ) .\n",
      "4,360          => four thousand six hundred || [19, 8, 13, 10, 39, 0] \n",
      "                  it has one asphalt paved runway designated 18 / 36 which measures <SAMPLE> by 75 feet ( 1 , 329 x 23 m ) .\n",
      "6,457          => six thousand six hundred fifty seven || [20, 8, 19, 10, 38, 18, 0] \n",
      "                  there were <SAMPLE> men and 214 officers in the division .\n",
      "80018          => eighty thousand eight || [27, 8, 40, 0] \n",
      "                  lupton , mead , and erie ; or in the denver area zip codes of 80010 , 80011 , 80012 , <SAMPLE> and 80019 .\n",
      "1996-97 AHL    => the tenth of september nineteen sixty six || [9, 15, 15, 20, 58, 15, 18, 58, 656, 0] \n",
      "                  <SAMPLE> standings the internet hockey database .\n"
     ]
    }
   ],
   "source": [
    "print_local_wrong_predictions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "110000  20% (  3m 24s)   0.367   |   0.00: 53 -> fifty three (✓) (forcing)\n",
      "120000  40% (  6m 50s)   0.337   |   0.01: 1656 -> sixteen fifty six (✓) (forcing)\n",
      "130000  60% ( 10m 17s)   0.329   |   0.00: 19 -> nineteen (✓) (forcing)\n",
      "140000  80% ( 13m 47s)   0.359   |   0.00: June 7, 2011 -> june seventh twenty eleven (✓) (forcing)\n",
      "150000 100% ( 17m 14s)   0.361   |   0.02: August 24, 2011 -> august twenty fourth twenty eleven (✓) (forcing)\n",
      "Saved model to data/models/numbers_gen_9_attention_no_embedding_1/150000_(EncoderRNN/DecoderRNN)\n",
      "Accuracy: 80.35% (    8035/   10000)\n"
     ]
    }
   ],
   "source": [
    "train_iterations(n_iters=50000, print_every=10000, teacher_forcing_ratio=0.5, lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160000  20% (  3m 48s)   0.343   |   0.01: 2003 -> two thousand three (✓) \n",
      "170000  40% (  7m 44s)   0.357   |   0.17: 51.6% -> fifty one point six percent (✓) (forcing)\n",
      "180000  60% ( 11m 35s)   0.320   |   0.02: 1987 -> nineteen eighty seven (✓) \n",
      "190000  80% ( 15m 25s)   0.340   |   0.31: 21 September 1950 -> the twenty first of september nineteen fifty five (✗: [11, 6, 56, 12, 64, 7, 38, 0]) \n",
      "200000 100% ( 19m 14s)   0.370   |   0.02: 2010 -> twenty ten (✓) (forcing)\n",
      "Saved model to data/models/numbers_gen_9_attention_no_embedding_1/200000_(EncoderRNN/DecoderRNN)\n",
      "Accuracy: 79.74% (    7974/   10000)\n"
     ]
    }
   ],
   "source": [
    "train_iterations(n_iters=50000, print_every=10000, teacher_forcing_ratio=0.5, lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6pm            => six p          || [20, 24, 32, 0] \n",
      "                  the court adjourned at <SAMPLE> .\n",
      "2011           => twenty eleven  || [5, 8, 48, 0] \n",
      "                  robbie power took over from geraghty as big zeb 's regular jockey for the <SAMPLE> / 2012 national hunt season .\n",
      "260 m          => two hundred sixty six || [5, 10, 39, 108, 0] \n",
      "                  the elevation of the stream at its source is between 840 feet ( <SAMPLE> ) and 860 feet ( 260 m ) .\n",
      "-60,000        => minus hundred sixty || [119, 39, 8, 0] \n",
      "                  the ( red ) mac pro was auctioned for $977 , 000 ( sotheby 's had estimated it would bring $40 , 000 <SAMPLE> ) .\n",
      "$5             => five           || [14, 85, 0] \n",
      "                  it is a margin operation that requires him to pay <SAMPLE> a week for \" tuition \" .\n",
      "29/11/2007     => the twenty ninth of february two thousand seven || [11, 6, 84, 12, 69, 5, 8, 18, 0] \n",
      "                  \" police numbers - <SAMPLE> - qwn \" .\n",
      "December 21, 2008 => december twenty eight thousand eight || [65, 6, 56, 5, 8, 16, 0] \n",
      "                  retrieved <SAMPLE> .\n",
      "28-05-2014     => the twenty eighth of august two || [11, 6, 80, 12, 66, 6, 50, 0] \n",
      "                  28 - 05 - 2014 interview : o . f . t . b keeps it real shockya . com <SAMPLE> retrieved .\n",
      "2003-09-09     => the second of september two thousand three || [11, 84, 12, 64, 5, 8, 13, 0] \n",
      "                  emert , rich ( <SAMPLE> ) .\n",
      "Sep 30, 1978   => september eighth nineteen seventy eight || [64, 103, 7, 33, 16, 0] \n",
      "                  39 ( <SAMPLE> ) : 48 .\n"
     ]
    }
   ],
   "source": [
    "print_local_wrong_predictions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-5f89e33bc75c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_iterations\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_iters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprint_every\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mteacher_forcing_ratio\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.001\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-27-ef1eedc363a0>\u001b[0m in \u001b[0;36mtrain_iterations\u001b[0;34m(n_iters, lr, teacher_forcing_ratio, print_every, plot_every)\u001b[0m\n\u001b[1;32m     24\u001b[0m                              \u001b[0mencoder_optimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoder_optimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder_optimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdecoder_optimizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m                              \u001b[0mloss_function\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNLLLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_teacher_forcing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_teacher_forcing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m                              max_length=40 )\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0mcurrent_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-26-dc73b6a14abe>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(s_bef, s_aft, s_sentence, encoder_optimizer, decoder_optimizer, loss_function, use_teacher_forcing, max_length)\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0mdecoded_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecoded_output\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0mencoder_optimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py3_pytorch_2/lib/python3.6/site-packages/torch/autograd/variable.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, retain_variables)\u001b[0m\n\u001b[1;32m    154\u001b[0m                 \u001b[0mVariable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m         \"\"\"\n\u001b[0;32m--> 156\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py3_pytorch_2/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(variables, grad_variables, retain_graph, create_graph, retain_variables)\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[0;32m---> 98\u001b[0;31m         variables, grad_variables, retain_graph)\n\u001b[0m\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_iterations(n_iters=100000, print_every=10000, teacher_forcing_ratio=0.3, lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print_local_wrong_predictions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_iterations(n_iters=100000, print_every=10000, teacher_forcing_ratio=0.5, lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print_local_wrong_predictions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_iterations(n_iters=100000, print_every=10000, teacher_forcing_ratio=0.1, lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print_local_wrong_predictions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_iterations(n_iters=200000, print_every=10000, teacher_forcing_ratio=0.1, lr=0.0005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print_local_wrong_predictions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_iterations(n_iters=300000, print_every=10000, teacher_forcing_ratio=0.1, lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print_local_wrong_predictions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_iterations(n_iters=200000, print_every=10000, teacher_forcing_ratio=0, lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print_local_wrong_predictions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_iterations(n_iters=200000, print_every=10000, teacher_forcing_ratio=0, lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print_local_wrong_predictions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_iterations(n_iters=500000, print_every=10000, teacher_forcing_ratio=0, lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print_local_wrong_predictions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_iterations(n_iters=500000, print_every=10000, teacher_forcing_ratio=0, lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print_local_wrong_predictions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_iterations(n_iters=500000, print_every=10000, teacher_forcing_ratio=0, lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print_local_wrong_predictions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_iterations(n_iters=500000, print_every=10000, teacher_forcing_ratio=0, lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print_local_wrong_predictions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a | c', 'b | b', 'c | a']"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp = ['a', 'b', 'c']\n",
    "[\"{} | {}\".format(tmp[i], tmp[-1-i]) for i in range(len(tmp))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input:   24\n",
      "output:  ['twenty', 'four']\n",
      "target:    twenty four\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAyYAAAFeCAYAAABw2Qu3AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nbMYZiQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f9257690d68>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def debug_show_attention(input_sentence, output_words, attentions):\n",
    "    # Set up figure with colorbar\n",
    "    fig = plt.figure(figsize=(15,6))\n",
    "    ax = fig.add_subplot(111)\n",
    "    \n",
    "    #cax = ax.matshow(attentions.numpy(), cmap='bone')\n",
    "    cax = ax.matshow(attentions, cmap='bone')\n",
    "    fig.colorbar(cax)\n",
    "    # Set up axes\n",
    "    #ax.set_xticklabels([''] + input_sentence.split(' ') + ['<EOS>'], rotation=90)\n",
    "    input_sentence = input_sentence + ['<EOS>']\n",
    "    inp_arr = [\"{}\\n{}\".format(input_sentence[i], input_sentence[-1-i]) for i in range(len(input_sentence))]\n",
    "    ax.set_xticklabels([''] + inp_arr, rotation=0)\n",
    "    ax.set_yticklabels([''] + output_words)\n",
    "    \n",
    "    # Show label at every tick\n",
    "    ax.xaxis.set_major_locator(matplotlib.ticker.MultipleLocator(1))\n",
    "    ax.yaxis.set_major_locator(matplotlib.ticker.MultipleLocator(1))\n",
    "    \n",
    "    #ax_lab = input_sentence + ['<EOS>']\n",
    "    #ax_lab = [\"{} | {}\".format(ax_lab[i], ax_lab[-1-i]) for i in range(len(ax_lab))]\n",
    "    #ax2.set_xticklabels([''] + ['jaa', 'joo_____'], rotation=0)\n",
    "    #ax2.xaxis.set_major_locator(matplotlib.ticker.MultipleLocator(1))\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "def debug_eval_sample_show_attention():\n",
    "    output, decoded_output, decoder_attns_arr, sample = test_model_single_sample(None, return_more=True)\n",
    "    print('input:  ', sample[0])\n",
    "    print('output: ', decoded_output)\n",
    "    print('target:   ', ' '.join([words_after_common[w] for w in sample[1][:-1]]))\n",
    "\n",
    "    attns = np.array([arr.data[0].cpu().numpy() for arr in decoder_attns_arr])\n",
    "\n",
    "    debug_show_attention(list(sample[0]), decoded_output, attns)\n",
    "    #plt.matshow(attns)\n",
    "    \n",
    "debug_eval_sample_show_attention()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def debug_show_attention(input_sentence, output_words, attentions):\n",
    "    # Set up figure with colorbar\n",
    "    fig = plt.figure(figsize=(15,6))\n",
    "    ax = fig.add_subplot(111)\n",
    "    #cax = ax.matshow(attentions.numpy(), cmap='bone')\n",
    "    cax = ax.matshow(attentions, cmap='bone')\n",
    "    fig.colorbar(cax)\n",
    "    # Set up axes\n",
    "    #ax.set_xticklabels([''] + input_sentence.split(' ') + ['<EOS>'], rotation=90)\n",
    "    ax.set_xticklabels([''] + input_sentence + ['<EOS>'], rotation=90)\n",
    "    ax.set_yticklabels([''] + output_words)\n",
    "\n",
    "    # Show label at every tick\n",
    "    ax.xaxis.set_major_locator(matplotlib.ticker.MultipleLocator(1))\n",
    "    ax.yaxis.set_major_locator(matplotlib.ticker.MultipleLocator(1))\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "def debug_eval_sample_show_attention():\n",
    "    output, decoded_output, decoder_attns_arr, sample = test_model_single_sample(None, return_more=True)\n",
    "    print('input:  ', sample[0])\n",
    "    print('output: ', decoded_output)\n",
    "    print('target:   ', ' '.join([words_after_common[w] for w in sample[1][:-1]]))\n",
    "\n",
    "    attns = np.array([arr.data[0].cpu().numpy() for arr in decoder_attns_arr])\n",
    "\n",
    "    debug_show_attention(list(sample[0]), decoded_output, attns)\n",
    "    #plt.matshow(attns)\n",
    "    \n",
    "debug_eval_sample_show_attention()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:py3_pytorch_2]",
   "language": "python",
   "name": "conda-env-py3_pytorch_2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
