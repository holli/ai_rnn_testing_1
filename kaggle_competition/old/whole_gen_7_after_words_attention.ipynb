{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pytorch utils oh: pytorch_utils_oh_2.py\n",
      "Pytorch: 0.2.0_4\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import importlib\n",
    "from pytorch_utils_oh_2 import *\n",
    "import IPython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MODEL_SAVE_PATH = 'whole_gen_7_after_words_attention'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pytorch utils oh: pytorch_utils_oh_2.py\n",
      "Pytorch: 0.2.0_4\n"
     ]
    }
   ],
   "source": [
    "import pytorch_utils_oh_2; importlib.reload(pytorch_utils_oh_2); from pytorch_utils_oh_2 import *;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_data = pickle.load(open(\"data/en_train_fixed_4_sentences.pkl\", \"rb\" ))\n",
    "all_data_sentence_index = all_data.set_index('sentence_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ELECTRONIC', 'LETTERS', 'NOT_CHANGED', 'NUMBERS', 'PLAIN', 'VERBATIM']\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "categories_all = sorted(all_data[\"class\"].unique())\n",
    "print(categories_all)\n",
    "print(len(categories_all))\n",
    "categories_index = dict((c, i) for i, c in enumerate(categories_all))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utils stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<SOS><EOS>☒ !\"#$%&'(),-./0123456789:;ABCDEFGHIJKLMNOPQRSTUVWXYZ_abcdefghijklmnopqrstuvwxyz~£¥ª²³µº¼½¾éɒʻˈΩμ—€⅓⅔⅛\n"
     ]
    }
   ],
   "source": [
    "chars_normal, chars_normal_index = load_characters_pkl('data/en_features/chars_normal.pkl')\n",
    "print(''.join(chars_normal))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "common_words, common_words_index = load_common_words_10k()\n",
    "len(common_words)\n",
    "common_words[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wv_vecs, wv_words, wv_idx = load_glove('/home/ohu/koodi/data/glove_wordvec/glove.6B.50d.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### After words handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<EOS>', '<SOS>', '<UNK>', '<0000>', '<SAMPLE>', 'two', 'twenty']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "1351"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_after_common = pickle.load(open(\"data/en_features/words_after_ext.pkl\", 'rb'))\n",
    "words_after_index = dict((c, i) for i, c in enumerate(words_after_common))\n",
    "words_after_common[0:7]\n",
    "len(words_after_common)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#onehot_sos = torch.zeros(1, 1, len(words_after_index))\n",
    "#onehot_sos[0, 0, words_after_index[SOS_TOKEN]] = 1\n",
    "#onehot_sos.size()\n",
    "#del(onehot_sos)\n",
    "\n",
    "sos_tensor = torch.LongTensor([words_after_index[SOS_TOKEN]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### More balanced sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data rows: 659544,  (dropped rows: 9258648)\n"
     ]
    }
   ],
   "source": [
    "sample_data = all_data[all_data['class'] != 'NOT_CHANGED']\n",
    "print(\"Data rows: {},  (dropped rows: {})\".format(len(sample_data), len(all_data)-len(sample_data)))\n",
    "sample_data = sample_data.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "balanced_data_classes_select = list(sample_data.groupby('class'))\n",
    "\n",
    "balanced_data_accessed_counter = 0 \n",
    "balanced_data_length = 0\n",
    "def balanced_data_randomize(max_len=20000):\n",
    "    global balanced_data, balanced_data_length, balanced_data_accessed_counter\n",
    "    balanced_data = pd.concat([v.sample(min(max_len, len(v))) for k, v in balanced_data_classes_select])\n",
    "    balanced_data_length = len(balanced_data)\n",
    "    balanced_data_accessed_counter = 0\n",
    "\n",
    "def balanced_data_sample_row():\n",
    "    global balanced_data_accessed_counter\n",
    "    global balanced_data_last_sample\n",
    "    balanced_data_accessed_counter += 1\n",
    "    if balanced_data_accessed_counter/balanced_data_length > 0.2:\n",
    "        balanced_data_randomize()\n",
    "    balanced_data_last_sample = balanced_data.iloc[random.randint(1, balanced_data_length-1)]\n",
    "    return balanced_data_last_sample\n",
    "    \n",
    "balanced_data_randomize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105 µs ± 1.97 µs per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "balanced_data_sample_row()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "class\n",
       "ELECTRONIC     4964\n",
       "LETTERS       20000\n",
       "NUMBERS       20000\n",
       "PLAIN         20000\n",
       "VERBATIM      16950\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#all_data.groupby('class')['class'].count()\n",
    "#sample_data.groupby('class')['class'].count()\n",
    "balanced_data.groupby('class')['class'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentence_id                                               101271\n",
       "token_id                                                       9\n",
       "class                                                      PLAIN\n",
       "before                                                         -\n",
       "after                                                         to\n",
       "class_org                                                  PLAIN\n",
       "a_word_ind                                               [57, 0]\n",
       "sentence       journal of the neurological sciences , 220 ( 1...\n",
       "Name: 88946, dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " balanced_data_sample_row()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NUMBERS : -170 -> minus one hundred seventy <EOS> [119, 9, 10, 33, 0]\n",
      "journal of child psychology and psychiatry , 45 : 135 <SAMPLE> .\n",
      "torch.Size([1, 5, 104])\n"
     ]
    }
   ],
   "source": [
    "def get_random_sample():\n",
    "    sample_row = balanced_data_sample_row()\n",
    "    sentence_id = sample_row['class']\n",
    "    \n",
    "    return sample_row['before'], sample_row['a_word_ind'], sample_row['class'], sample_row['sentence']\n",
    "            \n",
    "def tmp():\n",
    "    s_bef, s_aft, s_class, s_sentence = get_random_sample()\n",
    "    s_aft_str = ' '.join([words_after_common[i] for i in s_aft])\n",
    "    print(s_class, ':', s_bef, '->', s_aft_str, s_aft)\n",
    "    print(s_sentence)\n",
    "    print(string_to_tensor(s_bef, chars_normal_index).shape)\n",
    "tmp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "153 µs ± 6.06 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "get_random_sample()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "use_cuda = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MAX_ATTENTION_LENGTH = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EncoderRNN (\n",
       "  (rnn_words): LSTM(50, 64, batch_first=True, bidirectional=True)\n",
       "  (rnn_chars): LSTM(104, 128, batch_first=True, bidirectional=True)\n",
       ")"
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, words_input_size, chars_input_size, words_hidden_size, chars_hidden_size,\n",
    "                 words_layers=1, chars_layers=1):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        \n",
    "        self.words_layers = words_layers\n",
    "        self.chars_layers = chars_layers\n",
    "        self.words_hidden_size = words_hidden_size\n",
    "        self.chars_hidden_size = chars_hidden_size\n",
    "        self.hidden_size = words_hidden_size + chars_hidden_size\n",
    "\n",
    "        self.rnn_words = nn.LSTM(words_input_size, words_hidden_size // 2, words_layers,\n",
    "                                 batch_first=True, bidirectional=True)\n",
    "\n",
    "        self.rnn_chars = nn.LSTM(chars_input_size, chars_hidden_size // 2, chars_layers,\n",
    "                                batch_first=True, bidirectional=True)\n",
    "        \n",
    "    def forward(self, word_vectors, string_tensor, hidden = None, init_hidden = True):\n",
    "        if init_hidden:\n",
    "            hidden_words, hidden_chars = self.init_hidden()\n",
    "        \n",
    "        all_outputs_words, hidden_words = self.rnn_words(word_vectors, hidden_words)\n",
    "        output_words = all_outputs_words[:, -1]\n",
    "        \n",
    "        all_outputs_chars, hidden_chars = self.rnn_chars(string_tensor, hidden_chars)\n",
    "        output_chars = all_outputs_chars[:, -1]\n",
    "        \n",
    "        hidden_states_cat = Variable(torch.zeros(MAX_ATTENTION_LENGTH, self.hidden_size)).cuda()\n",
    "        for ei in range(min(MAX_ATTENTION_LENGTH, len(string_tensor))):\n",
    "            hidden_states_cat[ei] = torch.cat((output_words, all_outputs_chars[:,ei]), 1)\n",
    "                \n",
    "        #output = torch.cat((output_words, output_chars), 1)\n",
    "        #output = torch.cat((output_words, output_chars), 1)\n",
    "        \n",
    "        #return output, all_outputs_chars\n",
    "        return hidden_states_cat[-1], hidden_states_cat\n",
    "\n",
    "    def init_hidden(self):\n",
    "        var1_1 = Variable(torch.zeros(2 * self.words_layers, 1, self.words_hidden_size // 2))\n",
    "        var1_2 = Variable(torch.zeros(2 * self.words_layers, 1, self.words_hidden_size // 2))\n",
    "        var2_1 = Variable(torch.zeros(2 * self.chars_layers, 1, self.chars_hidden_size // 2))\n",
    "        var2_2 = Variable(torch.zeros(2 * self.chars_layers, 1, self.chars_hidden_size // 2))\n",
    "        \n",
    "        var1_1 = var1_1.cuda(); var1_2 = var1_2.cuda()\n",
    "        var2_1 = var2_1.cuda(); var2_2 = var2_2.cuda()\n",
    "        return ((var1_1, var1_2), (var2_1, var2_2))\n",
    "    \n",
    "    \n",
    "encoder_rnn = EncoderRNN(words_input_size=wv_vecs.shape[-1], chars_input_size=len(chars_normal),\n",
    "                         words_hidden_size=128, chars_hidden_size=256,\n",
    "                         words_layers=1, chars_layers=1).cuda()\n",
    "encoder_rnn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Narr\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([384])"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([50, 384])"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def test_encoder_single_sample():\n",
    "    s_bef, s_aft, s_class, s_sentence = get_random_sample()\n",
    "    print(s_bef)\n",
    "    \n",
    "    words_t = Variable(words_to_word_vectors_tensor(list(s_sentence), wv_vecs, wv_idx)).cuda()\n",
    "    \n",
    "    string_t = string_to_tensor(s_bef, chars_normal_index)\n",
    "    string_t = Variable(string_t).cuda()\n",
    "    \n",
    "    return encoder_rnn(words_t, string_t)\n",
    "    \n",
    "encoder_output, encoder_outputs = test_encoder_single_sample()\n",
    "encoder_output.size()\n",
    "encoder_outputs.size()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecoderRNN (\n",
       "  (rnn): GRU(384, 384, batch_first=True)\n",
       "  (lin_out): Linear (384 -> 1351)\n",
       "  (embedding): Embedding(1351, 384)\n",
       "  (attn): Linear (768 -> 100)\n",
       "  (attn_combine): Linear (768 -> 384)\n",
       "  (dropout): Dropout (p = 0.1)\n",
       ")"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[torch.Size([1, 1351]), torch.Size([1, 1, 384]), torch.Size([1, 100])]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class DecoderRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, n_layers=1, dropout_p=0.1, max_length=MAX_ATTENTION_LENGTH):\n",
    "        super(DecoderRNN, self).__init__()\n",
    "        self.n_layers = n_layers\n",
    "        self.hidden_size = hidden_size\n",
    "        \n",
    "        #self.rnn = nn.GRU(input_size, hidden_size, n_layers,\n",
    "        self.rnn = nn.GRU(hidden_size, hidden_size, n_layers,\n",
    "                                 batch_first=True, bidirectional=False)\n",
    "        \n",
    "        self.lin_out = nn.Linear(hidden_size, input_size)\n",
    "        #self.softmax = nn.LogSoftmax()\n",
    "        \n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        self.max_length = max_length\n",
    "        self.attn = nn.Linear(hidden_size*2, self.max_length)\n",
    "        self.attn_combine = nn.Linear(self.hidden_size * 2, self.hidden_size)\n",
    "        self.dropout = nn.Dropout(dropout_p)\n",
    "        \n",
    "    #def forward(self, char, hidden):\n",
    "    def forward(self, last_input, hidden, encoder_outputs):\n",
    "        embedded = self.embedding(last_input).view(1, 1, -1)\n",
    "        embedded = self.dropout(embedded)\n",
    "        #IPython.core.debugger.Pdb().set_trace()\n",
    "        #attn_weights = F.softmax(self.attn(torch.cat((char[0], hidden[0]), 1)))\n",
    "        attn_weights = F.softmax(self.attn(torch.cat((embedded[0], hidden[0]), 1)))\n",
    "        attn_applied = torch.bmm(attn_weights.unsqueeze(0), encoder_outputs.unsqueeze(0))\n",
    "        \n",
    "        output = torch.cat((embedded[0], attn_applied[0]), 1)\n",
    "        output = self.attn_combine(output).unsqueeze(0)\n",
    "\n",
    "        \n",
    "        output = F.relu(output)\n",
    "        output, hidden = self.rnn(output, hidden)\n",
    "\n",
    "        output = F.log_softmax(self.lin_out(output[0]))\n",
    "        return output, hidden, attn_weights\n",
    "    \n",
    "    def init_rest_hidden(self, input_var):\n",
    "        if self.n_layers > 1:\n",
    "            hid_var = Variable(torch.zeros(self.n_layers - 1, 1, self.hidden_size)).cuda()\n",
    "            res = torch.cat((input_var, hid_var), 0)\n",
    "            return res\n",
    "        else:\n",
    "            return input_var\n",
    "        \n",
    "\n",
    "decoder_rnn = DecoderRNN(input_size=len(words_after_common), hidden_size=encoder_output.size()[0], n_layers=1)\n",
    "decoder_rnn = decoder_rnn.cuda()\n",
    "decoder_rnn\n",
    "\n",
    "tmp_outputs = Variable(torch.zeros(MAX_ATTENTION_LENGTH, encoder_output.size()[0])).cuda()\n",
    "tmp_hiddens = decoder_rnn.init_rest_hidden(encoder_output.view(1,1,-1))\n",
    "tmp = decoder_rnn(Variable(sos_tensor).cuda(), tmp_hiddens, tmp_outputs)\n",
    "[v.size() for v in tmp]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "(0 ,.,.) = \n",
       "  0  1  2\n",
       "  3  4  5\n",
       "  6  7  8\n",
       "[torch.FloatTensor of size 1x3x3]"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.arange(0, 9).view(1,3,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "(0 ,.,.) = \n",
       "  15  19  23\n",
       "[torch.FloatTensor of size 1x1x3]"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.bmm(torch.FloatTensor([1,1,2]).view(1,1,-1), torch.arange(0, 9).view(1,3,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[torch.Size([1, 1351]), torch.Size([1, 1, 384]), torch.Size([1, 100])]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      " 1145\n",
      "[torch.cuda.LongTensor of size 1x1 (GPU 0)]\n",
      "\n",
      "cape\n"
     ]
    }
   ],
   "source": [
    "tmp_outputs = Variable(torch.zeros(MAX_ATTENTION_LENGTH, encoder_output.size()[0])).cuda()\n",
    "tmp_hiddens = decoder_rnn.init_rest_hidden(encoder_output.view(1,1,-1))\n",
    "tmp = decoder_rnn(Variable(sos_tensor).cuda(), tmp_hiddens, tmp_outputs)\n",
    "[v.size() for v in tmp]\n",
    "print(tmp[0].topk(1)[1])\n",
    "print(words_after_common[tmp[0].topk(1)[1].data[0][0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training etc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('nineteen eighty',\n",
       " 'nineteen eighty',\n",
       " 'nineteen eighty',\n",
       " ('1980',\n",
       "  [7, 27, 0],\n",
       "  'NUMBERS',\n",
       "  'in <SAMPLE> , body changes made the wagon more aerodynamic for better fuel efficiency .'))"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def test_model_single_sample(model=None, return_more=False):\n",
    "    decoder_rnn.eval()\n",
    "    encoder_rnn.eval()\n",
    "    \n",
    "    s_bef, s_aft, s_class, s_sentence = sample = get_random_sample()\n",
    "        \n",
    "    words_t = Variable(words_to_word_vectors_tensor(list(s_sentence), wv_vecs, wv_idx)).cuda()\n",
    "    \n",
    "    string_t = string_to_tensor(s_bef, chars_normal_index)\n",
    "    string_t = Variable(string_t).cuda()\n",
    "    \n",
    "    encoder_output, encoder_outputs = encoder_rnn(words_t, string_t)\n",
    "    \n",
    "    #encoder_output = encoder_output.view(1,1,-1)\n",
    "    \n",
    "    decoder_hidden = decoder_rnn.init_rest_hidden(encoder_outputs[0].view(1,1,-1))\n",
    "    decoder_input = Variable(sos_tensor).cuda()\n",
    "\n",
    "    decoded_output = []\n",
    "    decoder_attns_arr = []\n",
    "    max_length = 20\n",
    "    for _ in range(max_length):\n",
    "        decoder_output, decoder_hidden, decoder_attns = decoder_rnn(decoder_input, decoder_hidden, encoder_outputs)\n",
    "        decoder_attns_arr.append(decoder_attns)\n",
    "        #return decoder_output\n",
    "\n",
    "        topv, topi = decoder_output.data.topk(1)\n",
    "        word_index = topi[0][0]\n",
    "        word = words_after_common[word_index] # Use own prediction as next input\n",
    "                \n",
    "        if word == EOS_TOKEN:\n",
    "            break\n",
    "\n",
    "        decoded_output.append(word)\n",
    "        \n",
    "        decoder_intput = torch.LongTensor([word_index])\n",
    "        #decoder_input = torch.zeros(1, 1, len(words_after_index))\n",
    "        #decoder_input[0, 0, word_index] = 1\n",
    "        #decoder_input = Variable(decoder_input).cuda()\n",
    "    \n",
    "    output = ' '.join(decoded_output)\n",
    "    sample_target = ' '.join([words_after_common[w] for w in s_aft][:-1])\n",
    "    \n",
    "    decoder_rnn.train()\n",
    "    encoder_rnn.train()\n",
    "    \n",
    "    if return_more:\n",
    "        return output, decoded_output, decoder_attns_arr, sample\n",
    "    \n",
    "    return output, output, sample_target, sample\n",
    "    \n",
    "tmp = test_model_single_sample(None)\n",
    "tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'nineteen ninety nine'"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp = test_model_single_sample(None, return_more=True)\n",
    "tmp[0]\n",
    "len(tmp[2])\n",
    "tmp[3][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1999'"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Variable containing:\n",
       "  1.0000e+00  1.6132e-07  4.4260e-10  1.3326e-10\n",
       " [torch.cuda.FloatTensor of size 1x4 (GPU 0)], Variable containing:\n",
       "   7  31  91   0\n",
       " [torch.cuda.LongTensor of size 1x4 (GPU 0)])"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp[2][3].topk(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('&', [55, 0], 'VERBATIM', 'the barnes <SAMPLE> noble review .')"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "κ              => alpha          || [167, 0] \n",
      "                  limnakaro ( greek : λ ι μ ν α <SAMPLE> α ρ ο ) is a small ( approx .\n",
      "EUCC           => e u u c        || [28, 43, 21, 21, 0] \n",
      "                  eucc counts with a regional office for the mediterranean sea , the <SAMPLE> mediterranean centre in barcelona , spain .\n"
     ]
    }
   ],
   "source": [
    "def print_local_wrong_predictions(max_results=10):\n",
    "    arr = get_some_wrong_predictions(None, test_model_single_sample, max_iterations=10000, max_results=max_results)\n",
    "    for sample, predict, output in arr:\n",
    "        s_bef, s_aft, s_class, s_sentence = sample\n",
    "        print(\"{:<14} => {:<14} || {} \\n{:>17} {}\".format(s_bef, predict, s_aft, '', s_sentence, ))\n",
    "print_local_wrong_predictions(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.00% (       0/    1000)\n",
      "CPU times: user 22 s, sys: 152 ms, total: 22.2 s\n",
      "Wall time: 22.2 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "test_model_accuracy(encoder_rnn, test_model_single_sample, n_sample=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train(s_bef, s_aft, s_sentence, encoder_optimizer, decoder_optimizer, loss_function,\n",
    "          use_teacher_forcing, max_length=20):\n",
    "    \n",
    "    words_t = Variable(words_to_word_vectors_tensor(list(s_sentence), wv_vecs, wv_idx)).cuda()\n",
    "    \n",
    "    string_t = string_to_tensor(s_bef, chars_normal_index)\n",
    "    string_t = Variable(string_t).cuda()\n",
    "    \n",
    "    encoder_output, encoder_outputs = encoder_rnn(words_t, string_t)\n",
    "    \n",
    "    #encoder_output = encoder_output.view(1,1,-1)\n",
    "    \n",
    "    decoder_hidden = decoder_rnn.init_rest_hidden(encoder_outputs[0].view(1,1,-1))\n",
    "    decoder_input = Variable(sos_tensor).cuda()\n",
    "    \n",
    "    ###\n",
    "    target_arr = s_aft\n",
    "    #target_arr = after_sentence_to_word_indexes(s_aft, include_eos=True)\n",
    "    \n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "    loss = 0\n",
    "    \n",
    "    decoded_output = []\n",
    "    for i in range(len(target_arr)):\n",
    "        decoder_output, decoder_hidden, decoder_attns = decoder_rnn(decoder_input, decoder_hidden, encoder_outputs)\n",
    "\n",
    "        #decoder_target_i = chars_after_index[target_arr[i]]\n",
    "        decoder_target_i = target_arr[i]\n",
    "        decoder_target_i = Variable(torch.LongTensor([decoder_target_i])).cuda()\n",
    "        loss += loss_function(decoder_output, decoder_target_i)\n",
    "        \n",
    "        topv, topi = decoder_output.data.topk(1)\n",
    "        word_index = topi[0][0]\n",
    "        word = words_after_common[word_index] # Use own prediction as next input\n",
    "        decoded_output.append(word)\n",
    "        \n",
    "        if use_teacher_forcing:\n",
    "            word_index = target_arr[i] # replace input with right target\n",
    "        else:\n",
    "            # use output normally as input \n",
    "            if word == EOS_TOKEN:\n",
    "                break\n",
    "                \n",
    "        decoder_intput = torch.LongTensor([word_index])\n",
    "        \n",
    "    if decoded_output[-1] == EOS_TOKEN:\n",
    "        decoded_output = decoded_output[:-1]\n",
    "        \n",
    "    loss.backward()\n",
    "\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "\n",
    "    return ' '.join(decoded_output), (loss.data[0] / len(target_arr))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_iterations(n_iters=100000, lr=0.001, teacher_forcing_ratio=0.5,\n",
    "                     print_every=10000, plot_every=1000):\n",
    "\n",
    "    start = time.time()\n",
    "    \n",
    "    decoder_rnn.train()\n",
    "    encoder_rnn.train()\n",
    "\n",
    "    current_loss = 0\n",
    "    current_loss_iter = 0\n",
    "\n",
    "    encoder_optimizer = torch.optim.Adam(encoder_rnn.parameters(), lr=lr)\n",
    "    decoder_optimizer = torch.optim.Adam(decoder_rnn.parameters(), lr=lr)\n",
    "    loss_function = nn.NLLLoss()\n",
    "    \n",
    "    for iteration in range(1, n_iters + 1):\n",
    "        model_training.iterations += 1\n",
    "        \n",
    "        use_teacher_forcing = random.random() < teacher_forcing_ratio\n",
    "        \n",
    "        s_bef, s_aft, s_class, s_sentence = get_random_sample()\n",
    "        \n",
    "        result, loss = train(s_bef=s_bef, s_aft=s_aft, s_sentence=s_sentence,\n",
    "                             encoder_optimizer=encoder_optimizer, decoder_optimizer=decoder_optimizer,\n",
    "                             loss_function=nn.NLLLoss(), use_teacher_forcing=use_teacher_forcing,\n",
    "                             max_length=40 )\n",
    "        \n",
    "        current_loss += loss\n",
    "        current_loss_iter += 1\n",
    "\n",
    "        # Print iter number, loss, name and guess\n",
    "        if iteration % print_every == 0:\n",
    "            teacher_forcing_str = \"\"\n",
    "            if use_teacher_forcing:\n",
    "                teacher_forcing_str = \"(forcing)\"\n",
    "            s_aft_sentence = ' '.join([words_after_common[w] for w in s_aft][:-1])\n",
    "            correct = '✓' if result == s_aft_sentence else \"✗: {}\".format(s_aft)\n",
    "            \n",
    "            print(\"{:>6d} {:>4.0%} ({:>8}) {:>7.3f}   | {:>6.2f}: {} -> {} ({}) {}\".format(\n",
    "                      model_training.iterations, iteration/n_iters, time_since(start),\n",
    "                      current_loss/current_loss_iter, loss,\n",
    "                      s_bef, result, correct, teacher_forcing_str))\n",
    "\n",
    "        # Add current loss avg to list of losses\n",
    "        if iteration % plot_every == 0:\n",
    "            model_training.losses.append(current_loss / plot_every)\n",
    "            model_training.learning_rates.append(lr)\n",
    "            current_loss = 0\n",
    "            current_loss_iter = 0\n",
    "            \n",
    "        if model_training.iterations % 50000 == 0 or model_training.iterations == 10:\n",
    "            model_training.save_models()\n",
    "            acc = test_model_accuracy(encoder_rnn, test_model_single_sample)\n",
    "            model_training.accuracy.append(acc)\n",
    "    \n",
    "    # test_model_accuracy(model, n_sample=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Save path: data/models/whole_gen_7_after_words_attention\n"
     ]
    }
   ],
   "source": [
    "model_training = ModelTraining(MODEL_SAVE_PATH, [encoder_rnn, decoder_rnn])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     9  18% (   0m 0s)   5.723   |   3.57: - ->  (✗: [57, 0]) \n",
      "Saved model to data/models/whole_gen_7_after_words_attention/10_(EncoderRNN/DecoderRNN)\n",
      "Accuracy: 0.00% (       0/   10000)\n",
      "    18  36% (  0m 45s)   5.576   |   6.46: dr -> <EOS> (✗: [113, 0]) (forcing)\n",
      "    27  54% (  0m 45s)   5.280   |   5.89: - -> <EOS> (✗: [57, 0]) (forcing)\n",
      "    36  72% (  0m 45s)   4.936   |   5.17: - -> <EOS> (✗: [57, 0]) (forcing)\n",
      "    45  90% (  0m 45s)   4.442   |   5.33: gt -> <EOS> <EOS> (✗: [53, 30, 0]) (forcing)\n"
     ]
    }
   ],
   "source": [
    "train_iterations(n_iters=50, print_every=9, lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   550  53% (   0m 7s)   2.954   |   2.61: # -> <EOS> (✗: [109, 0]) (forcing)\n"
     ]
    }
   ],
   "source": [
    "train_iterations(n_iters=(1000-model_training.iterations), print_every=500, lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  2000  11% (  0m 16s)   2.818   |   2.03: st -> and (✗: [102, 0]) \n",
      "  3000  22% (  0m 32s)   2.558   |   2.13: dr -> to (✗: [113, 0]) (forcing)\n",
      "  4000  33% (  0m 49s)   2.355   |   4.13: # -> to (✗: [175, 0]) (forcing)\n",
      "  5000  44% (   1m 4s)   2.286   |   2.11: ltd -> versus (✗: [118, 0]) \n",
      "  6000  56% (  1m 21s)   2.314   |   1.45: st -> to (✗: [102, 0]) \n",
      "  7000  67% (  1m 37s)   2.223   |   3.05: ATP -> p <EOS> <EOS> (✗: [22, 30, 24, 0]) (forcing)\n",
      "  8000  78% (  1m 54s)   2.093   |   4.11: 14 May 1943 -> the <EOS> of <EOS> <EOS> <EOS> <EOS> (✗: [11, 96, 12, 66, 7, 41, 13, 0]) (forcing)\n",
      "  9000  89% (  2m 10s)   2.151   |   0.02: & -> and (✗: [55, 0]) (forcing)\n",
      " 10000 100% (  2m 28s)   2.004   |   3.35: 1767 -> nineteen hundred <EOS> (✗: [81, 39, 18, 0]) (forcing)\n"
     ]
    }
   ],
   "source": [
    "train_iterations(n_iters=9000, lr=0.0001, print_every=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 20000  11% (   3m 4s)   1.089   |   0.00: & -> and (✗: [55, 0]) (forcing)\n",
      " 30000  22% (  6m 16s)   0.857   |   0.49: colours -> colors (✗: [197, 0]) (forcing)\n",
      " 40000  33% (  9m 38s)   0.627   |   0.66: adrsta -> a (✗: [22, 26, 35, 17, 30, 22, 0]) \n",
      " 50000  44% (  13m 4s)   0.680   |   0.00: & -> and (✗: [55, 0]) (forcing)\n",
      "Saved model to data/models/whole_gen_7_after_words_attention/50000_(EncoderRNN/DecoderRNN)\n",
      "Accuracy: 0.00% (       0/   10000)\n",
      " 60000  56% ( 17m 38s)   0.632   |   1.02: 28 May 2015 -> the twenty of of july fifteen fifteen (✗: [11, 6, 80, 12, 66, 6, 51, 0]) (forcing)\n",
      " 70000  67% ( 20m 56s)   0.554   |   0.00: dr -> doctor (✗: [113, 0]) \n",
      " 80000  78% ( 24m 14s)   0.569   |   3.76: ξ -> iota (✗: [367, 0]) (forcing)\n",
      " 90000  89% ( 27m 31s)   0.561   |   0.00: metres -> meters (✗: [108, 0]) (forcing)\n",
      "100000 100% ( 30m 59s)   0.507   |   0.00: : -> to (✗: [57, 0]) (forcing)\n",
      "Saved model to data/models/whole_gen_7_after_words_attention/100000_(EncoderRNN/DecoderRNN)\n",
      "Accuracy: 0.00% (       0/   10000)\n"
     ]
    }
   ],
   "source": [
    "train_iterations(n_iters=90000, print_every=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100145  17% (   0m 0s)   0.963   |   0.00: & -> and (✓) (forcing)\n",
      "100150  33% (   0m 0s)   0.600   |   0.00: & -> and (✓) (forcing)\n",
      "100155  50% (   0m 0s)   0.542   |   0.00: & -> and (✓) (forcing)\n",
      "100160  67% (   0m 0s)   0.621   |   0.02: MV -> m v (✓) (forcing)\n",
      "100165  83% (   0m 0s)   0.530   |   0.00: & -> and (✓) (forcing)\n",
      "100170 100% (   0m 0s)   0.523   |   0.01: 1886 -> eighteen eighty six (✓) \n"
     ]
    }
   ],
   "source": [
    "train_iterations(n_iters=30, print_every=5, teacher_forcing_ratio=0.5, lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "110170   3% (  3m 14s)   0.484   |   0.00: jr -> junior (✓) \n",
      "120170   7% (  6m 30s)   0.488   |   0.03: 1960 -> nineteen sixty (✓) (forcing)\n",
      "130170  10% (  9m 36s)   0.468   |   0.00: & -> and (✓) \n",
      "140170  13% ( 12m 50s)   0.505   |   0.10: IOR -> i o r (✓) (forcing)\n",
      "Saved model to data/models/whole_gen_7_after_words_attention/150000_(EncoderRNN/DecoderRNN)\n",
      "Accuracy: 76.46% (    7646/   10000)\n",
      "150170  17% ( 17m 19s)   0.457   |   0.33: J. A. M. -> j a m (✓) (forcing)\n",
      "160170  20% ( 20m 50s)   0.422   |   0.00: - -> to (✓) \n",
      "170170  23% ( 24m 12s)   0.437   |   0.00: behaviour -> behavior (✓) \n",
      "180170  27% ( 27m 23s)   0.432   |   0.00: & -> and (✓) (forcing)\n",
      "190170  30% ( 30m 50s)   0.424   |   0.00: - -> to (✓) (forcing)\n",
      "Saved model to data/models/whole_gen_7_after_words_attention/200000_(EncoderRNN/DecoderRNN)\n",
      "Accuracy: 79.93% (    7993/   10000)\n",
      "200170  33% (  35m 5s)   0.457   |   0.00: & -> and (✓) (forcing)\n",
      "210170  37% ( 38m 29s)   0.435   |   0.00: Ph -> p h (✓) \n",
      "220170  40% ( 41m 57s)   0.338   |   0.01: 1971 -> nineteen seventy one (✓) (forcing)\n",
      "230170  43% ( 45m 11s)   0.358   |   0.00: UK -> u k (✓) \n",
      "240170  47% ( 48m 22s)   0.370   |   0.00: 26 August 2014 -> the twenty sixth of august twenty fourteen (✓) (forcing)\n",
      "Saved model to data/models/whole_gen_7_after_words_attention/250000_(EncoderRNN/DecoderRNN)\n",
      "Accuracy: 80.58% (    8058/   10000)\n",
      "250170  50% ( 52m 34s)   0.373   |   0.00: & -> and (✓) (forcing)\n",
      "260170  53% ( 55m 46s)   0.322   |   0.00: G.W. -> g w (✓) (forcing)\n",
      "270170  57% ( 58m 49s)   0.361   |   0.01: MRR -> m r r (✓) (forcing)\n",
      "280170  60% (  62m 3s)   0.296   |   0.00: & -> and (✓) (forcing)\n",
      "290170  63% (  65m 7s)   0.340   |   0.00: # -> number (✓) (forcing)\n",
      "Saved model to data/models/whole_gen_7_after_words_attention/300000_(EncoderRNN/DecoderRNN)\n",
      "Accuracy: 82.11% (    8211/   10000)\n",
      "300170  67% ( 69m 30s)   0.424   |   0.00: # -> number (✓) (forcing)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-62-dec7d4e222e9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_iterations\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_iters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m300000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprint_every\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mteacher_forcing_ratio\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.001\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-60-fc5438e8eb84>\u001b[0m in \u001b[0;36mtrain_iterations\u001b[0;34m(n_iters, lr, teacher_forcing_ratio, print_every, plot_every)\u001b[0m\n\u001b[1;32m     24\u001b[0m                              \u001b[0mencoder_optimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoder_optimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder_optimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdecoder_optimizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m                              \u001b[0mloss_function\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNLLLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_teacher_forcing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_teacher_forcing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m                              max_length=40 )\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0mcurrent_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-29-8fe5bd18af36>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(s_bef, s_aft, s_sentence, encoder_optimizer, decoder_optimizer, loss_function, use_teacher_forcing, max_length)\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0mdecoded_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecoded_output\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mencoder_optimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py3_pytorch_2/lib/python3.6/site-packages/torch/autograd/variable.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, retain_variables)\u001b[0m\n\u001b[1;32m    154\u001b[0m                 \u001b[0mVariable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m         \"\"\"\n\u001b[0;32m--> 156\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py3_pytorch_2/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(variables, grad_variables, retain_graph, create_graph, retain_variables)\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[0;32m---> 98\u001b[0;31m         variables, grad_variables, retain_graph)\n\u001b[0m\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_iterations(n_iters=300000, print_every=10000, teacher_forcing_ratio=0.5, lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print_local_wrong_predictions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_iterations(n_iters=300000, print_every=10000, teacher_forcing_ratio=0.3, lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print_local_wrong_predictions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_iterations(n_iters=100000, print_every=10000, teacher_forcing_ratio=0.5, lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print_local_wrong_predictions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_iterations(n_iters=100000, print_every=10000, teacher_forcing_ratio=0.1, lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print_local_wrong_predictions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_iterations(n_iters=200000, print_every=10000, teacher_forcing_ratio=0.1, lr=0.0005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print_local_wrong_predictions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_iterations(n_iters=300000, print_every=10000, teacher_forcing_ratio=0.1, lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print_local_wrong_predictions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_iterations(n_iters=200000, print_every=10000, teacher_forcing_ratio=0, lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print_local_wrong_predictions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_iterations(n_iters=200000, print_every=10000, teacher_forcing_ratio=0, lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print_local_wrong_predictions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_iterations(n_iters=500000, print_every=10000, teacher_forcing_ratio=0, lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print_local_wrong_predictions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_iterations(n_iters=500000, print_every=10000, teacher_forcing_ratio=0, lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print_local_wrong_predictions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_iterations(n_iters=500000, print_every=10000, teacher_forcing_ratio=0, lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print_local_wrong_predictions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_iterations(n_iters=500000, print_every=10000, teacher_forcing_ratio=0, lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print_local_wrong_predictions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.ticker as ticker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input:   ['april', 'thirtieth', 'twenty', 'fifteen']\n",
      "output:  ['april', 'thirtieth', 'twenty', 'fifteen']\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAADxCAYAAADIvgx4AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAFntJREFUeJzt3XmUXFWdwPHvL4EYBTRCB8EkCGrUiQqCEZxxAUfA4Ki4\n4GFxRR1ExGVcRlBnhkHnuDIuAxIiosNxQUZR0YOCOm5DFNPIokHQGLbgAkEEgRkkqd/8cV9j0Xa6\nq5PXXa/rfT8573TVe69e3erk/Ormd+/73chMJEmDb1a/GyBJmh4GfElqCQO+JLWEAV+SWsKAL0kt\nYcCXpJYw4EtSSxjwJaklDPiS1BJb9bsBkjQIli1bluvXr+/p3Isvvvj8zFw2xU36CwZ8SarB+vXr\nGR4e7unciBia4uaMyYAvSTVpem0yA74k1SCBjZ1Ov5sxLgO+JNUiSezhS9LgS+g0O94b8CWpLubw\nJakFEugY8CWpHezhS1ILZKazdCSpLezhS1JLOC1TklqgDNr2uxXjM+BLUk1M6UhSGzhoK0ntkNjD\nl6TW8MYrSWoJe/iS1ApWy5SkVkirZUpSe3ScpSNJg89qmZLUIg7aSlIbZNrDl6S2sIcvSS2QwEYD\nviS1gz18SWoJA74ktUA6aCtJ7WEPX5JawoAvSS1QZulYWkGSWsHiaZLUBpmmdCSpDVziUJJaxGmZ\nktQS9vAlqQUyk40ugCJJ7eCatpLUEk2fljmr3w2QpEEwMkunl60XEbEsIq6KiDURcdwYxx8QEV+N\niMsiYnVEHDnRNQ34klSTugJ+RMwGTgEOApYAh0fEklGnvRa4IjP3APYDToqIOeNd15SOJNWh3kHb\nvYE1mbkWICLOAg4Gruh+R2C7iAhgW+D3wIbxLmrAl6QaTPLGq6GIGO56viIzV3Q9XwBc3/V8HbDP\nqGucDJwL/BrYDjg0c/xiPgZ8SarJJG68Wp+ZS7fw7Z4BXAr8LfAw4JsR8YPMvG1TLzCHL0k1yR7/\n9OAGYFHX84XVvm5HAudksQa4GnjUeBc14EtSTTJ723qwClgcEbtVA7GHUdI33a4Dng4QEQ8CHgms\nHe+ipnQkqQZJfbV0MnNDRBwLnA/MBs7IzNURcXR1fDnwLuBTEfFTIIC3Zeb68a5rwJekOtRcWiEz\nzwPOG7VvedfjXwMHTuaaBnxJqoHlkSWpRQz4ktQS1sOXpFboecpl3xjwJakGk5hy2TcGfEmqiQug\nSFIL1DkPf6oY8CWpJs7SkaQ2mMTiJv0y0AE/Iu4DvADYla7Pmpkn9qtNkgaYAb+vvgLcClwM3NXn\ntkgacJ2NBvx+WpiZy/rdCEmDr0zLbHbAH/TyyCsj4rH9boSkdqhzEfOpMJA9/KpcaFI+35ERsZaS\n0gkgM3P3UecH8CXg+Mz8+XS3V9IgcNC2X541yfMPBJ4AvAp4c/3NkdQG2Wl2wB/IlE5mXpuZ1wLv\nrn6eQ/kSuA149xgveSUl2D87Igb1S1DSFBrJ4Tc5pTOQAb/Lo6ufhwIPpiwb9pyIeEaVxiEihoBH\nZ+bXgW8Bz+1LSyXNeNnp9LT1y0D2ZiPieODtwH0j4jZK7h7gT8BKSo9/VkT8Fuj+7X+SsmzYF6ax\nuZIGRMNT+IPZw8/M92TmdsAHMvP+1eMnAWcCTwN+DBwDfJmyGvxrq9etAnaOiEVjX1mSNiGT7PS2\n9ctA9vC7vCMiXgy8D7iSMhPnmsx8GkBEzAP2zcxvdL3mLcAQcP10N1bSzOYsnf46hZKy+d/MfHpE\nPBA4PiKOAYaBNcD+EbF9Zv4eIDO/2b/mSpqpXNO2//bJzL0i4k6AzLylGqR9KyWV81tgA5AR8T1K\n3Z1rgJdl5iV9arOkGcqA31+zI+KF1c/nA/cHbgBOBJYDD83MuyPiCMr8+92APYGPAk/pU5slzUSZ\n5MZmL4AykIO2Xb4FnET5YvsX4COU3PyrgbuqYL8YOAo4MzNvzsxvAdv0q8GSZi7n4fdRZr6Zchft\nh4CPA0+kpHG+BMyJiJ2B9ZQZPN/qeul9p7mpkgbAyLq2E239MpApnYi4f2beFhHbAzcCpwEvBY4D\n9gfuAO6mDNzOBm7LzNXVa/cF1val4ZJmLAdt++ezlFIKF1P+Hh4M/B/lxqvtgG8C+wGPAB5L+UIY\nMUy5M1eSejcDyiMPVMCvBmYBzqgejxRCOwl4c2aeExEHAO+kBP6zKD3+yyLiC8Bq4GOZ+btpbrqk\nGS/pNHzQdqACPvDsUc+fAZxPKZp2NKWkwnHA84EjgX8EVgD/U53/eOCiiHhRZl44LS2WNDDs4U+j\nzDwSICLmAvcD9gLeBFwHPDYi7qJ85nXAfSgB/mZgp8z8MXBuRHyJkuLZZ/o/gaSZyhWvpllVRgHg\nc8AvKdUy11By97dQyiusBM4A7q5urvoj5Y5cADLzUkq6R5Imp+HTdAaqh8+f589fClxGuXnq+9W+\n3av9zwPeC7wqIh5Y3X07Z+QC1cyegfoilDQ9stkp/MEKbJl5WkSMTLM8Adg+M/8V2Iky//4IynTM\nO6uXXBARzwGIiO0iYj/g65R5+5I0KU2/8WrQevhk5saIOJwStL8dES/gzzV1LqGUTfgkpUb+WspM\nnY3A1cAVlFWyvtqf1kuasTLp9HFxk14MXMCvXBgRJwOvoAzaEhG3U+6gPZUye2dP4AfACS5cLmlL\n1X3jVUQso5SDmQ2cnpnvHeOc/YAPA1sD6zNz3/GuOagB/3HVz4uqnw8C5gN/oAzefgq4PjNPBoiI\nn2XmY0ZeHBEXZOaB09dcSTNe1reIeZWaPgU4gDKrcFVEnJuZV3SdMw/4GLAsM6+LiB0nuu6gBvzX\nZOaVEbFX175dgb2Bl1NWvfos3POLfdio18+fhjZKGjT19fD3BtZk5lqAiDgLOJiSdh5xBHBOZl5X\n3jpvnOiigxrwj4+IWyk3V0G1CAplJatZlJ7/NhHxR8qUzVtHvb7Zk2klNVCtA7ILuPeqe+v4y3uD\nHgFsHRHfpUwl/0hmnjneRQc14D+YMv9+9+r5SZQpmr8EHkCZp38o5c7cWcCnI2JPykBuYLVMSZuh\n03tKZygihruer8jMFZN8u60oN48+nRKzfhgRP8rMX4z3gkG0c2a+CyAi/gb4AqWY2onACcALKVM1\n/706/7ddj0eeS1LPcnI5/PWZuXSc4zcAi7qeL6z2dVsH3JyZdwB3RMT3gT2A1gX8CyLiMODvKPn5\nXSgj3f8GzKXUvr+RrtRNZr6+D+2UNEBqTOmsAhZHxG6UQH8YJWff7SvAyRGxFTCHkvIZ9x6iQQ34\nfw+8kZKe2UD5nB1KfZ1ZlF/mTZSpTDvRlSuLiF2AjZk5+ttUksZVV8DPzA0RcSyl+ONs4IzMXB0R\nR1fHl2fmzyPiG8DllPh2emb+bLzrDmTAz8ztqhIJ/wWcDPy+OnQjZSD3dZRf4m6U+jq7d738dODt\n/OV/nyRpHPXeRZuZ5wHnjdq3fNTzDwAf6PWaAxnwI+IySjC/L/BUSq9+I3A7sC1lQPfXlMHcW4Ev\nAwdUvfv5mTk81nUlaZOsltk32wGHUKZc7k+pdz+Lkur5DfA+4C7KilhnU3L8UJZB/OR0N1bSzJdA\nbsyetn4ZyB4+ZeT6gogI4EeUL4ANwA+BHYFzKYufjNTMOTgiHkEZGHlKH9oraQA0vYc/qAF/64hY\nTRm5vpPSu0/+nJe/kbLG7TBlYHcbSu7+p5l5y/Q3V9KM1+dKmL0Y1IC/L/BA4IPAdyipmrdSaum8\nFXhDZo4M5BIR96Okek6c/qZKGhR11dKZKgMZ8DPzVspg7CHVrlO6Dr9kjPPvpNyBK0mbzR6+JLVA\n3eWRp8KgztK5R0QcNfrxWPsG6XiT2tL0401qS9OPN6ktU3V8i2SSnU5PW9/0uiRXvzfgaOCl1eNP\nAYf0+Lrh0Y/H2jdIx5vUlqYfb1Jbmn68SW2ZquNbsu20YJc8/j2n9bTV9Z6T3WZESicitspRd5hJ\nUtNUXyCNNa0BPyK+TKkAN5dSu3lFlKUHPw4cSKlSeVhm3lTVeL4UeDLwuYjYDrg9Mz/Y6/sNDQ3l\nokWL2Ovxj89LfvKTkTZk989NPZ7px+t+r4hSOXrWrFk58o+6KZ+1ab+rQT7epLbUfTwzgy2RzQ/4\n4+bwI2JeRBxTPd4vIr62ifNOj4glmzj2xijTHqGsMfs7Sv3m10fEDpQ58MOZ+Wjge8C/RMTbq/Pn\nUGbaHMlm2OUhD+Hnv/wFP1h54ea8XF3mbD2X+8yZy5yt5/a7KVIjJb2nyPtlokHbecAxE10kM1+V\nXWstjoiyfOAbKVUqAV5PWcnlfEpPfzGlytvnq+OfpvToRwL+55mkiDgqIoYjYnj9TTdN9uWStJmS\nzsZOT1u/TBTw3ws8LCIupVRk2zYivhARV0bE2V29/+9GxNLq8e0RcVKUAmbvoKw+9Z2IuIRS12Ye\npYd/CX9ecWo4Ik6rHu9MKXq2D/Cuqh2zq3PfEhEXVM/HlJkrMnNpZi4dmj+fWTGLWTHwk5GmXHb9\nkTSGnPk9/OOAX2Xm4yh3qO5J6bEvAR4OvGWM12wDXJSZe2TmiZSqlE+jrDR1C+V/Pg8H/rraD+WL\nZWP182zK+rO3AiMppMWUGvYfpNwt+5BNNfhePfz16yf4eJJUo8zetj6ZbNf3x5m5LjM7lIJkC6ve\n/yMpZYihBPSDACLiFZQePZRSB0+hVKY8G7iOsggvwCco0y6fBZxatWsH4A2UetDrKCu2Q6lwuQPw\n/rEaeK8e/tDQJD+eJG2+hsf7Sc/Suavr8UpK6uUMSrrnPRExhxLwHxsRF1F68hspqZmFwHzKQuL/\nXb33DZT/RRyWmV+NiPcDz6fk9T9D6eEPVz+vpixNuD9lQZOzJ2rsH+64gy9e9ONJfkSNZenSg+55\nvHLll/rYEqmZRgZtm2yiHv4fKT358RwD/JSycO65lGANZZGRmyhTLV9BWV19FSWn/9Tq2iO1br4W\nZYWqa4FdgbuB0VOkTqfM1gng0cBnx2pMd0rntj/8YYKmS1JNshRP62Xrl3F7+Jl5c0RcGBE/o+TV\nfzfqlHmU+vJ/qrYVlID/MOBRlC+UCyk5/yFK5cp5lFz8KyhryiZwGSXIX0oZnL0LOLy6zospqZ+/\nAl5NKXd8c2bevIk2r6jawc6Lds0rL7qyt9+ExvWoPfa857E9/M3R3X9pdi9Qmyvp9LNsQg8mzOFn\n5hGZ+ZjMfEJmPqvr0JuAmymDsrsCVwB7UHrf/0H5V31aZh5ACdLXAv9Aye8/Fzg8M3elpHw+CDyD\nMpB7QWbuRLXQeGZeU73H7yg3aM0CfrVFn1qSpkDTZ+ls9p22I71/SlrmBOAqYM/MXBMR11Lupv3B\nyOnAO4ELKHn8+cDXI+JOyhTLhwJPpOT5d6oGgh8ALKmmc24FnEOZu3/oeO2OUgjpKID7z9t+cz+e\nJE1ew3P4saXfNhFxDbCUMsNmaWYeGxEvH3lcnXN7Zm5bPX4d8ODMPH7UdZ4NHJGZh4/zHi+npIoe\nnpn79dC2Zv/2Z5DufyelzII0WLa0tMKOOy3KQ1/6hp7OPfkDb704M5duyfttjum6I+nuiNi6evxt\n4JCI2BEgIraPiIdQ1p59UkQ8vNq/TZR1Zkf8J2Xlqs+N90bdg7a1fwpJGkfTp2VOV8BfAVweEZ+p\nSjC8E7ggIi4HvgnsnJk3UXrwn6v2/5DSmx/xsszcnXJD1iZ1z8Ofig8iSWPrvUxxv2xxSqfJIuIm\n4A5g5Jbboerx0Bj7Bul4k9rS9ONNakvTjzepLXUf3yYz57MFdnzQwnzBi17X07nLP3RcX1I6016A\nf7o3GrS4wnQdb1Jbmn68SW1p+vEmtWWqjm/JNrTjgnz1G97T01bXe052mxELoEjSTFB9gTSWAV+S\natHnEdketCHgrxjj8Vj7Bul4k9rS9ONNakvTjzepLVN1fPNl83v4Az1oK0nTZf6OC/LgQ17T07mf\nOPWf+jJo24YeviRNuaT5PXwDviTVYQakdAz4klSLNOBLUlsY8CWpJfq5uEkvpquWjiQNtMx6V7yK\niGURcVVErImI48Y57wkRsSEiDtnUOSMM+JJUk15LHEwkImYDp1AWjFoCHB4RSzZx3vsoa41MyIAv\nSbXovaZND/YG1mTm2sz8E3AWcPAY570O+CJwYy8XNeBLUh3qTeksAK7ver6u2nePiFgAPA84tdcm\nOmgrSTWZxCydoVGLNK3IzMmWePgw8LbM7PS6Cp0BX5JqMMk7bddPUFrhBsoa3iMWVvu6LQXOqoL9\nEPDMiNiQmV/e1EUN+JJUiyQ7nboutgpYHBG7UQL9YcAR93q3zN1GHkfEp4CvjRfswYAvSfVIyJri\nfWZuiIhjgfOB2cAZmbk6Io6uji/fnOsa8CWpJnXeaZuZ5wHnjdo3ZqDPzJf3ck0DviTVxNIKktQC\nlkeWpLbIpLOxtkHbKWHAl6S62MOXpHZIDPiSNPDSFa8kqS2SrGsi/hQx4EtSTezhS1JLdOorrTAl\nDPiSVINS696AL0ntYEpHktrBaZmS1BIO2kpSKySdzsZ+N2JcBnxJqoE3XklSixjwJaklDPiS1Arp\ntExJaovEG68kaeBlWlpBkloizeFLUltYS0eSWsIeviS1hAFfktognZYpSa2QQCetpSNJLeAsHUlq\nDQO+JLWEAV+SWqCM2ToPX5JaIElLK0hSO7imrSS1hDl8SWqFNIcvSW0wE9a0ndXvBkjSoMjMnrZe\nRMSyiLgqItZExHFjHH9RRFweET+NiJURscdE17SHL0k1qWsBlIiYDZwCHACsA1ZFxLmZeUXXaVcD\n+2bmLRFxELAC2Ge86xrwJakWCfXl8PcG1mTmWoCIOAs4GLgn4Gfmyq7zfwQsnOiipnQkqSbZ4x9g\nKCKGu7ajRl1qAXB91/N11b5NeSXw9YnaZw9fkmowyUHb9Zm5tI73jYinUQL+kyc614AvSTWpcZbO\nDcCirucLq333EhG7A6cDB2XmzRNd1IAvSbWodR7+KmBxROxGCfSHAUd0nxARuwDnAC/JzF/0clED\nviTVpK5ZOpm5ISKOBc4HZgNnZObqiDi6Or4c+GdgB+BjEQGwYaI0UTT9RgFJmgnmzt02d931MT2d\ne9VVF11cVw5/MuzhS1ItXNNWklojsZaOJLVC01PkBnxJqkXWNmg7VQz4klQDlziUpBYxpSNJLWHA\nl6RWcFqmJLWGi5hLUgtkQqezsd/NGJcBX5Jq0fvyhf1iwJekmhjwJaklDPiS1BLeeCVJbZBOy5Sk\nVkigYw9fktrBlI4ktYLTMiWpNQz4ktQCZczWgC9JLZCkpRUkqR0sniZJLWFKR5JawoAvSS2Qmc7D\nl6S2sIcvSS3R6djDl6R2sIcvSW2QJPbwJWngeaetJLWIAV+SWsKAL0mtkHSspSNJg28m5PBn9bsB\nkjQwRta1nWjrQUQsi4irImJNRBw3xvGIiI9Wxy+PiL0muqYBX5JqkT3/mUhEzAZOAQ4ClgCHR8SS\nUacdBCyutqOAUye6rgFfkmqS2elp68HewJrMXJuZfwLOAg4edc7BwJlZ/AiYFxE7j3dRc/iSVJMa\nSyssAK7ver4O2KeHcxYAv9nURQ34klSP84GhHs+dGxHDXc9XZOaKKWjTvRjwJakGmbmsxsvdACzq\ner6w2jfZc+7FHL4kNc8qYHFE7BYRc4DDgHNHnXMu8NJqts4TgVszc5PpHLCHL0mNk5kbIuJYSppo\nNnBGZq6OiKOr48uB84BnAmuAO4EjJ7puNP1GAUlSPUzpSFJLGPAlqSUM+JLUEgZ8SWoJA74ktYQB\nX5JawoAvSS1hwJeklvh/Xe8+mIf2ETcAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f032a8d1048>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def debug_show_attention(input_sentence, output_words, attentions):\n",
    "    # Set up figure with colorbar\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)\n",
    "    #cax = ax.matshow(attentions.numpy(), cmap='bone')\n",
    "    cax = ax.matshow(attentions, cmap='bone')\n",
    "    fig.colorbar(cax)\n",
    "    # Set up axes\n",
    "    #ax.set_xticklabels([''] + input_sentence.split(' ') + ['<EOS>'], rotation=90)\n",
    "    ax.set_xticklabels([''] + input_sentence + ['<EOS>'], rotation=90)\n",
    "    ax.set_yticklabels([''] + output_words)\n",
    "\n",
    "    # Show label at every tick\n",
    "    ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "def debug_eval_sample_show_attention():\n",
    "    #output_words, attentions = evaluate(encoder1, attn_decoder1, input_sentence)\n",
    "    output, decoded_output, decoder_attns_arr, sample = test_model_single_sample(None, return_more=True)\n",
    "    print('input: ', [words_after_common[w] for w in sample[1]])\n",
    "    print(output)\n",
    "\n",
    "    showAttention(input_sentence, output_words, attentions)\n",
    "\n",
    "output, decoded_output, decoder_attns_arr, sample = test_model_single_sample(None, return_more=True)\n",
    "sample_input = [words_after_common[w] for w in sample[1][:-1]]\n",
    "print('input:  ', sample_input)\n",
    "print('output: ', decoded_output)\n",
    "\n",
    "attns = np.array([arr.data[0].cpu().numpy() for arr in decoder_attns_arr])\n",
    "\n",
    "debug_show_attention(sample_input, decoded_output, attns)\n",
    "#debug_eval_sample_show_attention()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f032a3e7fd0>"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA5wAAABPCAYAAACH8MrNAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n7rsBGgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f032a8d6d68>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tmp = [r/sum(r) for r in attns]\n",
    "plt.matshow(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  9.99980748e-01,   9.92407198e-12,   9.14397296e-18,\n",
       "         1.80283575e-19,   1.89822130e-10,   5.82498404e-17,\n",
       "         6.55974017e-22,   3.32263016e-06,   3.80407387e-19,\n",
       "         1.55128228e-17,   4.37699182e-12,   1.29124508e-16,\n",
       "         2.60259817e-19,   5.70190056e-21,   1.04794817e-20,\n",
       "         7.80802356e-09,   9.30033284e-20,   4.89955488e-17,\n",
       "         7.25619118e-19,   4.47494472e-13,   5.47296264e-10,\n",
       "         7.37232265e-17,   1.34295270e-14,   6.67527472e-23,\n",
       "         9.58605033e-19,   4.16910517e-12,   1.43581158e-19,\n",
       "         1.77782237e-16,   1.46719429e-19,   1.78220064e-10,\n",
       "         8.51443436e-20,   1.56323222e-05,   1.01024068e-23,\n",
       "         4.07252681e-20,   4.30995799e-18,   1.48798811e-18,\n",
       "         4.30555408e-18,   3.61784605e-19,   9.95954296e-21,\n",
       "         9.93238219e-20,   2.51739159e-19,   9.62528040e-22,\n",
       "         1.78173557e-13,   1.87591884e-19,   1.06507755e-18,\n",
       "         1.80711804e-12,   1.35986731e-17,   1.52575645e-20,\n",
       "         1.17458678e-20,   4.08638100e-18,   1.09600955e-20,\n",
       "         6.61544064e-18,   6.92335078e-08,   1.98000718e-17,\n",
       "         6.45830395e-17,   1.83666422e-17,   5.28210118e-18,\n",
       "         1.53887506e-14,   4.23949168e-21,   1.78542667e-17,\n",
       "         8.97371127e-19,   1.39288233e-07,   2.59904739e-18,\n",
       "         1.38214178e-16,   6.75167422e-10,   6.49253803e-14,\n",
       "         1.41259904e-09,   4.05232060e-19,   4.05404793e-10,\n",
       "         7.58543728e-10,   1.49247898e-18,   3.07892496e-11,\n",
       "         7.20272151e-18,   5.33666450e-18,   7.14335072e-16,\n",
       "         8.95160036e-17,   4.57293257e-19,   4.35791220e-21,\n",
       "         5.91020149e-11,   3.26987726e-09,   2.02247863e-09,\n",
       "         3.79272489e-21,   2.10007164e-12,   3.52182723e-22,\n",
       "         6.92622229e-14,   3.59880758e-20,   4.29313893e-18,\n",
       "         9.95621055e-19,   2.30183771e-11,   6.05181527e-14,\n",
       "         6.27797935e-21,   7.39202761e-08,   9.60375876e-13,\n",
       "         7.06379209e-16,   1.46647727e-09,   2.81558003e-21,\n",
       "         2.03013232e-19,   9.85382412e-17,   4.86269068e-16,\n",
       "         8.79102326e-18], dtype=float32)"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attns[2]/sum(attns[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:py3_pytorch_2]",
   "language": "python",
   "name": "conda-env-py3_pytorch_2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
