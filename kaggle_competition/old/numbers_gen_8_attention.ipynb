{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pytorch utils oh: pytorch_utils_oh_2.py\n",
      "Pytorch: 0.2.0_4\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import importlib\n",
    "from pytorch_utils_oh_2 import *\n",
    "import IPython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MODEL_SAVE_PATH = 'numbers_gen_8_attention'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pytorch utils oh: pytorch_utils_oh_2.py\n",
      "Pytorch: 0.2.0_4\n"
     ]
    }
   ],
   "source": [
    "import pytorch_utils_oh_2; importlib.reload(pytorch_utils_oh_2); from pytorch_utils_oh_2 import *;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# all_data = pickle.load(open(\"data/en_train_fixed_4_sentences.pkl\", \"rb\" ))\n",
    "all_data = pickle.load(open(\"data/en_train_fixed_5_manual.pkl\", \"rb\" ))\n",
    "# all_data_sentence_index = all_data.set_index('sentence_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data rows: 448170,  (dropped rows: 9470022)\n"
     ]
    }
   ],
   "source": [
    "sample_data = all_data.copy()\n",
    "#sample_data = sample_data[sample_data['class'] != 'NOT_CHANGED']\n",
    "#sample_data = sample_data[sample_data['class'] != 'MANUAL']\n",
    "\n",
    "sample_data =  sample_data[sample_data['class'] == 'NUMBERS']\n",
    "\n",
    "print(\"Data rows: {},  (dropped rows: {})\".format(len(sample_data), len(all_data)-len(sample_data)))\n",
    "sample_data = sample_data.reset_index(drop=True)\n",
    "del(all_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['NUMBERS']\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "categories_all = sorted(sample_data[\"class\"].unique())\n",
    "print(categories_all)\n",
    "print(len(categories_all))\n",
    "categories_index = dict((c, i) for i, c in enumerate(categories_all))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utils stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<SOS><EOS>☒ !\"#$%&'(),-./0123456789:;ABCDEFGHIJKLMNOPQRSTUVWXYZ_abcdefghijklmnopqrstuvwxyz~£¥ª²³µº¼½¾éɒʻˈΩμ—€⅓⅔⅛\n"
     ]
    }
   ],
   "source": [
    "chars_normal, chars_normal_index = load_characters_pkl('data/en_features/chars_normal.pkl')\n",
    "print(''.join(chars_normal))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "common_words, common_words_index = load_common_words_10k()\n",
    "len(common_words)\n",
    "common_words[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wv_vecs, wv_words, wv_idx = load_glove('/home/ohu/koodi/data/glove_wordvec/glove.6B.50d.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### After words handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<EOS>', '<SOS>', '<UNK>', '<0000>', '<SAMPLE>', 'two', 'twenty']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "1351"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_after_common = pickle.load(open(\"data/en_features/words_after_ext.pkl\", 'rb'))\n",
    "words_after_index = dict((c, i) for i, c in enumerate(words_after_common))\n",
    "words_after_common[0:7]\n",
    "len(words_after_common)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#onehot_sos = torch.zeros(1, 1, len(words_after_index))\n",
    "#onehot_sos[0, 0, words_after_index[SOS_TOKEN]] = 1\n",
    "#onehot_sos.size()\n",
    "#del(onehot_sos)\n",
    "\n",
    "sos_tensor = torch.LongTensor([words_after_index[SOS_TOKEN]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### More balanced sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "balanced_data_classes_select = list(sample_data.groupby('class'))\n",
    "\n",
    "balanced_data_accessed_counter = 0 \n",
    "balanced_data_length = 0\n",
    "def balanced_data_randomize(max_len=20000):\n",
    "    global balanced_data, balanced_data_length, balanced_data_accessed_counter\n",
    "    balanced_data = pd.concat([v.sample(min(max_len, len(v))) for k, v in balanced_data_classes_select])\n",
    "    balanced_data_length = len(balanced_data)\n",
    "    balanced_data_accessed_counter = 0\n",
    "\n",
    "def balanced_data_sample_row():\n",
    "    global balanced_data_accessed_counter\n",
    "    global balanced_data_last_sample\n",
    "    balanced_data_accessed_counter += 1\n",
    "    if balanced_data_accessed_counter/balanced_data_length > 0.2:\n",
    "        balanced_data_randomize()\n",
    "    balanced_data_last_sample = balanced_data.iloc[random.randint(1, balanced_data_length-1)]\n",
    "    return balanced_data_last_sample\n",
    "    \n",
    "balanced_data_randomize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "108 µs ± 2.04 µs per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "balanced_data_sample_row()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "class\n",
       "NUMBERS    20000\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#all_data.groupby('class')['class'].count()\n",
    "#sample_data.groupby('class')['class'].count()\n",
    "balanced_data.groupby('class')['class'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentence_id                          498487\n",
       "token_id                                  3\n",
       "class                               NUMBERS\n",
       "before                           October 10\n",
       "after                         october tenth\n",
       "class_org                              DATE\n",
       "a_word_ind                      [61, 93, 0]\n",
       "sentence       the independent , <SAMPLE> .\n",
       "Name: 297436, dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " balanced_data_sample_row()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NUMBERS : 13 October 2008 -> the thirteenth of october two thousand eight <EOS> [11, 100, 12, 61, 5, 8, 16, 0]\n",
      "mccarthy , caroline ( <SAMPLE> ) .\n",
      "torch.Size([1, 16, 104])\n"
     ]
    }
   ],
   "source": [
    "def get_random_sample():\n",
    "    sample_row = balanced_data_sample_row()\n",
    "    sentence_id = sample_row['class']\n",
    "    \n",
    "    return sample_row['before'], sample_row['a_word_ind'], sample_row['class'], sample_row['sentence']\n",
    "            \n",
    "def tmp():\n",
    "    s_bef, s_aft, s_class, s_sentence = get_random_sample()\n",
    "    s_aft_str = ' '.join([words_after_common[i] for i in s_aft])\n",
    "    print(s_class, ':', s_bef, '->', s_aft_str, s_aft)\n",
    "    print(s_sentence)\n",
    "    print(string_to_tensor(s_bef, chars_normal_index).shape)\n",
    "tmp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "154 µs ± 1.33 µs per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "get_random_sample()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "use_cuda = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MAX_ATTENTION_LENGTH = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EncoderRNN (\n",
       "  (rnn_words): LSTM(50, 64, batch_first=True, bidirectional=True)\n",
       "  (rnn_chars): LSTM(104, 128, batch_first=True, bidirectional=True)\n",
       ")"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, words_input_size, chars_input_size, words_hidden_size, chars_hidden_size,\n",
    "                 words_layers=1, chars_layers=1):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        \n",
    "        self.words_layers = words_layers\n",
    "        self.chars_layers = chars_layers\n",
    "        self.words_hidden_size = words_hidden_size\n",
    "        self.chars_hidden_size = chars_hidden_size\n",
    "        self.hidden_size = words_hidden_size + chars_hidden_size\n",
    "\n",
    "        self.rnn_words = nn.LSTM(words_input_size, words_hidden_size // 2, words_layers,\n",
    "                                 batch_first=True, bidirectional=True)\n",
    "\n",
    "        self.rnn_chars = nn.LSTM(chars_input_size, chars_hidden_size // 2, chars_layers,\n",
    "                                batch_first=True, bidirectional=True)\n",
    "        \n",
    "    def forward(self, word_vectors, string_tensor, hidden = None, init_hidden = True):\n",
    "        if init_hidden:\n",
    "            hidden_words, hidden_chars = self.init_hidden()\n",
    "        \n",
    "        all_outputs_words, hidden_words = self.rnn_words(word_vectors, hidden_words)\n",
    "        output_words = all_outputs_words[:, -1]\n",
    "        \n",
    "        all_outputs_chars, hidden_chars = self.rnn_chars(string_tensor, hidden_chars)\n",
    "        output_chars = all_outputs_chars[:, -1]\n",
    "        \n",
    "        hidden_states_cat = Variable(torch.zeros(MAX_ATTENTION_LENGTH, self.hidden_size)).cuda()\n",
    "        for ei in range(min(MAX_ATTENTION_LENGTH, len(string_tensor[0]))):\n",
    "            hidden_states_cat[ei] = torch.cat((output_words, all_outputs_chars[0, ei].view(1,-1)), 1)\n",
    "                \n",
    "        output = torch.cat((output_words[0], output_chars[0]), 0)\n",
    "        #output = torch.cat((output_words, output_chars), 1)\n",
    "        \n",
    "        #return output, all_outputs_chars\n",
    "        return output, hidden_states_cat\n",
    "\n",
    "    def init_hidden(self):\n",
    "        var1_1 = Variable(torch.zeros(2 * self.words_layers, 1, self.words_hidden_size // 2))\n",
    "        var1_2 = Variable(torch.zeros(2 * self.words_layers, 1, self.words_hidden_size // 2))\n",
    "        var2_1 = Variable(torch.zeros(2 * self.chars_layers, 1, self.chars_hidden_size // 2))\n",
    "        var2_2 = Variable(torch.zeros(2 * self.chars_layers, 1, self.chars_hidden_size // 2))\n",
    "        \n",
    "        var1_1 = var1_1.cuda(); var1_2 = var1_2.cuda()\n",
    "        var2_1 = var2_1.cuda(); var2_2 = var2_2.cuda()\n",
    "        return ((var1_1, var1_2), (var2_1, var2_2))\n",
    "    \n",
    "    \n",
    "encoder_rnn = EncoderRNN(words_input_size=wv_vecs.shape[-1], chars_input_size=len(chars_normal),\n",
    "                         words_hidden_size=128, chars_hidden_size=256,\n",
    "                         words_layers=1, chars_layers=1).cuda()\n",
    "encoder_rnn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1 GHz'"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([384])"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([20, 384])"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def test_encoder_single_sample():\n",
    "    s_bef, s_aft, s_class, s_sentence = get_random_sample()\n",
    "    \n",
    "    words_t = Variable(words_to_word_vectors_tensor(list(s_sentence), wv_vecs, wv_idx)).cuda()\n",
    "    \n",
    "    string_t = string_to_tensor(s_bef, chars_normal_index)\n",
    "    string_t = Variable(string_t).cuda()\n",
    "    \n",
    "    return encoder_rnn(words_t, string_t), s_bef\n",
    "    \n",
    "(encoder_output, encoder_outputs), tmp = test_encoder_single_sample()\n",
    "tmp\n",
    "encoder_output.size()\n",
    "encoder_outputs.size()\n",
    "list(encoder_output.data.cpu().numpy()) == list(encoder_outputs[len(tmp)].data.cpu().numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecoderRNN (\n",
       "  (rnn): GRU(384, 384, batch_first=True)\n",
       "  (lin_out): Linear (384 -> 1351)\n",
       "  (embedding): Embedding(1351, 384)\n",
       "  (attn): Linear (768 -> 20)\n",
       "  (attn_combine): Linear (768 -> 384)\n",
       "  (dropout): Dropout (p = 0.1)\n",
       ")"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[torch.Size([1, 1351]), torch.Size([1, 1, 384]), torch.Size([1, 20])]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class DecoderRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, n_layers=1, dropout_p=0.1, max_length=MAX_ATTENTION_LENGTH):\n",
    "        super(DecoderRNN, self).__init__()\n",
    "        self.n_layers = n_layers\n",
    "        self.hidden_size = hidden_size\n",
    "        \n",
    "        \n",
    "        self.rnn = nn.GRU(hidden_size, hidden_size, n_layers,\n",
    "                                 batch_first=True, bidirectional=False)\n",
    "        \n",
    "        self.lin_out = nn.Linear(hidden_size, input_size)\n",
    "\n",
    "        \n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        self.max_length = max_length\n",
    "        self.attn = nn.Linear(hidden_size*2, self.max_length)\n",
    "        self.attn_combine = nn.Linear(self.hidden_size * 2, self.hidden_size)\n",
    "        self.dropout = nn.Dropout(dropout_p)\n",
    "        \n",
    "    #def forward(self, char, hidden):\n",
    "    def forward(self, last_input, hidden, encoder_outputs):\n",
    "        embedded = self.embedding(last_input).view(1, 1, -1)\n",
    "        embedded = self.dropout(embedded)\n",
    "        #IPython.core.debugger.Pdb().set_trace()\n",
    "        #attn_weights = F.softmax(self.attn(torch.cat((char[0], hidden[0]), 1)))\n",
    "        attn_weights = F.softmax(self.attn(torch.cat((embedded[0], hidden[0]), 1)))\n",
    "        attn_applied = torch.bmm(attn_weights.unsqueeze(0), encoder_outputs.unsqueeze(0))\n",
    "        \n",
    "        output = torch.cat((embedded[0], attn_applied[0]), 1)\n",
    "        output = self.attn_combine(output).unsqueeze(0)\n",
    "\n",
    "        \n",
    "        output = F.relu(output)\n",
    "        output, hidden = self.rnn(output, hidden)\n",
    "\n",
    "        output = F.log_softmax(self.lin_out(output[0]))\n",
    "        return output, hidden, attn_weights\n",
    "    \n",
    "    def init_rest_hidden(self, input_var):\n",
    "        if self.n_layers > 1:\n",
    "            hid_var = Variable(torch.zeros(self.n_layers - 1, 1, self.hidden_size)).cuda()\n",
    "            res = torch.cat((input_var, hid_var), 0)\n",
    "            return res\n",
    "        else:\n",
    "            return input_var\n",
    "        \n",
    "\n",
    "decoder_rnn = DecoderRNN(input_size=len(words_after_common), hidden_size=encoder_output.size()[0], n_layers=1)\n",
    "decoder_rnn = decoder_rnn.cuda()\n",
    "decoder_rnn\n",
    "\n",
    "tmp_outputs = Variable(torch.zeros(MAX_ATTENTION_LENGTH, encoder_output.size()[0])).cuda()\n",
    "tmp_hiddens = decoder_rnn.init_rest_hidden(encoder_output.view(1,1,-1))\n",
    "tmp = decoder_rnn(Variable(sos_tensor).cuda(), tmp_hiddens, tmp_outputs)\n",
    "[v.size() for v in tmp]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "(0 ,.,.) = \n",
       "  1.2000  2.4000  3.6000  4.8000\n",
       "[torch.FloatTensor of size 1x1x4]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.bmm(torch.FloatTensor([1,0.1,0.1]).view(1,1,-1), torch.arange(0, 12).view(1,3,-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[torch.Size([1, 1351]), torch.Size([1, 1, 384]), torch.Size([1, 20])]"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      " 725\n",
      "[torch.cuda.LongTensor of size 1x1 (GPU 0)]\n",
      "\n",
      "nukupuu\n"
     ]
    }
   ],
   "source": [
    "tmp_outputs = Variable(torch.zeros(MAX_ATTENTION_LENGTH, encoder_output.size()[0])).cuda()\n",
    "tmp_hiddens = decoder_rnn.init_rest_hidden(encoder_output.view(1,1,-1))\n",
    "tmp = decoder_rnn(Variable(sos_tensor).cuda(), tmp_hiddens, tmp_outputs)\n",
    "[v.size() for v in tmp]\n",
    "print(tmp[0].topk(1)[1])\n",
    "print(words_after_common[tmp[0].topk(1)[1].data[0][0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training etc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('nukupuu nukupuu nukupuu nukupuu nukupuu nukupuu nukupuu nukupuu nukupuu nukupuu nukupuu nukupuu nukupuu nukupuu nukupuu nukupuu nukupuu nukupuu nukupuu nukupuu',\n",
       " 'nukupuu nukupuu nukupuu nukupuu nukupuu nukupuu nukupuu nukupuu nukupuu nukupuu nukupuu nukupuu nukupuu nukupuu nukupuu nukupuu nukupuu nukupuu nukupuu nukupuu',\n",
       " 'the twelfth of june twenty ten',\n",
       " ('12 June 2010',\n",
       "  [11, 95, 12, 68, 6, 44, 0],\n",
       "  'NUMBERS',\n",
       "  '<SAMPLE> five hours from paris film . com .'))"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def test_model_single_sample(model=None, return_more=False):\n",
    "    decoder_rnn.eval()\n",
    "    encoder_rnn.eval()\n",
    "    \n",
    "    s_bef, s_aft, s_class, s_sentence = sample = get_random_sample()\n",
    "        \n",
    "    words_t = Variable(words_to_word_vectors_tensor(list(s_sentence), wv_vecs, wv_idx)).cuda()\n",
    "    \n",
    "    string_t = string_to_tensor(s_bef, chars_normal_index)\n",
    "    string_t = Variable(string_t).cuda()\n",
    "    \n",
    "    encoder_output, encoder_outputs = encoder_rnn(words_t, string_t)\n",
    "    \n",
    "    #encoder_output = encoder_output.view(1,1,-1)\n",
    "    \n",
    "    decoder_hidden = decoder_rnn.init_rest_hidden(encoder_outputs[0].view(1,1,-1))\n",
    "    decoder_input = Variable(sos_tensor).cuda()\n",
    "\n",
    "    decoded_output = []\n",
    "    decoder_attns_arr = []\n",
    "    max_length = 20\n",
    "    for _ in range(max_length):\n",
    "        decoder_output, decoder_hidden, decoder_attns = decoder_rnn(decoder_input, decoder_hidden, encoder_outputs)\n",
    "        decoder_attns_arr.append(decoder_attns)\n",
    "        #return decoder_output\n",
    "\n",
    "        topv, topi = decoder_output.data.topk(1)\n",
    "        word_index = topi[0][0]\n",
    "        word = words_after_common[word_index] # Use own prediction as next input\n",
    "                \n",
    "        if word == EOS_TOKEN:\n",
    "            break\n",
    "\n",
    "        decoded_output.append(word)\n",
    "        \n",
    "        # HERE WE HAVE MISTAKE\n",
    "        # HERE WE HAVE MISTAKE\n",
    "        # HERE WE HAVE MISTAKE\n",
    "        # HERE WE HAVE MISTAKE\n",
    "        # HERE WE HAVE MISTAKE\n",
    "        # HERE WE HAVE MISTAKE\n",
    "        ASDFFDSA\n",
    "        #INTPUT\n",
    "        #INTPUT\n",
    "        decoder_intput = torch.LongTensor([word_index])\n",
    "        #decoder_input = torch.zeros(1, 1, len(words_after_index))\n",
    "        #decoder_input[0, 0, word_index] = 1\n",
    "        #decoder_input = Variable(decoder_input).cuda()\n",
    "    \n",
    "    output = ' '.join(decoded_output)\n",
    "    sample_target = ' '.join([words_after_common[w] for w in s_aft][:-1])\n",
    "    \n",
    "    decoder_rnn.train()\n",
    "    encoder_rnn.train()\n",
    "    \n",
    "    if return_more:\n",
    "        return output, decoded_output, decoder_attns_arr, sample\n",
    "    \n",
    "    return output, output, sample_target, sample\n",
    "    \n",
    "tmp = test_model_single_sample(None)\n",
    "tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2004           => nukupuu nukupuu nukupuu nukupuu nukupuu nukupuu nukupuu nukupuu nukupuu nukupuu nukupuu nukupuu nukupuu nukupuu nukupuu nukupuu nukupuu nukupuu nukupuu nukupuu || [5, 8, 19, 0] \n",
      "                  since <SAMPLE> , standard telephone numbers in rostov on don have been seven digits in length .\n",
      "2010           => nukupuu nukupuu nukupuu nukupuu nukupuu nukupuu nukupuu nukupuu nukupuu nukupuu nukupuu nukupuu nukupuu nukupuu nukupuu nukupuu nukupuu nukupuu nukupuu nukupuu || [6, 44, 0] \n",
      "                  dear alice competed at the <SAMPLE> moscow film festival .\n"
     ]
    }
   ],
   "source": [
    "def print_local_wrong_predictions(max_results=10):\n",
    "    arr = get_some_wrong_predictions(None, test_model_single_sample, max_iterations=10000, max_results=max_results)\n",
    "    for sample, predict, output in arr:\n",
    "        s_bef, s_aft, s_class, s_sentence = sample\n",
    "        print(\"{:<14} => {:<14} || {} \\n{:>17} {}\".format(s_bef, predict, s_aft, '', s_sentence, ))\n",
    "print_local_wrong_predictions(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train(s_bef, s_aft, s_sentence, encoder_optimizer, decoder_optimizer, loss_function,\n",
    "          use_teacher_forcing, max_length=20):\n",
    "    \n",
    "    words_t = Variable(words_to_word_vectors_tensor(list(s_sentence), wv_vecs, wv_idx)).cuda()\n",
    "    \n",
    "    string_t = string_to_tensor(s_bef, chars_normal_index)\n",
    "    string_t = Variable(string_t).cuda()\n",
    "    \n",
    "    encoder_output, encoder_outputs = encoder_rnn(words_t, string_t)\n",
    "    \n",
    "    #encoder_output = encoder_output.view(1,1,-1)\n",
    "    \n",
    "    decoder_hidden = decoder_rnn.init_rest_hidden(encoder_outputs[0].view(1,1,-1))\n",
    "    decoder_input = Variable(sos_tensor).cuda()\n",
    "    \n",
    "    ###\n",
    "    target_arr = s_aft\n",
    "    #target_arr = after_sentence_to_word_indexes(s_aft, include_eos=True)\n",
    "    \n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "    loss = 0\n",
    "    \n",
    "    decoded_output = []\n",
    "    for i in range(len(target_arr)):\n",
    "        decoder_output, decoder_hidden, decoder_attns = decoder_rnn(decoder_input, decoder_hidden, encoder_outputs)\n",
    "\n",
    "        #decoder_target_i = chars_after_index[target_arr[i]]\n",
    "        decoder_target_i = target_arr[i]\n",
    "        decoder_target_i = Variable(torch.LongTensor([decoder_target_i])).cuda()\n",
    "        loss += loss_function(decoder_output, decoder_target_i)\n",
    "        \n",
    "        topv, topi = decoder_output.data.topk(1)\n",
    "        word_index = topi[0][0]\n",
    "        word = words_after_common[word_index] # Use own prediction as next input\n",
    "        decoded_output.append(word)\n",
    "        \n",
    "        if use_teacher_forcing:\n",
    "            word_index = target_arr[i] # replace input with right target\n",
    "        else:\n",
    "            # use output normally as input \n",
    "            if word == EOS_TOKEN:\n",
    "                break\n",
    "        \n",
    "                \n",
    "        # HERE WE HAVE MISTAKE\n",
    "        # HERE WE HAVE MISTAKE\n",
    "        # HERE WE HAVE MISTAKE\n",
    "        # HERE WE HAVE MISTAKE\n",
    "        # HERE WE HAVE MISTAKE\n",
    "        # HERE WE HAVE MISTAKE\n",
    "        ASDFFDSA\n",
    "        #INTPUT\n",
    "        #INTPUT\n",
    "        decoder_intput = torch.LongTensor([word_index])\n",
    "        \n",
    "    if decoded_output[-1] == EOS_TOKEN:\n",
    "        decoded_output = decoded_output[:-1]\n",
    "        \n",
    "    loss.backward()\n",
    "\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "\n",
    "    return ' '.join(decoded_output), (loss.data[0] / len(target_arr))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_iterations(n_iters=100000, lr=0.001, teacher_forcing_ratio=0.5,\n",
    "                     print_every=10000, plot_every=1000):\n",
    "\n",
    "    start = time.time()\n",
    "    \n",
    "    decoder_rnn.train()\n",
    "    encoder_rnn.train()\n",
    "\n",
    "    current_loss = 0\n",
    "    current_loss_iter = 0\n",
    "\n",
    "    encoder_optimizer = torch.optim.Adam(encoder_rnn.parameters(), lr=lr)\n",
    "    decoder_optimizer = torch.optim.Adam(decoder_rnn.parameters(), lr=lr)\n",
    "    loss_function = nn.NLLLoss()\n",
    "    \n",
    "    for iteration in range(1, n_iters + 1):\n",
    "        model_training.iterations += 1\n",
    "        \n",
    "        use_teacher_forcing = random.random() < teacher_forcing_ratio\n",
    "        \n",
    "        s_bef, s_aft, s_class, s_sentence = get_random_sample()\n",
    "        \n",
    "        result, loss = train(s_bef=s_bef, s_aft=s_aft, s_sentence=s_sentence,\n",
    "                             encoder_optimizer=encoder_optimizer, decoder_optimizer=decoder_optimizer,\n",
    "                             loss_function=nn.NLLLoss(), use_teacher_forcing=use_teacher_forcing,\n",
    "                             max_length=40 )\n",
    "        \n",
    "        current_loss += loss\n",
    "        current_loss_iter += 1\n",
    "\n",
    "        # Print iter number, loss, name and guess\n",
    "        if iteration % print_every == 0:\n",
    "            teacher_forcing_str = \"\"\n",
    "            if use_teacher_forcing:\n",
    "                teacher_forcing_str = \"(forcing)\"\n",
    "            s_aft_sentence = ' '.join([words_after_common[w] for w in s_aft][:-1])\n",
    "            correct = '✓' if result == s_aft_sentence else \"✗: {}\".format(s_aft)\n",
    "            \n",
    "            print(\"{:>6d} {:>4.0%} ({:>8}) {:>7.3f}   | {:>6.2f}: {} -> {} ({}) {}\".format(\n",
    "                      model_training.iterations, iteration/n_iters, time_since(start),\n",
    "                      current_loss/current_loss_iter, loss,\n",
    "                      s_bef, result, correct, teacher_forcing_str))\n",
    "\n",
    "        # Add current loss avg to list of losses\n",
    "        if iteration % plot_every == 0:\n",
    "            model_training.losses.append(current_loss / plot_every)\n",
    "            model_training.learning_rates.append(lr)\n",
    "            current_loss = 0\n",
    "            current_loss_iter = 0\n",
    "            \n",
    "        if model_training.iterations % 50000 == 0: # or model_training.iterations == 10:\n",
    "            model_training.save_models()\n",
    "            acc = test_model_accuracy(encoder_rnn, test_model_single_sample)\n",
    "            model_training.accuracy.append(acc)\n",
    "    \n",
    "    # test_model_accuracy(model, n_sample=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Save path: data/models/numbers_gen_8_attention_2\n"
     ]
    }
   ],
   "source": [
    "model_training = ModelTraining(MODEL_SAVE_PATH, [encoder_rnn, decoder_rnn])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     9  18% (   0m 0s)   4.770   |   6.55: 7 -> <EOS> (✗: [18, 0]) (forcing)\n",
      "    18  36% (   0m 0s)   4.890   |   6.58: 10 September 1960 -> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> (✗: [11, 93, 12, 64, 7, 39, 0]) (forcing)\n",
      "    27  54% (   0m 0s)   4.869   |   5.58: 10 -> <EOS> (✗: [44, 0]) (forcing)\n",
      "    36  72% (   0m 0s)   4.824   |   5.77: May 3, 2012 -> <EOS> <EOS> <EOS> <EOS> (✗: [66, 76, 6, 47, 0]) (forcing)\n",
      "    45  90% (   0m 0s)   4.491   |   1.25: June 15, 1887 ->  (✗: [68, 91, 40, 27, 18, 0]) \n"
     ]
    }
   ],
   "source": [
    "train_iterations(n_iters=50, print_every=9, lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   550  53% (   0m 8s)   2.693   |   0.84: 1993 -> nineteen (✗: [9, 8, 15, 10, 23, 13, 0]) \n"
     ]
    }
   ],
   "source": [
    "train_iterations(n_iters=(1000-model_training.iterations), print_every=500, lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  2000  11% (  0m 18s)   2.547   |   6.32: 11.4/km² -> the twenty of <EOS> <EOS> <EOS> (✗: [48, 46, 19, 112, 106, 89, 0]) (forcing)\n",
      "  3000  22% (  0m 38s)   2.289   |   1.04: 2003 -> two thousand (✗: [5, 8, 13, 0]) \n",
      "  4000  33% (  0m 57s)   2.196   |   0.94: 2009 -> two thousand (✗: [5, 8, 15, 0]) \n",
      "  5000  44% (  1m 17s)   2.140   |   1.16: 2 -> two (✓) \n",
      "  6000  56% (  1m 36s)   2.061   |   1.75: 6 -> one (✗: [20, 0]) \n",
      "  7000  67% (  1m 55s)   2.045   |   2.29: August 28, 2004 -> february twenty two thousand (✗: [70, 6, 80, 5, 8, 19, 0]) \n",
      "  8000  78% (  2m 14s)   1.966   |   0.73: 1997 -> nineteen ninety nine (✗: [7, 23, 18, 0]) \n",
      "  9000  89% (  2m 33s)   1.954   |   1.37: 21 June 2007 -> the twenty of of twenty twenty thousand <EOS> (✗: [11, 6, 56, 12, 68, 5, 8, 18, 0]) (forcing)\n",
      " 10000 100% (  2m 53s)   1.923   |   2.14: 740 -> one hundred (✗: [18, 10, 41, 0]) \n"
     ]
    }
   ],
   "source": [
    "train_iterations(n_iters=9000, lr=0.0001, print_every=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 20000  11% (  3m 27s)   0.972   |   0.19: 1968 -> nineteen sixty eight (✓) \n",
      " 30000  22% (  6m 49s)   0.579   |   0.01: 26 -> twenty six (✓) (forcing)\n",
      " 40000  33% ( 10m 20s)   0.532   |   0.67: 16 February 1952 -> the eighteenth of october nineteen fifty five (✗: [11, 98, 12, 72, 7, 38, 5, 0]) \n",
      " 50000  44% ( 13m 47s)   0.448   |   0.59: December 6, 2012 -> december twelfth twenty twelve (✗: [65, 79, 6, 47, 0]) \n",
      "Saved model to data/models/numbers_gen_8_attention_2/50000_(EncoderRNN/DecoderRNN)\n",
      "Accuracy: 67.54% (    6754/   10000)\n",
      " 60000  56% ( 18m 26s)   0.451   |   0.00: 2004 -> two thousand four (✓) (forcing)\n",
      " 70000  67% ( 21m 56s)   0.312   |   0.93: December 8, 1903 -> december sixth nineteen thirty three (✗: [65, 80, 7, 25, 13, 0]) (forcing)\n",
      " 80000  78% ( 25m 52s)   0.394   |   0.01: 78 -> seventy eight (✓) \n",
      " 90000  89% ( 29m 46s)   0.288   |   0.09: 1128 -> eleven twenty eight (✓) (forcing)\n",
      "100000 100% ( 33m 49s)   0.251   |   0.01: 35 -> thirty five (✓) \n",
      "Saved model to data/models/numbers_gen_8_attention_2/100000_(EncoderRNN/DecoderRNN)\n",
      "Accuracy: 82.92% (    8292/   10000)\n"
     ]
    }
   ],
   "source": [
    "train_iterations(n_iters=90000, print_every=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24 March 2015  => the twenty fifth of march twenty fifteen || [11, 6, 77, 12, 62, 6, 51, 0] \n",
      "                  guest services , inc retrieved <SAMPLE> .\n",
      "230,000        => two hundred fifty thousand thousand || [5, 10, 34, 8, 0] \n",
      "                  as of 2008 , the circulation is about <SAMPLE> .\n",
      "2008-11-03     => the third of february two thousand eight || [11, 76, 12, 69, 5, 8, 16, 0] \n",
      "                  margot williams ( <SAMPLE> ) .\n",
      "1315           => thirteen thirteen || [49, 51, 0] \n",
      "                  ralph was possessed of land in three oxfordshire townships in <SAMPLE> , viz .\n",
      "VIII           => the seventh    || [11, 80, 0] \n",
      "                  henry <SAMPLE> and the court : art , politics and performance , co edited with thomas betteridge , ashgate , 2013 .\n",
      "1984           => nineteen eighty four || [9, 8, 15, 10, 27, 19, 0] \n",
      "                  during 1983 - <SAMPLE> butenas worked for the soviet embassy in afghanistan .\n",
      "11g            => one hundred a  || [48, 288, 0] \n",
      "                  in september 2011 j developer <SAMPLE> ( 11 build 6081 ) , r 2 / ps 1 became available .\n",
      "2010-07-08     => the eighth of august twenty ten || [11, 80, 12, 67, 6, 44, 0] \n",
      "                  hornsby , tom ( <SAMPLE> ) .\n",
      "669.1/km²      => six hundred seventy nine point square per || [20, 10, 39, 15, 46, 9, 112, 106, 89, 0] \n",
      "                  the population density was 1 , 733 people per square mile ( <SAMPLE> ) .\n",
      "Wednesday, February 9, 2011 => the ninth ninth of || [236, 72, 84, 6, 48, 0] \n",
      "                  <SAMPLE> , 14 : 22 gmt .\n"
     ]
    }
   ],
   "source": [
    "print_local_wrong_predictions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "110000  10% (  3m 49s)   0.271   |   0.01: 457 -> four hundred fifty seven (✓) (forcing)\n",
      "120000  20% (  7m 34s)   0.254   |   0.04: 1983 -> nineteen eighty three (✓) \n",
      "130000  30% ( 11m 12s)   0.248   |   0.04: October 13, 1942 -> october thirteenth nineteen forty two (✓) (forcing)\n",
      "140000  40% ( 14m 49s)   0.228   |   0.01: 63 -> sixty three (✓) \n",
      "150000  50% ( 18m 28s)   0.208   |   0.00: 2004 -> two thousand four (✓) \n",
      "Saved model to data/models/numbers_gen_8_attention_2/150000_(EncoderRNN/DecoderRNN)\n",
      "Accuracy: 86.94% (    8694/   10000)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-159-64f00a41d86a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_iterations\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_iters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprint_every\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mteacher_forcing_ratio\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.001\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-110-ef1eedc363a0>\u001b[0m in \u001b[0;36mtrain_iterations\u001b[0;34m(n_iters, lr, teacher_forcing_ratio, print_every, plot_every)\u001b[0m\n\u001b[1;32m     24\u001b[0m                              \u001b[0mencoder_optimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoder_optimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder_optimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdecoder_optimizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m                              \u001b[0mloss_function\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNLLLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_teacher_forcing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_teacher_forcing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m                              max_length=40 )\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0mcurrent_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-104-8fe5bd18af36>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(s_bef, s_aft, s_sentence, encoder_optimizer, decoder_optimizer, loss_function, use_teacher_forcing, max_length)\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0mdecoded_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecoded_output\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mencoder_optimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py3_pytorch_2/lib/python3.6/site-packages/torch/autograd/variable.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, retain_variables)\u001b[0m\n\u001b[1;32m    154\u001b[0m                 \u001b[0mVariable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m         \"\"\"\n\u001b[0;32m--> 156\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py3_pytorch_2/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(variables, grad_variables, retain_graph, create_graph, retain_variables)\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[0;32m---> 98\u001b[0;31m         variables, grad_variables, retain_graph)\n\u001b[0m\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_iterations(n_iters=50000, print_every=10000, teacher_forcing_ratio=0.5, lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "168017  20% (  3m 31s)   0.215   |   0.00: 380 -> three hundred eighty (✓) (forcing)\n",
      "178017  40% (   7m 4s)   0.201   |   0.02: 18 -> eighteen (✓) (forcing)\n",
      "188017  60% ( 10m 35s)   0.186   |   0.01: 1991 -> nineteen ninety one (✓) \n",
      "198017  80% (  14m 8s)   0.156   |   0.02: 18 March 1945 -> the eighteenth of march nineteen forty five (✓) \n",
      "Saved model to data/models/numbers_gen_8_attention_2/200000_(EncoderRNN/DecoderRNN)\n",
      "Accuracy: 85.33% (    8533/   10000)\n",
      "208017 100% (  19m 1s)   0.190   |   0.00: October 30, 2010 -> october thirtieth twenty ten (✓) (forcing)\n"
     ]
    }
   ],
   "source": [
    "train_iterations(n_iters=50000, print_every=10000, teacher_forcing_ratio=0.5, lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print_local_wrong_predictions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_iterations(n_iters=100000, print_every=10000, teacher_forcing_ratio=0.3, lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print_local_wrong_predictions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_iterations(n_iters=100000, print_every=10000, teacher_forcing_ratio=0.5, lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print_local_wrong_predictions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_iterations(n_iters=100000, print_every=10000, teacher_forcing_ratio=0.1, lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print_local_wrong_predictions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_iterations(n_iters=200000, print_every=10000, teacher_forcing_ratio=0.1, lr=0.0005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print_local_wrong_predictions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_iterations(n_iters=300000, print_every=10000, teacher_forcing_ratio=0.1, lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print_local_wrong_predictions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_iterations(n_iters=200000, print_every=10000, teacher_forcing_ratio=0, lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print_local_wrong_predictions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_iterations(n_iters=200000, print_every=10000, teacher_forcing_ratio=0, lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print_local_wrong_predictions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_iterations(n_iters=500000, print_every=10000, teacher_forcing_ratio=0, lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print_local_wrong_predictions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_iterations(n_iters=500000, print_every=10000, teacher_forcing_ratio=0, lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print_local_wrong_predictions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_iterations(n_iters=500000, print_every=10000, teacher_forcing_ratio=0, lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print_local_wrong_predictions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_iterations(n_iters=500000, print_every=10000, teacher_forcing_ratio=0, lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print_local_wrong_predictions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input:   2,600 ft\n",
      "output:  ['two', 'thousand', 'six', 'hundred', 'six', 'hundred']\n",
      "target:    two thousand six hundred feet\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAzIAAAFeCAYAAABenColAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f43952879e8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def debug_show_attention(input_sentence, output_words, attentions):\n",
    "    # Set up figure with colorbar\n",
    "    fig = plt.figure(figsize=(15,6))\n",
    "    ax = fig.add_subplot(111)\n",
    "    #cax = ax.matshow(attentions.numpy(), cmap='bone')\n",
    "    cax = ax.matshow(attentions, cmap='bone')\n",
    "    fig.colorbar(cax)\n",
    "    # Set up axes\n",
    "    #ax.set_xticklabels([''] + input_sentence.split(' ') + ['<EOS>'], rotation=90)\n",
    "    ax.set_xticklabels([''] + input_sentence + ['<EOS>'], rotation=90)\n",
    "    ax.set_yticklabels([''] + output_words)\n",
    "\n",
    "    # Show label at every tick\n",
    "    ax.xaxis.set_major_locator(matplotlib.ticker.MultipleLocator(1))\n",
    "    ax.yaxis.set_major_locator(matplotlib.ticker.MultipleLocator(1))\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "def debug_eval_sample_show_attention():\n",
    "    #output_words, attentions = evaluate(encoder1, attn_decoder1, input_sentence)\n",
    "    output, decoded_output, decoder_attns_arr, sample = test_model_single_sample(None, return_more=True)\n",
    "    print('input: ', [words_after_common[w] for w in sample[1]])\n",
    "    print(output)\n",
    "\n",
    "    showAttention(input_sentence, output_words, attentions)\n",
    "\n",
    "    \n",
    "output, decoded_output, decoder_attns_arr, sample = test_model_single_sample(None, return_more=True)\n",
    "print('input:  ', sample[0])\n",
    "print('output: ', decoded_output)\n",
    "print('target:   ', ' '.join([words_after_common[w] for w in sample[1][:-1]]))\n",
    "\n",
    "attns = np.array([arr.data[0].cpu().numpy() for arr in decoder_attns_arr])\n",
    "\n",
    "debug_show_attention(list(sample[0]), decoded_output, attns)\n",
    "\n",
    "#debug_eval_sample_show_attention()\n",
    "#tmp = [r/sum(r) for r in attns]\n",
    "#plt.matshow(tmp)\n",
    "#plt.matshow(attns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input:   92.0\n",
      "output:  ['ninety', 'two', 'point', 'zero']\n",
      "target:    ninety two point zero\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAyMAAAFeCAYAAACW8MDzAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f43b7913208>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def debug_show_attention(input_sentence, output_words, attentions):\n",
    "    # Set up figure with colorbar\n",
    "    fig = plt.figure(figsize=(15,6))\n",
    "    ax = fig.add_subplot(111)\n",
    "    #cax = ax.matshow(attentions.numpy(), cmap='bone')\n",
    "    cax = ax.matshow(attentions, cmap='bone')\n",
    "    fig.colorbar(cax)\n",
    "    # Set up axes\n",
    "    #ax.set_xticklabels([''] + input_sentence.split(' ') + ['<EOS>'], rotation=90)\n",
    "    ax.set_xticklabels([''] + input_sentence + ['<EOS>'], rotation=90)\n",
    "    ax.set_yticklabels([''] + output_words)\n",
    "\n",
    "    # Show label at every tick\n",
    "    ax.xaxis.set_major_locator(matplotlib.ticker.MultipleLocator(1))\n",
    "    ax.yaxis.set_major_locator(matplotlib.ticker.MultipleLocator(1))\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "def debug_eval_sample_show_attention():\n",
    "    #output_words, attentions = evaluate(encoder1, attn_decoder1, input_sentence)\n",
    "    output, decoded_output, decoder_attns_arr, sample = test_model_single_sample(None, return_more=True)\n",
    "    print('input: ', [words_after_common[w] for w in sample[1]])\n",
    "    print(output)\n",
    "\n",
    "    showAttention(input_sentence, output_words, attentions)\n",
    "\n",
    "    \n",
    "output, decoded_output, decoder_attns_arr, sample = test_model_single_sample(None, return_more=True)\n",
    "print('input:  ', sample[0])\n",
    "print('output: ', decoded_output)\n",
    "print('target:   ', ' '.join([words_after_common[w] for w in sample[1][:-1]]))\n",
    "\n",
    "attns = np.array([arr.data[0].cpu().numpy() for arr in decoder_attns_arr])\n",
    "\n",
    "debug_show_attention(list(sample[0]), decoded_output, attns)\n",
    "\n",
    "#debug_eval_sample_show_attention()\n",
    "#tmp = [r/sum(r) for r in attns]\n",
    "#plt.matshow(tmp)\n",
    "#plt.matshow(attns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:py3_pytorch_2]",
   "language": "python",
   "name": "conda-env-py3_pytorch_2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
