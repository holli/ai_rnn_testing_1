{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker\n",
    "import numpy as np\n",
    "import random\n",
    "import time\n",
    "import os\n",
    "import pandas as pd\n",
    "import math\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pytorch: 0.2.0_4\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "print(\"Pytorch: {}\".format(torch.__version__))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data to train and validation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data_org = pd.read_csv('data/en_train_org.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>token_id</th>\n",
       "      <th>class</th>\n",
       "      <th>before</th>\n",
       "      <th>after</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>616107</th>\n",
       "      <td>49226</td>\n",
       "      <td>17</td>\n",
       "      <td>LETTERS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>n a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>684691</th>\n",
       "      <td>54634</td>\n",
       "      <td>1</td>\n",
       "      <td>PLAIN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>965529</th>\n",
       "      <td>76612</td>\n",
       "      <td>7</td>\n",
       "      <td>PLAIN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        sentence_id  token_id    class before after\n",
       "616107        49226        17  LETTERS    NaN   n a\n",
       "684691        54634         1    PLAIN    NaN   NaN\n",
       "965529        76612         7    PLAIN    NaN   NaN"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data_org[pd.isnull(all_data_org['before'])][:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data rows: 9918390,  (dropped none rows: 51)\n",
      "Data rows: 9840282,  (dropped rows: 78159)\n"
     ]
    }
   ],
   "source": [
    "all_data = all_data_org.dropna()\n",
    "print(\"Data rows: {},  (dropped none rows: {})\".format(len(all_data), len(all_data_org)-len(all_data)))\n",
    "all_data = all_data[all_data['class'] != 'VERBATIM']\n",
    "print(\"Data rows: {},  (dropped rows: {})\".format(len(all_data), len(all_data_org)-len(all_data)))\n",
    "all_data = all_data.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note we dropped VERBATIM class. Thats because it had so many weird characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_sentences = all_data.groupby('sentence_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_indexes_grouped = random.sample(list(grouped_sentences.indices.values()), int(len(grouped_sentences)*0.3))\n",
    "validation_indexes = [item for sublist in validation_indexes_grouped for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_data = all_data.loc[validation_indexes]\n",
    "train_data = all_data.loc[~all_data.index.isin(validation_indexes)]\n",
    "train_data = train_data.sort_values(['sentence_id','token_id'])\n",
    "validation_data = validation_data.sort_values(['sentence_id','token_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sizes: all_data 9840282, train_data 6890758 (0.7003), validation_data 2949524 (0.2997)\n",
      "Match : True\n"
     ]
    }
   ],
   "source": [
    "print(\"sizes: all_data {}, train_data {} ({:.4f}), validation_data {} ({:.4f})\".format(\n",
    "    len(all_data), len(train_data), len(train_data)/len(all_data),\n",
    "    len(validation_data), len(validation_data)/len(all_data)))\n",
    "print(\"Match : {}\".format(len(all_data)==(len(validation_data)+len(train_data))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>token_id</th>\n",
       "      <th>class</th>\n",
       "      <th>before</th>\n",
       "      <th>after</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>DATE</td>\n",
       "      <td>2006</td>\n",
       "      <td>two thousand six</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>LETTERS</td>\n",
       "      <td>IUCN</td>\n",
       "      <td>i u c n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>PLAIN</td>\n",
       "      <td>Red</td>\n",
       "      <td>Red</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>PLAIN</td>\n",
       "      <td>List</td>\n",
       "      <td>List</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>PLAIN</td>\n",
       "      <td>of</td>\n",
       "      <td>of</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    sentence_id  token_id    class before             after\n",
       "10            1         0     DATE   2006  two thousand six\n",
       "11            1         1  LETTERS   IUCN           i u c n\n",
       "12            1         2    PLAIN    Red               Red\n",
       "13            1         3    PLAIN   List              List\n",
       "14            1         4    PLAIN     of                of"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>token_id</th>\n",
       "      <th>class</th>\n",
       "      <th>before</th>\n",
       "      <th>after</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>PLAIN</td>\n",
       "      <td>Brillantaisia</td>\n",
       "      <td>Brillantaisia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>PLAIN</td>\n",
       "      <td>is</td>\n",
       "      <td>is</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>PLAIN</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>PLAIN</td>\n",
       "      <td>genus</td>\n",
       "      <td>genus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>PLAIN</td>\n",
       "      <td>of</td>\n",
       "      <td>of</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentence_id  token_id  class         before          after\n",
       "0            0         0  PLAIN  Brillantaisia  Brillantaisia\n",
       "1            0         1  PLAIN             is             is\n",
       "2            0         2  PLAIN              a              a\n",
       "3            0         3  PLAIN          genus          genus\n",
       "4            0         4  PLAIN             of             of"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "td = testing_data = validation_data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = testing_data.groupby(['before', 'after']).size()\n",
    "d = d.reset_index().sort_values(0, ascending=False)\n",
    "d = d.loc[d['before'].drop_duplicates(keep='first').index]\n",
    "d = d.loc[d['before'] != d['after']]\n",
    "d = d.set_index('before')['after'].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_words = list(set(list(all_data['before']) + list(all_data['after'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "570696"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_words_indices = dict((c, i) for i, c in enumerate(all_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.48 s, sys: 4 ms, total: 3.49 s\n",
      "Wall time: 3.48 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_x = np.zeros(len(all_data['before']), dtype=np.int)\n",
    "for idx, word in enumerate(list(all_data['after'])):\n",
    "    train_x[idx] = all_words_indices[word]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y = np.zeros(len(all_data['after']), dtype=np.int)\n",
    "for idx, word in enumerate(list(all_data['after'])):\n",
    "    train_y[idx] = all_words_indices[word]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### More balanced sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "class\n",
       "ADDRESS           522\n",
       "CARDINAL       133744\n",
       "DATE           258348\n",
       "DECIMAL          9821\n",
       "DIGIT            5442\n",
       "ELECTRONIC       5162\n",
       "FRACTION         1196\n",
       "LETTERS        152790\n",
       "MEASURE         14783\n",
       "MONEY            6128\n",
       "ORDINAL         12703\n",
       "PLAIN         7353647\n",
       "PUNCT         1880507\n",
       "TELEPHONE        4024\n",
       "TIME             1465\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data.groupby(\"class\")[\"class\"].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_data_classes = list(all_data.groupby('class'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>token_id</th>\n",
       "      <th>class</th>\n",
       "      <th>before</th>\n",
       "      <th>after</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6763915</th>\n",
       "      <td>517972</td>\n",
       "      <td>5</td>\n",
       "      <td>ADDRESS</td>\n",
       "      <td>A1</td>\n",
       "      <td>a one</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>355029</th>\n",
       "      <td>28762</td>\n",
       "      <td>14</td>\n",
       "      <td>ADDRESS</td>\n",
       "      <td>B23762</td>\n",
       "      <td>b two three seven six two</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6628438</th>\n",
       "      <td>507789</td>\n",
       "      <td>5</td>\n",
       "      <td>CARDINAL</td>\n",
       "      <td>8,062</td>\n",
       "      <td>eight thousand sixty two</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8527222</th>\n",
       "      <td>650178</td>\n",
       "      <td>3</td>\n",
       "      <td>CARDINAL</td>\n",
       "      <td>17,</td>\n",
       "      <td>seventeen</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         sentence_id  token_id     class   before                      after\n",
       "6763915       517972         5   ADDRESS       A1                      a one\n",
       "355029         28762        14   ADDRESS  B23762   b two three seven six two\n",
       "6628438       507789         5  CARDINAL    8,062   eight thousand sixty two\n",
       "8527222       650178         3  CARDINAL      17,                  seventeen"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data_classes[0][1].sample(2).append(all_data_classes[1][1].sample(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_balanced_classes = pd.concat([v.sample(min(50000, len(v))) for k, v in all_data_classes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "class\n",
       "ADDRESS         522\n",
       "CARDINAL      50000\n",
       "DATE          50000\n",
       "DECIMAL        9821\n",
       "DIGIT          5442\n",
       "ELECTRONIC     5162\n",
       "FRACTION       1196\n",
       "LETTERS       50000\n",
       "MEASURE       14783\n",
       "MONEY          6128\n",
       "ORDINAL       12703\n",
       "PLAIN         50000\n",
       "PUNCT         50000\n",
       "TELEPHONE      4024\n",
       "TIME           1465\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_balanced_classes.groupby(\"class\")[\"class\"].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>token_id</th>\n",
       "      <th>class</th>\n",
       "      <th>before</th>\n",
       "      <th>after</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2189122</th>\n",
       "      <td>171713</td>\n",
       "      <td>11</td>\n",
       "      <td>PLAIN</td>\n",
       "      <td>Massachusetts</td>\n",
       "      <td>Massachusetts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2512519</th>\n",
       "      <td>196502</td>\n",
       "      <td>4</td>\n",
       "      <td>DATE</td>\n",
       "      <td>1986</td>\n",
       "      <td>nineteen eighty six</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2104358</th>\n",
       "      <td>165181</td>\n",
       "      <td>3</td>\n",
       "      <td>CARDINAL</td>\n",
       "      <td>15</td>\n",
       "      <td>fifteen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4734991</th>\n",
       "      <td>365380</td>\n",
       "      <td>4</td>\n",
       "      <td>TELEPHONE</td>\n",
       "      <td>0-89608-006-4</td>\n",
       "      <td>o sil eight nine six o eight sil o o six sil four</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9813745</th>\n",
       "      <td>746087</td>\n",
       "      <td>8</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>(</td>\n",
       "      <td>(</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2612339</th>\n",
       "      <td>204115</td>\n",
       "      <td>2</td>\n",
       "      <td>DECIMAL</td>\n",
       "      <td>96.5</td>\n",
       "      <td>ninety six point five</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9441849</th>\n",
       "      <td>718401</td>\n",
       "      <td>4</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>)</td>\n",
       "      <td>)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7539214</th>\n",
       "      <td>576226</td>\n",
       "      <td>19</td>\n",
       "      <td>DATE</td>\n",
       "      <td>31 August</td>\n",
       "      <td>the thirty first of august</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6636190</th>\n",
       "      <td>508366</td>\n",
       "      <td>7</td>\n",
       "      <td>DATE</td>\n",
       "      <td>2000</td>\n",
       "      <td>two thousand</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5346734</th>\n",
       "      <td>411533</td>\n",
       "      <td>1</td>\n",
       "      <td>CARDINAL</td>\n",
       "      <td>5</td>\n",
       "      <td>five</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         sentence_id  token_id      class         before  \\\n",
       "2189122       171713        11      PLAIN  Massachusetts   \n",
       "2512519       196502         4       DATE           1986   \n",
       "2104358       165181         3   CARDINAL             15   \n",
       "4734991       365380         4  TELEPHONE  0-89608-006-4   \n",
       "9813745       746087         8      PUNCT              (   \n",
       "2612339       204115         2    DECIMAL           96.5   \n",
       "9441849       718401         4      PUNCT              )   \n",
       "7539214       576226        19       DATE      31 August   \n",
       "6636190       508366         7       DATE           2000   \n",
       "5346734       411533         1   CARDINAL              5   \n",
       "\n",
       "                                                     after  \n",
       "2189122                                      Massachusetts  \n",
       "2512519                                nineteen eighty six  \n",
       "2104358                                            fifteen  \n",
       "4734991  o sil eight nine six o eight sil o o six sil four  \n",
       "9813745                                                  (  \n",
       "2612339                              ninety six point five  \n",
       "9441849                                                  )  \n",
       "7539214                         the thirty first of august  \n",
       "6636190                                       two thousand  \n",
       "5346734                                               five  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_balanced_classes.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting string class from characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['DATE' 'LETTERS' 'PLAIN' 'PUNCT' 'CARDINAL' 'MEASURE' 'MONEY' 'ORDINAL'\n",
      " 'TIME' 'ELECTRONIC' 'DIGIT' 'DECIMAL' 'FRACTION' 'TELEPHONE' 'ADDRESS']\n"
     ]
    }
   ],
   "source": [
    "categories_all = train_data[\"class\"].unique()\n",
    "print(categories_all)\n",
    "len(categories_all)\n",
    "categories_index = dict((c, i) for i, c in enumerate(categories_all))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " !\"#$%&'()+,-./0123456789:;?ABCDEFGHIJKLMNOPQRSTUVWXYZ[]_abcdefghijklmnopqrstuvwxyz|~¡£¥ª«²³µº»¼½¾¿éɒʻˈΩμ—€⅓⅔⅛⅝⅞\n",
      "112\n"
     ]
    }
   ],
   "source": [
    "letters_all = sorted(list(set(''.join(all_data['before']))))\n",
    "letters_index = dict((c, i) for i, c in enumerate(letters_all))\n",
    "letters_n = len(letters_all)\n",
    "print(''.join(letters_all))\n",
    "print(len(letters_all))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6, 1, 112])\n"
     ]
    }
   ],
   "source": [
    "def lineToTensor(line):\n",
    "    tensor = torch.zeros(len(line), 1, letters_n)\n",
    "    for li, letter in enumerate(line):\n",
    "        tensor[li][0][letters_index[letter]] = 1\n",
    "    return tensor\n",
    "print(lineToTensor('wordup').size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 956,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "use_cuda = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "use_cuda = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GRU_RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, n_layers=1):\n",
    "        super(GRU_RNN, self).__init__()\n",
    "\n",
    "        self.n_layers = n_layers\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "\n",
    "        self.gru = nn.GRU(input_size, hidden_size, n_layers)\n",
    "        self.lin_1 = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, word, hidden = None, init_hidden = True):\n",
    "        if init_hidden:\n",
    "            hidden = self.init_hidden()\n",
    "        all_outputs, hidden = self.gru(word, hidden)\n",
    "        output = all_outputs[-1]\n",
    "        output = self.lin_1(output)\n",
    "        output = F.log_softmax(output)\n",
    "        return output\n",
    "\n",
    "    def init_hidden(self):\n",
    "        var = Variable(torch.zeros(self.n_layers, 1, self.hidden_size))\n",
    "        if use_cuda:\n",
    "            var = var.cuda()\n",
    "        return var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      "\n",
      "Columns 0 to 9 \n",
      "-2.6137 -2.8012 -2.7312 -2.6314 -2.7330 -2.7659 -2.6428 -2.7836 -2.6171 -2.7698\n",
      "\n",
      "Columns 10 to 14 \n",
      "-2.7313 -2.7399 -2.6866 -2.7747 -2.6299\n",
      "[torch.cuda.FloatTensor of size 1x15 (GPU 0)]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = GRU_RNN(input_size=letters_n, hidden_size=128, output_size=len(categories_all))\n",
    "input_info = Variable(lineToTensor('wordup'))\n",
    "\n",
    "if use_cuda:\n",
    "    model = model.cuda()\n",
    "    input_info = input_info.cuda()\n",
    "\n",
    "output = model(input_info)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM_RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, n_layers=1):\n",
    "        super(LSTM_RNN, self).__init__()\n",
    "\n",
    "        self.n_layers = n_layers\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "\n",
    "        self.rnn = nn.LSTM(input_size, hidden_size, n_layers)\n",
    "        self.lin_1 = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, word, hidden = None, init_hidden = True):\n",
    "        if init_hidden:\n",
    "            hidden = self.init_hidden()\n",
    "        all_outputs, hidden = self.rnn(word, hidden)\n",
    "        output = all_outputs[-1]\n",
    "        output = self.lin_1(output)\n",
    "        output = F.log_softmax(output)\n",
    "        return output\n",
    "\n",
    "    def init_hidden(self):\n",
    "        var1 = Variable(torch.zeros(self.n_layers, 1, self.hidden_size))\n",
    "        var2 = Variable(torch.zeros(self.n_layers, 1, self.hidden_size))\n",
    "        if use_cuda:\n",
    "            var1 = var1.cuda()\n",
    "            var2 = var2.cuda()\n",
    "        return (var1, var2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      "\n",
      "Columns 0 to 9 \n",
      "-2.6711 -2.7176 -2.7785 -2.6064 -2.7067 -2.6893 -2.7523 -2.6069 -2.8061 -2.6135\n",
      "\n",
      "Columns 10 to 14 \n",
      "-2.7407 -2.8133 -2.7165 -2.7551 -2.6783\n",
      "[torch.cuda.FloatTensor of size 1x15 (GPU 0)]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = LSTM_RNN(input_size=letters_n, hidden_size=128, output_size=len(categories_all))\n",
    "input_info = Variable(lineToTensor('wordup'))\n",
    "\n",
    "if use_cuda:\n",
    "    model = model.cuda()\n",
    "    input_info = input_info.cuda()\n",
    "\n",
    "output = model(input_info)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('PUNCT', 3)\n"
     ]
    }
   ],
   "source": [
    "def categoryFromOutput(output):\n",
    "    top_n, top_i = output.data.topk(1) # Tensor out of Variable with .data\n",
    "    category_i = top_i[0][0]\n",
    "    return categories_all[category_i], category_i\n",
    "\n",
    "print(categoryFromOutput(output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data_balanced_classes.sample(frac=1)\n",
    "train_x = list(data['before'])\n",
    "train_y = list(data['class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "category = PLAIN / line = compression      ( torch.Size([1])\n",
      "category = DATE / line = 1795      ( torch.Size([1])\n",
      "category = CARDINAL / line = 38      ( torch.Size([1])\n",
      "category = PLAIN / line = Falls      ( torch.Size([1])\n",
      "category = LETTERS / line = C.      ( torch.Size([1])\n",
      "category = ORDINAL / line = 8th      ( torch.Size([1])\n",
      "category = DATE / line = 2005      ( torch.Size([1])\n",
      "category = PLAIN / line = The      ( torch.Size([1])\n",
      "category = PUNCT / line = (      ( torch.Size([1])\n",
      "category = DATE / line = 29.12.2012      ( torch.Size([1])\n"
     ]
    }
   ],
   "source": [
    "def randomTrainingExample():\n",
    "    #sample = data_balanced_classes.sample(1)\n",
    "    #category = sample['class'].item()\n",
    "    #line = sample['before'].item()\n",
    "    i = random.randint(0, len(train_x)-1)\n",
    "    category = train_y[i]\n",
    "    line = train_x[i]\n",
    "    category_tensor = Variable(torch.LongTensor([categories_index[category]]))\n",
    "    line_tensor = Variable(lineToTensor(line))\n",
    "    if use_cuda:\n",
    "        category_tensor = category_tensor.cuda()\n",
    "        line_tensor = line_tensor.cuda()\n",
    "    return category, line, category_tensor, line_tensor\n",
    "\n",
    "for i in range(10):\n",
    "    category, line, category_tensor, line_tensor = randomTrainingExample()\n",
    "    print('category =', category, '/ line =', line,\n",
    "          '     (', category_tensor.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       " 13\n",
       "[torch.cuda.LongTensor of size 1 (GPU 0)]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "randomTrainingExample()[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53.5 µs ± 3.76 µs per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "randomTrainingExample()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test_model_accuracy(model, n_sample=10000):\n",
    "    model.eval()\n",
    "    n_correct = 0\n",
    "    for iteration in range(n_sample):\n",
    "        category, line, category_tensor, line_tensor = randomTrainingExample()\n",
    "        output = model(line_tensor)\n",
    "        if category == categoryFromOutput(output)[0]:\n",
    "            n_correct += 1\n",
    "\n",
    "    print(\"Accuracy: {:>4.2%} ({:>8d}/{:>8d})\".format(\n",
    "            n_correct/n_sample, n_correct, n_sample))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 12.38% (    1238/   10000)\n",
      "CPU times: user 7.42 s, sys: 88 ms, total: 7.51 s\n",
      "Wall time: 6.91 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "test_model_accuracy(model, n_sample=10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, category_tensor, line_tensor):\n",
    "    output = model(line_tensor)\n",
    "    loss = loss_function(output, category_tensor)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    return output, loss.data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def timeSince(since):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_iterations(n_iters=100000, start_iter=0, print_every=5000, plot_every=1000):\n",
    "    model.train()\n",
    "    start = time.time()\n",
    "    all_losses = []\n",
    "    current_loss = 0\n",
    "    current_loss_iter = 0\n",
    "\n",
    "    for iteration in range(1, n_iters + 1):\n",
    "        category, line, category_tensor, line_tensor = randomTrainingExample()\n",
    "        output, loss = train(model, category_tensor, line_tensor)\n",
    "        current_loss += loss\n",
    "        current_loss_iter += 1\n",
    "\n",
    "        # Print iter number, loss, name and guess\n",
    "        if iteration % print_every == 0:\n",
    "            guess, guess_i = categoryFromOutput(output)\n",
    "            correct = '✓' if guess == category else \"✗ ({})\".format(category)\n",
    "            print(\"{:>6d} {:>4.0%} ({:>8}) {:>6.2f}   | {:>6.2f}: {} -> {} {}\".format(\n",
    "                (iteration+start_iter), iteration/n_iters, timeSince(start),\n",
    "                current_loss/current_loss_iter, loss,\n",
    "                line, guess, correct ))\n",
    "\n",
    "        # Add current loss avg to list of losses\n",
    "        if iteration % plot_every == 0:\n",
    "            all_losses.append(current_loss / plot_every)\n",
    "            current_loss = 0\n",
    "            current_loss_iter = 0\n",
    "    \n",
    "    test_model_accuracy(model, n_sample=10000)\n",
    "    return all_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1070,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  5000  10% (   0m 9s)   2.26   |   1.88: June 27, 2009 -> PLAIN ✗ (DATE)\n",
      " 10000  20% (  0m 18s)   1.93   |   2.35: 130 -> DATE ✗ (CARDINAL)\n",
      " 15000  30% (  0m 27s)   1.75   |   1.61: . -> PUNCT ✓\n",
      " 20000  40% (  0m 36s)   1.68   |   1.36: , -> PUNCT ✓\n",
      " 25000  50% (  0m 45s)   1.62   |   2.05: a -> PUNCT ✗ (PLAIN)\n",
      " 30000  60% (  0m 54s)   1.54   |   0.54: August 7, 2012 -> DATE ✓\n",
      " 35000  70% (   1m 3s)   1.43   |   0.52: May 19, 2006 -> DATE ✓\n",
      " 40000  80% (  1m 12s)   1.37   |   1.73: III -> LETTERS ✗ (CARDINAL)\n",
      " 45000  90% (  1m 21s)   1.33   |   1.31: PD -> LETTERS ✓\n",
      " 50000 100% (  1m 31s)   1.16   |   0.94: 1996 -> DATE ✓\n",
      "Accuracy: 70.30% (    7030/   10000)\n"
     ]
    }
   ],
   "source": [
    "model = LSTM_RNN(input_size=letters_n, hidden_size=128, output_size=len(categories_all)).cuda()\n",
    "loss_function = nn.NLLLoss()\n",
    "# optimizer = torch.optim.Adam(model.top_model.parameters(), lr=0.001)\n",
    "all_losses = train_iterations(n_iters=50000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1071,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  5000  10% (   0m 9s)   2.26   |   2.01: 2008 -> PLAIN ✗ (DATE)\n",
      " 10000  20% (  0m 19s)   1.95   |   1.92: \" -> DATE ✗ (PUNCT)\n",
      " 15000  30% (  0m 28s)   1.83   |   1.93: WROC- -> DATE ✗ (LETTERS)\n",
      " 20000  40% (  0m 37s)   1.62   |   1.85: SJ -> PLAIN ✗ (LETTERS)\n",
      " 25000  50% (  0m 46s)   1.63   |   1.73: BP -> PUNCT ✗ (LETTERS)\n",
      " 30000  60% (  0m 55s)   1.51   |   1.34: and -> PLAIN ✓\n",
      " 35000  70% (   1m 5s)   1.50   |   1.72: It -> PUNCT ✗ (PLAIN)\n",
      " 40000  80% (  1m 14s)   1.43   |   1.63: 28 -> LETTERS ✗ (CARDINAL)\n",
      " 45000  90% (  1m 23s)   1.33   |   4.48: 11th -> PLAIN ✗ (ORDINAL)\n",
      " 50000 100% (  1m 32s)   1.19   |   0.85: 1940 -> DATE ✓\n",
      "Accuracy: 69.18% (    6918/   10000)\n"
     ]
    }
   ],
   "source": [
    "model = LSTM_RNN(input_size=letters_n, hidden_size=128, output_size=len(categories_all)).cuda()\n",
    "# loss function changed\n",
    "loss_function = F.cross_entropy\n",
    "all_losses = train_iterations(n_iters=50000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1074,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  5000  10% (  0m 10s)   0.30   |   0.85: Lebor -> LETTERS ✗ (PLAIN)\n",
      " 10000  20% (  0m 20s)   0.20   |   0.00: . -> PUNCT ✓\n",
      " 15000  30% (  0m 30s)   0.19   |   0.00: N. -> LETTERS ✓\n",
      " 20000  40% (  0m 40s)   0.19   |   5.42: ALEX -> LETTERS ✗ (PLAIN)\n",
      " 25000  50% (  0m 50s)   0.13   |   0.02: KD -> LETTERS ✓\n",
      " 30000  60% (   1m 0s)   0.13   |   0.52: 9.3 percent -> MEASURE ✓\n",
      " 35000  70% (  1m 11s)   0.11   |   0.00: \" -> PUNCT ✓\n",
      " 40000  80% (  1m 21s)   0.10   |   0.04: meta -> PLAIN ✓\n",
      " 45000  90% (  1m 31s)   0.11   |   0.00: . -> PUNCT ✓\n",
      " 50000 100% (  1m 42s)   0.10   |   0.00: electrification -> PLAIN ✓\n",
      "Accuracy: 97.00% (    9700/   10000)\n"
     ]
    }
   ],
   "source": [
    "model = LSTM_RNN(input_size=letters_n, hidden_size=128, output_size=len(categories_all)).cuda()\n",
    "# loss and optimizer changed\n",
    "loss_function = F.cross_entropy\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "all_losses = train_iterations(n_iters=50000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1083,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  5000  10% (   0m 9s)   0.24   |   0.00: Robert -> PLAIN ✓\n",
      " 10000  20% (  0m 18s)   0.14   |   0.00: , -> PUNCT ✓\n",
      " 15000  30% (  0m 28s)   0.14   |   0.00: ( -> PUNCT ✓\n",
      " 20000  40% (  0m 38s)   0.11   |   0.00: G. -> LETTERS ✓\n",
      " 25000  50% (  0m 47s)   0.11   |   0.01: 215 -> CARDINAL ✓\n",
      " 30000  60% (  0m 57s)   0.11   |   0.01: Romania -> PLAIN ✓\n",
      " 35000  70% (   1m 6s)   0.11   |   0.03: 2008 -> DATE ✓\n",
      " 40000  80% (  1m 15s)   0.10   |   0.02: Working -> PLAIN ✓\n",
      " 45000  90% (  1m 25s)   0.10   |   1.68: ve -> PLAIN ✗ (LETTERS)\n",
      " 50000 100% (  1m 35s)   0.11   |   0.00: April 5, 2012 -> DATE ✓\n",
      "Accuracy: 97.22% (    9722/   10000)\n"
     ]
    }
   ],
   "source": [
    "model = GRU_RNN(input_size=letters_n, hidden_size=128, output_size=len(categories_all)).cuda()\n",
    "loss_function = F.cross_entropy\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "all_losses = train_iterations(n_iters=50000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  5000  10% (  0m 12s)   0.24   |   0.00: . -> PUNCT ✓\n",
      " 10000  20% (  0m 24s)   0.22   |   0.02: of -> PLAIN ✓\n",
      " 15000  30% (  0m 37s)   0.17   |   0.00: PDF -> LETTERS ✓\n",
      " 20000  40% (  0m 49s)   0.18   |   0.00: A.E. -> LETTERS ✓\n",
      " 25000  50% (   1m 1s)   0.15   |   0.44: g -> LETTERS ✓\n",
      " 30000  60% (  1m 13s)   0.20   |   0.03: AJ -> LETTERS ✓\n",
      " 35000  70% (  1m 26s)   0.13   |   0.00: 14.4% -> MEASURE ✓\n",
      " 40000  80% (  1m 39s)   0.15   |   0.00: partners -> PLAIN ✓\n",
      " 45000  90% (  1m 51s)   0.14   |   0.00: . -> PUNCT ✓\n",
      " 50000 100% (   2m 3s)   0.12   |   0.02: 12 -> CARDINAL ✓\n",
      "Accuracy: 96.28% (    9628/   10000)\n"
     ]
    }
   ],
   "source": [
    "model = GRU_RNN(input_size=letters_n, hidden_size=256, output_size=len(categories_all), n_layers=2).cuda()\n",
    "loss_function = F.cross_entropy\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "all_losses = train_iterations(n_iters=50000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 55000   2% (  0m 12s)   0.14   |   0.09: 3 -> CARDINAL ✓\n",
      " 60000   3% (  0m 23s)   0.13   |   0.04: On -> PLAIN ✓\n",
      " 65000   5% (  0m 35s)   0.14   |   0.01: NWA -> LETTERS ✓\n",
      " 70000   7% (  0m 48s)   0.14   |   0.02: LQR -> LETTERS ✓\n",
      " 75000   8% (   1m 0s)   0.13   |   0.25: 0 -> CARDINAL ✓\n",
      " 80000  10% (  1m 12s)   0.09   |   0.06: I. A. -> LETTERS ✓\n",
      " 85000  12% (  1m 24s)   0.16   |   0.00: . -> PUNCT ✓\n",
      " 90000  13% (  1m 36s)   0.12   |   0.00: 25 mm -> MEASURE ✓\n",
      " 95000  15% (  1m 48s)   0.11   |   0.01: quarter -> PLAIN ✓\n",
      "100000  17% (   2m 0s)   0.16   |   0.00: 1990s -> DATE ✓\n",
      "105000  18% (  2m 13s)   0.11   |   0.11: 2 -> CARDINAL ✓\n",
      "110000  20% (  2m 25s)   0.13   |   0.00: Beef -> PLAIN ✓\n",
      "115000  22% (  2m 37s)   0.12   |   0.02: 1994 -> DATE ✓\n",
      "120000  23% (  2m 49s)   0.11   |   0.00: iTunesCharts.net -> ELECTRONIC ✓\n",
      "125000  25% (   3m 1s)   0.12   |   0.00: 4th -> ORDINAL ✓\n",
      "130000  27% (  3m 13s)   0.12   |   0.00: 733.0 -> DECIMAL ✓\n",
      "135000  28% (  3m 25s)   0.12   |   3.21: 2007 -> DATE ✗ (CARDINAL)\n",
      "140000  30% (  3m 37s)   0.11   |   0.16: s -> LETTERS ✓\n",
      "145000  32% (  3m 49s)   0.13   |   0.08: 4 -> CARDINAL ✓\n",
      "150000  33% (   4m 2s)   0.13   |   0.00: 2.5 -> DECIMAL ✓\n",
      "155000  35% (  4m 14s)   0.13   |   0.13: 5 -> CARDINAL ✓\n",
      "160000  37% (  4m 26s)   0.16   |   0.00: them -> PLAIN ✓\n",
      "165000  38% (  4m 38s)   0.11   |   0.07: 2009 -> DATE ✓\n",
      "170000  40% (  4m 50s)   0.11   |   0.01: is -> PLAIN ✓\n",
      "175000  42% (   5m 2s)   0.13   |   0.00: 0-8061-1467-3 ISBN 978-0-8061-1467-5 -> TELEPHONE ✓\n",
      "180000  43% (  5m 14s)   0.13   |   3.63: 300 -> CARDINAL ✗ (DIGIT)\n",
      "185000  45% (  5m 27s)   0.13   |   0.00: . -> PUNCT ✓\n",
      "190000  47% (  5m 39s)   0.13   |   0.00: 17 May 1985 -> DATE ✓\n",
      "195000  48% (  5m 51s)   0.12   |   0.00: 47th -> ORDINAL ✓\n",
      "200000  50% (   6m 4s)   0.14   |   0.00: M.C. -> LETTERS ✓\n",
      "205000  52% (  6m 16s)   0.17   |   0.00: 3rd -> ORDINAL ✓\n",
      "210000  53% (  6m 28s)   0.13   |   0.12: 3 -> CARDINAL ✓\n",
      "215000  55% (  6m 40s)   0.16   |   0.03: 73 -> CARDINAL ✓\n",
      "220000  57% (  6m 52s)   0.15   |   0.23: 2013 -> DATE ✓\n",
      "225000  58% (   7m 5s)   0.12   |   0.05: 7 -> CARDINAL ✓\n",
      "230000  60% (  7m 17s)   0.12   |   0.00: 18 November 2015 -> DATE ✓\n",
      "235000  62% (  7m 29s)   0.11   |   0.00: 4,500 m2 -> MEASURE ✓\n",
      "240000  63% (  7m 42s)   0.16   |   0.00: to -> PLAIN ✓\n",
      "245000  65% (  7m 54s)   0.12   |   0.35: 07 -> DIGIT ✓\n",
      "250000  67% (   8m 6s)   0.15   |   0.16: 1998 -> DATE ✓\n",
      "255000  68% (  8m 18s)   0.12   |   0.00: , -> PUNCT ✓\n",
      "260000  70% (  8m 30s)   0.15   |   0.04: 5 -> CARDINAL ✓\n",
      "265000  72% (  8m 42s)   0.11   |   0.00: ) -> PUNCT ✓\n",
      "270000  73% (  8m 54s)   0.14   |   0.01: Twist -> PLAIN ✓\n",
      "275000  75% (   9m 6s)   0.11   |   0.00: film -> PLAIN ✓\n",
      "280000  77% (  9m 18s)   0.15   |   0.15: 2011 -> DATE ✓\n",
      "285000  78% (  9m 32s)   0.17   |   0.02: SV -> LETTERS ✓\n",
      "290000  80% (  9m 45s)   0.10   |   0.00: ERP -> LETTERS ✓\n",
      "295000  82% (  9m 58s)   0.12   |   0.00: 93933- -> DIGIT ✓\n",
      "300000  83% ( 10m 11s)   0.13   |   0.00: ( -> PUNCT ✓\n",
      "305000  85% ( 10m 23s)   0.14   |   0.00: 18 June 2015 -> DATE ✓\n",
      "310000  87% ( 10m 35s)   0.13   |   0.00: B. -> LETTERS ✓\n",
      "315000  88% ( 10m 48s)   0.13   |   0.02: 450 -> CARDINAL ✓\n",
      "320000  90% (  11m 0s)   0.15   |   0.00: 2009-12-13 -> DATE ✓\n",
      "325000  92% ( 11m 12s)   0.12   |   0.00: , -> PUNCT ✓\n",
      "330000  93% ( 11m 25s)   0.10   |   0.00: , -> PUNCT ✓\n",
      "335000  95% ( 11m 37s)   0.11   |   0.00: December 2012 -> DATE ✓\n",
      "340000  97% ( 11m 50s)   0.10   |   0.06: 1990 -> DATE ✓\n",
      "345000  98% (  12m 3s)   0.16   |   0.15: 2 -> CARDINAL ✓\n",
      "350000 100% ( 12m 16s)   0.10   |   0.00: 13 June 1986 -> DATE ✓\n",
      "Accuracy: 96.98% (    9698/   10000)\n"
     ]
    }
   ],
   "source": [
    "all_losses = train_iterations(n_iters=300000, start_iter=50000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 30000  10% (  1m 22s)   0.15   |   0.02: Musicals -> PLAIN ✓\n",
      " 60000  20% (  2m 44s)   0.12   |   0.04: the -> PLAIN ✓\n",
      " 90000  30% (   4m 6s)   0.14   |   0.01: nya -> LETTERS ✓\n",
      "120000  40% (  5m 27s)   0.09   |   0.00: 63% -> MEASURE ✓\n",
      "150000  50% (  6m 50s)   0.10   |   0.00: ) -> PUNCT ✓\n",
      "180000  60% (  8m 12s)   0.13   |   0.00: \" -> PUNCT ✓\n",
      "210000  70% (  9m 34s)   0.13   |   0.04: 590 -> CARDINAL ✓\n",
      "240000  80% ( 10m 54s)   0.12   |   0.00: 10 January 2013 -> DATE ✓\n",
      "270000  90% ( 12m 12s)   0.10   |   0.18: MALAXA -> LETTERS ✓\n",
      "300000 100% ( 13m 30s)   0.13   |   0.00: be -> PLAIN ✓\n",
      "Accuracy: 96.79% (    9679/   10000)\n"
     ]
    }
   ],
   "source": [
    "model = LSTM_RNN(input_size=letters_n, output_size=len(categories_all), hidden_size=256, n_layers=2).cuda()\n",
    "loss_function = F.cross_entropy\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "all_losses = train_iterations(n_iters=300000, print_every=30000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 50000  17% (  2m 39s)   0.16   |   0.00: January 1998 -> DATE ✓\n",
      "100000  33% (  5m 14s)   0.17   |   0.29: 9000 -> CARDINAL ✓\n",
      "150000  50% (  7m 50s)   0.11   |   0.07: 1857 -> DATE ✓\n",
      "200000  67% ( 10m 24s)   0.11   |   0.06: 500 -> CARDINAL ✓\n",
      "250000  83% (  13m 5s)   0.11   |   0.03: x -> LETTERS ✓\n",
      "300000 100% ( 15m 42s)   0.13   |   0.12: 5 -> CARDINAL ✓\n",
      "Accuracy: 96.70% (    9670/   10000)\n"
     ]
    }
   ],
   "source": [
    "model = LSTM_RNN(input_size=letters_n, output_size=len(categories_all), hidden_size=512, n_layers=2).cuda()\n",
    "loss_function = F.cross_entropy\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "all_losses = train_iterations(n_iters=300000, print_every=50000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "340000  20% (   1m 2s)   0.11   |   0.00: J. -> LETTERS ✓\n",
      "360000  40% (   2m 3s)   0.10   |   0.00: 07:25 -> TIME ✓\n",
      "380000  60% (   3m 5s)   0.10   |   0.00: . -> PUNCT ✓\n",
      "400000  80% (   4m 7s)   0.09   |   1.86: 2008-NAN -> TIME ✗ (TELEPHONE)\n",
      "420000 100% (  5m 11s)   0.08   |   0.00: . -> PUNCT ✓\n",
      "Accuracy: 96.95% (    9695/   10000)\n"
     ]
    }
   ],
   "source": [
    "loss_function = F.cross_entropy\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
    "all_losses = train_iterations(n_iters=100000, start_iter=320000, print_every=20000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "340000  20% (   1m 1s)   0.10   |   0.04: 345 -> CARDINAL ✓\n",
      "360000  40% (   2m 2s)   0.10   |   0.05: Club -> PLAIN ✓\n",
      "380000  60% (   3m 2s)   0.11   |   0.00: Italy -> PLAIN ✓\n",
      "400000  80% (   4m 3s)   0.11   |   0.00: 8:30 a.m. -> TIME ✓\n",
      "420000 100% (   5m 4s)   0.09   |   0.00: TPB -> LETTERS ✓\n",
      "Accuracy: 96.88% (    9688/   10000)\n"
     ]
    }
   ],
   "source": [
    "loss_function = F.cross_entropy\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
    "all_losses = train_iterations(n_iters=100000, start_iter=320000, print_every=20000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Just return an output given a line\n",
    "def evaluate(model, line_tensor):\n",
    "    #hidden = rnn.initHidden()\n",
    "\n",
    "    #for i in range(line_tensor.size()[0]):\n",
    "    #    output, hidden = rnn(line_tensor[i], hidden)\n",
    "    output = rnn(line_tensor, rnn.initHidden())\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWAAAAEzCAYAAAAPe9kVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n94ReTTEEEwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fbd32eb3048>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Keep track of correct guesses in a confusion matrix\n",
    "confusion = torch.zeros(len(categories_all), len(categories_all))\n",
    "n_confusion = 100000\n",
    "\n",
    "# Go through a bunch of examples and record which are correctly guessed\n",
    "for i in range(n_confusion):\n",
    "    category, line, category_tensor, line_tensor = randomTrainingExample()\n",
    "    output = model(line_tensor)\n",
    "    guess, guess_i = categoryFromOutput(output)\n",
    "    category_i = categories_index[category]\n",
    "    confusion[category_i][guess_i] += 1\n",
    "\n",
    "# Normalize by dividing every row by its sum\n",
    "for i in range(len(categories_all)):\n",
    "    confusion[i] = confusion[i] / confusion[i].sum()\n",
    "\n",
    "# Set up plot\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "cax = ax.matshow(confusion.numpy())\n",
    "fig.colorbar(cax)\n",
    "\n",
    "# Set up axes\n",
    "ax.set_xticklabels([''] + list(categories_all), rotation=90)\n",
    "ax.set_yticklabels([''] + list(categories_all))\n",
    "\n",
    "# Force label at every tick\n",
    "ax.xaxis.set_major_locator(matplotlib.ticker.MultipleLocator(1))\n",
    "ax.yaxis.set_major_locator(matplotlib.ticker.MultipleLocator(1))\n",
    "\n",
    "# sphinx_gallery_thumbnail_number = 2\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 774,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(input_line, n_predictions=3):\n",
    "    print('\\n> %s' % input_line)\n",
    "    output = evaluate(Variable(lineToTensor(input_line)))\n",
    "\n",
    "    # Get top N categories\n",
    "    #topv, topi = output.data.topk(n_predictions, 1, True)\n",
    "    topv, topi = output.data.topk(n_predictions, 2, True)\n",
    "    predictions = []\n",
    "\n",
    "    for i in range(n_predictions):\n",
    "        value = topv[0][0][i]\n",
    "        category_index = topi[0][0][i]\n",
    "        print('(%.2f) %s' % (value, categories_all[category_index]))\n",
    "        predictions.append([value, categories_all[category_index]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 981,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "> Normal\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "torch.addmm received an invalid combination of arguments - got (int, torch.cuda.FloatTensor, int, torch.FloatTensor, torch.cuda.FloatTensor, out=torch.cuda.FloatTensor), but expected one of:\n * (torch.cuda.FloatTensor source, torch.cuda.FloatTensor mat1, torch.cuda.FloatTensor mat2, *, torch.cuda.FloatTensor out)\n * (torch.cuda.FloatTensor source, torch.cuda.sparse.FloatTensor mat1, torch.cuda.FloatTensor mat2, *, torch.cuda.FloatTensor out)\n * (float beta, torch.cuda.FloatTensor source, torch.cuda.FloatTensor mat1, torch.cuda.FloatTensor mat2, *, torch.cuda.FloatTensor out)\n * (torch.cuda.FloatTensor source, float alpha, torch.cuda.FloatTensor mat1, torch.cuda.FloatTensor mat2, *, torch.cuda.FloatTensor out)\n * (float beta, torch.cuda.FloatTensor source, torch.cuda.sparse.FloatTensor mat1, torch.cuda.FloatTensor mat2, *, torch.cuda.FloatTensor out)\n * (torch.cuda.FloatTensor source, float alpha, torch.cuda.sparse.FloatTensor mat1, torch.cuda.FloatTensor mat2, *, torch.cuda.FloatTensor out)\n * (float beta, torch.cuda.FloatTensor source, float alpha, torch.cuda.FloatTensor mat1, torch.cuda.FloatTensor mat2, *, torch.cuda.FloatTensor out)\n      didn't match because some of the arguments have invalid types: (\u001b[32;1mint\u001b[0m, \u001b[32;1mtorch.cuda.FloatTensor\u001b[0m, \u001b[32;1mint\u001b[0m, \u001b[31;1mtorch.FloatTensor\u001b[0m, \u001b[32;1mtorch.cuda.FloatTensor\u001b[0m, \u001b[32;1mout=torch.cuda.FloatTensor\u001b[0m)\n * (float beta, torch.cuda.FloatTensor source, float alpha, torch.cuda.sparse.FloatTensor mat1, torch.cuda.FloatTensor mat2, *, torch.cuda.FloatTensor out)\n      didn't match because some of the arguments have invalid types: (\u001b[32;1mint\u001b[0m, \u001b[32;1mtorch.cuda.FloatTensor\u001b[0m, \u001b[32;1mint\u001b[0m, \u001b[31;1mtorch.FloatTensor\u001b[0m, \u001b[32;1mtorch.cuda.FloatTensor\u001b[0m, \u001b[32;1mout=torch.cuda.FloatTensor\u001b[0m)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-981-30e2edc83b4b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Normal'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'2017-12-12'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'~'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'20'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-774-c1cd57c97bfb>\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(input_line, n_predictions)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_line\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_predictions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\n> %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0minput_line\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlineToTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_line\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;31m# Get top N categories\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-854-e96b18806d94>\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(line_tensor)\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;31m#for i in range(line_tensor.size()[0]):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;31m#    output, hidden = rnn(line_tensor[i], hidden)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitHidden\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py3_pytorch_2/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    222\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_pre_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m             \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    225\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-971-0cbd20399d28>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, word, hidden)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mall_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgru\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0;31m#output = hidden\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0;31m#output = output.view(1, -1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py3_pytorch_2/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    222\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_pre_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m             \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    225\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py3_pytorch_2/lib/python3.6/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    160\u001b[0m             \u001b[0mflat_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mflat_weight\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m         )\n\u001b[0;32m--> 162\u001b[0;31m         \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall_weights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    163\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_packed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPackedSequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py3_pytorch_2/lib/python3.6/site-packages/torch/nn/_functions/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(input, *fargs, **fkwargs)\u001b[0m\n\u001b[1;32m    349\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    350\u001b[0m             \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAutogradRNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 351\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mfargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    352\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py3_pytorch_2/lib/python3.6/site-packages/torch/nn/_functions/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(input, weight, hidden)\u001b[0m\n\u001b[1;32m    242\u001b[0m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 244\u001b[0;31m         \u001b[0mnexth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    245\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch_first\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py3_pytorch_2/lib/python3.6/site-packages/torch/nn/_functions/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(input, hidden, weight)\u001b[0m\n\u001b[1;32m     82\u001b[0m                 \u001b[0ml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnum_directions\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m                 \u001b[0mhy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m                 \u001b[0mnext_hidden\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m                 \u001b[0mall_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py3_pytorch_2/lib/python3.6/site-packages/torch/nn/_functions/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(input, hidden, weight)\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0msteps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mreverse\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msteps\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m             \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m             \u001b[0;31m# hack to handle LSTM\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m             \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py3_pytorch_2/lib/python3.6/site-packages/torch/nn/_functions/rnn.py\u001b[0m in \u001b[0;36mGRUCell\u001b[0;34m(input, hidden, w_ih, w_hh, b_ih, b_hh)\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mb_ih\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb_ih\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb_hh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m     \u001b[0mgi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw_ih\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb_ih\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m     \u001b[0mgh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw_hh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb_hh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0mi_r\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi_i\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi_n\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py3_pytorch_2/lib/python3.6/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m    551\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m         \u001b[0;31m# fused op is marginally faster\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 553\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    555\u001b[0m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py3_pytorch_2/lib/python3.6/site-packages/torch/autograd/variable.py\u001b[0m in \u001b[0;36maddmm\u001b[0;34m(cls, *args)\u001b[0m\n\u001b[1;32m    922\u001b[0m         \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    923\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0maddmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 924\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_blas\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mAddmm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    925\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    926\u001b[0m         \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py3_pytorch_2/lib/python3.6/site-packages/torch/autograd/variable.py\u001b[0m in \u001b[0;36m_blas\u001b[0;34m(cls, args, inplace)\u001b[0m\n\u001b[1;32m    918\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m                 \u001b[0mtensors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 920\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    921\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    922\u001b[0m         \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py3_pytorch_2/lib/python3.6/site-packages/torch/autograd/_functions/blas.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(ctx, add_matrix, matrix1, matrix2, alpha, beta, inplace)\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_matrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         return torch.addmm(alpha, add_matrix, beta,\n\u001b[0;32m---> 26\u001b[0;31m                            matrix1, matrix2, out=output)\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: torch.addmm received an invalid combination of arguments - got (int, torch.cuda.FloatTensor, int, torch.FloatTensor, torch.cuda.FloatTensor, out=torch.cuda.FloatTensor), but expected one of:\n * (torch.cuda.FloatTensor source, torch.cuda.FloatTensor mat1, torch.cuda.FloatTensor mat2, *, torch.cuda.FloatTensor out)\n * (torch.cuda.FloatTensor source, torch.cuda.sparse.FloatTensor mat1, torch.cuda.FloatTensor mat2, *, torch.cuda.FloatTensor out)\n * (float beta, torch.cuda.FloatTensor source, torch.cuda.FloatTensor mat1, torch.cuda.FloatTensor mat2, *, torch.cuda.FloatTensor out)\n * (torch.cuda.FloatTensor source, float alpha, torch.cuda.FloatTensor mat1, torch.cuda.FloatTensor mat2, *, torch.cuda.FloatTensor out)\n * (float beta, torch.cuda.FloatTensor source, torch.cuda.sparse.FloatTensor mat1, torch.cuda.FloatTensor mat2, *, torch.cuda.FloatTensor out)\n * (torch.cuda.FloatTensor source, float alpha, torch.cuda.sparse.FloatTensor mat1, torch.cuda.FloatTensor mat2, *, torch.cuda.FloatTensor out)\n * (float beta, torch.cuda.FloatTensor source, float alpha, torch.cuda.FloatTensor mat1, torch.cuda.FloatTensor mat2, *, torch.cuda.FloatTensor out)\n      didn't match because some of the arguments have invalid types: (\u001b[32;1mint\u001b[0m, \u001b[32;1mtorch.cuda.FloatTensor\u001b[0m, \u001b[32;1mint\u001b[0m, \u001b[31;1mtorch.FloatTensor\u001b[0m, \u001b[32;1mtorch.cuda.FloatTensor\u001b[0m, \u001b[32;1mout=torch.cuda.FloatTensor\u001b[0m)\n * (float beta, torch.cuda.FloatTensor source, float alpha, torch.cuda.sparse.FloatTensor mat1, torch.cuda.FloatTensor mat2, *, torch.cuda.FloatTensor out)\n      didn't match because some of the arguments have invalid types: (\u001b[32;1mint\u001b[0m, \u001b[32;1mtorch.cuda.FloatTensor\u001b[0m, \u001b[32;1mint\u001b[0m, \u001b[31;1mtorch.FloatTensor\u001b[0m, \u001b[32;1mtorch.cuda.FloatTensor\u001b[0m, \u001b[32;1mout=torch.cuda.FloatTensor\u001b[0m)\n"
     ]
    }
   ],
   "source": [
    "predict('Normal')\n",
    "predict('2017-12-12')\n",
    "predict('~')\n",
    "predict('20')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:py3_pytorch_2]",
   "language": "python",
   "name": "conda-env-py3_pytorch_2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
