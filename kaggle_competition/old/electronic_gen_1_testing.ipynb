{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pytorch utils oh: pytorch_utils_oh_2.py\n",
      "Pytorch: 0.2.0_4\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import importlib\n",
    "from pytorch_utils_oh_2 import *\n",
    "import IPython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MODEL_SAVE_PATH = 'electronic_gen_1_testing'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pytorch utils oh: pytorch_utils_oh_2.py\n",
      "Pytorch: 0.2.0_4\n"
     ]
    }
   ],
   "source": [
    "import pytorch_utils_oh_2; importlib.reload(pytorch_utils_oh_2); from pytorch_utils_oh_2 import *;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# all_data = pickle.load(open(\"data/en_train_fixed_4_sentences.pkl\", \"rb\" ))\n",
    "all_data = pickle.load(open(\"data/en_train_fixed_5_manual.pkl\", \"rb\" ))\n",
    "# all_data_sentence_index = all_data.set_index('sentence_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data rows: 4964,  (dropped rows: 9913228)\n"
     ]
    }
   ],
   "source": [
    "sample_data = all_data.copy()\n",
    "sample_data = sample_data[sample_data['class'] == 'ELECTRONIC']\n",
    "print(\"Data rows: {},  (dropped rows: {})\".format(len(sample_data), len(all_data)-len(sample_data)))\n",
    "sample_data = sample_data.reset_index(drop=True)\n",
    "del(all_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ELECTRONIC']\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "categories_all = sorted(sample_data[\"class\"].unique())\n",
    "print(categories_all)\n",
    "print(len(categories_all))\n",
    "categories_index = dict((c, i) for i, c in enumerate(categories_all))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utils stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<SOS><EOS>☒ !\"#$%&'(),-./0123456789:;ABCDEFGHIJKLMNOPQRSTUVWXYZ_abcdefghijklmnopqrstuvwxyz~£¥ª²³µº¼½¾éɒʻˈΩμ—€⅓⅔⅛\n"
     ]
    }
   ],
   "source": [
    "chars_normal, chars_normal_index = load_characters_pkl('data/en_features/chars_normal.pkl')\n",
    "print(''.join(chars_normal))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "common_words, common_words_index = load_common_words_10k()\n",
    "len(common_words)\n",
    "common_words[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wv_vecs, wv_words, wv_idx = load_glove('/home/ohu/koodi/data/glove_wordvec/glove.6B.50d.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### After words handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<EOS>', '<SOS>', '<UNK>', '<0000>', '<SAMPLE>', 'two', 'twenty']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "1351"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_after_common = pickle.load(open(\"data/en_features/words_after_ext.pkl\", 'rb'))\n",
    "words_after_index = dict((c, i) for i, c in enumerate(words_after_common))\n",
    "words_after_common[0:7]\n",
    "len(words_after_common)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 1351])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sos_tensor = torch.zeros(1, 1, len(words_after_index))\n",
    "sos_tensor[0, 0, words_after_index[SOS_TOKEN]] = 1\n",
    "sos_tensor.size()\n",
    "#del(onehot_sos)\n",
    "\n",
    "# sos_tensor = torch.LongTensor([words_after_index[SOS_TOKEN]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### More balanced sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "balanced_data_classes_select = list(sample_data.groupby('class'))\n",
    "\n",
    "balanced_data_accessed_counter = 0 \n",
    "balanced_data_randomize_freq = False\n",
    "balanced_data_length = 0\n",
    "\n",
    "def balanced_data_randomize_org(max_len=20000):\n",
    "    global balanced_data, balanced_data_length, balanced_data_accessed_counter, balanced_data_randomize_freq\n",
    "    balanced_data = pd.concat([v.sample(min(max_len, len(v))) for k, v in balanced_data_classes_select])\n",
    "    balanced_data_length = len(balanced_data)\n",
    "    balanced_data_randomize_freq = balanced_data_length * 0.2\n",
    "    balanced_data_accessed_counter = 0\n",
    "balanced_data_randomize = balanced_data_randomize_org\n",
    "\n",
    "def balanced_data_sample_row():\n",
    "    global balanced_data_accessed_counter\n",
    "    global balanced_data_last_sample\n",
    "    balanced_data_accessed_counter += 1\n",
    "    #if balanced_data_randomize_freq and balanced_data_accessed_counter > balanced_data_randomize_freq:\n",
    "    #    balanced_data_randomize()\n",
    "    balanced_data_last_sample = balanced_data.iloc[random.randint(1, balanced_data_length-1)]\n",
    "    return balanced_data_last_sample\n",
    "    \n",
    "balanced_data_randomize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4964"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sample_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "class\n",
       "ELECTRONIC    4964\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#all_data.groupby('class')['class'].count()\n",
    "#sample_data.groupby('class')['class'].count()\n",
    "balanced_data.groupby('class')['class'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentence_id                                               541782\n",
       "token_id                                                       4\n",
       "class                                                 ELECTRONIC\n",
       "before                                                  3.1.13.2\n",
       "after          t h r e e dot o n e dot t h i r t e e n dot t w o\n",
       "class_org                                             ELECTRONIC\n",
       "a_word_ind     [30, 45, 35, 28, 28, 74, 25, 29, 28, 74, 30, 4...\n",
       "sentence        exoribonuclease h ( ec <SAMPLE> ) is an enzyme .\n",
       "Name: 3599, dtype: object"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "balanced_data_sample_row()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ELECTRONIC : lessthan3.com -> l e s s t h a n t h r e e dot c o m <EOS> [42, 28, 17, 17, 30, 45, 22, 29, 30, 45, 35, 28, 28, 74, 21, 25, 32, 0]\n",
      "24th idma ( 2009 ) 25th idma ( 2010 ) 27th idma ( 2012 ) 30th idma ( 2015 ) 31 st idma ( 2016 ) <SAMPLE> : grammy nominations for deadmau5 , mat zo , and more .\n",
      "torch.Size([1, 14, 104])\n"
     ]
    }
   ],
   "source": [
    "def get_random_sample():\n",
    "    sample_row = balanced_data_sample_row()   \n",
    "    return sample_row['before'], sample_row['a_word_ind'], sample_row['class'], sample_row['sentence']\n",
    "            \n",
    "def tmp():\n",
    "    s_bef, s_aft, s_class, s_sentence = get_random_sample()\n",
    "    s_aft_str = ' '.join([words_after_common[i] for i in s_aft])\n",
    "    print(s_class, ':', s_bef, '->', s_aft_str, s_aft)\n",
    "    print(s_sentence)\n",
    "    print(string_to_tensor(s_bef, chars_normal_index).shape)\n",
    "tmp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "137 µs ± 1.53 µs per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "get_random_sample()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "use_cuda = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MAX_ATTENTION_LENGTH = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "106"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>token_id</th>\n",
       "      <th>class</th>\n",
       "      <th>before</th>\n",
       "      <th>after</th>\n",
       "      <th>class_org</th>\n",
       "      <th>a_word_ind</th>\n",
       "      <th>sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4388</th>\n",
       "      <td>663964</td>\n",
       "      <td>7</td>\n",
       "      <td>ELECTRONIC</td>\n",
       "      <td>http://www.ubu.es/ubu/cm/bubuhttp://www.ubu.es...</td>\n",
       "      <td>h t t p colon slash slash w w w dot u b u dot ...</td>\n",
       "      <td>ELECTRONIC</td>\n",
       "      <td>[45, 30, 30, 24, 129, 101, 101, 52, 52, 52, 74...</td>\n",
       "      <td>biblioteca universitaria de la universidad de ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4478</th>\n",
       "      <td>676846</td>\n",
       "      <td>17</td>\n",
       "      <td>ELECTRONIC</td>\n",
       "      <td>http://www.instrumentationservices.net/hand-he...</td>\n",
       "      <td>h t t p colon slash slash w w w dot i n s t r ...</td>\n",
       "      <td>ELECTRONIC</td>\n",
       "      <td>[45, 30, 30, 24, 129, 101, 101, 52, 52, 52, 74...</td>\n",
       "      <td>carbon resistors ( pdf ) , retrieved 2011 - 11...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      sentence_id  token_id       class  \\\n",
       "4388       663964         7  ELECTRONIC   \n",
       "4478       676846        17  ELECTRONIC   \n",
       "\n",
       "                                                 before  \\\n",
       "4388  http://www.ubu.es/ubu/cm/bubuhttp://www.ubu.es...   \n",
       "4478  http://www.instrumentationservices.net/hand-he...   \n",
       "\n",
       "                                                  after   class_org  \\\n",
       "4388  h t t p colon slash slash w w w dot u b u dot ...  ELECTRONIC   \n",
       "4478  h t t p colon slash slash w w w dot i n s t r ...  ELECTRONIC   \n",
       "\n",
       "                                             a_word_ind  \\\n",
       "4388  [45, 30, 30, 24, 129, 101, 101, 52, 52, 52, 74...   \n",
       "4478  [45, 30, 30, 24, 129, 101, 101, 52, 52, 52, 74...   \n",
       "\n",
       "                                               sentence  \n",
       "4388  biblioteca universitaria de la universidad de ...  \n",
       "4478  carbon resistors ( pdf ) , retrieved 2011 - 11...  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>token_id</th>\n",
       "      <th>class</th>\n",
       "      <th>before</th>\n",
       "      <th>after</th>\n",
       "      <th>class_org</th>\n",
       "      <th>a_word_ind</th>\n",
       "      <th>sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2187</th>\n",
       "      <td>339237</td>\n",
       "      <td>6</td>\n",
       "      <td>ELECTRONIC</td>\n",
       "      <td>Resultsnola.combestofneworleans.comthehullabal...</td>\n",
       "      <td>r e s u l t s n o l a dot c o m b e s t o f n ...</td>\n",
       "      <td>ELECTRONIC</td>\n",
       "      <td>[35, 28, 17, 43, 42, 30, 17, 29, 25, 42, 22, 7...</td>\n",
       "      <td>broadway to vegas february 15 , 2004 newslibra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021</th>\n",
       "      <td>313820</td>\n",
       "      <td>0</td>\n",
       "      <td>ELECTRONIC</td>\n",
       "      <td>Findagrave.comFindagrave.comFindagrave.comFind...</td>\n",
       "      <td>f i n d a g r a v e dot c o m f i n d a g r a ...</td>\n",
       "      <td>ELECTRONIC</td>\n",
       "      <td>[37, 31, 29, 26, 22, 53, 35, 22, 54, 28, 74, 2...</td>\n",
       "      <td>&lt;SAMPLE&gt; \" hibbard , spencer , bartlett &amp; co \" .</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      sentence_id  token_id       class  \\\n",
       "2187       339237         6  ELECTRONIC   \n",
       "2021       313820         0  ELECTRONIC   \n",
       "\n",
       "                                                 before  \\\n",
       "2187  Resultsnola.combestofneworleans.comthehullabal...   \n",
       "2021  Findagrave.comFindagrave.comFindagrave.comFind...   \n",
       "\n",
       "                                                  after   class_org  \\\n",
       "2187  r e s u l t s n o l a dot c o m b e s t o f n ...  ELECTRONIC   \n",
       "2021  f i n d a g r a v e dot c o m f i n d a g r a ...  ELECTRONIC   \n",
       "\n",
       "                                             a_word_ind  \\\n",
       "2187  [35, 28, 17, 43, 42, 30, 17, 29, 25, 42, 22, 7...   \n",
       "2021  [37, 31, 29, 26, 22, 53, 35, 22, 54, 28, 74, 2...   \n",
       "\n",
       "                                               sentence  \n",
       "2187  broadway to vegas february 15 , 2004 newslibra...  \n",
       "2021   <SAMPLE> \" hibbard , spencer , bartlett & co \" .  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp = sample_data[sample_data['before'].str.len()>MAX_ATTENTION_LENGTH]\n",
    "len(tmp)\n",
    "tmp.sample(2)\n",
    "tmp[~tmp['before'].str.contains('/')].sample(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EncoderRNN (\n",
       "  (rnn_words): LSTM(50, 64, batch_first=True, bidirectional=True)\n",
       "  (rnn_chars): LSTM(104, 128, batch_first=True, bidirectional=True)\n",
       ")"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, words_input_size, chars_input_size, words_hidden_size, chars_hidden_size,\n",
    "                 words_layers=1, chars_layers=1):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        \n",
    "        self.words_layers = words_layers\n",
    "        self.chars_layers = chars_layers\n",
    "        self.words_hidden_size = words_hidden_size\n",
    "        self.chars_hidden_size = chars_hidden_size\n",
    "        self.hidden_size = words_hidden_size + chars_hidden_size\n",
    "\n",
    "        self.rnn_words = nn.LSTM(words_input_size, words_hidden_size // 2, words_layers,\n",
    "                                 batch_first=True, bidirectional=True)\n",
    "\n",
    "        self.rnn_chars = nn.LSTM(chars_input_size, chars_hidden_size // 2, chars_layers,\n",
    "                                batch_first=True, bidirectional=True)\n",
    "        \n",
    "    def forward(self, word_vectors, string_tensor, hidden = None, init_hidden = True):\n",
    "        if init_hidden:\n",
    "            hidden_words, hidden_chars = self.init_hidden()\n",
    "        \n",
    "        all_outputs_words, hidden_words = self.rnn_words(word_vectors, hidden_words)\n",
    "        output_words = all_outputs_words[:, -1]\n",
    "        \n",
    "        all_outputs_chars, hidden_chars = self.rnn_chars(string_tensor, hidden_chars)\n",
    "        output_chars = all_outputs_chars[:, -1]\n",
    "        \n",
    "        hidden_states_cat = Variable(torch.zeros(MAX_ATTENTION_LENGTH, self.hidden_size)).cuda()\n",
    "        for ei in range(min(MAX_ATTENTION_LENGTH, len(string_tensor[0]))):\n",
    "            hidden_states_cat[ei] = torch.cat((output_words, all_outputs_chars[0, ei].view(1,-1)), 1)\n",
    "                \n",
    "        output = torch.cat((output_words[0], output_chars[0]), 0)\n",
    "\n",
    "        #output = torch.cat((output_words, output_chars), 1)\n",
    "        \n",
    "        #return output, all_outputs_chars\n",
    "        return output, hidden_states_cat\n",
    "\n",
    "    def init_hidden(self):\n",
    "        var1_1 = Variable(torch.zeros(2 * self.words_layers, 1, self.words_hidden_size // 2))\n",
    "        var1_2 = Variable(torch.zeros(2 * self.words_layers, 1, self.words_hidden_size // 2))\n",
    "        var2_1 = Variable(torch.zeros(2 * self.chars_layers, 1, self.chars_hidden_size // 2))\n",
    "        var2_2 = Variable(torch.zeros(2 * self.chars_layers, 1, self.chars_hidden_size // 2))\n",
    "        \n",
    "        var1_1 = var1_1.cuda(); var1_2 = var1_2.cuda()\n",
    "        var2_1 = var2_1.cuda(); var2_2 = var2_2.cuda()\n",
    "        return ((var1_1, var1_2), (var2_1, var2_2))\n",
    "    \n",
    "    \n",
    "encoder_rnn = EncoderRNN(words_input_size=wv_vecs.shape[-1], chars_input_size=len(chars_normal),\n",
    "                         words_hidden_size=128, chars_hidden_size=256,\n",
    "                         words_layers=1, chars_layers=1).cuda()\n",
    "encoder_rnn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scrum.com\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Scrum.com'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([384])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 384])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def test_encoder_single_sample():\n",
    "    s_bef, s_aft, s_class, s_sentence = get_random_sample()\n",
    "    print(s_bef)\n",
    "    \n",
    "    words_t = Variable(words_to_word_vectors_tensor(list(s_sentence), wv_vecs, wv_idx)).cuda()\n",
    "    \n",
    "    string_t = string_to_tensor(s_bef, chars_normal_index)\n",
    "    string_t = Variable(string_t).cuda()\n",
    "    \n",
    "    return encoder_rnn(words_t, string_t), s_bef\n",
    "    \n",
    "(encoder_output, encoder_outputs), tmp = test_encoder_single_sample()\n",
    "tmp\n",
    "encoder_output.size()\n",
    "encoder_outputs.size()\n",
    "torch.eq(encoder_output, encoder_outputs[len(tmp)]).data.all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecoderRNN (\n",
       "  (rnn): GRU(384, 384, batch_first=True)\n",
       "  (lin_out): Linear (384 -> 1351)\n",
       "  (emb_lin): Linear (1351 -> 384)\n",
       "  (attn): Linear (768 -> 100)\n",
       "  (attn_combine): Linear (768 -> 384)\n",
       "  (dropout): Dropout (p = 0.1)\n",
       ")"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[torch.Size([1, 1351]), torch.Size([1, 1, 384]), torch.Size([1, 100])]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class DecoderRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, n_layers=1, dropout_p=0.1, max_length=MAX_ATTENTION_LENGTH):\n",
    "        super(DecoderRNN, self).__init__()\n",
    "        self.n_layers = n_layers\n",
    "        self.hidden_size = hidden_size\n",
    "        \n",
    "        #self.rnn = nn.GRU(input_size, hidden_size, n_layers,\n",
    "        self.rnn = nn.GRU(hidden_size, hidden_size, n_layers,\n",
    "                                 batch_first=True, bidirectional=False)\n",
    "        \n",
    "        self.lin_out = nn.Linear(hidden_size, input_size)\n",
    "        #self.softmax = nn.LogSoftmax()\n",
    "        \n",
    "        #self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        self.emb_lin = nn.Linear(input_size, hidden_size)\n",
    "        self.max_length = max_length\n",
    "        self.attn = nn.Linear(hidden_size*2, self.max_length)\n",
    "        self.attn_combine = nn.Linear(self.hidden_size * 2, self.hidden_size)\n",
    "        self.dropout = nn.Dropout(dropout_p)\n",
    "        \n",
    "    #def forward(self, char, hidden):\n",
    "    def forward(self, last_input, hidden, encoder_outputs):\n",
    "        #embedded = self.embedding(last_input).view(1, 1, -1)\n",
    "        embedded = self.emb_lin(last_input).view(1, 1, -1)\n",
    "        embedded = self.dropout(embedded)\n",
    "        #IPython.core.debugger.Pdb().set_trace()\n",
    "        #attn_weights = F.softmax(self.attn(torch.cat((char[0], hidden[0]), 1)))\n",
    "        attn_weights = F.softmax(self.attn(torch.cat((embedded[0], hidden[0]), 1)))\n",
    "        attn_applied = torch.bmm(attn_weights.unsqueeze(0), encoder_outputs.unsqueeze(0))\n",
    "        \n",
    "        output = torch.cat((embedded[0], attn_applied[0]), 1)\n",
    "        output = self.attn_combine(output).unsqueeze(0)\n",
    "\n",
    "        \n",
    "        output = F.relu(output)\n",
    "        output, hidden = self.rnn(output, hidden)\n",
    "\n",
    "        output = F.log_softmax(self.lin_out(output[0]))\n",
    "        return output, hidden, attn_weights\n",
    "    \n",
    "    def init_rest_hidden(self, input_var):\n",
    "        if self.n_layers > 1:\n",
    "            hid_var = Variable(torch.zeros(self.n_layers - 1, 1, self.hidden_size)).cuda()\n",
    "            res = torch.cat((input_var, hid_var), 0)\n",
    "            return res\n",
    "        else:\n",
    "            return input_var\n",
    "        \n",
    "\n",
    "decoder_rnn = DecoderRNN(input_size=len(words_after_common), hidden_size=encoder_output.size()[0], n_layers=1)\n",
    "decoder_rnn = decoder_rnn.cuda()\n",
    "decoder_rnn\n",
    "\n",
    "tmp_outputs = Variable(torch.zeros(MAX_ATTENTION_LENGTH, encoder_output.size()[0])).cuda()\n",
    "tmp_hiddens = decoder_rnn.init_rest_hidden(encoder_output.view(1,1,-1))\n",
    "tmp = decoder_rnn(Variable(sos_tensor).cuda(), tmp_hiddens, tmp_outputs)\n",
    "[v.size() for v in tmp]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "(0 ,.,.) = \n",
       "  1.2000  2.4000  3.6000  4.8000\n",
       "[torch.FloatTensor of size 1x1x4]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.bmm(torch.FloatTensor([1,0.1,0.1]).view(1,1,-1), torch.arange(0, 12).view(1,3,-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[torch.Size([1, 1351]), torch.Size([1, 1, 384]), torch.Size([1, 100])]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      " 883\n",
      "[torch.cuda.LongTensor of size 1x1 (GPU 0)]\n",
      "\n",
      "stigmatized\n"
     ]
    }
   ],
   "source": [
    "tmp_outputs = Variable(torch.zeros(MAX_ATTENTION_LENGTH, encoder_output.size()[0])).cuda()\n",
    "tmp_hiddens = decoder_rnn.init_rest_hidden(encoder_output.view(1,1,-1))\n",
    "tmp = decoder_rnn(Variable(sos_tensor).cuda(), tmp_hiddens, tmp_outputs)\n",
    "[v.size() for v in tmp]\n",
    "print(tmp[0].topk(1)[1])\n",
    "print(words_after_common[tmp[0].topk(1)[1].data[0][0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training etc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('odor reorganized reorganized reorganized reorganized reorganized reorganized reorganized reorganized reorganized reorganized reorganized reorganized reorganized reorganized reorganized reorganized reorganized reorganized reorganized',\n",
       " 'odor reorganized reorganized reorganized reorganized reorganized reorganized reorganized reorganized reorganized reorganized reorganized reorganized reorganized reorganized reorganized reorganized reorganized reorganized reorganized',\n",
       " 'd n a i n d i a dot c o m',\n",
       " ('DNAindia.com',\n",
       "  [26, 29, 22, 31, 29, 26, 31, 22, 74, 21, 25, 32, 0],\n",
       "  'ELECTRONIC',\n",
       "  '<SAMPLE> , 16 june 2007 .'))"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def test_model_single_sample(model=None, return_more=False, sample=False):\n",
    "    decoder_rnn.eval()\n",
    "    encoder_rnn.eval()\n",
    "    \n",
    "    if not sample:\n",
    "        sample = get_random_sample()\n",
    "    s_bef, s_aft, s_class, s_sentence = sample\n",
    "        \n",
    "    words_t = Variable(words_to_word_vectors_tensor(list(s_sentence), wv_vecs, wv_idx)).cuda()\n",
    "    \n",
    "    string_t = string_to_tensor(s_bef, chars_normal_index)\n",
    "    string_t = Variable(string_t).cuda()\n",
    "    \n",
    "    encoder_output, encoder_outputs = encoder_rnn(words_t, string_t)\n",
    "    \n",
    "    #encoder_output = encoder_output.view(1,1,-1)\n",
    "    \n",
    "    decoder_hidden = decoder_rnn.init_rest_hidden(encoder_outputs[0].view(1,1,-1))\n",
    "    decoder_input = Variable(sos_tensor).cuda()\n",
    "\n",
    "    decoded_output = []\n",
    "    decoder_attns_arr = []\n",
    "    max_length = 20\n",
    "    for _ in range(max_length):\n",
    "        decoder_output, decoder_hidden, decoder_attns = decoder_rnn(decoder_input, decoder_hidden, encoder_outputs)\n",
    "        decoder_attns_arr.append(decoder_attns)\n",
    "        #return decoder_output\n",
    "\n",
    "        topv, topi = decoder_output.data.topk(1)\n",
    "        word_index = topi[0][0]\n",
    "        word = words_after_common[word_index] # Use own prediction as next input\n",
    "                \n",
    "        if word == EOS_TOKEN:\n",
    "            break\n",
    "\n",
    "        decoded_output.append(word)\n",
    "        \n",
    "        #decoder_input = Variable(torch.LongTensor([word_index])).cuda()\n",
    "        \n",
    "        decoder_input = torch.zeros(1, 1, len(words_after_index))\n",
    "        decoder_input[0, 0, word_index] = 1\n",
    "        decoder_input = Variable(decoder_input).cuda()\n",
    "    \n",
    "    output = ' '.join(decoded_output)\n",
    "    sample_target = ' '.join([words_after_common[w] for w in s_aft][:-1])\n",
    "    \n",
    "    decoder_rnn.train()\n",
    "    encoder_rnn.train()\n",
    "    \n",
    "    if return_more:\n",
    "        return output, decoded_output, decoder_attns_arr, sample\n",
    "    \n",
    "    return output, output, sample_target, sample\n",
    "    \n",
    "tmp = test_model_single_sample(None)\n",
    "tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BookFinder.com => newcrush reorganized reorganized reorganized reorganized reorganized reorganized reorganized reorganized reorganized reorganized reorganized reorganized reorganized reorganized reorganized reorganized reorganized reorganized reorganized || [36, 25, 25, 59, 37, 31, 29, 26, 28, 35, 74, 21, 25, 32, 0] \n",
      "                  american water works association — <SAMPLE> , accessed june 5 , 2012 .\n",
      "DigitalWebbing.com => analog reorganized reorganized reorganized reorganized reorganized reorganized reorganized reorganized reorganized reorganized reorganized reorganized reorganized reorganized reorganized reorganized reorganized reorganized reorganized || [26, 31, 53, 31, 30, 22, 42, 52, 28, 36, 36, 31, 29, 53, 74, 21, 25, 32, 0] \n",
      "                  <SAMPLE> ( internet archive ) .\n"
     ]
    }
   ],
   "source": [
    "def print_local_wrong_predictions(max_results=10):\n",
    "    arr = get_some_wrong_predictions(None, test_model_single_sample, max_iterations=10000, max_results=max_results)\n",
    "    for sample, predict, output in arr:\n",
    "        s_bef, s_aft, s_class, s_sentence = sample\n",
    "        print(\"{:<14} => {:<14} || {} \\n{:>17} {}\".format(s_bef, predict, s_aft, '', s_sentence, ))\n",
    "print_local_wrong_predictions(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.00% (       0/     100)\n",
      "CPU times: user 2.29 s, sys: 12 ms, total: 2.3 s\n",
      "Wall time: 2.3 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "test_model_accuracy(encoder_rnn, test_model_single_sample, n_sample=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train(s_bef, s_aft, s_sentence, encoder_optimizer, decoder_optimizer, loss_function,\n",
    "          use_teacher_forcing, max_length=20):\n",
    "    \n",
    "    words_t = Variable(words_to_word_vectors_tensor(list(s_sentence), wv_vecs, wv_idx)).cuda()\n",
    "    \n",
    "    string_t = string_to_tensor(s_bef, chars_normal_index)\n",
    "    string_t = Variable(string_t).cuda()\n",
    "    \n",
    "    encoder_output, encoder_outputs = encoder_rnn(words_t, string_t)\n",
    "    \n",
    "    #encoder_output = encoder_output.view(1,1,-1)\n",
    "    \n",
    "    decoder_hidden = decoder_rnn.init_rest_hidden(encoder_outputs[0].view(1,1,-1))\n",
    "    decoder_input = Variable(sos_tensor).cuda()\n",
    "    \n",
    "    ###\n",
    "    target_arr = s_aft\n",
    "    #target_arr = after_sentence_to_word_indexes(s_aft, include_eos=True)\n",
    "    \n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "    loss = 0\n",
    "    \n",
    "    decoded_output = []\n",
    "    for i in range(len(target_arr)):\n",
    "        decoder_output, decoder_hidden, decoder_attns = decoder_rnn(decoder_input, decoder_hidden, encoder_outputs)\n",
    "\n",
    "        #decoder_target_i = chars_after_index[target_arr[i]]\n",
    "        decoder_target_i = target_arr[i]\n",
    "        decoder_target_i = Variable(torch.LongTensor([decoder_target_i])).cuda()\n",
    "        loss += loss_function(decoder_output, decoder_target_i)\n",
    "        \n",
    "        topv, topi = decoder_output.data.topk(1)\n",
    "        word_index = topi[0][0]\n",
    "        word = words_after_common[word_index] # Use own prediction as next input\n",
    "        decoded_output.append(word)\n",
    "        \n",
    "        if use_teacher_forcing:\n",
    "            word_index = target_arr[i] # replace input with right target\n",
    "        else:\n",
    "            # use output normally as input \n",
    "            if word == EOS_TOKEN:\n",
    "                break\n",
    "                \n",
    "        decoder_input = torch.zeros(1, 1, len(words_after_index))\n",
    "        decoder_input[0, 0, word_index] = 1\n",
    "        decoder_input = Variable(decoder_input).cuda()\n",
    "        #decoder_input = Variable(torch.LongTensor([word_index])).cuda()\n",
    "        \n",
    "    if decoded_output[-1] == EOS_TOKEN:\n",
    "        decoded_output = decoded_output[:-1]\n",
    "        \n",
    "    loss.backward()\n",
    "\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "\n",
    "    return ' '.join(decoded_output), (loss.data[0] / len(target_arr))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_iterations(n_iters=100000, lr=0.001, teacher_forcing_ratio=0.5,\n",
    "                     print_every=10000, plot_every=1000):\n",
    "\n",
    "    start = time.time()\n",
    "    \n",
    "    decoder_rnn.train()\n",
    "    encoder_rnn.train()\n",
    "\n",
    "    current_loss = 0\n",
    "    current_loss_iter = 0\n",
    "\n",
    "    encoder_optimizer = torch.optim.Adam(encoder_rnn.parameters(), lr=lr)\n",
    "    decoder_optimizer = torch.optim.Adam(decoder_rnn.parameters(), lr=lr)\n",
    "    loss_function = nn.NLLLoss()\n",
    "    \n",
    "    for iteration in range(1, n_iters + 1):\n",
    "        model_training.iterations += 1\n",
    "        \n",
    "        use_teacher_forcing = random.random() < teacher_forcing_ratio\n",
    "        \n",
    "        s_bef, s_aft, s_class, s_sentence = get_random_sample()\n",
    "        \n",
    "        result, loss = train(s_bef=s_bef, s_aft=s_aft, s_sentence=s_sentence,\n",
    "                             encoder_optimizer=encoder_optimizer, decoder_optimizer=decoder_optimizer,\n",
    "                             loss_function=nn.NLLLoss(), use_teacher_forcing=use_teacher_forcing,\n",
    "                             max_length=40 )\n",
    "        \n",
    "        current_loss += loss\n",
    "        current_loss_iter += 1\n",
    "\n",
    "        # Print iter number, loss, name and guess\n",
    "        if iteration % print_every == 0:\n",
    "            teacher_forcing_str = \"\"\n",
    "            if use_teacher_forcing:\n",
    "                teacher_forcing_str = \"(forcing)\"\n",
    "            s_aft_sentence = ' '.join([words_after_common[w] for w in s_aft][:-1])\n",
    "            correct = '✓' if result == s_aft_sentence else \"✗: {}\".format(s_aft_sentence)\n",
    "            \n",
    "            print(\"{:>6d} {:>4.0%} ({:>8}) {:>7.3f}   | {:>6.2f}: {} -> {} ({}) {}\".format(\n",
    "                      model_training.iterations, iteration/n_iters, time_since(start),\n",
    "                      current_loss/current_loss_iter, loss,\n",
    "                      s_bef, result, correct, teacher_forcing_str))\n",
    "\n",
    "        # Add current loss avg to list of losses\n",
    "        if iteration % plot_every == 0:\n",
    "            model_training.losses.append(current_loss / plot_every)\n",
    "            model_training.learning_rates.append(lr)\n",
    "            current_loss = 0\n",
    "            current_loss_iter = 0\n",
    "            \n",
    "        if model_training.iterations % 50000 == 0 or model_training.iterations == 10:\n",
    "            model_training.save_models()\n",
    "            acc = test_model_accuracy(encoder_rnn, test_model_single_sample)\n",
    "            model_training.accuracy.append(acc)\n",
    "    \n",
    "    # test_model_accuracy(model, n_sample=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Save path: data/models/electronic_gen_1_testing\n"
     ]
    }
   ],
   "source": [
    "model_training = ModelTraining(MODEL_SAVE_PATH, [encoder_rnn, decoder_rnn])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     9  18% (   0m 1s)   7.194   |   7.17: Billboard.com -> tantalize krone dot dot dot dot dot dot dot dot dot dot dot dot (✗: b i l l b o a r d dot c o m) \n",
      "Saved model to data/models/electronic_gen_1_testing/10_(EncoderRNN/DecoderRNN)\n",
      "Accuracy: 0.00% (       0/   10000)\n",
      "    18  36% (   4m 6s)   7.179   |   7.16: Discogs.com -> decolonization dot dot dot dot dot dot dot dot dot dot dot (✗: d i s c o g s dot c o m) \n",
      "    27  54% (   4m 7s)   7.165   |   7.12: BioLib.cz -> dot dot dot dot dot dot dot dot dot dot (✗: b i o l i b dot c z) \n",
      "    36  72% (   4m 8s)   7.145   |   7.05: http://www.nedstat.com/nedstat-news-archive/359-nedstat-and-ecircle-announce-partnershipOmniture -> dot dot dot dot dot dot dot dot dot dot dot dot dot dot dot dot dot dot dot dot dot dot dot dot dot dot dot dot dot dot dot dot dot dot dot dot dot dot dot dot dot dot dot dot dot dot dot dot dot dot dot dot dot dot dot dot dot dot dot dot dot dot dot dot dot dot dot dot dot dot dot dot dot dot dot dot dot dot dot dot dot dot dot dot dot dot dot dot dot dot dot dot dot dot dot dot dot dot dot dot dot dot dot dot dot (✗: h t t p colon slash slash w w w dot n e d s t a t dot com slash n e d s t a t dash n e w s dash a r c h i v e slash t h r e e f i v e n i n e dash n e d s t a t dash a n d dash e c i r c l e dash a n n o u n c e dash p a r t n e r s h i p o m n i t u r e) (forcing)\n",
      "    45  90% (   4m 9s)   7.119   |   7.00: Schooldigger.com -> dot dot dot dot dot dot dot dot dot dot dot dot dot dot dot dot dot (✗: s c h o o l d i g g e r dot c o m) (forcing)\n"
     ]
    }
   ],
   "source": [
    "train_iterations(n_iters=50, print_every=9, lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   550  53% (  0m 42s)   3.541   |   3.02: nba.com -> a a e e e e e e (✗: n b a dot c o m) (forcing)\n"
     ]
    }
   ],
   "source": [
    "train_iterations(n_iters=(1000-model_training.iterations), print_every=500, lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 12936  11% ( 13m 58s)   1.888   |   1.41: grovemusic.com -> g u o g e r a s dot c dot c o m (✗: g r o v e m u s i c dot c o m) (forcing)\n",
      " 22936  22% ( 27m 31s)   1.437   |   1.92: Reddit.com -> r e d d i n e dot c o m (✗: r e d d i t dot c o m) \n",
      " 32936  33% ( 41m 11s)   1.192   |   1.02: thetelegraphandargus.co.uk -> t h e t e l e g r a a h a r d a r a a e t c o dot u k (✗: t h e t e l e g r a p h a n d a r g u s dot c o dot u k) (forcing)\n",
      " 42936  44% (  55m 2s)   1.017   |   0.72: BanknoteNews.com -> b a n k n o n e e n e s dot c o m (✗: b a n k n o t e n e w s dot c o m) \n",
      "Saved model to data/models/electronic_gen_1_testing/50000_(EncoderRNN/DecoderRNN)\n",
      "Accuracy: 26.72% (    2672/   10000)\n",
      " 52936  56% ( 72m 19s)   0.884   |   0.01: BBC.co.uk -> b b c dot c o dot u k (✓) (forcing)\n",
      " 62936  67% ( 86m 44s)   0.867   |   0.44: Amazon.ca -> a m a z o n dot c o m (✗: a m a z o n dot c a) \n",
      " 72936  78% (100m 55s)   0.774   |   0.09: National-Football-Teams.com -> n a t i o n a l d a s h f o o t b a l l d a s h t e a m s dot c o m (✓) (forcing)\n",
      " 82936  89% (115m 13s)   0.755   |   2.28: e.viii.2 -> e v i dot i i v i t (✗: e dot v i i i dot t w o) \n",
      " 92936 100% (129m 25s)   0.676   |   0.84: Amazon.comEngel -> a m a z z n o c o m g n g g <EOS> (✗: a m a z o n dot c o m e n g e l) (forcing)\n"
     ]
    }
   ],
   "source": [
    "train_iterations(n_iters=90000, print_every=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 97936  50% (  7m 11s)   0.613   |   0.32: wgaeast.org -> w g a a a s t dot o r g (✗: w g a e a s t dot o r g) (forcing)\n",
      "Saved model to data/models/electronic_gen_1_testing/100000_(EncoderRNN/DecoderRNN)\n",
      "Accuracy: 33.49% (    3349/   10000)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-62-857485e54e32>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_iterations\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_iters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprint_every\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-38-27807fc3707c>\u001b[0m in \u001b[0;36mtrain_iterations\u001b[0;34m(n_iters, lr, teacher_forcing_ratio, print_every, plot_every)\u001b[0m\n\u001b[1;32m     24\u001b[0m                              \u001b[0mencoder_optimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoder_optimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder_optimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdecoder_optimizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m                              \u001b[0mloss_function\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNLLLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_teacher_forcing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_teacher_forcing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m                              max_length=40 )\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0mcurrent_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-37-95336e4ebf15>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(s_bef, s_aft, s_sentence, encoder_optimizer, decoder_optimizer, loss_function, use_teacher_forcing, max_length)\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0mdecoded_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecoded_output\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0mencoder_optimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py3_pytorch_2/lib/python3.6/site-packages/torch/autograd/variable.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, retain_variables)\u001b[0m\n\u001b[1;32m    154\u001b[0m                 \u001b[0mVariable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m         \"\"\"\n\u001b[0;32m--> 156\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py3_pytorch_2/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(variables, grad_variables, retain_graph, create_graph, retain_variables)\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[0;32m---> 98\u001b[0;31m         variables, grad_variables, retain_graph)\n\u001b[0m\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_iterations(n_iters=10000, print_every=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iterations(n_iters=200000, print_every=10000, teacher_forcing_ratio=0.5, lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_local_wrong_predictions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iterations(n_iters=200000, print_every=10000, teacher_forcing_ratio=0.3, lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_local_wrong_predictions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iterations(n_iters=100000, print_every=10000, teacher_forcing_ratio=0.5, lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_local_wrong_predictions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iterations(n_iters=100000, print_every=10000, teacher_forcing_ratio=0.1, lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_local_wrong_predictions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iterations(n_iters=200000, print_every=10000, teacher_forcing_ratio=0.1, lr=0.0005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_local_wrong_predictions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iterations(n_iters=300000, print_every=10000, teacher_forcing_ratio=0.1, lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_local_wrong_predictions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iterations(n_iters=300000, print_every=10000, teacher_forcing_ratio=0, lr=0.0005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_local_wrong_predictions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iterations(n_iters=200000, print_every=10000, teacher_forcing_ratio=0, lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input:   InsideHigherEd.com\n",
      "output:  i n s i d e h i g h r e r d d dot c o m\n",
      "target:  i n s i d e h i g h e r e d dot c o m\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAxQAAAFeCAYAAAAc31myAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f8872f84898>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def debug_show_attention(input_sentence, output_words, attentions):\n",
    "    # Set up figure with colorbar\n",
    "    fig = plt.figure(figsize=(15,6))\n",
    "    ax = fig.add_subplot(111)\n",
    "    #cax = ax.matshow(attentions.numpy(), cmap='bone')\n",
    "    cax = ax.matshow(attentions, cmap='bone')\n",
    "    fig.colorbar(cax)\n",
    "    # Set up axes\n",
    "    #ax.set_xticklabels([''] + input_sentence.split(' ') + ['<EOS>'], rotation=90)\n",
    "    #ax.set_xticklabels([''] + input_sentence + ['<EOS>'], rotation=90)\n",
    "    ax.set_yticklabels([''] + output_words)\n",
    "    \n",
    "    input_sentence = input_sentence + ['<EOS>']\n",
    "    inp_arr = [\"{}\\n{}\".format(input_sentence[i], input_sentence[-1-i]) for i in range(len(input_sentence))]\n",
    "    ax.set_xticklabels([''] + inp_arr, rotation=0)\n",
    "\n",
    "    # Show label at every tick\n",
    "    ax.xaxis.set_major_locator(matplotlib.ticker.MultipleLocator(1))\n",
    "    ax.yaxis.set_major_locator(matplotlib.ticker.MultipleLocator(1))\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "def debug_eval_sample_show_attention():\n",
    "    \n",
    "    sample_row = balanced_data_sample_row()\n",
    "    sample_row = balanced_data[balanced_data['before'].str.len()>15].sample(1).iloc[0]\n",
    "    sample = sample_row['before'], sample_row['a_word_ind'], sample_row['class'], sample_row['sentence']\n",
    "\n",
    "    output, decoded_output, decoder_attns_arr, sample = test_model_single_sample(None, \n",
    "                                                            return_more=True, sample=sample)\n",
    "    print('input:  ', sample[0])\n",
    "    print('output: ', ' '.join(decoded_output))\n",
    "    print('target: ', ' '.join([words_after_common[w] for w in sample[1][:-1]]))\n",
    "\n",
    "    attns = np.array([arr.data[0].cpu().numpy() for arr in decoder_attns_arr])\n",
    "\n",
    "    debug_show_attention(list(sample[0]), decoded_output, attns)\n",
    "    #plt.matshow(attns)\n",
    "\n",
    "debug_eval_sample_show_attention()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:py3_pytorch_2]",
   "language": "python",
   "name": "conda-env-py3_pytorch_2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
