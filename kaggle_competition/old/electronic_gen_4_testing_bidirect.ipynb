{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pytorch utils oh: pytorch_utils_oh_2.py\n",
      "Pytorch: 0.2.0_4\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import importlib\n",
    "from pytorch_utils_oh_2 import *\n",
    "import IPython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MODEL_SAVE_PATH = 'electronic_gen_4_testing_no_words'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pytorch utils oh: pytorch_utils_oh_2.py\n",
      "Pytorch: 0.2.0_4\n"
     ]
    }
   ],
   "source": [
    "import pytorch_utils_oh_2; importlib.reload(pytorch_utils_oh_2); from pytorch_utils_oh_2 import *;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# all_data = pickle.load(open(\"data/en_train_fixed_4_sentences.pkl\", \"rb\" ))\n",
    "all_data = pickle.load(open(\"data/en_train_fixed_5_manual.pkl\", \"rb\" ))\n",
    "# all_data_sentence_index = all_data.set_index('sentence_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>token_id</th>\n",
       "      <th>class</th>\n",
       "      <th>before</th>\n",
       "      <th>after</th>\n",
       "      <th>class_org</th>\n",
       "      <th>a_word_ind</th>\n",
       "      <th>sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3712301</th>\n",
       "      <td>285733</td>\n",
       "      <td>3</td>\n",
       "      <td>LETTERS</td>\n",
       "      <td>EPAR</td>\n",
       "      <td>e p a r</td>\n",
       "      <td>LETTERS</td>\n",
       "      <td>[28, 24, 22, 35, 0]</td>\n",
       "      <td>\" bosulif : &lt;SAMPLE&gt; — product information \" (...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4392161</th>\n",
       "      <td>336765</td>\n",
       "      <td>11</td>\n",
       "      <td>ELECTRONIC</td>\n",
       "      <td>mobile.jobberman.com</td>\n",
       "      <td>m o b i l e dot j o b b e r m a n dot c o m</td>\n",
       "      <td>ELECTRONIC</td>\n",
       "      <td>[32, 25, 36, 31, 42, 28, 74, 60, 25, 36, 36, 2...</td>\n",
       "      <td>in september 2011 , jobberman . com launched t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         sentence_id  token_id       class                before  \\\n",
       "3712301       285733         3     LETTERS                  EPAR   \n",
       "4392161       336765        11  ELECTRONIC  mobile.jobberman.com   \n",
       "\n",
       "                                               after   class_org  \\\n",
       "3712301                                      e p a r     LETTERS   \n",
       "4392161  m o b i l e dot j o b b e r m a n dot c o m  ELECTRONIC   \n",
       "\n",
       "                                                a_word_ind  \\\n",
       "3712301                                [28, 24, 22, 35, 0]   \n",
       "4392161  [32, 25, 36, 31, 42, 28, 74, 60, 25, 36, 36, 2...   \n",
       "\n",
       "                                                  sentence  \n",
       "3712301  \" bosulif : <SAMPLE> — product information \" (...  \n",
       "4392161  in september 2011 , jobberman . com launched t...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "32992"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data = all_data[(all_data['class'] == 'LETTERS') | (all_data['class'] == 'ELECTRONIC')]\n",
    "all_data = all_data[all_data['after'].str.len() > 5]\n",
    "all_data.sample(2)\n",
    "len(all_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sample_data = all_data.copy()\n",
    "sample_data = sample_data.reset_index(drop=True)\n",
    "del(all_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sample_data = all_data.copy()\n",
    "sample_data = sample_data[sample_data['class'] == 'ELECTRONIC']\n",
    "print(\"Data rows: {},  (dropped rows: {})\".format(len(sample_data), len(all_data)-len(sample_data)))\n",
    "sample_data = sample_data.reset_index(drop=True)\n",
    "del(all_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ELECTRONIC', 'LETTERS']\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "categories_all = sorted(sample_data[\"class\"].unique())\n",
    "print(categories_all)\n",
    "print(len(categories_all))\n",
    "categories_index = dict((c, i) for i, c in enumerate(categories_all))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>token_id</th>\n",
       "      <th>class</th>\n",
       "      <th>before</th>\n",
       "      <th>after</th>\n",
       "      <th>class_org</th>\n",
       "      <th>a_word_ind</th>\n",
       "      <th>sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>29646</th>\n",
       "      <td>673699</td>\n",
       "      <td>8</td>\n",
       "      <td>ELECTRONIC</td>\n",
       "      <td>amazon.com</td>\n",
       "      <td>a m a z o n dot c o m</td>\n",
       "      <td>ELECTRONIC</td>\n",
       "      <td>[22, 32, 22, 105, 25, 29, 74, 21, 25, 32, 0]</td>\n",
       "      <td>dirty water dirty water cd track listing at &lt;S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7331</th>\n",
       "      <td>175773</td>\n",
       "      <td>15</td>\n",
       "      <td>LETTERS</td>\n",
       "      <td>d'état</td>\n",
       "      <td>d e acute t a t</td>\n",
       "      <td>LETTERS</td>\n",
       "      <td>[26, 28, 121, 30, 22, 30, 0]</td>\n",
       "      <td>he was arrested in 2001 , but released in marc...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       sentence_id  token_id       class      before                  after  \\\n",
       "29646       673699         8  ELECTRONIC  amazon.com  a m a z o n dot c o m   \n",
       "7331        175773        15     LETTERS      d'état        d e acute t a t   \n",
       "\n",
       "        class_org                                    a_word_ind  \\\n",
       "29646  ELECTRONIC  [22, 32, 22, 105, 25, 29, 74, 21, 25, 32, 0]   \n",
       "7331      LETTERS                  [26, 28, 121, 30, 22, 30, 0]   \n",
       "\n",
       "                                                sentence  \n",
       "29646  dirty water dirty water cd track listing at <S...  \n",
       "7331   he was arrested in 2001 , but released in marc...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_data.sample(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utils stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<SOS><EOS>☒ !\"#$%&'(),-./0123456789:;ABCDEFGHIJKLMNOPQRSTUVWXYZ_abcdefghijklmnopqrstuvwxyz~£¥ª²³µº¼½¾éɒʻˈΩμ—€⅓⅔⅛\n"
     ]
    }
   ],
   "source": [
    "chars_normal, chars_normal_index = load_characters_pkl('data/en_features/chars_normal.pkl')\n",
    "print(''.join(chars_normal))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "arr = list(sample_data['after'])\n",
    "arr = [s.split(' ') for s in arr]\n",
    "words_after = [EOS_TOKEN, SOS_TOKEN, UNKNOWN_WORD_TOKEN, NUMBER_WORD_TOKEN, SAMPLE_WORD_TOKEN]\n",
    "words_after = words_after + sorted(list(set(np.concatenate(arr))))\n",
    "words_after_index = dict((c, i) for i, c in enumerate(words_after))\n",
    "words_after_by_length = sorted(words_after, key=len, reverse=True)\n",
    "words_after_regex = re.compile('(' + ')|('.join(words_after_by_length) + ')')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "152"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(words_after)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "chars_after = [EOS_TOKEN, SOS_TOKEN] + sorted(list(set(list(''.join(list(sample_data['after']))))))\n",
    "chars_after_index = dict((c, i) for i, c in enumerate(chars_after))\n",
    "''.join(chars_after)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[32, 26, 92, 19, 0]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "['dot', 'd', 'o', 'c', '<EOS>']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def after_sentence_to_word_indexes(sentence, include_eos=True):\n",
    "    reg = re.finditer(words_after_regex, sentence)\n",
    "    arr = [words_after_index[s[0]] for s in reg]\n",
    "    if include_eos:\n",
    "        arr += [words_after_index[EOS_TOKEN]]\n",
    "    return arr\n",
    "tmp = after_sentence_to_word_indexes('dot d o c')\n",
    "tmp\n",
    "[words_after[t] for t in tmp]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 152])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sos_tensor = torch.zeros(1, 1, len(words_after_index))\n",
    "sos_tensor[0, 0, words_after_index[SOS_TOKEN]] = 1\n",
    "sos_tensor.size()\n",
    "#del(onehot_sos)\n",
    "\n",
    "# sos_tensor = torch.LongTensor([words_after_index[SOS_TOKEN]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GOMC -> g o m c <EOS> [52, 92, 82, 19, 0]\n",
      "torch.Size([1, 5, 104])\n"
     ]
    }
   ],
   "source": [
    "balanced_data_length = len(sample_data)\n",
    "def get_random_sample():\n",
    "    #sample_row = balanced_data_sample_row()\n",
    "    sample_row = balanced_data_last_sample = sample_data.iloc[random.randint(1, balanced_data_length-1)]\n",
    "    \n",
    "    a_words_ind = after_sentence_to_word_indexes(sample_row['after'], include_eos=True)\n",
    "    return sample_row['before'], a_words_ind\n",
    "            \n",
    "def tmp():\n",
    "    s_bef, s_aft = get_random_sample()\n",
    "    s_aft_str = ' '.join([words_after[i] for i in s_aft])\n",
    "    print(s_bef, '->', s_aft_str, s_aft)\n",
    "    print(string_to_tensor(s_bef, chars_normal_index).shape)\n",
    "tmp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "254 µs ± 5.59 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "get_random_sample()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "use_cuda = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MAX_ATTENTION_LENGTH = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "498"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>token_id</th>\n",
       "      <th>class</th>\n",
       "      <th>before</th>\n",
       "      <th>after</th>\n",
       "      <th>class_org</th>\n",
       "      <th>a_word_ind</th>\n",
       "      <th>sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12134</th>\n",
       "      <td>279820</td>\n",
       "      <td>3</td>\n",
       "      <td>ELECTRONIC</td>\n",
       "      <td>http://www.ungei.org/resources/files/154743e.p...</td>\n",
       "      <td>h t t p colon slash slash w w w dot u n g e i ...</td>\n",
       "      <td>ELECTRONIC</td>\n",
       "      <td>[45, 30, 30, 24, 129, 101, 101, 52, 52, 52, 74...</td>\n",
       "      <td>unesdoc database : &lt;SAMPLE&gt; , saranga and kath...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8734</th>\n",
       "      <td>204144</td>\n",
       "      <td>22</td>\n",
       "      <td>ELECTRONIC</td>\n",
       "      <td>http://www.calabasashistoricalsociety.org/City...</td>\n",
       "      <td>h t t p colon slash slash w w w dot c a l a b ...</td>\n",
       "      <td>ELECTRONIC</td>\n",
       "      <td>[45, 30, 30, 24, 129, 101, 101, 52, 52, 52, 74...</td>\n",
       "      <td>hogle , gene nac green book of pacific coast t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       sentence_id  token_id       class  \\\n",
       "12134       279820         3  ELECTRONIC   \n",
       "8734        204144        22  ELECTRONIC   \n",
       "\n",
       "                                                  before  \\\n",
       "12134  http://www.ungei.org/resources/files/154743e.p...   \n",
       "8734   http://www.calabasashistoricalsociety.org/City...   \n",
       "\n",
       "                                                   after   class_org  \\\n",
       "12134  h t t p colon slash slash w w w dot u n g e i ...  ELECTRONIC   \n",
       "8734   h t t p colon slash slash w w w dot c a l a b ...  ELECTRONIC   \n",
       "\n",
       "                                              a_word_ind  \\\n",
       "12134  [45, 30, 30, 24, 129, 101, 101, 52, 52, 52, 74...   \n",
       "8734   [45, 30, 30, 24, 129, 101, 101, 52, 52, 52, 74...   \n",
       "\n",
       "                                                sentence  \n",
       "12134  unesdoc database : <SAMPLE> , saranga and kath...  \n",
       "8734   hogle , gene nac green book of pacific coast t...  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>token_id</th>\n",
       "      <th>class</th>\n",
       "      <th>before</th>\n",
       "      <th>after</th>\n",
       "      <th>class_org</th>\n",
       "      <th>a_word_ind</th>\n",
       "      <th>sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13513</th>\n",
       "      <td>313820</td>\n",
       "      <td>0</td>\n",
       "      <td>ELECTRONIC</td>\n",
       "      <td>Findagrave.comFindagrave.comFindagrave.comFind...</td>\n",
       "      <td>f i n d a g r a v e dot c o m f i n d a g r a ...</td>\n",
       "      <td>ELECTRONIC</td>\n",
       "      <td>[37, 31, 29, 26, 22, 53, 35, 22, 54, 28, 74, 2...</td>\n",
       "      <td>&lt;SAMPLE&gt; \" hibbard , spencer , bartlett &amp; co \" .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11534</th>\n",
       "      <td>265794</td>\n",
       "      <td>11</td>\n",
       "      <td>ELECTRONIC</td>\n",
       "      <td>p.39Templeofschlock.blogpot.comDiscogs.comBlog...</td>\n",
       "      <td>p dot t h i r t y n i n e t e m p l e o f s c ...</td>\n",
       "      <td>ELECTRONIC</td>\n",
       "      <td>[24, 74, 30, 45, 31, 35, 30, 86, 29, 31, 29, 2...</td>\n",
       "      <td>7th edn , 2000myspace . comtempleofschlock . b...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       sentence_id  token_id       class  \\\n",
       "13513       313820         0  ELECTRONIC   \n",
       "11534       265794        11  ELECTRONIC   \n",
       "\n",
       "                                                  before  \\\n",
       "13513  Findagrave.comFindagrave.comFindagrave.comFind...   \n",
       "11534  p.39Templeofschlock.blogpot.comDiscogs.comBlog...   \n",
       "\n",
       "                                                   after   class_org  \\\n",
       "13513  f i n d a g r a v e dot c o m f i n d a g r a ...  ELECTRONIC   \n",
       "11534  p dot t h i r t y n i n e t e m p l e o f s c ...  ELECTRONIC   \n",
       "\n",
       "                                              a_word_ind  \\\n",
       "13513  [37, 31, 29, 26, 22, 53, 35, 22, 54, 28, 74, 2...   \n",
       "11534  [24, 74, 30, 45, 31, 35, 30, 86, 29, 31, 29, 2...   \n",
       "\n",
       "                                                sentence  \n",
       "13513   <SAMPLE> \" hibbard , spencer , bartlett & co \" .  \n",
       "11534  7th edn , 2000myspace . comtempleofschlock . b...  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp = sample_data[sample_data['before'].str.len()>MAX_ATTENTION_LENGTH]\n",
    "len(tmp)\n",
    "tmp.sample(2)\n",
    "tmp[~tmp['before'].str.contains('/')].sample(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EncoderRNN (\n",
       "  (rnn_chars): LSTM(104, 128, batch_first=True, bidirectional=True)\n",
       ")"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, chars_input_size, chars_hidden_size, chars_layers=1):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        \n",
    "        self.chars_layers = chars_layers\n",
    "        self.chars_hidden_size = chars_hidden_size\n",
    "\n",
    "        self.rnn_chars = nn.LSTM(chars_input_size, chars_hidden_size//2, chars_layers,\n",
    "                                 # batch_first=True, bidirectional=False)\n",
    "                                 batch_first=True, bidirectional=True)\n",
    "        \n",
    "    def forward(self, string_tensor, hidden = None, init_hidden = True):\n",
    "        if init_hidden:\n",
    "            hidden_chars = self.init_hidden()\n",
    "        \n",
    "        all_outputs_chars, hidden_chars = self.rnn_chars(string_tensor, hidden_chars)\n",
    "        output_chars = all_outputs_chars[:, -1]\n",
    "        \n",
    "        hidden_states_cat = Variable(torch.zeros(MAX_ATTENTION_LENGTH, self.chars_hidden_size)).cuda()\n",
    "        for ei in range(min(MAX_ATTENTION_LENGTH, len(string_tensor[0]))):\n",
    "            hidden_states_cat[ei] = all_outputs_chars[0, ei]\n",
    "                \n",
    "        #return output, all_outputs_chars\n",
    "        return output_chars[0], hidden_states_cat\n",
    "\n",
    "    def init_hidden(self):\n",
    "        var2_1 = Variable(torch.zeros(2 * self.chars_layers, 1, self.chars_hidden_size//2))\n",
    "        var2_2 = Variable(torch.zeros(2 * self.chars_layers, 1, self.chars_hidden_size//2))\n",
    "        \n",
    "        var2_1 = var2_1.cuda(); var2_2 = var2_2.cuda()\n",
    "        return (var2_1, var2_2)\n",
    "    \n",
    "    \n",
    "encoder_rnn = EncoderRNN(chars_input_size=len(chars_normal),\n",
    "                         chars_hidden_size=256, chars_layers=1).cuda()\n",
    "encoder_rnn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NAZARETHANA'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([256])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([50, 256])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def test_encoder_single_sample():\n",
    "    s_bef, s_aft = get_random_sample()\n",
    "\n",
    "    string_t = string_to_tensor(s_bef, chars_normal_index)\n",
    "    string_t = Variable(string_t).cuda()\n",
    "    \n",
    "    return encoder_rnn(string_t), s_bef\n",
    "    \n",
    "(encoder_output, encoder_outputs), tmp = test_encoder_single_sample()\n",
    "tmp\n",
    "encoder_output.size()\n",
    "encoder_outputs.size()\n",
    "torch.eq(encoder_output, encoder_outputs[len(tmp)]).data.all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecoderRNN (\n",
       "  (emb_lin): Linear (152 -> 256)\n",
       "  (attn): Linear (512 -> 50)\n",
       "  (attn_combine): Linear (512 -> 256)\n",
       "  (dropout): Dropout (p = 0.1)\n",
       "  (rnn): GRU(256, 256, batch_first=True)\n",
       "  (lin_out): Linear (256 -> 152)\n",
       ")"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class DecoderRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, n_layers=1, dropout_p=0.1, max_length=MAX_ATTENTION_LENGTH):\n",
    "        super(DecoderRNN, self).__init__()\n",
    "        self.n_layers = n_layers\n",
    "        self.hidden_size = hidden_size\n",
    "        self.max_length = max_length\n",
    "        \n",
    "        self.emb_lin = nn.Linear(input_size, hidden_size)\n",
    "        self.attn = nn.Linear(hidden_size*2, self.max_length)\n",
    "        self.attn_combine = nn.Linear(self.hidden_size * 2, self.hidden_size)\n",
    "        self.dropout = nn.Dropout(dropout_p)\n",
    "        \n",
    "        self.rnn = nn.GRU(hidden_size, hidden_size, n_layers, batch_first=True, bidirectional=False)\n",
    "        self.lin_out = nn.Linear(hidden_size, input_size)\n",
    "        \n",
    "    #def forward(self, char, hidden):\n",
    "    def forward(self, last_input, hidden, encoder_outputs):\n",
    "        embedded = self.emb_lin(last_input).view(1, 1, -1)\n",
    "        embedded = self.dropout(embedded)\n",
    "\n",
    "        attn_weights = F.softmax(self.attn(torch.cat((embedded[0], hidden[0]), 1)))\n",
    "        attn_applied = torch.bmm(attn_weights.unsqueeze(0), encoder_outputs.unsqueeze(0))\n",
    "        \n",
    "        rnn_input = torch.cat((embedded[0], attn_applied[0]), 1)\n",
    "        rnn_input = self.attn_combine(rnn_input).unsqueeze(0)\n",
    "        rnn_input = F.relu(rnn_input)\n",
    "        \n",
    "        output, hidden = self.rnn(rnn_input, hidden)\n",
    "        output = F.log_softmax(self.lin_out(output[0]))\n",
    "        \n",
    "        return output, hidden, attn_weights\n",
    "    \n",
    "    def init_rest_hidden(self, input_var):\n",
    "        if self.n_layers > 1:\n",
    "            hid_var = Variable(torch.zeros(self.n_layers - 1, 1, self.hidden_size)).cuda()\n",
    "            res = torch.cat((input_var, hid_var), 0)\n",
    "            return res\n",
    "        else:\n",
    "            return input_var\n",
    "        \n",
    "\n",
    "decoder_rnn = DecoderRNN(input_size=len(words_after), hidden_size=encoder_output.size()[0], n_layers=1)\n",
    "decoder_rnn = decoder_rnn.cuda()\n",
    "decoder_rnn\n",
    "\n",
    "tmp_outputs = Variable(torch.zeros(MAX_ATTENTION_LENGTH, encoder_output.size()[0])).cuda()\n",
    "tmp_hiddens = decoder_rnn.init_rest_hidden(encoder_output.view(1,1,-1))\n",
    "tmp = decoder_rnn(Variable(sos_tensor).cuda(), tmp_hiddens, tmp_outputs)\n",
    "#[v.size() for v in tmp]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 152])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 256])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([50, 256])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sos_tensor.size()\n",
    "tmp_hiddens.size()\n",
    "tmp_outputs.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[torch.Size([1, 152]), torch.Size([1, 1, 256]), torch.Size([1, 50])]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      " 103\n",
      "[torch.cuda.LongTensor of size 1x1 (GPU 0)]\n",
      "\n",
      "plus\n"
     ]
    }
   ],
   "source": [
    "tmp_outputs = Variable(torch.zeros(MAX_ATTENTION_LENGTH, encoder_output.size()[0])).cuda()\n",
    "tmp_hiddens = decoder_rnn.init_rest_hidden(encoder_output.view(1,1,-1))\n",
    "tmp = decoder_rnn(Variable(sos_tensor).cuda(), tmp_hiddens, tmp_outputs)\n",
    "[v.size() for v in tmp]\n",
    "print(tmp[0].topk(1)[1])\n",
    "print(words_after[tmp[0].topk(1)[1].data[0][0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training etc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('plus plus plus plus plus plus plus plus plus plus plus plus plus plus plus plus plus plus plus plus',\n",
       " 'plus plus plus plus plus plus plus plus plus plus plus plus plus plus plus plus plus plus plus plus',\n",
       " 'g e r d a b dot i r',\n",
       " ('gerdab.ir', [52, 33, 109, 26, 5, 13, 32, 65, 109, 0]))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def test_model_single_sample(model=None, return_more=False, sample=False):\n",
    "    decoder_rnn.eval()\n",
    "    encoder_rnn.eval()\n",
    "    \n",
    "    if not sample:\n",
    "        sample = get_random_sample()\n",
    "    s_bef, s_aft = sample\n",
    "    \n",
    "    string_t = string_to_tensor(s_bef, chars_normal_index)\n",
    "    string_t = Variable(string_t).cuda()\n",
    "    \n",
    "    encoder_output, encoder_outputs = encoder_rnn(string_t)\n",
    "        \n",
    "    decoder_hidden = decoder_rnn.init_rest_hidden(encoder_outputs[0].view(1,1,-1))\n",
    "    decoder_input = Variable(sos_tensor).cuda()\n",
    "\n",
    "    decoded_output = []\n",
    "    decoder_attns_arr = []\n",
    "    max_length = 20\n",
    "    for _ in range(max_length):\n",
    "        decoder_output, decoder_hidden, decoder_attns = decoder_rnn(decoder_input, decoder_hidden, encoder_outputs)\n",
    "        decoder_attns_arr.append(decoder_attns)\n",
    "        #return decoder_output\n",
    "\n",
    "        topv, topi = decoder_output.data.topk(1)\n",
    "        word_index = topi[0][0]\n",
    "        word = words_after[word_index] # Use own prediction as next input\n",
    "                \n",
    "        if word == EOS_TOKEN:\n",
    "            break\n",
    "\n",
    "        decoded_output.append(word)\n",
    "        \n",
    "        #decoder_input = Variable(torch.LongTensor([word_index])).cuda()\n",
    "        \n",
    "        decoder_input = torch.zeros(1, 1, len(words_after_index))\n",
    "        decoder_input[0, 0, word_index] = 1\n",
    "        decoder_input = Variable(decoder_input).cuda()\n",
    "    \n",
    "    output = ' '.join(decoded_output)\n",
    "    sample_target = ' '.join([words_after[w] for w in s_aft][:-1])\n",
    "    \n",
    "    decoder_rnn.train()\n",
    "    encoder_rnn.train()\n",
    "    \n",
    "    if return_more:\n",
    "        return output, decoded_output, decoder_attns_arr, sample\n",
    "    \n",
    "    return output, output, sample_target, sample\n",
    "    \n",
    "tmp = test_model_single_sample(None)\n",
    "tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NHPTV          => plus plus plus plus plus plus plus plus plus plus plus plus plus plus plus plus plus plus plus plus || [87, 59, 100, 124, 138, 0] \n",
      "                  \n",
      "ISTE           => plus plus plus plus plus plus plus plus plus plus plus plus plus plus plus plus plus plus plus plus || [65, 113, 124, 33, 0] \n",
      "                  \n"
     ]
    }
   ],
   "source": [
    "def print_local_wrong_predictions(max_results=10):\n",
    "    arr = get_some_wrong_predictions(None, test_model_single_sample, max_iterations=10000, max_results=max_results)\n",
    "    for sample, predict, output in arr:\n",
    "        s_bef, s_aft = sample\n",
    "        print(\"{:<14} => {:<14} || {} \\n{:>17} {}\".format(s_bef, predict, s_aft, '', '' ))\n",
    "print_local_wrong_predictions(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.00% (       0/     100)\n",
      "CPU times: user 2.02 s, sys: 0 ns, total: 2.02 s\n",
      "Wall time: 2.02 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "test_model_accuracy(encoder_rnn, test_model_single_sample, n_sample=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train(s_bef, s_aft, s_sentence, encoder_optimizer, decoder_optimizer, loss_function,\n",
    "          use_teacher_forcing, max_length=20):\n",
    "    \n",
    "    string_t = string_to_tensor(s_bef, chars_normal_index)\n",
    "    string_t = Variable(string_t).cuda()\n",
    "    \n",
    "    encoder_output, encoder_outputs = encoder_rnn(string_t)\n",
    "    \n",
    "    #encoder_output = encoder_output.view(1,1,-1)\n",
    "    \n",
    "    decoder_hidden = decoder_rnn.init_rest_hidden(encoder_outputs[0].view(1,1,-1))\n",
    "    decoder_input = Variable(sos_tensor).cuda()\n",
    "    \n",
    "    ###\n",
    "    target_arr = s_aft\n",
    "    #target_arr = after_sentence_to_word_indexes(s_aft, include_eos=True)\n",
    "    \n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "    loss = 0\n",
    "    \n",
    "    decoded_output = []\n",
    "    for i in range(len(target_arr)):\n",
    "        decoder_output, decoder_hidden, decoder_attns = decoder_rnn(decoder_input, decoder_hidden, encoder_outputs)\n",
    "\n",
    "        #decoder_target_i = chars_after_index[target_arr[i]]\n",
    "        decoder_target_i = target_arr[i]\n",
    "        decoder_target_i = Variable(torch.LongTensor([decoder_target_i])).cuda()\n",
    "        loss += loss_function(decoder_output, decoder_target_i)\n",
    "        \n",
    "        topv, topi = decoder_output.data.topk(1)\n",
    "        word_index = topi[0][0]\n",
    "        word = words_after[word_index] # Use own prediction as next input\n",
    "        decoded_output.append(word)\n",
    "        \n",
    "        if use_teacher_forcing:\n",
    "            word_index = target_arr[i] # replace input with right target\n",
    "        else:\n",
    "            # use output normally as input \n",
    "            if word == EOS_TOKEN:\n",
    "                break\n",
    "                \n",
    "        decoder_input = torch.zeros(1, 1, len(words_after_index))\n",
    "        decoder_input[0, 0, word_index] = 1\n",
    "        decoder_input = Variable(decoder_input).cuda()\n",
    "        #decoder_input = Variable(torch.LongTensor([word_index])).cuda()\n",
    "        \n",
    "    if decoded_output[-1] == EOS_TOKEN:\n",
    "        decoded_output = decoded_output[:-1]\n",
    "        \n",
    "    loss.backward()\n",
    "\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "\n",
    "    return ' '.join(decoded_output), (loss.data[0] / len(target_arr))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_iterations(n_iters=100000, lr=0.001, teacher_forcing_ratio=0.5,\n",
    "                     print_every=10000, plot_every=1000):\n",
    "\n",
    "    start = time.time()\n",
    "    \n",
    "    decoder_rnn.train()\n",
    "    encoder_rnn.train()\n",
    "\n",
    "    current_loss = 0\n",
    "    current_loss_iter = 0\n",
    "\n",
    "    encoder_optimizer = torch.optim.Adam(encoder_rnn.parameters(), lr=lr)\n",
    "    decoder_optimizer = torch.optim.Adam(decoder_rnn.parameters(), lr=lr)\n",
    "    loss_function = nn.NLLLoss()\n",
    "    \n",
    "    for iteration in range(1, n_iters + 1):\n",
    "        model_training.iterations += 1\n",
    "        \n",
    "        use_teacher_forcing = random.random() < teacher_forcing_ratio\n",
    "        \n",
    "        s_bef, s_aft = get_random_sample()\n",
    "        s_sentence=''\n",
    "        \n",
    "        result, loss = train(s_bef=s_bef, s_aft=s_aft, s_sentence=s_sentence,\n",
    "                             encoder_optimizer=encoder_optimizer, decoder_optimizer=decoder_optimizer,\n",
    "                             loss_function=nn.NLLLoss(), use_teacher_forcing=use_teacher_forcing,\n",
    "                             max_length=40 )\n",
    "        \n",
    "        current_loss += loss\n",
    "        current_loss_iter += 1\n",
    "\n",
    "        # Print iter number, loss, name and guess\n",
    "        if iteration % print_every == 0:\n",
    "            teacher_forcing_str = \"\"\n",
    "            if use_teacher_forcing:\n",
    "                teacher_forcing_str = \"(forcing)\"\n",
    "            s_aft_sentence = ' '.join([words_after[w] for w in s_aft][:-1])\n",
    "            correct = '✓' if result == s_aft_sentence else \"✗: {}\".format(s_aft_sentence)\n",
    "            \n",
    "            print(\"{:>6d} {:>4.0%} ({:>8}) {:>7.3f}   | {:>6.2f}: {} -> {} ({}) {}\".format(\n",
    "                      model_training.iterations, iteration/n_iters, time_since(start),\n",
    "                      current_loss/current_loss_iter, loss,\n",
    "                      s_bef, result, correct, teacher_forcing_str))\n",
    "\n",
    "        # Add current loss avg to list of losses\n",
    "        if iteration % plot_every == 0:\n",
    "            model_training.losses.append(current_loss / plot_every)\n",
    "            model_training.learning_rates.append(lr)\n",
    "            current_loss = 0\n",
    "            current_loss_iter = 0\n",
    "            \n",
    "        if model_training.iterations % 50000 == 0 or model_training.iterations == 10:\n",
    "            model_training.save_models()\n",
    "            acc = test_model_accuracy(encoder_rnn, test_model_single_sample)\n",
    "            model_training.accuracy.append(acc)\n",
    "    \n",
    "    # test_model_accuracy(model, n_sample=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Save path: data/models/electronic_gen_4_testing_no_words\n"
     ]
    }
   ],
   "source": [
    "model_training = ModelTraining(MODEL_SAVE_PATH, [encoder_rnn, decoder_rnn])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     9  18% (   0m 0s)   5.024   |   5.00: NARSTIE -> plus plus plus plus plus plus plus plus (✗: n a r s t i e) \n",
      "Saved model to data/models/electronic_gen_4_testing_no_words/10_(EncoderRNN/DecoderRNN)\n",
      "Accuracy: 0.00% (       0/   10000)\n",
      "    18  36% (  3m 34s)   4.399   |   4.97: IRRI -> <EOS> <EOS> <EOS> <EOS> (✗: i r r i) (forcing)\n",
      "    27  54% (  3m 34s)   4.143   |   4.93: ISBN -> <EOS> <EOS> <EOS> <EOS> (✗: i s b n) (forcing)\n",
      "    36  72% (  3m 35s)   3.791   |   1.00: PFLP ->  (✗: p f l p) \n",
      "    45  90% (  3m 35s)   3.547   |   0.29: ThisIsKent.co.uk ->  (✗: t h i s i s k e n t dot c o dot u k) \n"
     ]
    }
   ],
   "source": [
    "train_iterations(n_iters=50, print_every=9, lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   550  53% (   0m 8s)   2.351   |   2.63: ISBN -> i s <EOS> <EOS> (✗: i s b n) (forcing)\n"
     ]
    }
   ],
   "source": [
    "train_iterations(n_iters=(1000-model_training.iterations), print_every=500, lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 11000  10% (  4m 28s)   0.225   |   1.33: Browseinside.harpercollins.com -> b r o w s e i n s i d e dot h r m <EOS> p s dot o r a s s h h c o m (✗: b r o w s e i n s i d e dot h a r p e r c o l l i n s dot c o m) (forcing)\n",
      " 21000  20% (   9m 4s)   0.140   |   0.00: Ofie -> o f i e (✓) \n",
      " 31000  30% ( 13m 29s)   0.118   |   0.01: é -> e acute (✓) \n",
      " 41000  40% ( 17m 58s)   0.141   |   0.02: Iida's -> i i d a's (✓) (forcing)\n",
      "Saved model to data/models/electronic_gen_4_testing_no_words/50000_(EncoderRNN/DecoderRNN)\n",
      "Accuracy: 92.51% (    9251/   10000)\n",
      " 51000  51% ( 23m 39s)   0.119   |   0.01: srpskih -> s r p s k i h (✓) \n",
      " 61000  61% (  28m 7s)   0.139   |   2.73: U.T.O.P.I.A. -> u l t p o m m (✗: u t o p i a) \n",
      " 71000  71% ( 32m 26s)   0.354   |   0.03: TNA's -> t n a's (✓) \n",
      " 81000  81% ( 36m 46s)   0.189   |   0.02: NGOs -> n g o's (✓) \n",
      " 91000  91% (  41m 4s)   0.688   |   0.98: WHYN's -> w h y n (✗: w h y n's) \n",
      "Saved model to data/models/electronic_gen_4_testing_no_words/100000_(EncoderRNN/DecoderRNN)\n",
      "Accuracy: 58.95% (    5895/   10000)\n"
     ]
    }
   ],
   "source": [
    "train_iterations(n_iters=99000, print_every=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "110000  10% (  4m 15s)   0.425   |   0.01: ISBN -> i s b n (✓) (forcing)\n",
      "120000  20% (  8m 36s)   0.662   |   0.05: E&M -> e and m (✓) (forcing)\n",
      "130000  30% (  13m 1s)   0.725   |   0.03: WJLA -> w j l a (✓) \n",
      "140000  40% ( 17m 19s)   0.549   |   0.02: SBAO -> s b a o (✓) \n",
      "150000  50% ( 21m 40s)   0.489   |   0.01: ADMN -> a d m n (✓) \n",
      "Saved model to data/models/electronic_gen_4_testing_no_words/150000_(EncoderRNN/DecoderRNN)\n",
      "Accuracy: 75.45% (    7545/   10000)\n",
      "160000  60% ( 27m 27s)   0.467   |   0.07: DFAT -> d f a t (✓) \n",
      "170000  70% (  32m 7s)   0.878   |   0.11: Lidl -> l i d l (✓) (forcing)\n",
      "180000  80% ( 36m 28s)   0.713   |   0.05: WDSE -> w d s e (✓) \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-42-ac23592386f6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_iterations\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_iters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprint_every\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-37-37d440257daf>\u001b[0m in \u001b[0;36mtrain_iterations\u001b[0;34m(n_iters, lr, teacher_forcing_ratio, print_every, plot_every)\u001b[0m\n\u001b[1;32m     25\u001b[0m                              \u001b[0mencoder_optimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoder_optimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder_optimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdecoder_optimizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m                              \u001b[0mloss_function\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNLLLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_teacher_forcing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_teacher_forcing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m                              max_length=40 )\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0mcurrent_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-36-71d079fa1e0a>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(s_bef, s_aft, s_sentence, encoder_optimizer, decoder_optimizer, loss_function, use_teacher_forcing, max_length)\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0mdecoded_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecoded_output\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mencoder_optimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py3_pytorch_2/lib/python3.6/site-packages/torch/autograd/variable.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, retain_variables)\u001b[0m\n\u001b[1;32m    154\u001b[0m                 \u001b[0mVariable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m         \"\"\"\n\u001b[0;32m--> 156\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py3_pytorch_2/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(variables, grad_variables, retain_graph, create_graph, retain_variables)\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[0;32m---> 98\u001b[0;31m         variables, grad_variables, retain_graph)\n\u001b[0m\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_iterations(n_iters=100000, print_every=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input:   DHAMOIRHAT\n",
      "output:  d h a t h d t h h h h h h e\n",
      "target:    dhamoirhat\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAwoAAAFeCAYAAAAluOjpAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fad50e3a240>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def debug_show_attention(input_sentence, output_words, attentions):\n",
    "    # Set up figure with colorbar\n",
    "    fig = plt.figure(figsize=(15,6))\n",
    "    ax = fig.add_subplot(111)\n",
    "    #cax = ax.matshow(attentions.numpy(), cmap='bone')\n",
    "    cax = ax.matshow(attentions, cmap='bone')\n",
    "    fig.colorbar(cax)\n",
    "    # Set up axes\n",
    "    #ax.set_xticklabels([''] + input_sentence.split(' ') + ['<EOS>'], rotation=90)\n",
    "    #ax.set_xticklabels([''] + input_sentence + ['<EOS>'], rotation=90)\n",
    "    ax.set_yticklabels([''] + output_words)\n",
    "    \n",
    "    input_sentence = input_sentence + ['<EOS>']\n",
    "    inp_arr = [\"{}\\n{}\".format(input_sentence[i], input_sentence[-1-i]) for i in range(len(input_sentence))]\n",
    "    ax.set_xticklabels([''] + inp_arr, rotation=0)\n",
    "\n",
    "    # Show label at every tick\n",
    "    ax.xaxis.set_major_locator(matplotlib.ticker.MultipleLocator(1))\n",
    "    ax.yaxis.set_major_locator(matplotlib.ticker.MultipleLocator(1))\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "def debug_eval_sample_show_attention():\n",
    "    \n",
    "    output, decoded_output, decoder_attns_arr, sample = test_model_single_sample(None, return_more=True)\n",
    "    print('input:  ', sample[0])\n",
    "    print('output: ', ' '.join(decoded_output))\n",
    "    print('target:   ', ''.join([words_after[w] for w in sample[1][:-1]]))\n",
    "\n",
    "    attns = np.array([arr.data[0].cpu().numpy() for arr in decoder_attns_arr])\n",
    "\n",
    "    debug_show_attention(list(sample[0]), decoded_output, attns)\n",
    "    #plt.matshow(attns)\n",
    "\n",
    "debug_eval_sample_show_attention()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "1+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:py3_pytorch_2]",
   "language": "python",
   "name": "conda-env-py3_pytorch_2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
