{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker\n",
    "import numpy as np\n",
    "import random\n",
    "import time\n",
    "import os\n",
    "import pandas as pd\n",
    "import math\n",
    "import bcolz\n",
    "import pickle\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pytorch: 0.2.0_4\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "print(\"Pytorch: {}\".format(torch.__version__))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_data_org = pd.read_csv('data/en_train_org.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data rows: 9918390,  (dropped none rows: 51)\n"
     ]
    }
   ],
   "source": [
    "all_data_org[pd.isnull(all_data_org['before'])][:3]\n",
    "all_data = all_data_org.dropna()\n",
    "print(\"Data rows: {},  (dropped none rows: {})\".format(len(all_data), len(all_data_org)-len(all_data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data rows: 9840282,  (dropped (verbatim) rows: 78159)\n"
     ]
    }
   ],
   "source": [
    "all_data = all_data[all_data['class'] != 'VERBATIM']\n",
    "print(\"Data rows: {},  (dropped (verbatim) rows: {})\".format(len(all_data), len(all_data_org)-len(all_data)))\n",
    "all_data = all_data.reset_index(drop=True)\n",
    "# Note we dropped VERBATIM class. Thats because it had so many weird characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_data_sentence_index = all_data.set_index('sentence_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "number_classes = ['DATE','CARDINAL','MEASURE','ORDINAL','DECIMAL','MONEY', 'DIGIT', 'TELEPHONE', 'TIME', 'FRACTION', 'ADDRESS']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data rows: 448176,  (dropped rows: 9470265)\n"
     ]
    }
   ],
   "source": [
    "number_data = all_data[all_data['class'].isin(number_classes)]\n",
    "print(\"Data rows: {},  (dropped rows: {})\".format(len(number_data), len(all_data_org)-len(number_data)))\n",
    "number_data = number_data.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>token_id</th>\n",
       "      <th>class</th>\n",
       "      <th>before</th>\n",
       "      <th>after</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>200641</th>\n",
       "      <td>335558</td>\n",
       "      <td>4</td>\n",
       "      <td>DATE</td>\n",
       "      <td>1998</td>\n",
       "      <td>nineteen ninety eight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>339036</th>\n",
       "      <td>566585</td>\n",
       "      <td>7</td>\n",
       "      <td>CARDINAL</td>\n",
       "      <td>103</td>\n",
       "      <td>one hundred three</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>324061</th>\n",
       "      <td>542055</td>\n",
       "      <td>6</td>\n",
       "      <td>ORDINAL</td>\n",
       "      <td>12th</td>\n",
       "      <td>twelfth</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414269</th>\n",
       "      <td>691284</td>\n",
       "      <td>4</td>\n",
       "      <td>DATE</td>\n",
       "      <td>28 June 1944</td>\n",
       "      <td>the twenty eighth of june nineteen forty four</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>327889</th>\n",
       "      <td>548472</td>\n",
       "      <td>14</td>\n",
       "      <td>MEASURE</td>\n",
       "      <td>1\"</td>\n",
       "      <td>one inch</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        sentence_id  token_id     class        before  \\\n",
       "200641       335558         4      DATE          1998   \n",
       "339036       566585         7  CARDINAL           103   \n",
       "324061       542055         6   ORDINAL          12th   \n",
       "414269       691284         4      DATE  28 June 1944   \n",
       "327889       548472        14   MEASURE            1\"   \n",
       "\n",
       "                                                after  \n",
       "200641                          nineteen ninety eight  \n",
       "339036                              one hundred three  \n",
       "324061                                        twelfth  \n",
       "414269  the twenty eighth of june nineteen forty four  \n",
       "327889                                       one inch  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "number_data.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "class\n",
       "ADDRESS         522\n",
       "CARDINAL     133744\n",
       "DATE         258348\n",
       "DECIMAL        9821\n",
       "DIGIT          5442\n",
       "FRACTION       1196\n",
       "MEASURE       14783\n",
       "MONEY          6128\n",
       "ORDINAL       12703\n",
       "TELEPHONE      4024\n",
       "TIME           1465\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "number_data.groupby(\"class\")[\"class\"].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### More balanced sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "balanced_data_classes_select = list(number_data.groupby('class'))\n",
    "def balanced_data_randomize(max_len=10000):\n",
    "    global balanced_data\n",
    "    balanced_data = pd.concat([v.sample(min(max_len, len(v))) for k, v in balanced_data_classes_select])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 0 ns, sys: 0 ns, total: 0 ns\n",
      "Wall time: 6.44 µs\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "balanced_data_randomize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "class\n",
       "ADDRESS        522\n",
       "CARDINAL     10000\n",
       "DATE         10000\n",
       "DECIMAL       9821\n",
       "DIGIT         5442\n",
       "FRACTION      1196\n",
       "MEASURE      10000\n",
       "MONEY         6128\n",
       "ORDINAL      10000\n",
       "TELEPHONE     4024\n",
       "TIME          1465\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "balanced_data.groupby(\"class\")[\"class\"].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>token_id</th>\n",
       "      <th>class</th>\n",
       "      <th>before</th>\n",
       "      <th>after</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>205374</th>\n",
       "      <td>343553</td>\n",
       "      <td>12</td>\n",
       "      <td>CARDINAL</td>\n",
       "      <td>3,813</td>\n",
       "      <td>three thousand eight hundred thirteen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120708</th>\n",
       "      <td>200288</td>\n",
       "      <td>8</td>\n",
       "      <td>MONEY</td>\n",
       "      <td>$17,708</td>\n",
       "      <td>seventeen thousand seven hundred eight dollars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>330851</th>\n",
       "      <td>553311</td>\n",
       "      <td>4</td>\n",
       "      <td>DATE</td>\n",
       "      <td>10 April 1970</td>\n",
       "      <td>the tenth of april nineteen seventy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117815</th>\n",
       "      <td>195285</td>\n",
       "      <td>1</td>\n",
       "      <td>DIGIT</td>\n",
       "      <td>1</td>\n",
       "      <td>one</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101375</th>\n",
       "      <td>167088</td>\n",
       "      <td>6</td>\n",
       "      <td>DECIMAL</td>\n",
       "      <td>89.0</td>\n",
       "      <td>eighty nine point zero</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        sentence_id  token_id     class         before  \\\n",
       "205374       343553        12  CARDINAL          3,813   \n",
       "120708       200288         8     MONEY        $17,708   \n",
       "330851       553311         4      DATE  10 April 1970   \n",
       "117815       195285         1     DIGIT              1   \n",
       "101375       167088         6   DECIMAL           89.0   \n",
       "\n",
       "                                                 after  \n",
       "205374           three thousand eight hundred thirteen  \n",
       "120708  seventeen thousand seven hundred eight dollars  \n",
       "330851             the tenth of april nineteen seventy  \n",
       "117815                                             one  \n",
       "101375                          eighty nine point zero  "
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "balanced_data.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_glove(name):\n",
    "    with open(name, 'r') as f: lines = [line.split() for line in f]\n",
    "    words = [d[0] for d in lines]\n",
    "    vecs = np.stack(np.array(d[1:], dtype=np.float32) for d in lines)\n",
    "    wordidx = {o:i for i,o in enumerate(words)}\n",
    "    return vecs, words, wordidx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wv_vecs, wv_words, wv_idx = load_glove('/home/ohu/koodi/data/glove_wordvec/glove.6B.50d.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['asdf', \"'s\", 'asdf', '-', 'testaaa']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re_apos = re.compile(r\"(\\w)'s\\b\")         # make 's a separate word\n",
    "re_mw_punc = re.compile(r\"(\\w[’'])(\\w)\")  # other ' in a word creates 2 words\n",
    "re_punc = re.compile(\"([\\\"().,;:/_?!—])\") # add spaces around punctuation\n",
    "re_mult_space = re.compile(r\"  *\")        # replace multiple spaces with just one\n",
    "\n",
    "def simple_tokeniser(sent):\n",
    "    sent = re_apos.sub(r\"\\1 's\", sent)\n",
    "    sent = re_mw_punc.sub(r\"\\1 \\2\", sent)\n",
    "    sent = re_punc.sub(r\" \\1 \", sent).replace('-', ' - ')\n",
    "    sent = re_punc.sub(r\" \\1 \", sent)\n",
    "    sent = re_mult_space.sub(' ', sent)\n",
    "    return sent.lower().split()\n",
    "simple_tokeniser(\"asdf's   asdf   -testaaa\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "546"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr = list(set(list(number_data['after'])))\n",
    "arr = [s.split(' ') for s in arr]\n",
    "arr = np.concatenate(arr)\n",
    "arr = list(set(arr))\n",
    "number_words = ['<EOS>', '<SOS>'] + arr\n",
    "number_words_index = dict((c, i) for i, c in enumerate(number_words))\n",
    "len(number_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "arr = list(number_data['after'])\n",
    "arr = [s.split(' ') for s in arr]\n",
    "arr = np.concatenate(arr)\n",
    "tmp = {}\n",
    "for s in arr:\n",
    "    tmp[s] = tmp.get(s, 0) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "544"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "312"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr = []\n",
    "for a, b in tmp.items():\n",
    "    if b > 2:\n",
    "        arr.append(a)\n",
    "len(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "546\n",
      "en - records - e - wednesday - 12 - ag - caribbean - yrs - double - centimeter\n"
     ]
    }
   ],
   "source": [
    "print(len(number_words))\n",
    "print(' - '.join(random.sample(number_words, 10)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "o six sil o nine sil o five sil gen sil re sil executive sil john sil houldsworth sil pleads sil guilty sil in sil fraud sil scheme\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>token_id</th>\n",
       "      <th>class</th>\n",
       "      <th>before</th>\n",
       "      <th>after</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>406487</th>\n",
       "      <td>678277</td>\n",
       "      <td>4</td>\n",
       "      <td>TELEPHONE</td>\n",
       "      <td>06-09-05 GEN RE EXECUTIVE JOHN HOULDSWORTH PLE...</td>\n",
       "      <td>o six sil o nine sil o five sil gen sil re sil...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        sentence_id  token_id      class  \\\n",
       "406487       678277         4  TELEPHONE   \n",
       "\n",
       "                                                   before  \\\n",
       "406487  06-09-05 GEN RE EXECUTIVE JOHN HOULDSWORTH PLE...   \n",
       "\n",
       "                                                    after  \n",
       "406487  o six sil o nine sil o five sil gen sil re sil...  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp = number_data[number_data['after'].str.contains('guilty')]\n",
    "print(tmp['after'].iloc[0])\n",
    "tmp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categories and Chars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "letters_before_all = sorted(list(set(''.join(all_data['before']))))\n",
    "print(len(letters_before_all))\n",
    "letters_after_all = sorted(list(set(''.join(all_data['after']))))\n",
    "print(len(letters_after_all))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "112\n",
      " !\"#$%&'()+,-./0123456789:;?ABCDEFGHIJKLMNOPQRSTUVWXYZ[]_abcdefghijklmnopqrstuvwxyz|~¡£¥ª«²³µº»¼½¾¿éɒʻˈΩμ—€⅓⅔⅛⅝⅞\n"
     ]
    }
   ],
   "source": [
    "print(len(sorted(list(set(''.join(all_data['before']))))))\n",
    "print(''.join(sorted(list(set(''.join(all_data['before']))))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92\n",
      " \"$%'(),-./0123456789:ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz£¥ª²³µº¼½¾Ωμ€⅓⅔⅛⅝⅞\n"
     ]
    }
   ],
   "source": [
    "print(len(sorted(list(set(''.join(number_data['before']))))))\n",
    "print(''.join(sorted(list(set(''.join(number_data['before']))))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66\n",
      " \"$%'(),-./0123456789:abcdefghijklmnopqrstuvwxyz£¥ª²³µº¼½¾μω€⅓⅔⅛⅝⅞\n"
     ]
    }
   ],
   "source": [
    "print(len(sorted(list(set(''.join(number_data['before']).lower())))))\n",
    "print(''.join(sorted(list(set(''.join(number_data['before']).lower())))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<EOS><SOS> \"$%'(),-./0123456789:ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz£¥ª²³µº¼½¾Ωμ€⅓⅔⅛⅝⅞\n",
      "94\n"
     ]
    }
   ],
   "source": [
    "tmp = sorted(list(set(''.join(number_data['before']))))\n",
    "letters_all = ['<EOS>', '<SOS>'] + sorted(list(set(tmp)))\n",
    "letters_all_index = dict((c, i) for i, c in enumerate(letters_all))\n",
    "print(''.join(letters_all))\n",
    "print(len(letters_all))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "def char_to_tensor(char): # single onehot\n",
    "    tensor = torch.zeros(1, len(letters_all))\n",
    "    tensor[0, letters_all_index[char]] = 1\n",
    "    return tensor\n",
    "print(char_to_tensor('<EOS>')[0, 0] == 1)\n",
    "sos_variable = Variable(char_to_tensor('<SOS>')).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 6, 94])\n",
      "torch.Size([1, 7, 94])\n"
     ]
    }
   ],
   "source": [
    "def string_to_tensor(line, include_eos=True):\n",
    "    tensor_length = len(line)+1 if include_eos else len(line)\n",
    "    tensor = torch.zeros(1, tensor_length, len(letters_all))\n",
    "    for li, letter in enumerate(line):\n",
    "        tensor[0, li, letters_all_index[letter]] = 1\n",
    "    if include_eos:\n",
    "        tensor[0, -1, letters_all_index['<EOS>']] = 1\n",
    "    return tensor\n",
    "print(string_to_tensor('wordup', include_eos=False).size())\n",
    "print(string_to_tensor('wordup', include_eos=True).size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "arr = [simple_tokeniser(s_)[0] for s_ in list(all_data.sample(1000)['before'])]\n",
    "[s in wv_idx for s in arr].count(True) / 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 4, 50)"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def sentence_word_vectorize(str_list):\n",
    "    word_vect = np.zeros((1, len(str_list), wv_vecs.shape[1]), dtype=np.float32)\n",
    "    for i, w in enumerate(str_list):\n",
    "        if w=='<SAMPLE>':\n",
    "            word_vect[0][i] = np.zeros((1, wv_vecs.shape[1]))\n",
    "        else:\n",
    "            try:\n",
    "                word_vect[0][i] = wv_vecs[wv_idx[w]]\n",
    "            except KeyError:\n",
    "                word_vect[0][i] = np.random.rand(1, wv_vecs.shape[1])\n",
    "    return word_vect\n",
    "sentence_word_vectorize(['and', 'here', 'she', '<SAMPLE>']).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "(1, 3, 546)\n",
      "(1, 2, 546)\n"
     ]
    }
   ],
   "source": [
    "def number_words_onehot(word_list, include_eos=True):\n",
    "    if type(word_list) != list: raise\n",
    "    tensor_length = len(word_list)+1 if include_eos else len(word_list)\n",
    "    tensor = np.zeros((1, tensor_length, len(number_words)), dtype=np.float32)\n",
    "    for i, w in enumerate(word_list):\n",
    "        tensor[0,i,number_words_index[w]]=1\n",
    "    if include_eos:\n",
    "        tensor[0, -1, letters_all_index['<EOS>']] = 1\n",
    "    return tensor\n",
    "tmp = ['one', 'hundred']\n",
    "print(number_words[np.argmax(numbers_words_onehot(tmp)[0][0])] == tmp[0])\n",
    "print(number_words_onehot(tmp).shape)\n",
    "print(number_words_onehot(tmp, include_eos=False).shape)\n",
    "# print(numbers_words_onehot('single').shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 546])"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "number_words_onehot_sos = number_words_onehot(['<SOS>'], include_eos=False)\n",
    "number_words_onehot_sos = Variable(torch.from_numpy(number_words_onehot_sos)).cuda()\n",
    "number_words_onehot_sos.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MEASURE : 59 kg -> fifty nine kilograms\n",
      "She represented Australia at the 2010 Commonwealth Games in free style wrestling , finishing sixth in the U / <SAMPLE> division .\n",
      "(1, 22, 50)\n",
      "(1, 4, 546)\n"
     ]
    }
   ],
   "source": [
    "def get_random_sample():\n",
    "    sample_row = balanced_data.iloc[random.randint(1, len(balanced_data)-1)]\n",
    "    sentence_id = sample_row['class']\n",
    "\n",
    "    #rows = all_data[all_data['sentence_id']==sample_row['sentence_id']]\n",
    "    rows = all_data_sentence_index.loc[sample_row['sentence_id']]\n",
    "    befores = rows.before.values\n",
    "        \n",
    "    token_id_idx = list(rows['token_id']).index(sample_row['token_id'])\n",
    "    befores[token_id_idx] = '<SAMPLE>'\n",
    "    #sentence = ' '.join(befores)\n",
    "    #str_list = simple_tokeniser(sentence)\n",
    "    \n",
    "    #word_vect = word_vectorize(str_list)\n",
    "\n",
    "    return sample_row['before'], sample_row['after'], sample_row['class'], befores\n",
    "            \n",
    "def tmp():\n",
    "    # get_random_sample()\n",
    "    s_bef, s_aft, s_class, s_sentence = get_random_sample()\n",
    "    print(s_class, ':', s_bef, '->', s_aft)\n",
    "    print(' '.join(s_sentence))\n",
    "    print(sentence_word_vectorize(s_sentence).shape)\n",
    "    print(number_words_onehot(s_aft.split(' ')).shape)\n",
    "tmp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "427 µs ± 20.2 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "get_random_sample()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "use_cuda = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, wordvect_size, chars_input_size, words_hidden_size, chars_hidden_size,\n",
    "                 words_layers=1, chars_layers=1):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "\n",
    "        #self.train_iterations = 0\n",
    "        #self.train_history = []\n",
    "        \n",
    "        self.words_layers = words_layers\n",
    "        self.chars_layers = chars_layers\n",
    "        self.words_hidden_size = words_hidden_size\n",
    "        self.chars_hidden_size = chars_hidden_size\n",
    "        # self.output_size = output_size\n",
    "\n",
    "        self.rnn_words = nn.LSTM(wordvect_size, words_hidden_size // 2, words_layers,\n",
    "                                 batch_first=True, bidirectional=True)\n",
    "\n",
    "        self.rnn_chars = nn.LSTM(chars_input_size, chars_hidden_size // 2, chars_layers,\n",
    "                                batch_first=True, bidirectional=True)\n",
    "        \n",
    "        # self.lin_output = nn.Linear(hidden_size*2, output_size)\n",
    "\n",
    "    def forward(self, word_vectors, string_tensor, hidden = None, init_hidden = True):\n",
    "        if init_hidden:\n",
    "            hidden_words, hidden_chars = self.init_hidden()\n",
    "        \n",
    "        all_outputs_words, hidden_words = self.rnn_words(word_vectors, hidden_words)\n",
    "        output_words = all_outputs_words[:, -1]\n",
    "        \n",
    "        all_outputs_chars, hidden_chars = self.rnn_chars(string_tensor, hidden_chars)\n",
    "        output_chars = all_outputs_chars[:, -1]\n",
    "        \n",
    "        output = torch.cat((output_words, output_chars), 1)\n",
    "        \n",
    "        # output = self.lin_output(output)\n",
    "        # output = F.log_softmax(output)\n",
    "        return output\n",
    "\n",
    "    def init_hidden(self):\n",
    "        var1_1 = Variable(torch.zeros(2 * self.words_layers, 1, self.words_hidden_size // 2))\n",
    "        var1_2 = Variable(torch.zeros(2 * self.words_layers, 1, self.words_hidden_size // 2))\n",
    "        var2_1 = Variable(torch.zeros(2 * self.chars_layers, 1, self.chars_hidden_size // 2))\n",
    "        var2_2 = Variable(torch.zeros(2 * self.chars_layers, 1, self.chars_hidden_size // 2))\n",
    "        if use_cuda:\n",
    "            var1_1 = var1_1.cuda(); var1_2 = var1_2.cuda()\n",
    "            var2_1 = var2_1.cuda(); var2_2 = var2_2.cuda()\n",
    "        return ((var1_1, var1_2), (var2_1, var2_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word vect size: (1, 16, 50) . String vector size: torch.Size([1, 4, 94])\n",
      "Output: torch.Size([1, 192])\n"
     ]
    }
   ],
   "source": [
    "def get_encoder(debug=False):\n",
    "    # s_bef, s_aft, s_class, s_word_vs = get_random_sample()\n",
    "    s_bef, s_aft, s_class, s_sentence = get_random_sample()\n",
    "    \n",
    "    s_word_vs = sentence_word_vectorize(s_sentence)\n",
    "    s_string = string_to_tensor(s_bef)\n",
    "    target = number_words_onehot(s_aft.split(' '))\n",
    "    \n",
    "    encoder_rnn = EncoderRNN(wordvect_size=s_word_vs.shape[-1], chars_input_size=len(letters_all),\n",
    "                                      words_hidden_size=64, chars_hidden_size=128,\n",
    "                                      words_layers=1, chars_layers=1).cuda()\n",
    "    output_encoded = encoder_rnn(Variable(torch.from_numpy(s_word_vs)).cuda(), Variable(s_string).cuda())\n",
    "    if debug:\n",
    "        print('Word vect size:', s_word_vs.shape, '. String vector size:', s_string.size())\n",
    "        print('Output:', output_encoded.size())\n",
    "    return encoder_rnn, output_encoded;\n",
    "encoder_rnn, output_encoded = get_encoder(debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class DecoderRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, n_layers=1):\n",
    "        super(DecoderRNN, self).__init__()\n",
    "        self.n_layers = n_layers\n",
    "        self.hidden_size = hidden_size\n",
    "        \n",
    "        self.rnn = nn.GRU(input_size, hidden_size, n_layers,\n",
    "                                 batch_first=True, bidirectional=False)\n",
    "                         # LSTM would require own hidden included\n",
    "        \n",
    "        self.lin_out = nn.Linear(hidden_size, input_size)\n",
    "        #self.softmax = nn.LogSoftmax()\n",
    "\n",
    "    def forward(self, char, hidden):\n",
    "        #char = char.view(1,1,-1)\n",
    "        #hidden = hidden.view(1,1,-1)\n",
    "        output, hidden = self.rnn(char, hidden)\n",
    "        output = output[:, -1] # view(1,-1)\n",
    "        output = self.lin_out(output)\n",
    "        output = F.log_softmax(output)\n",
    "        return output, hidden\n",
    "\n",
    "decoder_rnn = DecoderRNN(input_size=len(number_words), hidden_size=output_encoded.size()[-1])\n",
    "decoder_rnn = decoder_rnn.cuda()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 546])\n",
      "Variable containing:\n",
      "-6.1277\n",
      "[torch.cuda.FloatTensor of size 1x1 (GPU 0)]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tmp_a, tmp_b = decoder_rnn(number_words_onehot_sos, output_encoded.view(1,1,-1))\n",
    "print(tmp_a.size())\n",
    "print(tmp_a.topk(1)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[torch.Size([1, 546]), torch.Size([1, 1, 192])]"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp_input = number_words_onehot([number_words[tmp_a.topk(1)[1].data[0][0]]])\n",
    "tmp_input = Variable(torch.from_numpy(tmp_input)).cuda()\n",
    "tmp = decoder_rnn(tmp_input, tmp_b)\n",
    "[t.size() for t in tmp]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training etc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def timeSince(since):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['one', 'hundred', '<EOS>']"
      ]
     },
     "execution_count": 267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"one hundred\".split(' ') + ['<EOS>']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train(s_bef, s_aft, s_sentence, encoder, decoder, encoder_optimizer, decoder_optimizer, loss_function,\n",
    "          use_teacher_forcing, max_length=20):\n",
    "\n",
    "    s_word_vs = sentence_word_vectorize(s_sentence)\n",
    "    s_bef_string = string_to_tensor(s_bef, include_eos=True)\n",
    "    target_arr = s_aft.split(' ') + ['<EOS>']\n",
    "    \n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "    loss = 0\n",
    "\n",
    "    encoder_output = encoder(Variable(torch.from_numpy(s_word_vs)).cuda(), Variable(s_bef_string).cuda())\n",
    "    encoder_output = encoder_output.view(1,1,-1)\n",
    "    decoder_hidden = encoder_output\n",
    "\n",
    "    decoder_input = number_words_onehot_sos\n",
    "\n",
    "    decoded_output = []\n",
    "    for i in range(len(target_arr)):\n",
    "        decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden)\n",
    "\n",
    "        decoder_target = number_words_index[target_arr[i]]\n",
    "        #print(decoder_target)\n",
    "        decoder_target = Variable(torch.LongTensor([decoder_target])).cuda()\n",
    "        \n",
    "        # import IPython; IPython.core.debugger.set_trace()\n",
    "        \n",
    "        loss += loss_function(decoder_output, decoder_target)\n",
    "\n",
    "        topv, topi = decoder_output.data.topk(1)\n",
    "        word_index = topi[0][0]\n",
    "        word = number_words[word_index] # Use own prediction as next input\n",
    "        decoded_output.append(word)\n",
    "        \n",
    "        if use_teacher_forcing:\n",
    "            word = target_arr[i] # replace input with right target\n",
    "        else:\n",
    "            # use output normally as input \n",
    "            if word == '<EOS>':\n",
    "                break\n",
    "\n",
    "        decoder_input = number_words_onehot([word], include_eos=False)\n",
    "        decoder_input = Variable(torch.from_numpy(decoder_input)).cuda()\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "\n",
    "    return((loss.data[0] / len(target_arr)), ' '.join(decoded_output))\n",
    "#print(train())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "encoder_rnn, output_encoded = get_encoder()\n",
    "decoder_rnn = DecoderRNN(input_size=len(number_words), hidden_size=output_encoded.size()[-1]).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_train_iterations = 0\n",
    "model_train_history = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_iterations(n_iters=100000, lr=0.001, teacher_forcing_ratio=0.5,\n",
    "                     print_every=5000, plot_every=1000):\n",
    "    global model_train_iterations\n",
    "    global model_train_history\n",
    "    start = time.time()\n",
    "    decoder_rnn.train()\n",
    "    encoder_rnn.train()\n",
    "\n",
    "    current_loss = 0\n",
    "    current_loss_iter = 0\n",
    "\n",
    "    encoder_optimizer = torch.optim.Adam(encoder_rnn.parameters(), lr=lr)\n",
    "    decoder_optimizer = torch.optim.Adam(decoder_rnn.parameters(), lr=lr)\n",
    "    loss_function = nn.NLLLoss()\n",
    "    \n",
    "    for iteration in range(1, n_iters + 1):\n",
    "        model_train_iterations += 1\n",
    "\n",
    "        use_teacher_forcing = random.random() < teacher_forcing_ratio\n",
    "        \n",
    "        s_bef, s_aft, s_class, s_sentence = get_random_sample()\n",
    "        \n",
    "        #print(s_class, ':', s_bef, '->', s_aft, '('+str(len(s_aft))+')')\n",
    "        loss, result = train(s_bef=s_bef, s_aft=s_aft, s_sentence=s_sentence,\n",
    "                             encoder=encoder_rnn, decoder=decoder_rnn,\n",
    "                             encoder_optimizer=encoder_optimizer, decoder_optimizer=decoder_optimizer,\n",
    "                             loss_function=nn.NLLLoss(), use_teacher_forcing=use_teacher_forcing,\n",
    "                             max_length=40 )\n",
    "\n",
    "        current_loss += loss\n",
    "        current_loss_iter += 1\n",
    "\n",
    "        # Print iter number, loss, name and guess\n",
    "        if iteration % print_every == 0:\n",
    "            teacher_forcing_str = \"\"\n",
    "            if use_teacher_forcing:\n",
    "                teacher_forcing_str = \"(forcing)\"\n",
    "            print(\"{:>6d} {:>4.0%} ({:>8}) {:>7.3f}   | {:>6.2f}: {} -> {} {} ({})\".format(\n",
    "                      model_train_iterations, iteration/n_iters, timeSince(start),\n",
    "                      current_loss/current_loss_iter, loss,\n",
    "                      s_bef, teacher_forcing_str, result, s_aft))\n",
    "\n",
    "        # Add current loss avg to list of losses\n",
    "        if iteration % plot_every == 0:\n",
    "            model_train_history.append((current_loss / plot_every, lr))\n",
    "            current_loss = 0\n",
    "            current_loss_iter = 0\n",
    "            \n",
    "        if model_train_iterations % 10000 == 0:\n",
    "            balanced_data_randomize()\n",
    "            \n",
    "        if model_train_iterations % 10000 == 0:\n",
    "            save_model()\n",
    "    \n",
    "    # test_model_accuracy(model, n_sample=10000)\n",
    "    if model_train_iterations > 1000:\n",
    "        test_model_accuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   100  10% (   0m 1s)   4.482   |   4.06: 1.16MW -> (forcing) <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> (one point one six megawatts)\n",
      "   200  20% (   0m 2s)   3.988   |   2.88: .1574 -> (forcing) point <EOS> <EOS> <EOS> <EOS> <EOS> (point one five seven four)\n",
      "   300  30% (   0m 3s)   3.785   |   3.52: 92.1% -> (forcing) one point <EOS> <EOS> <EOS> <EOS> (ninety two point one percent)\n",
      "   400  40% (   0m 4s)   3.708   |   4.05: 13 -> (forcing) two <EOS> (thirteen)\n",
      "   500  50% (   0m 5s)   3.649   |   2.13: 2002 -> (forcing) one <EOS> <EOS> <EOS> (two thousand two)\n",
      "   600  60% (   0m 7s)   3.562   |   2.80: .201 -> (forcing) one <EOS> <EOS> <EOS> <EOS> (point two o one)\n",
      "   700  70% (   0m 8s)   3.486   |   2.76: 2.4 km -> (forcing) one hundred one <EOS> <EOS> (two point four kilometers)\n",
      "   800  80% (   0m 9s)   3.432   |   2.33: 1,300 -> (forcing) nineteen hundred <EOS> <EOS> <EOS> (one thousand three hundred)\n",
      "   900  90% (  0m 10s)   3.388   |   6.91: 75 hl -> (forcing) nineteen point <EOS> <EOS> <EOS> (seventy five hecto liters)\n",
      "  1000 100% (  0m 12s)   3.337   |   2.76: US$ 1.3 million -> (forcing) one sil one sil <EOS> <EOS> (one point three million dollars)\n"
     ]
    }
   ],
   "source": [
    "train_iterations(n_iters=1000, print_every=100, teacher_forcing_ratio=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  8239  36% (  0m 12s)   1.760   |   0.54: VIII -> (forcing) the third <EOS> (the eighth)\n",
      "  9239  72% (  0m 23s)   1.602   |   1.97: 64 ->  five hundred <EOS> (sixty four)\n"
     ]
    }
   ],
   "source": [
    "train_iterations(n_iters=(10000-model_train_iterations), print_every=1000, teacher_forcing_ratio=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 15000  17% (  0m 57s)   1.059   |   0.86: 84 -> (forcing) forty eight <EOS> (eight four)\n",
      " 20000  33% (  1m 55s)   0.902   |   0.25: 1997 -> (forcing) nineteen ninety seven <EOS> (nineteen ninety seven)\n",
      " 25000  50% (  2m 53s)   0.705   |   0.37: 8.9 km2 -> (forcing) eight point nine square kilometers <EOS> (eight point nine square kilometers)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'data_balance_randomize_classes' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-379-2620bd0ec660>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_iterations\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_iters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprint_every\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mteacher_forcing_ratio\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-370-4c9b0fd29182>\u001b[0m in \u001b[0;36mtrain_iterations\u001b[0;34m(n_iters, lr, teacher_forcing_ratio, print_every, plot_every)\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmodel_train_iterations\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m25000\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m             \u001b[0mdata_balance_randomize_classes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmodel_train_iterations\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m25000\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'data_balance_randomize_classes' is not defined"
     ]
    }
   ],
   "source": [
    "train_iterations(n_iters=30000, print_every=5000, teacher_forcing_ratio=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 26000  20% (  0m 11s)   0.738   |   1.11: 1900 ->  nineteen o <EOS> (nineteen hundred)\n",
      " 27000  40% (  0m 22s)   0.768   |   0.15: 0.5/km² -> (forcing) zero point five per square kilometers <EOS> (zero point five per square kilometers)\n",
      " 28000  60% (  0m 34s)   0.733   |   0.02: 44% ->  forty four percent <EOS> (forty four percent)\n",
      " 29000  80% (  0m 45s)   0.710   |   0.78: 1896 ->  nineteen eighty six <EOS> (eighteen ninety six)\n",
      " 30000 100% (  0m 57s)   0.683   |   2.43: $17,054 ->  seventeen thousand five hundred fifty dollars (seventeen thousand fifty four dollars)\n"
     ]
    }
   ],
   "source": [
    "train_iterations(n_iters=(30000-model_train_iterations), print_every=1000, teacher_forcing_ratio=0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving: data/models/numbers_gen_1_rnn_30120\n",
      "Saving: data/models/numbers_gen_1_rnn_30130\n",
      "Saving: data/models/numbers_gen_1_rnn_30140\n",
      "Saving: data/models/numbers_gen_1_rnn_30150\n",
      " 30160  50% (   0m 0s)   0.696   |   2.87: 03 - 24 ->  three sil two sil sil sil (o three sil two four)\n",
      "Saving: data/models/numbers_gen_1_rnn_30160\n",
      "Saving: data/models/numbers_gen_1_rnn_30170\n",
      "Saving: data/models/numbers_gen_1_rnn_30180\n",
      "Saving: data/models/numbers_gen_1_rnn_30190\n",
      "Saving: data/models/numbers_gen_1_rnn_30200\n",
      " 30210 100% (   0m 1s)   0.611   |   0.01: 3.0 ->  three point zero <EOS> (three point zero)\n",
      "Saving: data/models/numbers_gen_1_rnn_30210\n"
     ]
    }
   ],
   "source": [
    "train_iterations(n_iters=100, print_every=50, teacher_forcing_ratio=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 35210  25% (  0m 58s)   0.615   |   0.00: .8 ->  point eight <EOS> (point eight)\n",
      "Saving: data/models/numbers_gen_1_rnn_40000\n",
      " 40210  51% (  1m 55s)   0.607   |   0.06: 2003 ->  two thousand three <EOS> (two thousand three)\n",
      " 45210  76% (  2m 52s)   0.536   |   0.72: $87,498 ->  eighty four thousand eight hundred ninety eight dollars <EOS> (eighty seven thousand four hundred ninety eight dollars)\n",
      "Saving: data/models/numbers_gen_1_rnn_50000\n"
     ]
    }
   ],
   "source": [
    "train_iterations(n_iters=(20000-(model_train_iterations%10000)), print_every=5000, teacher_forcing_ratio=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 55000  25% (  0m 58s)   0.488   |   0.00: 3rd ->  third <EOS> (third)\n",
      " 60000  50% (  1m 56s)   0.510   |   0.09: 1870 ->  eighteen seventy <EOS> (eighteen seventy)\n",
      "Saving: data/models/numbers_gen_1_rnn_60000\n",
      " 65000  75% (  2m 54s)   0.403   |   0.09: $21,118 ->  twenty one thousand one hundred eighteen dollars <EOS> (twenty one thousand one hundred eighteen dollars)\n",
      " 70000 100% (  3m 51s)   0.395   |   0.01: 30 ->  thirty <EOS> (thirty)\n",
      "Saving: data/models/numbers_gen_1_rnn_70000\n"
     ]
    }
   ],
   "source": [
    "train_iterations(n_iters=20000, print_every=5000, teacher_forcing_ratio=0.3, lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 75000  25% (  0m 57s)   0.317   |   0.00: 9.1 ->  nine point one <EOS> (nine point one)\n",
      " 80000  50% (  1m 55s)   0.324   |   0.06: 100 million ->  one hundred million <EOS> (one hundred million)\n",
      "Saving: data/models/numbers_gen_1_rnn_80000\n",
      " 85000  75% (  2m 53s)   0.295   |   0.26: 5:36pm ->  five thirty six p m <EOS> (five thirty six p m)\n",
      " 90000 100% (  3m 51s)   0.292   |   0.13: $25,481 ->  twenty five thousand four hundred eighty one dollars <EOS> (twenty five thousand four hundred eighty one dollars)\n",
      "Saving: data/models/numbers_gen_1_rnn_90000\n"
     ]
    }
   ],
   "source": [
    "train_iterations(n_iters=20000, print_every=5000, teacher_forcing_ratio=0.3, lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 95000  25% (  0m 57s)   0.421   |   0.66: 30 Apr. 2013 ->  the thirtieth of march twenty thirteen <EOS> (the thirtieth of april twenty thirteen)\n",
      "100000  50% (  1m 55s)   0.380   |   0.00: 5th ->  fifth <EOS> (fifth)\n",
      "Saving: data/models/numbers_gen_1_rnn_100000\n",
      "105000  75% (  2m 53s)   0.375   |   0.22: 2011 ->  twenty eleven <EOS> (twenty eleven)\n",
      "110000 100% (  3m 50s)   0.345   |   0.09: $38,485 ->  thirty eight thousand four hundred eighty five dollars <EOS> (thirty eight thousand four hundred eighty five dollars)\n",
      "Saving: data/models/numbers_gen_1_rnn_110000\n"
     ]
    }
   ],
   "source": [
    "train_iterations(n_iters=20000, print_every=5000, teacher_forcing_ratio=0.1, lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "115000  25% (  0m 57s)   0.317   |   0.01: 2 million ->  two million <EOS> (two million)\n",
      "120000  50% (  1m 54s)   0.299   |   0.03: $3,990 ->  three thousand nine hundred ninety dollars <EOS> (three thousand nine hundred ninety dollars)\n",
      "Saving: data/models/numbers_gen_1_rnn_120000\n",
      "125000  75% (  2m 52s)   0.284   |   0.28: $18,031 ->  eighteen thousand thirty one dollars <EOS> (eighteen thousand thirty one dollars)\n",
      "130000 100% (  3m 49s)   0.303   |   0.01: 24 ->  twenty four <EOS> (twenty four)\n",
      "Saving: data/models/numbers_gen_1_rnn_130000\n"
     ]
    }
   ],
   "source": [
    "train_iterations(n_iters=20000, print_every=5000, teacher_forcing_ratio=0, lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "135000  10% (   1m 1s)   0.400   |   0.05: 0.23% -> (forcing) zero point two three percent <EOS> (zero point two three percent)\n",
      "140000  20% (  1m 59s)   0.328   |   0.02: 20 ->  twenty <EOS> (twenty)\n",
      "Saving: data/models/numbers_gen_1_rnn_140000\n",
      "145000  30% (  2m 58s)   0.321   |   0.03: 2005 ->  two thousand five <EOS> (two thousand five)\n",
      "150000  40% (  3m 57s)   0.306   |   0.09: $10.05 million ->  ten point o five million dollars <EOS> (ten point o five million dollars)\n",
      "Saving: data/models/numbers_gen_1_rnn_150000\n",
      "155000  50% (  4m 56s)   0.290   |   0.01: 10,000m -> (forcing) ten thousand meters <EOS> (ten thousand meters)\n",
      "160000  60% (  5m 54s)   0.283   |   1.90: 47Gs -> (forcing) four seven giga hours <EOS> (forty seven giga seconds)\n",
      "Saving: data/models/numbers_gen_1_rnn_160000\n",
      "165000  70% (  6m 53s)   0.322   |   1.48: 978-2-04-019820-61992 -> (forcing) nine seven eight sil o sil eight eight two two two two two two nine sil nine <EOS> sil two sil sil (nine seven eight sil two sil o four sil o one nine eight two o sil six one nine nine two)\n",
      "170000  80% (  7m 51s)   0.324   |   0.75: 2010 -> (forcing) twenty o <EOS> (twenty ten)\n",
      "Saving: data/models/numbers_gen_1_rnn_170000\n",
      "175000  90% (  8m 52s)   0.262   |   0.11: 2,477 ft ->  two thousand four hundred seventy seven feet <EOS> (two thousand four hundred seventy seven feet)\n",
      "180000 100% (  9m 53s)   0.242   |   0.00: 1% ->  one percent <EOS> (one percent)\n",
      "Saving: data/models/numbers_gen_1_rnn_180000\n"
     ]
    }
   ],
   "source": [
    "train_iterations(n_iters=50000, print_every=5000, teacher_forcing_ratio=0.3, lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 81.16% (    8116/   10000)\n"
     ]
    }
   ],
   "source": [
    "test_model_accuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "185000  10% (  0m 58s)   0.337   |   1.47: £6,247,200 ->  six million two hundred seventy two thousand seven hundred twenty pounds (six million two hundred forty seven thousand two hundred pounds)\n",
      "190000  20% (  1m 57s)   0.316   |   0.55: 2006 ->  two thousand o six (two thousand six)\n",
      "Saving: data/models/numbers_gen_1_rnn_190000\n",
      "195000  30% (  2m 56s)   0.280   |   0.00: 20th -> (forcing) twentieth <EOS> (twentieth)\n",
      "200000  40% (  3m 54s)   0.258   |   0.10: May 13, 1919 ->  may thirteenth nineteen nineteen <EOS> (may thirteenth nineteen nineteen)\n",
      "Saving: data/models/numbers_gen_1_rnn_200000\n",
      "205000  50% (  4m 53s)   0.306   |   0.02: £15 ->  fifteen pounds <EOS> (fifteen pounds)\n",
      "210000  60% (  5m 53s)   0.315   |   0.02: 0.00 -> (forcing) zero point o o <EOS> (zero point o o)\n",
      "Saving: data/models/numbers_gen_1_rnn_210000\n",
      "215000  70% (  6m 51s)   0.260   |   0.00: 1 ->  one <EOS> (one)\n",
      "220000  80% (  7m 50s)   0.265   |   0.00: 1st ->  first <EOS> (first)\n",
      "Saving: data/models/numbers_gen_1_rnn_220000\n",
      "225000  90% (  8m 49s)   0.242   |   0.02: $600 million ->  six hundred million dollars <EOS> (six hundred million dollars)\n",
      "230000 100% (  9m 48s)   0.236   |   0.07: 1163 m ->  one thousand one hundred sixty three meters <EOS> (one thousand one hundred sixty three meters)\n",
      "Saving: data/models/numbers_gen_1_rnn_230000\n"
     ]
    }
   ],
   "source": [
    "train_iterations(n_iters=50000, print_every=5000, teacher_forcing_ratio=0.2, lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "235000  10% (  0m 57s)   0.234   |   0.03: 1:25 ->  one twenty five <EOS> (one twenty five)\n",
      "240000  20% (  1m 57s)   0.225   |   0.86: 1965 ->  nineteen nine five five <EOS> (one nine six five)\n",
      "Saving: data/models/numbers_gen_1_rnn_240000\n",
      "245000  30% (  2m 55s)   0.174   |   0.03: $19,755 ->  nineteen thousand seven hundred fifty five dollars <EOS> (nineteen thousand seven hundred fifty five dollars)\n",
      "250000  40% (  3m 54s)   0.189   |   0.01: $27,262 -> (forcing) twenty seven thousand two hundred sixty two dollars <EOS> (twenty seven thousand two hundred sixty two dollars)\n",
      "Saving: data/models/numbers_gen_1_rnn_250000\n",
      "255000  50% (  4m 52s)   0.170   |   0.00: 59th ->  fifty ninth <EOS> (fifty ninth)\n",
      "260000  60% (  5m 52s)   0.177   |   0.26: 3112th -> (forcing) three thousand one hundred twelfth <EOS> (three thousand one hundred twelfth)\n",
      "Saving: data/models/numbers_gen_1_rnn_260000\n",
      "265000  70% (  6m 52s)   0.180   |   0.01: 17.3% ->  seventeen point three percent <EOS> (seventeen point three percent)\n",
      "270000  80% (  7m 51s)   0.189   |   0.05: October 31, 2015 ->  october thirty first twenty fifteen <EOS> (october thirty first twenty fifteen)\n",
      "Saving: data/models/numbers_gen_1_rnn_270000\n",
      "275000  90% (  8m 50s)   0.148   |   0.01: 1979 -> (forcing) nineteen seventy nine <EOS> (nineteen seventy nine)\n",
      "280000 100% (  9m 49s)   0.208   |   1.26: 2009-05-23 ->  the twenty of of two thousand nine sil <EOS> (the twenty third of may two thousand nine)\n",
      "Saving: data/models/numbers_gen_1_rnn_280000\n"
     ]
    }
   ],
   "source": [
    "train_iterations(n_iters=50000, print_every=5000, teacher_forcing_ratio=0.2, lr=0.0001)\n",
    "test_model_accuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "285000  10% (  0m 58s)   0.257   |   1.51: 24.403 km² ->  twenty four point four o square kilometers <EOS> (twenty four point four o three square kilometers)\n",
      "290000  20% (  1m 58s)   0.279   |   0.00: 2 ->  two <EOS> (two)\n",
      "Saving: data/models/numbers_gen_1_rnn_290000\n",
      "295000  30% (  2m 57s)   0.235   |   0.00: 30% ->  thirty percent <EOS> (thirty percent)\n",
      "300000  40% (  3m 56s)   0.246   |   0.00: .166 -> (forcing) point one six six <EOS> (point one six six)\n",
      "Saving: data/models/numbers_gen_1_rnn_300000\n",
      "305000  50% (  4m 55s)   0.214   |   0.00: 2.09 ->  two point o nine <EOS> (two point o nine)\n",
      "310000  60% (  5m 54s)   0.235   |   0.02: 8,000 ->  eight thousand <EOS> (eight thousand)\n",
      "Saving: data/models/numbers_gen_1_rnn_310000\n",
      "315000  70% (  6m 54s)   0.254   |   0.12: II -> (forcing) the second <EOS> (the second)\n",
      "320000  80% (  7m 54s)   0.264   |   0.00: 1 ->  one <EOS> (one)\n",
      "Saving: data/models/numbers_gen_1_rnn_320000\n",
      "325000  90% (  8m 52s)   0.239   |   0.01: 90.31% -> (forcing) ninety point three one percent <EOS> (ninety point three one percent)\n",
      "330000 100% (  9m 50s)   0.255   |   0.02: £12.7 million -> (forcing) twelve point seven million pounds <EOS> (twelve point seven million pounds)\n",
      "Saving: data/models/numbers_gen_1_rnn_330000\n"
     ]
    }
   ],
   "source": [
    "train_iterations(n_iters=50000, print_every=5000, teacher_forcing_ratio=0.3, lr=0.001)\n",
    "test_model_accuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "335000  10% (  0m 58s)   0.196   |   0.01: $4,000 ->  four thousand dollars <EOS> (four thousand dollars)\n",
      "340000  20% (  1m 58s)   0.177   |   0.01: 1879 ->  eighteen seventy nine <EOS> (eighteen seventy nine)\n",
      "Saving: data/models/numbers_gen_1_rnn_340000\n",
      "345000  30% (  2m 57s)   0.183   |   0.38: A5 -> (forcing) a five <EOS> (a five)\n",
      "350000  40% (  3m 56s)   0.230   |   0.01: 1975 -> (forcing) nineteen seventy five <EOS> (nineteen seventy five)\n",
      "Saving: data/models/numbers_gen_1_rnn_350000\n",
      "355000  50% (  4m 55s)   0.197   |   0.05: $368,000 ->  three hundred sixty eight thousand dollars <EOS> (three hundred sixty eight thousand dollars)\n",
      "360000  60% (  5m 55s)   0.218   |   0.02: 7 July ->  the seventh of july <EOS> (the seventh of july)\n",
      "Saving: data/models/numbers_gen_1_rnn_360000\n",
      "365000  70% (  6m 54s)   0.205   |   0.17: Jul 2015 -> (forcing) july twenty fifteen <EOS> (july twenty fifteen)\n",
      "370000  80% (  7m 52s)   0.197   |   0.00: .38 ->  point three eight <EOS> (point three eight)\n",
      "Saving: data/models/numbers_gen_1_rnn_370000\n",
      "375000  90% (  8m 54s)   0.215   |   0.34: 978-0-571-22005-2 -> (forcing) nine seven eight sil o sil seven seven one sil two two o o two sil two <EOS> (nine seven eight sil o sil five seven one sil two two o o five sil two)\n",
      "380000 100% (  9m 55s)   0.214   |   0.00: 2nd ->  second <EOS> (second)\n",
      "Saving: data/models/numbers_gen_1_rnn_380000\n"
     ]
    }
   ],
   "source": [
    "train_iterations(n_iters=50000, print_every=10000, teacher_forcing_ratio=0.3, lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 84.52% (    8452/   10000)\n"
     ]
    }
   ],
   "source": [
    "test_model_accuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "440000  20% (  2m 10s)   0.183   |   0.01: 45 ->  forty five <EOS> (forty five)\n",
      "Saving: data/models/numbers_gen_1_rnn_440000\n",
      "450000  40% (  4m 21s)   0.175   |   0.06: 24 ->  two four <EOS> (two four)\n",
      "Saving: data/models/numbers_gen_1_rnn_450000\n",
      "460000  60% (  6m 35s)   0.178   |   0.00: 3 ->  three <EOS> (three)\n",
      "Saving: data/models/numbers_gen_1_rnn_460000\n",
      "470000  80% (  8m 50s)   0.141   |   2.02: 200921 ->  two o o nine two two <EOS> (two hundred thousand nine hundred twenty one)\n",
      "Saving: data/models/numbers_gen_1_rnn_470000\n",
      "480000 100% (  11m 3s)   0.142   |   0.00: $250,000 ->  two hundred fifty thousand dollars <EOS> (two hundred fifty thousand dollars)\n",
      "Saving: data/models/numbers_gen_1_rnn_480000\n",
      "Accuracy: 88.91% (    8891/   10000)\n"
     ]
    }
   ],
   "source": [
    "train_iterations(n_iters=50000, print_every=10000, teacher_forcing_ratio=0, lr=0.0001)\n",
    "test_model_accuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "490000  20% (   2m 9s)   0.145   |   0.00: 4.61 ->  four point six one <EOS> (four point six one)\n",
      "Saving: data/models/numbers_gen_1_rnn_490000\n",
      "500000  40% (  4m 20s)   0.125   |   0.06: A404 ->  a four o four <EOS> (a four o four)\n",
      "Saving: data/models/numbers_gen_1_rnn_500000\n",
      "510000  60% (  6m 31s)   0.188   |   0.00: 30 million ->  thirty million <EOS> (thirty million)\n",
      "Saving: data/models/numbers_gen_1_rnn_510000\n",
      "520000  80% (  8m 43s)   0.174   |   0.00: 69 ->  sixty nine <EOS> (sixty nine)\n",
      "Saving: data/models/numbers_gen_1_rnn_520000\n",
      "530000 100% ( 10m 53s)   0.137   |   0.00: 14 mm ->  fourteen millimeters <EOS> (fourteen millimeters)\n",
      "Saving: data/models/numbers_gen_1_rnn_530000\n",
      "Accuracy: 89.81% (    8981/   10000)\n"
     ]
    }
   ],
   "source": [
    "train_iterations(n_iters=50000, print_every=10000, teacher_forcing_ratio=0, lr=0.0001)\n",
    "test_model_accuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "540000  20% (   2m 2s)   0.132   |   0.01: 10.5 cm ->  ten point five centimeters <EOS> (ten point five centimeters)\n",
      "Saving: data/models/numbers_gen_1_rnn_540000\n",
      "550000  40% (   4m 3s)   0.149   |   0.01: July 17, 2012 ->  july seventeenth twenty twelve <EOS> (july seventeenth twenty twelve)\n",
      "Saving: data/models/numbers_gen_1_rnn_550000\n",
      "560000  60% (   6m 9s)   0.132   |   0.12: 28 April ->  the twenty eighth of april <EOS> (the twenty eighth of april)\n",
      "Saving: data/models/numbers_gen_1_rnn_560000\n",
      "570000  80% (  8m 11s)   0.124   |   0.00: $9,321 ->  nine thousand three hundred twenty one dollars <EOS> (nine thousand three hundred twenty one dollars)\n",
      "Saving: data/models/numbers_gen_1_rnn_570000\n",
      "580000 100% ( 10m 10s)   0.117   |   0.00: 2nd ->  second <EOS> (second)\n",
      "Saving: data/models/numbers_gen_1_rnn_580000\n",
      "Accuracy: 90.01% (    9001/   10000)\n"
     ]
    }
   ],
   "source": [
    "train_iterations(n_iters=50000, print_every=10000, teacher_forcing_ratio=0, lr=0.0001)\n",
    "test_model_accuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 90.29% (    9029/   10000)\n"
     ]
    }
   ],
   "source": [
    "test_model_accuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving: data/models/numbers_gen_1_rnn_640000\n",
      "650000  40% (  3m 59s)   0.175   |   0.01: 8,047 ->  eight thousand forty seven <EOS> (eight thousand forty seven)\n",
      "Saving: data/models/numbers_gen_1_rnn_650000\n",
      "Saving: data/models/numbers_gen_1_rnn_660000\n",
      "670000  80% (   8m 2s)   0.165   |   0.00: 1999 ->  nineteen ninety nine <EOS> (nineteen ninety nine)\n",
      "Saving: data/models/numbers_gen_1_rnn_670000\n",
      "Saving: data/models/numbers_gen_1_rnn_680000\n",
      "Accuracy: 84.72% (    8472/   10000)\n"
     ]
    }
   ],
   "source": [
    "train_iterations(n_iters=50000, print_every=20000, teacher_forcing_ratio=0, lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving: data/models/numbers_gen_1_rnn_690000\n",
      "700000  40% (   4m 2s)   0.160   |   0.01: 95.3 ->  ninety five point three <EOS> (ninety five point three)\n",
      "Saving: data/models/numbers_gen_1_rnn_700000\n",
      "Saving: data/models/numbers_gen_1_rnn_710000\n",
      "720000  80% (  7m 58s)   0.122   |   0.00: 3 ->  three <EOS> (three)\n",
      "Saving: data/models/numbers_gen_1_rnn_720000\n",
      "Saving: data/models/numbers_gen_1_rnn_730000\n",
      "Accuracy: 89.26% (    8926/   10000)\n"
     ]
    }
   ],
   "source": [
    "train_iterations(n_iters=50000, print_every=20000, teacher_forcing_ratio=0, lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving: data/models/numbers_gen_1_rnn_740000\n",
      "750000  40% (  3m 59s)   0.135   |   0.00: 8.5% ->  eight point five percent <EOS> (eight point five percent)\n",
      "Saving: data/models/numbers_gen_1_rnn_750000\n",
      "Saving: data/models/numbers_gen_1_rnn_760000\n",
      "770000  80% (  7m 57s)   0.135   |   0.00: 10.4 ->  ten point four <EOS> (ten point four)\n",
      "Saving: data/models/numbers_gen_1_rnn_770000\n",
      "Saving: data/models/numbers_gen_1_rnn_780000\n",
      "Accuracy: 90.05% (    9005/   10000)\n"
     ]
    }
   ],
   "source": [
    "train_iterations(n_iters=50000, print_every=20000, teacher_forcing_ratio=0, lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving: data/models/numbers_gen_1_rnn_790000\n",
      "800000  40% (   4m 1s)   0.137   |   1.46: $640 b ->  six hundred forty pounds <EOS> (six hundred forty billion dollars)\n",
      "Saving: data/models/numbers_gen_1_rnn_800000\n",
      "Saving: data/models/numbers_gen_1_rnn_810000\n",
      "820000  80% (   8m 9s)   0.087   |   0.00: £100,000 ->  one hundred thousand pounds <EOS> (one hundred thousand pounds)\n",
      "Saving: data/models/numbers_gen_1_rnn_820000\n",
      "Saving: data/models/numbers_gen_1_rnn_830000\n",
      "Accuracy: 90.85% (    9085/   10000)\n"
     ]
    }
   ],
   "source": [
    "train_iterations(n_iters=50000, print_every=20000, teacher_forcing_ratio=0, lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving: data/models/numbers_gen_1_rnn_840000\n",
      "850000  40% (  3m 54s)   0.109   |   1.48: I ->  the first (one)\n",
      "Saving: data/models/numbers_gen_1_rnn_850000\n",
      "Saving: data/models/numbers_gen_1_rnn_860000\n",
      "870000  80% (   8m 0s)   0.135   |   0.00: 1/3 ->  one third <EOS> (one third)\n",
      "Saving: data/models/numbers_gen_1_rnn_870000\n",
      "Saving: data/models/numbers_gen_1_rnn_880000\n",
      "Accuracy: 90.84% (    9084/   10000)\n"
     ]
    }
   ],
   "source": [
    "train_iterations(n_iters=50000, print_every=20000, teacher_forcing_ratio=0, lr=0.0001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'twelfth'"
      ]
     },
     "execution_count": 405,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def evaluate(encoder, decoder, s_bef, s_sentence, max_length=20):\n",
    "    encoder.eval()\n",
    "    decoder.eval()\n",
    "    s_word_vs = sentence_word_vectorize(s_sentence)\n",
    "    s_bef_string = string_to_tensor(s_bef, include_eos=True)\n",
    "\n",
    "    encoder_output = encoder(Variable(torch.from_numpy(s_word_vs)).cuda(), Variable(s_bef_string).cuda())\n",
    "    encoder_output = encoder_output.view(1,1,-1)\n",
    "    \n",
    "    decoder_hidden = encoder_output\n",
    "    decoder_input = number_words_onehot_sos\n",
    "\n",
    "    decoded_output = []\n",
    "    for _ in range(max_length):\n",
    "        decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden)\n",
    "\n",
    "        topv, topi = decoder_output.data.topk(1)\n",
    "        word_index = topi[0][0]\n",
    "        word = number_words[word_index] # Use own prediction as next input\n",
    "                \n",
    "        if word == '<EOS>':\n",
    "            break\n",
    "\n",
    "        decoded_output.append(word)\n",
    "        \n",
    "        decoder_input = number_words_onehot([word], include_eos=False)\n",
    "        decoder_input = Variable(torch.from_numpy(decoder_input)).cuda()\n",
    "\n",
    "    return ' '.join(decoded_output)\n",
    "\n",
    "evaluate(encoder_rnn, decoder_rnn, '12th', 'he was <SAMPLE>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000-07-02           ---> the twenty of july two thousand seven \n",
      "                       != the second of july two thousand\n",
      "1998-                ---> nineteen nine eight eight \n",
      "                       != one nine nine eight\n",
      "Accuracy: 80.00% (       8/      10)\n"
     ]
    }
   ],
   "source": [
    "def test_model_accuracy(n_sample=10000, print_wrongs=False):\n",
    "    balanced_data_randomize()\n",
    "    n_correct = 0\n",
    "    for iteration in range(n_sample):\n",
    "        s_bef, s_aft, s_class, s_sentence = get_random_sample()\n",
    "        output = evaluate(encoder_rnn, decoder_rnn, s_bef, s_sentence)\n",
    "        if s_aft == output:\n",
    "            n_correct += 1\n",
    "        else:\n",
    "            if print_wrongs:\n",
    "                print(\"{:<20} ---> {} \\n{:<22} != {}\".format(s_bef, output, '', s_aft))\n",
    "                \n",
    "\n",
    "    print(\"Accuracy: {:>4.2%} ({:>8d}/{:>8d})\".format(\n",
    "            n_correct/n_sample, n_correct, n_sample))\n",
    "\n",
    "test_model_accuracy(10, print_wrongs=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "91-85884-52-9        ---> nine one sil eight five eight five five sil five five sil nine \n",
      "                       != nine one sil eight five eight eight four sil five two sil nine\n",
      "US 420               ---> s r two forty \n",
      "                       != u s four twenty\n",
      "1930                 ---> nineteen thirty \n",
      "                       != one nine three o\n",
      "2001-08-24           ---> the twenty fourth of april two thousand \n",
      "                       != the twenty fourth of august two thousand one\n",
      "1998                 ---> nineteen thousand nine hundred ninety eight \n",
      "                       != one thousand nine hundred ninety eight\n",
      "0066 - EN            ---> o o six six sil \n",
      "                       != o o six six sil en\n",
      "0000 UTC             ---> o o o o u u c \n",
      "                       != o o o o sil u t c\n",
      "Accuracy: 93.00% (      93/     100)\n"
     ]
    }
   ],
   "source": [
    "test_model_accuracy(100, print_wrongs=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save_model():\n",
    "    saved_model_path = 'data/models/numbers_gen_1_rnn_' + str(model_train_iterations)\n",
    "    print(\"Saving:\", saved_model_path)\n",
    "    torch.save(decoder_rnn.state_dict(), saved_model_path+'_decoder')\n",
    "    torch.save(encoder_rnn.state_dict(), saved_model_path+'_encoder')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f147bc59e48>]"
      ]
     },
     "execution_count": 449,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nJgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f147bdcb630>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.plot(np.array(model_train_history)[:, 0][50:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:py3_pytorch_2]",
   "language": "python",
   "name": "conda-env-py3_pytorch_2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
