{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pytorch utils oh: pytorch_utils_oh_2.py\n",
      "Pytorch: 0.2.0_4\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import importlib\n",
    "from pytorch_utils_oh_2 import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MODEL_SAVE_PATH = 'whole_gen_6_after_words'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pytorch utils oh: pytorch_utils_oh_2.py\n",
      "Pytorch: 0.2.0_4\n"
     ]
    }
   ],
   "source": [
    "import pytorch_utils_oh_2; importlib.reload(pytorch_utils_oh_2); from pytorch_utils_oh_2 import *;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_data = pickle.load(open(\"data/en_train_fixed_1.pkl\", \"rb\" ))\n",
    "all_data_sentence_index = all_data.set_index('sentence_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ELECTRONIC', 'LETTERS', 'NOT_CHANGED', 'NUMBERS', 'PLAIN', 'VERBATIM']\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "categories_all = sorted(all_data[\"class\"].unique())\n",
    "print(categories_all)\n",
    "print(len(categories_all))\n",
    "categories_index = dict((c, i) for i, c in enumerate(categories_all))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utils stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<SOS><EOS>☒ !\"#$%&'(),-./0123456789:;ABCDEFGHIJKLMNOPQRSTUVWXYZ_abcdefghijklmnopqrstuvwxyz~£¥ª²³µº¼½¾éɒʻˈΩμ—€⅓⅔⅛\n"
     ]
    }
   ],
   "source": [
    "chars_normal, chars_normal_index = load_characters_pkl('data/en_features/chars_normal.pkl')\n",
    "print(''.join(chars_normal))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "common_words, common_words_index = load_common_words_10k()\n",
    "len(common_words)\n",
    "common_words[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wv_vecs, wv_words, wv_idx = load_glove('/home/ohu/koodi/data/glove_wordvec/glove.6B.50d.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### After words handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<EOS>', '<SOS>', '<UNK>', '<0000>', '<SAMPLE>', 'two', 'twenty']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_after_common = pickle.load(open(\"data/en_features/words_after_all.pkl\", \"rb\"))\n",
    "words_after_common = [EOS_TOKEN, SOS_TOKEN, UNKNOWN_WORD_TOKEN, NUMBER_WORD_TOKEN, SAMPLE_WORD_TOKEN] + words_after_common\n",
    "words_after_common[0:7]\n",
    "words_after_index = dict((c, i) for i, c in enumerate(words_after_common))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "words_after_by_length = sorted(words_after_common, key=len, reverse=True)\n",
    "words_after_regex = re.compile('(' + ')|('.join(words_after_by_length) + ')')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[9, 1212, 5, 1252, 9, 10, 0]"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "['one', 'plus', 'two', 'equals', 'one', 'hundred', '<EOS>']"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def after_sentence_to_word_indexes(sentence, include_eos=True):\n",
    "    reg = re.finditer(words_after_regex, sentence)\n",
    "    arr = [words_after_index[s[0]] for s in reg]\n",
    "    if include_eos:\n",
    "        arr += [words_after_index[EOS_TOKEN]]\n",
    "    return arr\n",
    "tmp = after_sentence_to_word_indexes('one plus two equals one hundred')\n",
    "tmp\n",
    "[words_after_common[s] for s in tmp]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def after_sentence_to_tensor(sentence, include_eos=True):\n",
    "    arr = after_sentence_to_word_indexes(sentence, include_eos)\n",
    "    tensor = torch.zeros(len(arr), len(words_after_index))\n",
    "    tensor.scatter_(1, torch.LongTensor(arr).view(-1,1) , 1)\n",
    "    return torch.unsqueeze(tensor, 0)\n",
    "tmp = after_sentence_to_tensor('one plus two equals one hundred')\n",
    "tmp.size()\n",
    "[words_after_common[i[0]] for i in tmp.topk(1)[1][0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 1351])"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "onehot_sos = torch.zeros(1, 1, len(words_after_index))\n",
    "onehot_sos[0, 0, words_after_index[SOS_TOKEN]] = 1\n",
    "\n",
    "onehot_sos.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### More balanced sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data rows: 659544,  (dropped rows: 9258648)\n"
     ]
    }
   ],
   "source": [
    "sample_data = all_data[all_data['class'] != 'NOT_CHANGED']\n",
    "print(\"Data rows: {},  (dropped rows: {})\".format(len(sample_data), len(all_data)-len(sample_data)))\n",
    "sample_data = sample_data.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "balanced_data_classes_select = list(sample_data.groupby('class'))\n",
    "\n",
    "balanced_data_accessed_counter = 0 \n",
    "balanced_data_length = 0\n",
    "def balanced_data_randomize(max_len=20000):\n",
    "    global balanced_data, balanced_data_length, balanced_data_accessed_counter\n",
    "    balanced_data = pd.concat([v.sample(min(max_len, len(v))) for k, v in balanced_data_classes_select])\n",
    "    balanced_data_length = len(balanced_data)\n",
    "    balanced_data_accessed_counter = 0\n",
    "\n",
    "def balanced_data_sample_row():\n",
    "    global balanced_data_accessed_counter\n",
    "    global balanced_data_last_sample\n",
    "    balanced_data_accessed_counter += 1\n",
    "    if balanced_data_accessed_counter/balanced_data_length > 0.2:\n",
    "        balanced_data_randomize()\n",
    "    balanced_data_last_sample = balanced_data.iloc[random.randint(1, balanced_data_length-1)]\n",
    "    return balanced_data_last_sample\n",
    "    \n",
    "balanced_data_randomize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102 µs ± 3.26 µs per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "balanced_data_sample_row()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "class\n",
       "ELECTRONIC     4964\n",
       "LETTERS       20000\n",
       "NUMBERS       20000\n",
       "PLAIN         20000\n",
       "VERBATIM      16950\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#all_data.groupby('class')['class'].count()\n",
    "#sample_data.groupby('class')['class'].count()\n",
    "balanced_data.groupby('class')['class'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentence_id                         507358\n",
       "token_id                                10\n",
       "class                              NUMBERS\n",
       "before                               1.63%\n",
       "after          one point six three percent\n",
       "class_org                          MEASURE\n",
       "Name: 444646, dtype: object"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " balanced_data_sample_row()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NUMBERS : 3 February 2008 -> the third of february two thousand eight\n",
      "Archived from the original on <SAMPLE> .\n",
      "['Archived', 'from', 'the', 'original', 'on', '<SAMPLE>', '.']\n",
      "torch.Size([1, 16, 104])\n",
      "[11, 76, 12, 72, 5, 8, 16, 0]\n",
      "the third of february two thousand eight <EOS>\n"
     ]
    }
   ],
   "source": [
    "def get_random_sample():\n",
    "    sample_row = balanced_data_sample_row()\n",
    "    sentence_id = sample_row['class']\n",
    "\n",
    "    rows = all_data_sentence_index.loc[sample_row['sentence_id']]\n",
    "    befores = list(rows.before)\n",
    "        \n",
    "    token_id_idx = list(rows['token_id']).index(sample_row['token_id'])\n",
    "    befores[token_id_idx] = SAMPLE_WORD_TOKEN\n",
    "    \n",
    "    return sample_row['before'], sample_row['after'], sample_row['class'], befores\n",
    "            \n",
    "def tmp():\n",
    "    s_bef, s_aft, s_class, s_sentence = get_random_sample()\n",
    "    print(s_class, ':', s_bef, '->', s_aft)\n",
    "    print(' '.join(s_sentence))\n",
    "    print(s_sentence)\n",
    "    print(string_to_tensor(s_bef, chars_normal_index).shape)\n",
    "    #tmp = after_sentence_to_tensor(s_aft)\n",
    "    tmp = after_sentence_to_word_indexes(s_aft)\n",
    "    print(tmp)\n",
    "    print(' '.join([words_after_common[i] for i in tmp]))\n",
    "    #print([words_after_common[i[0]] for i in tmp.topk(1)[1][0]])\n",
    "tmp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "787 µs ± 116 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "get_random_sample()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "use_cuda = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, words_input_size, chars_input_size, words_hidden_size, chars_hidden_size,\n",
    "                 words_layers=1, chars_layers=1):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        \n",
    "        self.words_layers = words_layers\n",
    "        self.chars_layers = chars_layers\n",
    "        self.words_hidden_size = words_hidden_size\n",
    "        self.chars_hidden_size = chars_hidden_size\n",
    "\n",
    "        self.rnn_words = nn.LSTM(words_input_size, words_hidden_size // 2, words_layers,\n",
    "                                 batch_first=True, bidirectional=True)\n",
    "\n",
    "        self.rnn_chars = nn.LSTM(chars_input_size, chars_hidden_size // 2, chars_layers,\n",
    "                                batch_first=True, bidirectional=True)\n",
    "        \n",
    "    def forward(self, word_vectors, string_tensor, hidden = None, init_hidden = True):\n",
    "        if init_hidden:\n",
    "            hidden_words, hidden_chars = self.init_hidden()\n",
    "        \n",
    "        all_outputs_words, hidden_words = self.rnn_words(word_vectors, hidden_words)\n",
    "        output_words = all_outputs_words[:, -1]\n",
    "        \n",
    "        all_outputs_chars, hidden_chars = self.rnn_chars(string_tensor, hidden_chars)\n",
    "        output_chars = all_outputs_chars[:, -1]\n",
    "        \n",
    "        output = torch.cat((output_words, output_chars), 1)\n",
    "        \n",
    "        return output\n",
    "\n",
    "    def init_hidden(self):\n",
    "        var1_1 = Variable(torch.zeros(2 * self.words_layers, 1, self.words_hidden_size // 2))\n",
    "        var1_2 = Variable(torch.zeros(2 * self.words_layers, 1, self.words_hidden_size // 2))\n",
    "        var2_1 = Variable(torch.zeros(2 * self.chars_layers, 1, self.chars_hidden_size // 2))\n",
    "        var2_2 = Variable(torch.zeros(2 * self.chars_layers, 1, self.chars_hidden_size // 2))\n",
    "        \n",
    "        var1_1 = var1_1.cuda(); var1_2 = var1_2.cuda()\n",
    "        var2_1 = var2_1.cuda(); var2_2 = var2_2.cuda()\n",
    "        return ((var1_1, var1_2), (var2_1, var2_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EncoderRNN (\n",
       "  (rnn_words): LSTM(50, 64, batch_first=True, bidirectional=True)\n",
       "  (rnn_chars): LSTM(104, 128, batch_first=True, bidirectional=True)\n",
       ")"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_rnn = EncoderRNN(words_input_size=wv_vecs.shape[-1], chars_input_size=len(chars_normal),\n",
    "                         words_hidden_size=128, chars_hidden_size=256,\n",
    "                         words_layers=1, chars_layers=1).cuda()\n",
    "encoder_rnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 384])"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def test_encoder_single_sample():\n",
    "    s_bef, s_aft, s_class, s_sentence = get_random_sample()\n",
    "    \n",
    "    words_t = Variable(words_to_word_vectors_tensor(list(s_sentence), wv_vecs, wv_idx)).cuda()\n",
    "    \n",
    "    string_t = string_to_tensor(s_bef, chars_normal_index)\n",
    "    string_t = Variable(string_t).cuda()\n",
    "    \n",
    "    return encoder_rnn(words_t, string_t)\n",
    "    \n",
    "encoder_output = test_encoder_single_sample()\n",
    "encoder_output.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecoderRNN (\n",
       "  (rnn): GRU(1351, 384, batch_first=True)\n",
       "  (lin_out): Linear (384 -> 1351)\n",
       ")"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class DecoderRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, n_layers=1):\n",
    "        super(DecoderRNN, self).__init__()\n",
    "        self.n_layers = n_layers\n",
    "        self.hidden_size = hidden_size\n",
    "        \n",
    "        self.rnn = nn.GRU(input_size, hidden_size, n_layers,\n",
    "                                 batch_first=True, bidirectional=False)\n",
    "        \n",
    "        self.lin_out = nn.Linear(hidden_size, input_size)\n",
    "        #self.softmax = nn.LogSoftmax()\n",
    "\n",
    "    def forward(self, char, hidden):\n",
    "        #char = char.view(1,1,-1)\n",
    "        #hidden = hidden.view(1,1,-1)\n",
    "        output, hidden = self.rnn(char, hidden)\n",
    "        output = output[:, -1] # view(1,-1)\n",
    "        output = self.lin_out(output)\n",
    "        output = F.log_softmax(output)\n",
    "        return output, hidden\n",
    "    \n",
    "    def init_rest_hidden(self, input_var):\n",
    "        if self.n_layers > 1:\n",
    "            hid_var = Variable(torch.zeros(self.n_layers - 1, 1, self.hidden_size)).cuda()\n",
    "            res = torch.cat((input_var, hid_var), 0)\n",
    "            return res\n",
    "        else:\n",
    "            return input_var\n",
    "        \n",
    "\n",
    "decoder_rnn = DecoderRNN(input_size=len(words_after_common), hidden_size=128+256, n_layers=1)\n",
    "decoder_rnn = decoder_rnn.cuda()\n",
    "decoder_rnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1351])\n",
      "torch.Size([1, 1, 384])\n",
      "Variable containing:\n",
      " 1176\n",
      "[torch.cuda.LongTensor of size 1x1 (GPU 0)]\n",
      "\n",
      "lumens\n"
     ]
    }
   ],
   "source": [
    "tmp_hiddens = decoder_rnn.init_rest_hidden(encoder_output.view(1,1,-1))\n",
    "tmp_a, tmp_b = decoder_rnn(Variable(onehot_sos).cuda(), tmp_hiddens)\n",
    "print(tmp_a.size())\n",
    "print(tmp_b.size())\n",
    "print(tmp_a.topk(1)[1])\n",
    "print(words_after_common[tmp_a.topk(1)[1].data[0][0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training etc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('lead lumens kohlschutter lumens kohlschutter lumens kohlschutter lumens kohlschutter lumens kohlschutter lumens kohlschutter lumens kohlschutter lumens kohlschutter lumens kohlschutter lumens',\n",
       " 'lead lumens kohlschutter lumens kohlschutter lumens kohlschutter lumens kohlschutter lumens kohlschutter lumens kohlschutter lumens kohlschutter lumens kohlschutter lumens kohlschutter lumens',\n",
       " 'p l o s',\n",
       " ('PLOS',\n",
       "  'p l o s',\n",
       "  'LETTERS',\n",
       "  ['<SAMPLE>', 'ONE', 'e', '45', ':', 'e', '45', '.']))"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def test_model_single_sample(model=None):\n",
    "    s_bef, s_aft, s_class, s_sentence = sample = get_random_sample()\n",
    "        \n",
    "    words_t = Variable(words_to_word_vectors_tensor(list(s_sentence), wv_vecs, wv_idx)).cuda()\n",
    "    \n",
    "    string_t = string_to_tensor(s_bef, chars_normal_index)\n",
    "    string_t = Variable(string_t).cuda()\n",
    "    \n",
    "    encoder_output = encoder_rnn(words_t, string_t)\n",
    "    \n",
    "    encoder_output = encoder_output.view(1,1,-1)\n",
    "    \n",
    "    decoder_hidden = decoder_rnn.init_rest_hidden(encoder_output)\n",
    "    decoder_input = Variable(onehot_sos).cuda()\n",
    "\n",
    "    decoded_output = []\n",
    "    max_length = 20\n",
    "    for _ in range(max_length):\n",
    "        decoder_output, decoder_hidden = decoder_rnn(decoder_input, decoder_hidden)\n",
    "        #return decoder_output\n",
    "\n",
    "        topv, topi = decoder_output.data.topk(1)\n",
    "        word_index = topi[0][0]\n",
    "        word = words_after_common[word_index] # Use own prediction as next input\n",
    "                \n",
    "        if word == EOS_TOKEN:\n",
    "            break\n",
    "\n",
    "        decoded_output.append(word)\n",
    "        \n",
    "        decoder_input = torch.zeros(1, 1, len(words_after_index))\n",
    "        decoder_input[0, 0, word_index] = 1\n",
    "        decoder_input = Variable(decoder_input).cuda()\n",
    "    \n",
    "    output = ' '.join(decoded_output)\n",
    "    return output, output, s_aft, sample\n",
    "    \n",
    "tmp = test_model_single_sample(None)\n",
    "tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def print_local_wrong_predictions(max_results=10):\n",
    "    arr = get_some_wrong_predictions(None, test_model_single_sample, max_iterations=10000, max_results=max_results)\n",
    "    for sample, predict, output in arr:\n",
    "        s_bef, s_aft, s_class, s_sentence = sample\n",
    "        print(\"{:<14} => {:<14} || {} \\n{:>17} {}\".format(s_bef, predict, s_aft, '', ' '.join(s_sentence), ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7              => capitalizing heer lumens kohlschutter lumens kohlschutter lumens kohlschutter lumens kohlschutter lumens kohlschutter lumens kohlschutter lumens kohlschutter lumens kohlschutter lumens kohlschutter || seven \n",
      "                  \" Lego Harry Potter Years 5 - <SAMPLE> Review \" .\n",
      "PRR            => capitalizing heer lumens kohlschutter lumens kohlschutter lumens kohlschutter lumens kohlschutter lumens kohlschutter lumens kohlschutter lumens kohlschutter lumens kohlschutter lumens kohlschutter || p r r \n",
      "                  \" <SAMPLE> CHRONOLOGY 1971 ( June 2005 Edition ) \" ( PDF ) .\n"
     ]
    }
   ],
   "source": [
    "print_local_wrong_predictions(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.00% (       0/    1000)\n",
      "CPU times: user 12 s, sys: 200 ms, total: 12.2 s\n",
      "Wall time: 12.2 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "test_model_accuracy(encoder_rnn, test_model_single_sample, n_sample=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train(s_bef, s_aft, s_sentence, encoder_optimizer, decoder_optimizer, loss_function,\n",
    "          use_teacher_forcing, max_length=20):\n",
    "    \n",
    "    words_t = Variable(words_to_word_vectors_tensor(list(s_sentence), wv_vecs, wv_idx)).cuda()\n",
    "    \n",
    "    string_t = string_to_tensor(s_bef, chars_normal_index)\n",
    "    string_t = Variable(string_t).cuda()\n",
    "    \n",
    "    encoder_output = encoder_rnn(words_t, string_t)\n",
    "    encoder_output = encoder_output.view(1,1,-1)\n",
    "    \n",
    "    decoder_hidden = decoder_rnn.init_rest_hidden(encoder_output)\n",
    "    decoder_input = Variable(onehot_sos).cuda()\n",
    "    \n",
    "    ###\n",
    "    \n",
    "    target_arr = after_sentence_to_word_indexes(s_aft, include_eos=True)\n",
    "    \n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "    loss = 0\n",
    "    \n",
    "    decoded_output = []\n",
    "    for i in range(len(target_arr)):\n",
    "        decoder_output, decoder_hidden = decoder_rnn(decoder_input, decoder_hidden)\n",
    "\n",
    "        #decoder_target_i = chars_after_index[target_arr[i]]\n",
    "        decoder_target_i = target_arr[i]\n",
    "        decoder_target_i = Variable(torch.LongTensor([decoder_target_i])).cuda()\n",
    "        loss += loss_function(decoder_output, decoder_target_i)\n",
    "        \n",
    "        topv, topi = decoder_output.data.topk(1)\n",
    "        word_index = topi[0][0]\n",
    "        word = words_after_common[word_index] # Use own prediction as next input\n",
    "        decoded_output.append(word)\n",
    "        \n",
    "        if use_teacher_forcing:\n",
    "            word_index = target_arr[i] # replace input with right target\n",
    "        else:\n",
    "            # use output normally as input \n",
    "            if word == EOS_TOKEN:\n",
    "                break\n",
    "                \n",
    "        decoder_input = torch.zeros(1, 1, len(words_after_index))\n",
    "        decoder_input[0, 0, word_index] = 1\n",
    "        decoder_input = Variable(decoder_input).cuda()\n",
    "        \n",
    "    if decoded_output[-1] == EOS_TOKEN:\n",
    "        decoded_output = decoded_output[:-1]\n",
    "        \n",
    "    loss.backward()\n",
    "\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "\n",
    "    return ' '.join(decoded_output), (loss.data[0] / len(target_arr))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_iterations(n_iters=100000, lr=0.001, teacher_forcing_ratio=0.5,\n",
    "                     print_every=10000, plot_every=1000):\n",
    "\n",
    "    start = time.time()\n",
    "    \n",
    "    decoder_rnn.train()\n",
    "    encoder_rnn.train()\n",
    "\n",
    "    current_loss = 0\n",
    "    current_loss_iter = 0\n",
    "\n",
    "    encoder_optimizer = torch.optim.Adam(encoder_rnn.parameters(), lr=lr)\n",
    "    decoder_optimizer = torch.optim.Adam(decoder_rnn.parameters(), lr=lr)\n",
    "    loss_function = nn.NLLLoss()\n",
    "    \n",
    "    for iteration in range(1, n_iters + 1):\n",
    "        model_training.iterations += 1\n",
    "        \n",
    "        use_teacher_forcing = random.random() < teacher_forcing_ratio\n",
    "        \n",
    "        s_bef, s_aft, s_class, s_sentence = get_random_sample()\n",
    "        \n",
    "        result, loss = train(s_bef=s_bef, s_aft=s_aft, s_sentence=s_sentence,\n",
    "                             encoder_optimizer=encoder_optimizer, decoder_optimizer=decoder_optimizer,\n",
    "                             loss_function=nn.NLLLoss(), use_teacher_forcing=use_teacher_forcing,\n",
    "                             max_length=40 )\n",
    "        \n",
    "        current_loss += loss\n",
    "        current_loss_iter += 1\n",
    "\n",
    "        # Print iter number, loss, name and guess\n",
    "        if iteration % print_every == 0:\n",
    "            teacher_forcing_str = \"\"\n",
    "            if use_teacher_forcing:\n",
    "                teacher_forcing_str = \"(forcing)\"\n",
    "            correct = '✓' if result == s_aft else \"✗: {}\".format(s_aft)\n",
    "            \n",
    "            print(\"{:>6d} {:>4.0%} ({:>8}) {:>7.3f}   | {:>6.2f}: {} -> {} ({}) {}\".format(\n",
    "                      model_training.iterations, iteration/n_iters, time_since(start),\n",
    "                      current_loss/current_loss_iter, loss,\n",
    "                      s_bef, result, correct, teacher_forcing_str))\n",
    "\n",
    "        # Add current loss avg to list of losses\n",
    "        if iteration % plot_every == 0:\n",
    "            model_training.losses.append(current_loss / plot_every)\n",
    "            model_training.learning_rates.append(lr)\n",
    "            current_loss = 0\n",
    "            current_loss_iter = 0\n",
    "            \n",
    "        if model_training.iterations % 50000 == 0 or model_training.iterations == 10:\n",
    "            model_training.save_models()\n",
    "            acc = test_model_accuracy(encoder_rnn, test_model_single_sample)\n",
    "            model_training.accuracy.append(acc)\n",
    "    \n",
    "    # test_model_accuracy(model, n_sample=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Save path: data/models/whole_gen_6_after_words\n"
     ]
    }
   ],
   "source": [
    "model_training = ModelTraining(MODEL_SAVE_PATH, [encoder_rnn, decoder_rnn])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     9  18% (   0m 0s)   7.209   |   7.19: τ -> lumens lumens (✗: tau) (forcing)\n",
      "Saved model to data/models/whole_gen_6_after_words/10_(EncoderRNN/DecoderRNN)\n",
      "Accuracy: 0.00% (       0/   10000)\n",
      "    18  36% (   2m 7s)   7.198   |   7.19: A. K. -> lumens two lumens (✗: a k) \n",
      "    27  54% (   2m 7s)   7.190   |   7.15: F.C. -> two two (✗: f c) (forcing)\n",
      "    36  72% (   2m 7s)   6.979   |   7.12: st -> <EOS> (✗: saint) (forcing)\n",
      "    45  90% (   2m 8s)   6.774   |   7.16: 16 April 2005 -> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> (✗: the sixteenth of april two thousand five) (forcing)\n"
     ]
    }
   ],
   "source": [
    "train_iterations(n_iters=50, print_every=9, lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   550  53% (   0m 6s)   3.506   |   5.94: 21 June 2014 -> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> (✗: the twenty first of june twenty fourteen) (forcing)\n"
     ]
    }
   ],
   "source": [
    "train_iterations(n_iters=(1000-model_training.iterations), print_every=500, lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  2000  11% (  0m 13s)   2.916   |   5.27: 6653084 -> to <EOS> <EOS> <EOS> <EOS> <EOS> e e e e (✗: six million six hundred fifty three thousand eighty four) (forcing)\n",
      "  3000  22% (  0m 26s)   2.676   |   3.28: ι -> and (✗: iota) (forcing)\n",
      "  4000  33% (  0m 39s)   2.566   |   2.25: 1424 -> nineteen (✗: fourteen twenty four) \n",
      "  5000  44% (  0m 51s)   2.407   |   0.72: - -> and (✗: to) (forcing)\n",
      "  6000  56% (   1m 4s)   2.351   |   0.18: & -> and (✓) \n",
      "  7000  67% (  1m 18s)   2.275   |   2.60: ST -> p (✗: saint) \n",
      "  8000  78% (  1m 31s)   2.148   |   3.35: 9 April 2013 -> the twenty twenty twenty two <EOS> (✗: the ninth of april twenty thirteen) (forcing)\n",
      "  9000  89% (  1m 44s)   2.122   |   2.99: 5 -> to (✗: five) \n",
      " 10000 100% (  1m 57s)   2.061   |   2.46: TV -> p (✗: t v) \n"
     ]
    }
   ],
   "source": [
    "train_iterations(n_iters=9000, lr=0.0001, print_every=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 20000  11% (  2m 20s)   1.443   |   1.89: kilometres -> kilometers (✓) \n",
      " 30000  22% (  4m 47s)   0.946   |   3.47: $32,083 -> two thousand three hundred eighty (✗: thirty two thousand eighty three dollars) \n",
      " 40000  33% (  7m 22s)   0.712   |   0.01: colours -> colors (✓) (forcing)\n",
      " 50000  44% (  10m 7s)   0.653   |   0.90: MG -> g m (✗: m g) \n",
      "Saved model to data/models/whole_gen_6_after_words/50000_(EncoderRNN/DecoderRNN)\n",
      "Accuracy: 68.06% (    6806/   10000)\n",
      " 60000  56% ( 13m 22s)   0.587   |   7.15: OO -> o o (✗: oxygen monoxide) \n",
      " 70000  67% ( 15m 45s)   0.499   |   0.20: A.V.V. -> a v v (✓) \n",
      " 80000  78% (  18m 9s)   0.549   |   6.45: 3½ -> thirty hundred <EOS> <EOS> (✗: three and a half) (forcing)\n",
      " 90000  89% ( 20m 37s)   0.511   |   0.00: & -> and (✓) \n",
      "100000 100% (  23m 6s)   0.484   |   0.00: US -> u s (✓) \n",
      "Saved model to data/models/whole_gen_6_after_words/100000_(EncoderRNN/DecoderRNN)\n",
      "Accuracy: 77.89% (    7789/   10000)\n"
     ]
    }
   ],
   "source": [
    "train_iterations(n_iters=90000, print_every=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "110000   3% (  2m 26s)   0.487   |   0.31: Spike.com -> s p i k e dot c o m (✓) (forcing)\n",
      "120000   7% (  4m 58s)   0.386   |   0.00: B. -> b (✓) (forcing)\n",
      "130000  10% (  7m 22s)   0.421   |   0.00: bros -> brothers (✓) \n",
      "140000  13% (  9m 51s)   0.413   |   0.00: 2006 -> two thousand six (✓) (forcing)\n",
      "150000  17% ( 12m 15s)   0.384   |   0.00: & -> and (✓) (forcing)\n",
      "Saved model to data/models/whole_gen_6_after_words/150000_(EncoderRNN/DecoderRNN)\n",
      "Accuracy: 80.19% (    8019/   10000)\n",
      "160000  20% ( 15m 17s)   0.394   |   0.00: US -> u s (✓) \n",
      "170000  23% ( 17m 40s)   0.336   |   0.00: catalogue -> catalog (✓) \n",
      "180000  27% (  20m 1s)   0.409   |   0.35: UCSF -> u c f f (✗: u c s f) \n",
      "190000  30% ( 22m 37s)   0.369   |   0.00: - -> to (✓) \n",
      "200000  33% (  25m 5s)   0.383   |   1.02: www.samizdat.com -> w w w dot a a m m d a a dot dot c o m (✗: w w w dot s a m i z d a t dot c o m) (forcing)\n",
      "Saved model to data/models/whole_gen_6_after_words/200000_(EncoderRNN/DecoderRNN)\n",
      "Accuracy: 82.31% (    8231/   10000)\n",
      "210000  37% ( 28m 25s)   0.364   |   0.00: 29 -> twenty nine (✓) \n",
      "220000  40% ( 31m 10s)   0.364   |   0.02: IV -> i v (✓) (forcing)\n",
      "230000  43% ( 33m 54s)   0.354   |   0.00: vol -> volume (✓) \n",
      "240000  47% ( 36m 39s)   0.328   |   0.00: st -> saint (✓) (forcing)\n",
      "250000  50% ( 39m 19s)   0.359   |   0.00: _ -> underscore (✓) (forcing)\n",
      "Saved model to data/models/whole_gen_6_after_words/250000_(EncoderRNN/DecoderRNN)\n",
      "Accuracy: 82.55% (    8255/   10000)\n",
      "260000  53% ( 42m 42s)   0.297   |   0.01: 6th -> sixth (✓) (forcing)\n",
      "270000  57% ( 45m 16s)   0.358   |   0.00: 1988 -> nineteen eighty eight (✓) \n",
      "280000  60% ( 47m 52s)   0.300   |   0.01: 1970 -> nineteen seventy (✓) \n",
      "290000  63% ( 50m 16s)   0.296   |   0.00: 3 -> three (✓) (forcing)\n",
      "300000  67% ( 52m 40s)   0.338   |   0.00: 88 -> eighty eight (✓) (forcing)\n",
      "Saved model to data/models/whole_gen_6_after_words/300000_(EncoderRNN/DecoderRNN)\n",
      "Accuracy: 83.33% (    8333/   10000)\n",
      "310000  70% ( 55m 37s)   0.338   |   0.09: 1905 -> nineteen o five (✓) (forcing)\n",
      "320000  73% ( 57m 59s)   0.313   |   0.00: L. -> l (✓) \n",
      "330000  77% ( 60m 26s)   0.332   |   0.99: Streetfilms.org -> s t r e e f f i f f o dot o r g (✗: s t r e e t f i l m s dot o r g) (forcing)\n",
      "340000  80% ( 62m 54s)   0.317   |   0.00: # -> number (✓) (forcing)\n",
      "350000  83% ( 65m 59s)   0.269   |   3.27: $115k -> fifteen thousand kilometers (✗: one hundred fifteen thousand dollars) \n",
      "Saved model to data/models/whole_gen_6_after_words/350000_(EncoderRNN/DecoderRNN)\n",
      "Accuracy: 83.86% (    8386/   10000)\n",
      "360000  87% ( 69m 45s)   0.277   |   0.00: st -> saint (✓) \n",
      "370000  90% ( 72m 28s)   0.322   |   0.79: β -> alpha (✗: beta) (forcing)\n",
      "380000  93% ( 75m 18s)   0.289   |   0.00: 9 -> nine (✓) (forcing)\n",
      "390000  97% ( 78m 11s)   0.269   |   0.01: 33 -> thirty three (✓) \n",
      "400000 100% (  81m 6s)   0.348   |   0.00: & -> and (✓) \n",
      "Saved model to data/models/whole_gen_6_after_words/400000_(EncoderRNN/DecoderRNN)\n",
      "Accuracy: 83.75% (    8375/   10000)\n"
     ]
    }
   ],
   "source": [
    "train_iterations(n_iters=300000, print_every=10000, teacher_forcing_ratio=0.5, lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WordPress.com  => w o r d p r s s e r dot c c m || w o r d p r e s s dot c o m \n",
      "                  Kirk of the Antarctic ( Blog at <SAMPLE> ) .\n",
      "ι              => epsilon        || iota \n",
      "                  This term derives from μ ε λ <SAMPLE> ζ ε ι ( melizei , \" to cut \" ) .\n",
      "1,373          => thirteen seventy three || one thousand three hundred seventy three \n",
      "                  As of the census of 2010 , there were 3,810 people , <SAMPLE> households , and 1,121 families residing in the village .\n",
      "δ              => tau            || delta \n",
      "                  \" Bound pillar \" , from Greek <SAMPLE> ε σ μ ο ς ( desmos ) , bond , and σ τ ῦ λ ο ς ( stulos ) , pillar , referring to the shape of the molars .\n",
      "$39,789        => thirty seven thousand nine hundred eighty three dollars || thirty nine thousand seven hundred eighty nine dollars \n",
      "                  The median income for a household in the CDP was <SAMPLE> , and the median income for a family was $46,035 .\n",
      "http://www.altpress.com/news/8375.htmNichole => h t t p colon slash slash w w w dot a r t s c h i s t || h t t p colon slash slash w w w dot a l t p r e s s dot com slash n e w s slash e i g h t t h r e e s e v e n f i v e dot h t m n i c h o l e \n",
      "                  J- 14 Interview http://www.j-14.com/2010/02/exclusive-qa-with-the-rocket-summer.htmlAlt Press Cover Art <SAMPLE> Fazekas .\n",
      "λ              => alpha          || lambda \n",
      "                  BOOKSINFO . GR Κ υ κ <SAMPLE> ο φ ο ρ η σ ε κ α ι ε κ δ ο σ η γ ' ε κ ν ε ο υ ε π ε ξ ε ρ γ α σ μ ε ν η , Α θ η ν α , ε κ δ .\n",
      "536 km²        => five hundred sixty five kilometers per square kilometers || five hundred thirty six square kilometers \n",
      "                  In 2007 the population was 4,440 in a total area of <SAMPLE> .\n",
      "II             => two            || the second \n",
      "                  Pomfret is referred to also in \" Richard <SAMPLE> \" ( V , , 1 , 52 ) .\n",
      "NOTCH          => n o t h c      || n o t c h \n",
      "                  Lck has been shown to interact with : ADAM 15 , CD 2 , CD 44 , CD 4 , COUP TFII , DLG 1 , <SAMPLE> 1 , PIK 3 CA , PTPN 6 , PTPRC , UNC 119 , SYK , UBE 3 A , andZAP 70 .\n"
     ]
    }
   ],
   "source": [
    "print_local_wrong_predictions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "410000   3% (  2m 48s)   0.332   |   0.11: DG -> d g (✓) \n",
      "420000   7% (  5m 41s)   0.302   |   0.00: 2003 -> two thousand three (✓) (forcing)\n",
      "430000  10% (  8m 36s)   0.269   |   0.00: μ -> mu (✓) (forcing)\n",
      "440000  13% ( 11m 44s)   0.319   |   0.00: & -> and (✓) (forcing)\n",
      "450000  17% ( 14m 30s)   0.299   |   0.00: & -> and (✓) \n",
      "Saved model to data/models/whole_gen_6_after_words/450000_(EncoderRNN/DecoderRNN)\n",
      "Accuracy: 83.54% (    8354/   10000)\n",
      "460000  20% (  18m 7s)   0.309   |   0.93: PatentlyO.com -> p n t t l t o y dot c c o m (✗: p a t e n t l y o dot c o m) (forcing)\n",
      "470000  23% (  21m 2s)   0.321   |   0.02: 1 -> one (✓) (forcing)\n",
      "480000  27% (  24m 3s)   0.312   |   0.00: & -> and (✓) (forcing)\n",
      "490000  30% ( 26m 56s)   0.267   |   0.78: 0 -> o (✗: zero) \n",
      "500000  33% ( 29m 48s)   0.301   |   0.00: 1931 -> nineteen thirty one (✓) (forcing)\n",
      "Saved model to data/models/whole_gen_6_after_words/500000_(EncoderRNN/DecoderRNN)\n",
      "Accuracy: 84.41% (    8441/   10000)\n",
      "510000  37% ( 33m 32s)   0.311   |   0.00: Lt -> l t (✓) (forcing)\n",
      "520000  40% ( 36m 25s)   0.294   |   0.00: & -> and (✓) \n",
      "530000  43% ( 39m 12s)   0.300   |   0.00: metres -> meters (✓) \n",
      "540000  47% (  42m 4s)   0.218   |   0.00: & -> and (✓) \n",
      "550000  50% (  45m 3s)   0.339   |   0.00: vol -> volume (✓) \n",
      "Saved model to data/models/whole_gen_6_after_words/550000_(EncoderRNN/DecoderRNN)\n",
      "Accuracy: 85.45% (    8545/   10000)\n",
      "560000  53% ( 48m 37s)   0.289   |   0.00: & -> and (✓) (forcing)\n",
      "570000  57% ( 51m 27s)   0.297   |   0.00: metres -> meters (✓) \n",
      "580000  60% ( 54m 15s)   0.238   |   0.00: : -> to (✓) (forcing)\n",
      "590000  63% (  57m 5s)   0.249   |   0.00: - -> to (✓) \n",
      "600000  67% ( 59m 56s)   0.292   |   2.24: κ -> alpha (✗: kappa) (forcing)\n",
      "Saved model to data/models/whole_gen_6_after_words/600000_(EncoderRNN/DecoderRNN)\n",
      "Accuracy: 85.33% (    8533/   10000)\n",
      "610000  70% ( 63m 38s)   0.266   |   0.00: LT -> l t (✓) \n",
      "620000  73% ( 66m 35s)   0.342   |   0.00: Theatre -> theater (✓) \n",
      "630000  77% ( 69m 21s)   0.290   |   1.08: Denik.cz -> d e n i dot c k (✗: d e n i k dot c z) \n",
      "640000  80% (  72m 8s)   0.282   |   0.16: necbl.com -> n e c b l dot c o m (✓) (forcing)\n",
      "650000  83% ( 74m 59s)   0.270   |   0.00: 20 -> twenty (✓) \n",
      "Saved model to data/models/whole_gen_6_after_words/650000_(EncoderRNN/DecoderRNN)\n",
      "Accuracy: 85.65% (    8565/   10000)\n",
      "660000  87% ( 78m 40s)   0.262   |   0.00: CD -> c d (✓) (forcing)\n",
      "670000  90% ( 81m 37s)   0.266   |   0.04: LD -> l d (✓) \n",
      "680000  93% ( 84m 26s)   0.233   |   0.00: 4 -> four (✓) \n",
      "690000  97% ( 87m 19s)   0.296   |   0.88: α -> omicron (✗: alpha) \n",
      "700000 100% ( 90m 16s)   0.292   |   2.97: 6357  -> six thousand three hundred fifty (✗: six three five seven) \n",
      "Saved model to data/models/whole_gen_6_after_words/700000_(EncoderRNN/DecoderRNN)\n",
      "Accuracy: 85.42% (    8542/   10000)\n"
     ]
    }
   ],
   "source": [
    "train_iterations(n_iters=300000, print_every=10000, teacher_forcing_ratio=0.3, lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Worldconstructiontoday.com => w o r l d c o t o n d o c o c o t c o m || w o r l d c o n s t r u c t i o n t o d a y dot c o m \n",
      "                  <SAMPLE> ( 6 April 2011 ) .\n",
      "TheFutonCritic.com => t h e f u t i n c i o c i t c c c dot c o || t h e f u t o n c r i t i c dot c o m \n",
      "                  \" Breaking News — Bravo's ' Live Earth ' Coverage Marks Network's Best Saturday — Ever — Across All Key Demos — <SAMPLE> \" .\n",
      "ο              => alpha          || omicron \n",
      "                  These two words are ( a ) metamellomai / μ ε τ α μ ε λ λ <SAMPLE> μ α ι or ( b ) metanoeo / μ ε τ α ν ο ἐ ω and its cognate metanoia / μ ε τ α ν ο ι α .\n",
      "http://asstr.org => h t t p colon colon slash slash s s t s dot g r g || h t t p colon slash slash a s s t r dot o r g \n",
      "                  The huge site <SAMPLE> archives and indexes erotic and pornographic stories posted to the Usenet group alt.sex.stories .\n",
      "Salem-News.com => s a l e e m s e s dot c o m s dot c o m || s a l e m d a s h n e w s dot c o m \n",
      "                  dr Mazin Qumsiyeh , Shepherds' nights , Israeli troops and more , <SAMPLE> , December 9, 2011 .\n",
      "LiveMint.com   => m i v e m i n i n dot c o m || l i v e m i n t dot c o m \n",
      "                  Live Mint.com ( Chennai : <SAMPLE> ) .\n",
      "I              => the            || the first \n",
      "                  Pedro <SAMPLE> encountered a number of crises during his reign .\n",
      "Asst           => a s s s        || a s s t \n",
      "                  Ike NolanMarisa Coughlan as Tanya LaneSam Anderson as Roth LaneJulianna McCarthy as Eileen HunterJoel Polis as <SAMPLE> .\n",
      "afp.google.com => a f g l g dot o dot g o m m m m dot c o m || a f p dot g o o g l e dot c o m \n",
      "                  \" <SAMPLE> , Boy Scout saves Maldives President from assassination \" .\n",
      "$41,177        => eleven thousand seven hundred seventy dollars dollars || forty one thousand one hundred seventy seven dollars \n",
      "                  The median income for a household in the county was $35,321 , and the median income for a family was <SAMPLE> .\n"
     ]
    }
   ],
   "source": [
    "print_local_wrong_predictions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "710000  10% (  2m 54s)   0.240   |   0.00: 1781 -> seventeen eighty one (✓) \n",
      "720000  20% (  5m 48s)   0.200   |   0.00: colonisation -> colonization (✓) (forcing)\n",
      "730000  30% (  8m 50s)   0.212   |   0.01: 1985 -> nineteen eighty five (✓) (forcing)\n",
      "740000  40% ( 11m 42s)   0.206   |   0.00: - -> to (✓) (forcing)\n",
      "750000  50% ( 14m 32s)   0.216   |   0.00: NWTF -> n w t f (✓) \n",
      "Saved model to data/models/whole_gen_6_after_words/750000_(EncoderRNN/DecoderRNN)\n",
      "Accuracy: 87.22% (    8722/   10000)\n",
      "760000  60% ( 18m 12s)   0.202   |   0.00: T. -> t (✓) (forcing)\n",
      "770000  70% ( 20m 53s)   0.245   |   0.00: P- -> p (✓) (forcing)\n",
      "780000  80% ( 23m 16s)   0.189   |   1.14: http://www.msnbc.msn.com/id/42103936/ -> h t t p colon slash slash w w w dot b b s c c dot com e slash e com slash c n slash t i u r t e o slash n e slash n h r e e slash i n e e h r e e s i x o o (✗: h t t p colon slash slash w w w dot m s n b c dot m s n dot com slash i d slash f o u r t w o o n e o t h r e e n i n e t h r e e s i x slash) (forcing)\n",
      "790000  90% ( 25m 43s)   0.243   |   0.03: I. -> i (✓) \n",
      "800000 100% (  28m 7s)   0.177   |   0.00: DNA -> d n a (✓) (forcing)\n",
      "Saved model to data/models/whole_gen_6_after_words/800000_(EncoderRNN/DecoderRNN)\n",
      "Accuracy: 87.88% (    8788/   10000)\n"
     ]
    }
   ],
   "source": [
    "train_iterations(n_iters=100000, print_every=10000, teacher_forcing_ratio=0.5, lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2012           => two thousand twelve || twenty twelve \n",
      "                  Tom Shutt from Case Western Reserve University was LUX co spokesperson between 2007 - <SAMPLE> .\n",
      "st             => saint          || street \n",
      "                  Grandstands for Charleston Athletic Association Park ( velodrome ) ( 1898 ) , northwest corner of Meeting st and Sheppard <SAMPLE> , charleston south carolina .\n",
      "ο              => iota           || omicron \n",
      "                  \" Ε θ ν ι κ ο κ α ι Κ α π ο δ ι σ τ ρ ι α κ ο Π α ν ε π ι σ τ η μ ι ο Α θ η ν ω ν , Τ μ η μ α Μ ο υ σ ι κ ω ν Σ π ο υ δ ω ν , Β ι β λ ι ο θ η κ η Τ μ η μ α τ <SAMPLE> ς Μ ο υ σ ι κ ω ν Σ π ο υ δ ω ν , Gregorios Protopsaltes Archive , Dossier 137 \" .\n",
      "will.i.amno    => w i l l dot i dot a n || w i l l dot i dot a m n o \n",
      "                  \" The Jackass Song \" uploaded by will.i.amBlog written by <SAMPLE> byline ( 2009-01-19 ) .\n",
      "ι              => sigma          || iota \n",
      "                  Great Synaxaristes : ( Greek ) Ὁ Ὅ σ ι ο ς Β α σ ι λ ε <SAMPLE> ο ς κ τ η τ ο ρ α ς τ ῆ ς Μ ο ν ῆ ς Β α θ ε ο ς Ρ υ α κ ο ς .\n",
      "Pokernews.com  => p o r e e n w e s dot c o m || p o k e r n e w s dot c o m \n",
      "                  Official Live Update at <SAMPLE> .\n",
      "http://www.stil.se/uploadedFiles/Stiletten5_2007.pdf => h t t p colon slash slash w w w dot s i s t l l e dot o || h t t p colon slash slash w w w dot s t i l dot s e slash u p l o a d e d f i l e s slash s t i l e t t e n f i v e u n d e r s c o r e t w o o o s e v e n dot p d f \n",
      "                  Stiletten ( PDF ) ( STI , Stiftarna av Independent Living i Sverige ) : 17 <SAMPLE> .\n",
      "Ε              => alpha          || epsilon \n",
      "                  124 Basic Training Wing ( 124 Π τ ε ρ υ γ α Β α σ ι κ η ς <SAMPLE> κ π α ι δ ε υ σ η ς ) , localted in Tripoli , Arcadia .\n",
      "tuttoabruzzo.it => t u t t u b a i z z o t dot z u || t u t t o a b r u z z o dot i t \n",
      "                  The Stone City ( 1999 ) ( ISBN 978-0-7544-0098-1 ) ( 15 December 2008 ) \" Doktoro Esperanto \" , stasera al Museo Colonna di Pescara , <SAMPLE> .\n",
      "C16            => c c six        || c sixteen \n",
      "                  Grant ( 2005 ) , <SAMPLE> .\n"
     ]
    }
   ],
   "source": [
    "print_local_wrong_predictions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "810000  10% (   3m 4s)   0.263   |   1.46: Malayalamcinema.com -> m a l a m a m a a m m a m m m o (✗: m a l a y a l a m c i n e m a dot c o m) \n",
      "820000  20% (  5m 40s)   0.279   |   0.00: A. -> a (✓) \n",
      "830000  30% (  8m 16s)   0.222   |   0.00: & -> and (✓) \n",
      "840000  40% ( 10m 45s)   0.306   |   0.35: 5000 -> five thousand hundred (✗: five thousand) \n",
      "850000  50% ( 13m 19s)   0.325   |   0.00: 1974 -> nineteen seventy four (✓) \n",
      "Saved model to data/models/whole_gen_6_after_words/850000_(EncoderRNN/DecoderRNN)\n",
      "Accuracy: 85.97% (    8597/   10000)\n",
      "860000  60% ( 16m 26s)   0.267   |   0.19: Aatw.com -> a a t w dot c o m (✓) \n",
      "870000  70% ( 18m 52s)   0.274   |   0.00: 2010 -> twenty ten (✓) \n",
      "880000  80% ( 21m 15s)   0.238   |   0.00: colour -> color (✓) \n",
      "890000  90% ( 23m 46s)   0.282   |   0.55: PILYA -> p y l y a a (✗: p i l y a) (forcing)\n",
      "900000 100% ( 26m 12s)   0.279   |   0.00: st -> saint (✓) \n",
      "Saved model to data/models/whole_gen_6_after_words/900000_(EncoderRNN/DecoderRNN)\n",
      "Accuracy: 85.45% (    8545/   10000)\n"
     ]
    }
   ],
   "source": [
    "train_iterations(n_iters=100000, print_every=10000, teacher_forcing_ratio=0.1, lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Β              => omicron        || beta \n",
      "                  Babrius ( Greek : <SAMPLE> α β ρ ι ο ς , Babrios ; florida .\n",
      "www.worldcat.org => w w w dot o o r d a r c dot o g || w w w dot w o r l d c a t dot o r g \n",
      "                  WorldCat ( <SAMPLE> ; OCLC 45342846 ) .\n",
      "st             => saint          || street \n",
      "                  Born in Gun <SAMPLE> of Polish Jewish parents .\n",
      "pp.vii-viii    => p p dot i i i i i i i i i i i i i i i i i || p p dot v i i d a s h v i i i \n",
      "                  Preface , Castle Tubin ( Norwood , Mass : Press One , 2006 ) , <SAMPLE> .\n",
      "Eds            => e d s          || e d's \n",
      "                  Bruckman , A.S. , Guzdial , M. , Kolodner , J.L. , Ram , A. , ( <SAMPLE> .\n",
      "Viddsee.com    => d i d d a e e e dot c o m || v i d d s e e dot c o m \n",
      "                  \" <SAMPLE> Site Info \" .\n",
      "29.530589      => two hundred fifty five million five hundred eighty five hundred || twenty nine point five three o five eight nine \n",
      "                  It turns with a modeled rotational period of 29.53 days ; the modern value for the synodic month is <SAMPLE> days .\n",
      "Reddit.com     => r e d i t dot c o m || r e d d i t dot c o m \n",
      "                  The only existing offshoot of the original TOTSE exists on <SAMPLE> .\n",
      "ο              => eta            || omicron \n",
      "                  In Antiquity the river was called Gerrhus or Gerrus ( Ancient Greek : Γ ε ρ ρ <SAMPLE> ς ) .\n",
      "κ              => rho            || kappa \n",
      "                  Great Synaxaristes : ( Greek ) Ὁ Ἅ γ ι ο ς Β α σ ι λ ε ι ο ς ὁ Μ ε γ α ς ὁ Κ α π π α δ ο <SAMPLE> η ς .\n"
     ]
    }
   ],
   "source": [
    "print_local_wrong_predictions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "910000   5% (  2m 29s)   0.253   |   1.19: ε -> omicron (✗: epsilon) \n",
      "920000  10% (   5m 0s)   0.226   |   0.00: & -> and (✓) \n",
      "930000  15% (  7m 35s)   0.283   |   0.22: specialise -> specialize (✓) \n",
      "940000  20% (  10m 4s)   0.235   |   1.60: κ -> omicron (✗: kappa) \n",
      "950000  25% ( 12m 32s)   0.244   |   0.00: K. -> k (✓) \n",
      "Saved model to data/models/whole_gen_6_after_words/950000_(EncoderRNN/DecoderRNN)\n",
      "Accuracy: 86.40% (    8640/   10000)\n",
      "960000  30% ( 15m 43s)   0.237   |   0.00: 3.8 -> three point eight (✓) \n",
      "970000  35% ( 18m 13s)   0.194   |   0.00: AJ -> a j (✓) \n",
      "980000  40% ( 20m 42s)   0.253   |   0.01: st -> saint (✓) (forcing)\n",
      "990000  45% (  23m 8s)   0.255   |   0.00: PDF -> p d f (✓) \n",
      "1000000  50% ( 25m 35s)   0.267   |   1.37: Weltfussball.de -> w e l t f u s e l l l l d dot d l (✗: w e l t f u s s b a l l dot d e) \n",
      "Saved model to data/models/whole_gen_6_after_words/1000000_(EncoderRNN/DecoderRNN)\n",
      "Accuracy: 87.71% (    8771/   10000)\n",
      "1010000  55% ( 28m 40s)   0.242   |   3.12: Cos -> c o (✗: cause) \n",
      "1020000  60% (  31m 8s)   0.264   |   0.00: sq -> square (✓) \n",
      "1030000  65% ( 33m 42s)   0.241   |   0.00: & -> and (✓) \n",
      "1040000  70% (  36m 4s)   0.209   |   0.35: 's -> s (✓) \n",
      "1050000  75% ( 38m 30s)   0.265   |   0.00: PTSD -> p t s d (✓) \n",
      "Saved model to data/models/whole_gen_6_after_words/1050000_(EncoderRNN/DecoderRNN)\n",
      "Accuracy: 87.89% (    8789/   10000)\n",
      "1060000  80% ( 41m 41s)   0.240   |   0.00: 10 -> ten (✓) \n",
      "1070000  85% ( 44m 10s)   0.325   |   0.00: & -> and (✓) \n",
      "1080000  90% ( 46m 48s)   0.221   |   0.00: 28 July 2011 -> the twenty eighth of july twenty eleven (✓) \n",
      "1090000  95% ( 49m 12s)   0.257   |   1.42: 0-8264-1727-2 -> o sil eight seven two two two sil two seven sil (✗: o sil eight two six four sil one seven two seven sil two) \n",
      "1100000 100% ( 51m 45s)   0.244   |   0.00: PDF -> p d f (✓) \n",
      "Saved model to data/models/whole_gen_6_after_words/1100000_(EncoderRNN/DecoderRNN)\n",
      "Accuracy: 87.17% (    8717/   10000)\n"
     ]
    }
   ],
   "source": [
    "train_iterations(n_iters=200000, print_every=10000, teacher_forcing_ratio=0.1, lr=0.0005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "81-7017-211    => one sil sil sil one one one one one sil one sil || eight one sil seven o one seven sil two one one \n",
      "                  ISBN <SAMPLE> - X . William Hunter Workman ; Fanny Bullock Workman ( 1904 ) .\n",
      "Gamlehaugen.no => g a m l e a l n n g n e dot dot n n || g a m l e h a u g e n dot n o \n",
      "                  \" <SAMPLE> Parken \" ( in Norwegian ) .\n",
      "Savour         => savior         || savor \n",
      "                  \" <SAMPLE> John Keats' poetry in garden where he wrote \" .\n",
      "NO             => nitrogen monoxide || n o \n",
      "                  The H 2 <SAMPLE> campaign had been conducted through an Internet memo to distributors and restaurants .\n",
      "#              => number         || hash \n",
      "                  Paper <SAMPLE> IAC- 12- A 1 .\n",
      "http://www.stuff.co.nz/national/politics/64209246/rizalman-report-may-see-disciplinary-action => h t t p colon slash slash w w w dot s f u i dot dot dot dot slash || h t t p colon slash slash w w w dot s t u f f dot c o dot n z slash n a t i o n a l slash p o l i t i c s slash s i x f o u r t w o o n i n e t w o f o u r s i x slash r i z a l m a n dash r e p o r t dash m a y dash s e e dash d i s c i p l i n a r y dash a c t i o n \n",
      "                  16 December 2014 <SAMPLE> .\n",
      "101.com        => o n e o n o dot c o m || o n e o o n e dot c o m \n",
      "                  Musicals <SAMPLE> , The Cyber Encyclopedia of Musical Theatre , Television and Film .\n",
      "τ              => rho            || tau \n",
      "                  Great Synaxaristes : ( Greek ) Ἡ Ἁ γ ι α Ἄ ν ν α θ υ γ α <SAMPLE> ε ρ α τ ο ῦ Φ α ν ο υ ὴ λ .\n",
      "http://www.etfo.ca/issuesineducation/eqaotesting/pages/default.aspx => h t t p colon slash slash w w w dot e c i s dot dot dot slash slash || h t t p colon slash slash w w w dot e t f o dot c a slash i s s u e s i n e d u c a t i o n slash e q a o t e s t i n g slash p a g e s slash d e f a u l t dot a s p x \n",
      "                  Retrieved October 26 , from <SAMPLE> .\n",
      "λ              => alpha          || lambda \n",
      "                  Kastellokampos ( Greek : Κ α σ τ ε λ <SAMPLE> ο κ α μ π ο ς ) is a neighbourhood of the city of Patras , Achaea , Greece .\n"
     ]
    }
   ],
   "source": [
    "print_local_wrong_predictions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_iterations(n_iters=300000, print_every=10000, teacher_forcing_ratio=0.1, lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print_local_wrong_predictions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_iterations(n_iters=200000, print_every=10000, teacher_forcing_ratio=0, lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print_local_wrong_predictions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_iterations(n_iters=200000, print_every=10000, teacher_forcing_ratio=0, lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print_local_wrong_predictions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_iterations(n_iters=500000, print_every=10000, teacher_forcing_ratio=0, lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print_local_wrong_predictions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_iterations(n_iters=500000, print_every=10000, teacher_forcing_ratio=0, lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print_local_wrong_predictions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_iterations(n_iters=500000, print_every=10000, teacher_forcing_ratio=0, lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print_local_wrong_predictions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_iterations(n_iters=500000, print_every=10000, teacher_forcing_ratio=0, lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print_local_wrong_predictions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:py3_pytorch_2]",
   "language": "python",
   "name": "conda-env-py3_pytorch_2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
