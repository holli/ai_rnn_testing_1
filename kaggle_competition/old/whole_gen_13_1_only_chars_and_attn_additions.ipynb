{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pytorch utils oh: pytorch_utils_oh_2.py\n",
      "Pytorch: 0.2.0_4\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import importlib\n",
    "from pytorch_utils_oh_2 import *\n",
    "import IPython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MODEL_SAVE_PATH = 'whole_gen_13_1_only_chars_and_attn'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pytorch utils oh: pytorch_utils_oh_2.py\n",
      "Pytorch: 0.2.0_4\n"
     ]
    }
   ],
   "source": [
    "import pytorch_utils_oh_2; importlib.reload(pytorch_utils_oh_2); from pytorch_utils_oh_2 import *;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# all_data = pickle.load(open(\"data/en_train_fixed_4_sentences.pkl\", \"rb\" ))\n",
    "all_data = pickle.load(open(\"data/en_train_fixed_5_manual.pkl\", \"rb\" ))\n",
    "# all_data_sentence_index = all_data.set_index('sentence_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data rows: 1654333,  (dropped rows: 8263859)\n"
     ]
    }
   ],
   "source": [
    "sample_data = all_data.copy()\n",
    "sample_data = sample_data[sample_data['class'] != 'NOT_CHANGED']\n",
    "sample_data = sample_data[sample_data['class'] != 'MANUAL']\n",
    "sample_data = pd.concat([sample_data, all_data[all_data['class_org'] == 'PLAIN'].sample(1000000)])\n",
    "# sample_data = sample_data[sample_data['class'] != 'ELECTRONIC']\n",
    "sample_data = sample_data.reset_index(drop=True)\n",
    "print(\"Data rows: {},  (dropped rows: {})\".format(len(sample_data), len(all_data)-len(sample_data)))\n",
    "#del(all_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>token_id</th>\n",
       "      <th>class</th>\n",
       "      <th>before</th>\n",
       "      <th>after</th>\n",
       "      <th>class_org</th>\n",
       "      <th>a_word_ind</th>\n",
       "      <th>sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1650614</th>\n",
       "      <td>527437</td>\n",
       "      <td>6</td>\n",
       "      <td>NOT_CHANGED</td>\n",
       "      <td>Heart</td>\n",
       "      <td>Heart</td>\n",
       "      <td>PLAIN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>soon after promoting \" this old &lt;SAMPLE&gt; of mi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>948140</th>\n",
       "      <td>530535</td>\n",
       "      <td>3</td>\n",
       "      <td>NOT_CHANGED</td>\n",
       "      <td>and</td>\n",
       "      <td>and</td>\n",
       "      <td>PLAIN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>the unusual shape &lt;SAMPLE&gt; diverse topography ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>806178</th>\n",
       "      <td>692652</td>\n",
       "      <td>0</td>\n",
       "      <td>NOT_CHANGED</td>\n",
       "      <td>Today</td>\n",
       "      <td>Today</td>\n",
       "      <td>PLAIN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;SAMPLE&gt; , 3 sr broadcasts as a relay of melbo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>570253</th>\n",
       "      <td>651585</td>\n",
       "      <td>1</td>\n",
       "      <td>LETTERS</td>\n",
       "      <td>IC</td>\n",
       "      <td>i c</td>\n",
       "      <td>LETTERS</td>\n",
       "      <td>[31, 21, 0]</td>\n",
       "      <td>rokos &lt;SAMPLE&gt; , larson dm , henry td et al .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>362657</th>\n",
       "      <td>418192</td>\n",
       "      <td>1</td>\n",
       "      <td>NUMBERS</td>\n",
       "      <td>2008</td>\n",
       "      <td>two thousand eight</td>\n",
       "      <td>DATE</td>\n",
       "      <td>[5, 8, 16, 0]</td>\n",
       "      <td>in &lt;SAMPLE&gt; the state government finally accee...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>520667</th>\n",
       "      <td>595422</td>\n",
       "      <td>4</td>\n",
       "      <td>NUMBERS</td>\n",
       "      <td>18 September 1945</td>\n",
       "      <td>the eighteenth of september nineteen forty five</td>\n",
       "      <td>DATE</td>\n",
       "      <td>[11, 94, 12, 64, 7, 41, 14, 0]</td>\n",
       "      <td>rousy chanev ( born &lt;SAMPLE&gt; ) is a bulgarian ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>346553</th>\n",
       "      <td>399461</td>\n",
       "      <td>6</td>\n",
       "      <td>NUMBERS</td>\n",
       "      <td>1860</td>\n",
       "      <td>eighteen sixty</td>\n",
       "      <td>DATE</td>\n",
       "      <td>[40, 39, 0]</td>\n",
       "      <td>it was described by thomson in &lt;SAMPLE&gt; .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1214426</th>\n",
       "      <td>586762</td>\n",
       "      <td>17</td>\n",
       "      <td>NOT_CHANGED</td>\n",
       "      <td>and</td>\n",
       "      <td>and</td>\n",
       "      <td>PLAIN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>he was released in 1924 and became active as a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50285</th>\n",
       "      <td>57857</td>\n",
       "      <td>2</td>\n",
       "      <td>NUMBERS</td>\n",
       "      <td>2011</td>\n",
       "      <td>twenty eleven</td>\n",
       "      <td>DATE</td>\n",
       "      <td>[6, 48, 0]</td>\n",
       "      <td>records , &lt;SAMPLE&gt; ) pepper spray the tears aw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297848</th>\n",
       "      <td>343202</td>\n",
       "      <td>9</td>\n",
       "      <td>NUMBERS</td>\n",
       "      <td>1874</td>\n",
       "      <td>eighteen seventy four</td>\n",
       "      <td>DATE</td>\n",
       "      <td>[40, 33, 19, 0]</td>\n",
       "      <td>ronge was born in vienna , austria , in &lt;SAMPL...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         sentence_id  token_id        class             before  \\\n",
       "1650614       527437         6  NOT_CHANGED              Heart   \n",
       "948140        530535         3  NOT_CHANGED                and   \n",
       "806178        692652         0  NOT_CHANGED              Today   \n",
       "570253        651585         1      LETTERS                 IC   \n",
       "362657        418192         1      NUMBERS               2008   \n",
       "520667        595422         4      NUMBERS  18 September 1945   \n",
       "346553        399461         6      NUMBERS               1860   \n",
       "1214426       586762        17  NOT_CHANGED                and   \n",
       "50285          57857         2      NUMBERS               2011   \n",
       "297848        343202         9      NUMBERS               1874   \n",
       "\n",
       "                                                   after class_org  \\\n",
       "1650614                                            Heart     PLAIN   \n",
       "948140                                               and     PLAIN   \n",
       "806178                                             Today     PLAIN   \n",
       "570253                                               i c   LETTERS   \n",
       "362657                                two thousand eight      DATE   \n",
       "520667   the eighteenth of september nineteen forty five      DATE   \n",
       "346553                                    eighteen sixty      DATE   \n",
       "1214426                                              and     PLAIN   \n",
       "50285                                      twenty eleven      DATE   \n",
       "297848                             eighteen seventy four      DATE   \n",
       "\n",
       "                             a_word_ind  \\\n",
       "1650614                             NaN   \n",
       "948140                              NaN   \n",
       "806178                              NaN   \n",
       "570253                      [31, 21, 0]   \n",
       "362657                    [5, 8, 16, 0]   \n",
       "520667   [11, 94, 12, 64, 7, 41, 14, 0]   \n",
       "346553                      [40, 39, 0]   \n",
       "1214426                             NaN   \n",
       "50285                        [6, 48, 0]   \n",
       "297848                  [40, 33, 19, 0]   \n",
       "\n",
       "                                                  sentence  \n",
       "1650614  soon after promoting \" this old <SAMPLE> of mi...  \n",
       "948140   the unusual shape <SAMPLE> diverse topography ...  \n",
       "806178   <SAMPLE> , 3 sr broadcasts as a relay of melbo...  \n",
       "570253       rokos <SAMPLE> , larson dm , henry td et al .  \n",
       "362657   in <SAMPLE> the state government finally accee...  \n",
       "520667   rousy chanev ( born <SAMPLE> ) is a bulgarian ...  \n",
       "346553           it was described by thomson in <SAMPLE> .  \n",
       "1214426  he was released in 1924 and became active as a...  \n",
       "50285    records , <SAMPLE> ) pepper spray the tears aw...  \n",
       "297848   ronge was born in vienna , austria , in <SAMPL...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_data.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del(all_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ELECTRONIC', 'LETTERS', 'NOT_CHANGED', 'NUMBERS', 'PLAIN', 'VERBATIM']\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "categories_all = sorted(sample_data[\"class\"].unique())\n",
    "print(categories_all)\n",
    "print(len(categories_all))\n",
    "categories_index = dict((c, i) for i, c in enumerate(categories_all))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>token_id</th>\n",
       "      <th>class</th>\n",
       "      <th>before</th>\n",
       "      <th>after</th>\n",
       "      <th>class_org</th>\n",
       "      <th>a_word_ind</th>\n",
       "      <th>sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>132260</th>\n",
       "      <td>152196</td>\n",
       "      <td>16</td>\n",
       "      <td>NUMBERS</td>\n",
       "      <td>6</td>\n",
       "      <td>six</td>\n",
       "      <td>CARDINAL</td>\n",
       "      <td>[20, 0]</td>\n",
       "      <td>the highway passes over the norfolk southern r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>752067</th>\n",
       "      <td>580827</td>\n",
       "      <td>1</td>\n",
       "      <td>NOT_CHANGED</td>\n",
       "      <td>Bjork's</td>\n",
       "      <td>Bjork's</td>\n",
       "      <td>PLAIN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>\" &lt;SAMPLE&gt; biophilia becomes first app in new ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        sentence_id  token_id        class   before    after class_org  \\\n",
       "132260       152196        16      NUMBERS        6      six  CARDINAL   \n",
       "752067       580827         1  NOT_CHANGED  Bjork's  Bjork's     PLAIN   \n",
       "\n",
       "       a_word_ind                                           sentence  \n",
       "132260    [20, 0]  the highway passes over the norfolk southern r...  \n",
       "752067        NaN  \" <SAMPLE> biophilia becomes first app in new ...  "
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_data.sample(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_data = sample_data[sample_data['before'].str.len() > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>token_id</th>\n",
       "      <th>class</th>\n",
       "      <th>before</th>\n",
       "      <th>after</th>\n",
       "      <th>class_org</th>\n",
       "      <th>a_word_ind</th>\n",
       "      <th>sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [sentence_id, token_id, class, before, after, class_org, a_word_ind, sentence]\n",
       "Index: []"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_data[sample_data['after'].str.len() < 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utils stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<SOS><EOS>☒ !\"#$%&'(),-./0123456789:;ABCDEFGHIJKLMNOPQRSTUVWXYZ_abcdefghijklmnopqrstuvwxyz~£¥ª²³µº¼½¾éɒʻˈΩμ—€⅓⅔⅛\n"
     ]
    }
   ],
   "source": [
    "chars_normal, chars_normal_index = load_characters_pkl('data/en_features/chars_normal.pkl')\n",
    "print(''.join(chars_normal))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<SOS><EOS>☒ '-abcdefghijklmnopqrstuvwxyzé\n"
     ]
    }
   ],
   "source": [
    "chars_after = sorted(list(set(''.join(list(sample_data['after'].unique())).lower())))\n",
    "chars_after = [SOS_TOKEN, EOS_TOKEN, UNKNOWN_CHAR] + chars_after\n",
    "chars_after_index = dict((c, i) for i, c in enumerate(chars_after))\n",
    "print(''.join(chars_after))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "chars_after, chars_after_index = load_characters_pkl('data/en_features/chars_after_1.pkl')\n",
    "print(''.join(chars_after))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wv_vecs, wv_words, wv_idx = load_glove('/home/ohu/koodi/data/glove_wordvec/glove.6B.50d.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### After words handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 33])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sos_tensor = torch.zeros(1, 1, len(chars_after_index))\n",
    "sos_tensor[0, 0, chars_after_index[SOS_TOKEN]] = 1\n",
    "sos_tensor.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### More balanced sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import collections\n",
    "\n",
    "balanced_data_classes_select = list(sample_data.groupby('class'))\n",
    "\n",
    "balanced_data_accessed_counter = 0 \n",
    "balanced_data_randomize_freq = False\n",
    "balanced_data_length = 0\n",
    "\n",
    "last_samples = collections.deque(maxlen=100)\n",
    "balanced_data_last_sample = last_samples\n",
    "\n",
    "def balanced_data_randomize_org(max_len=30000):\n",
    "    global balanced_data, balanced_data_length, balanced_data_accessed_counter, balanced_data_randomize_freq\n",
    "    balanced_data = pd.concat([v.sample(min(max_len, len(v))) for k, v in balanced_data_classes_select])\n",
    "    balanced_data = pd.concat([balanced_data, sample_data[sample_data['class']=='NOT_CHANGED'].sample(int(max_len*2))])\n",
    "    balanced_data_length = len(balanced_data)\n",
    "    balanced_data_randomize_freq = balanced_data_length * 0.2\n",
    "    balanced_data_accessed_counter = 0\n",
    "balanced_data_randomize = balanced_data_randomize_org\n",
    "\n",
    "def balanced_data_sample_row():\n",
    "    global balanced_data_accessed_counter\n",
    "    global balanced_data_last_sample\n",
    "    balanced_data_accessed_counter += 1\n",
    "    if balanced_data_randomize_freq and balanced_data_accessed_counter > balanced_data_randomize_freq:\n",
    "        balanced_data_randomize()\n",
    "        \n",
    "    sample = balanced_data.iloc[random.randint(1, balanced_data_length-1)]\n",
    "    last_samples.append(sample)\n",
    "    balanced_data_last_sample = sample\n",
    "    return sample\n",
    "    \n",
    "balanced_data_randomize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "class\n",
       "ELECTRONIC      4964\n",
       "LETTERS        30000\n",
       "NOT_CHANGED    90000\n",
       "NUMBERS        30000\n",
       "PLAIN          30000\n",
       "VERBATIM       11741\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#all_data.groupby('class')['class'].count()\n",
    "#sample_data.groupby('class')['class'].count()\n",
    "balanced_data.groupby('class')['class'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentence_id                                           365695\n",
       "token_id                                                   0\n",
       "class                                                  PLAIN\n",
       "before                                                    dr\n",
       "after                                                 doctor\n",
       "class_org                                              PLAIN\n",
       "a_word_ind                                          [113, 0]\n",
       "sentence       <SAMPLE> guy liagre succeeded him from 2012 .\n",
       "Name: 317119, dtype: object"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "balanced_data_sample_row()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentence_id                                               563382\n",
       "token_id                                                       6\n",
       "class                                                    LETTERS\n",
       "before                                                        C-\n",
       "after                                                          c\n",
       "class_org                                                LETTERS\n",
       "a_word_ind                                               [21, 0]\n",
       "sentence       86 wing and its complement of <SAMPLE> 47 dako...\n",
       "Name: 491851, dtype: object"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_samples[-2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PLAIN : vs -> versus\n",
      "['\"', 'ufc', '186', ':', 'johnson', '<SAMPLE>']\n",
      "torch.Size([1, 3, 104])\n"
     ]
    }
   ],
   "source": [
    "def get_random_sample():\n",
    "    sample_row = balanced_data_sample_row()   \n",
    "    return sample_row['before'], sample_row['after'].lower(), sample_row['class'], sample_row['sentence'].split(' ')\n",
    "            \n",
    "def tmp():\n",
    "    s_bef, s_aft, s_class, s_sentence = get_random_sample()\n",
    "    print(s_class, ':', s_bef, '->', s_aft)\n",
    "    print(s_sentence)\n",
    "    print(string_to_tensor(s_bef, chars_normal_index).shape)\n",
    "tmp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 0 ns, sys: 0 ns, total: 0 ns\n",
      "Wall time: 287 µs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('State', 'state', 'NOT_CHANGED', ['<SAMPLE>', 'of', 'alabama', '.'])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "get_random_sample()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "use_cuda = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MAX_ATTENTION_LENGTH = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "754"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>token_id</th>\n",
       "      <th>class</th>\n",
       "      <th>before</th>\n",
       "      <th>after</th>\n",
       "      <th>class_org</th>\n",
       "      <th>a_word_ind</th>\n",
       "      <th>sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>332252</th>\n",
       "      <td>382824</td>\n",
       "      <td>1</td>\n",
       "      <td>ELECTRONIC</td>\n",
       "      <td>http://www.qub.ac.uk/home/TheUniversity/Locati...</td>\n",
       "      <td>h t t p colon slash slash w w w dot q u b dot ...</td>\n",
       "      <td>ELECTRONIC</td>\n",
       "      <td>[45, 30, 30, 24, 129, 101, 101, 52, 52, 52, 74...</td>\n",
       "      <td>see &lt;SAMPLE&gt; , for example .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>457102</th>\n",
       "      <td>524515</td>\n",
       "      <td>2</td>\n",
       "      <td>ELECTRONIC</td>\n",
       "      <td>http://brain.oxfordjournals.org/content/137/2/...</td>\n",
       "      <td>h t t p colon slash slash b r a i n dot o x f ...</td>\n",
       "      <td>ELECTRONIC</td>\n",
       "      <td>[45, 30, 30, 24, 129, 101, 101, 36, 35, 22, 31...</td>\n",
       "      <td>online at &lt;SAMPLE&gt; , j . graham .</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        sentence_id  token_id       class  \\\n",
       "332252       382824         1  ELECTRONIC   \n",
       "457102       524515         2  ELECTRONIC   \n",
       "\n",
       "                                                   before  \\\n",
       "332252  http://www.qub.ac.uk/home/TheUniversity/Locati...   \n",
       "457102  http://brain.oxfordjournals.org/content/137/2/...   \n",
       "\n",
       "                                                    after   class_org  \\\n",
       "332252  h t t p colon slash slash w w w dot q u b dot ...  ELECTRONIC   \n",
       "457102  h t t p colon slash slash b r a i n dot o x f ...  ELECTRONIC   \n",
       "\n",
       "                                               a_word_ind  \\\n",
       "332252  [45, 30, 30, 24, 129, 101, 101, 52, 52, 52, 74...   \n",
       "457102  [45, 30, 30, 24, 129, 101, 101, 36, 35, 22, 31...   \n",
       "\n",
       "                                 sentence  \n",
       "332252       see <SAMPLE> , for example .  \n",
       "457102  online at <SAMPLE> , j . graham .  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp = sample_data[sample_data['before'].str.len()>MAX_ATTENTION_LENGTH]\n",
    "len(tmp)\n",
    "tmp.sample(2)\n",
    "# tmp[~tmp['before'].str.contains('/')].sample(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EncoderRNN (\n",
       "  (rnn_words): GRU(50, 64, batch_first=True, bidirectional=True)\n",
       "  (rnn_chars): GRU(104, 256, batch_first=True, bidirectional=True)\n",
       ")"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, words_input_size, chars_input_size, words_hidden_size, chars_hidden_size,\n",
    "                 words_layers=1, chars_layers=1):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        \n",
    "        self.words_layers = words_layers\n",
    "        self.chars_layers = chars_layers\n",
    "        self.words_hidden_size = words_hidden_size\n",
    "        self.chars_hidden_size = chars_hidden_size\n",
    "        self.hidden_size = words_hidden_size + chars_hidden_size\n",
    "\n",
    "        self.rnn_words = nn.GRU(words_input_size, words_hidden_size // 2, words_layers,\n",
    "                                 batch_first=True, bidirectional=True)\n",
    "\n",
    "        self.rnn_chars = nn.GRU(chars_input_size, chars_hidden_size // 2, chars_layers,\n",
    "                                 batch_first=True, bidirectional=True)\n",
    "        \n",
    "    def forward(self, word_vectors, string_tensor, hidden = None, init_hidden = True):\n",
    "        if init_hidden:\n",
    "            hidden_words, hidden_chars = self.init_hidden()\n",
    "        \n",
    "        all_outputs_words, hidden_words = self.rnn_words(word_vectors, hidden_words)\n",
    "        output_words = hidden_words.view(1, -1)\n",
    "        \n",
    "        all_outputs_chars, hidden_chars = self.rnn_chars(string_tensor, hidden_chars)\n",
    "        output_chars = hidden_chars.view(1, -1)\n",
    "        \n",
    "        #hidden_states_cat = Variable(torch.zeros(MAX_ATTENTION_LENGTH, self.hidden_size)).cuda()\n",
    "        #for ei in range(min(MAX_ATTENTION_LENGTH, len(string_tensor[0]))):\n",
    "        #    hidden_states_cat[ei] = torch.cat((output_words, all_outputs_chars[0, ei].view(1,-1)), 1)\n",
    "\n",
    "        all_outputs_chars_padded = Variable(torch.zeros(MAX_ATTENTION_LENGTH, self.chars_hidden_size)).cuda()\n",
    "        att_length = min(len(all_outputs_chars[0]), MAX_ATTENTION_LENGTH-1)\n",
    "        all_outputs_chars_padded[0:att_length] = all_outputs_chars[0][0:att_length]\n",
    "        \n",
    "        output = torch.cat((output_words, output_chars), 1)\n",
    "\n",
    "        #output = torch.cat((output_words, output_chars), 1)\n",
    "        \n",
    "        #return output, all_outputs_chars\n",
    "        return output, all_outputs_chars_padded\n",
    "\n",
    "    def init_hidden(self):\n",
    "        var1 = Variable(torch.zeros(2 * self.words_layers, 1, self.words_hidden_size // 2))\n",
    "        var2 = Variable(torch.zeros(2 * self.chars_layers, 1, self.chars_hidden_size // 2))\n",
    "        \n",
    "        var1 = var1.cuda(); var2 = var2.cuda()\n",
    "        return (var1, var2)\n",
    "    \n",
    "    \n",
    "encoder_rnn = EncoderRNN(words_input_size=wv_vecs.shape[-1], chars_input_size=len(chars_normal),\n",
    "                         words_hidden_size=128, chars_hidden_size=512,\n",
    "                         words_layers=1, chars_layers=1).cuda()\n",
    "encoder_rnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "died\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'died'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 640])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([30, 512])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def test_encoder_single_sample():\n",
    "    s_bef, s_aft, s_class, s_sentence = get_random_sample()\n",
    "    #s_bef, s_aft, s_class, s_sentence = get_random_sample(True)\n",
    "    print(s_bef)\n",
    "    \n",
    "    words_t = Variable(words_to_word_vectors_tensor(s_sentence, wv_vecs, wv_idx)).cuda()\n",
    "    \n",
    "    string_t = string_to_tensor(s_bef, chars_normal_index)\n",
    "    string_t = Variable(string_t).cuda()\n",
    "    \n",
    "    return encoder_rnn(words_t, string_t), s_bef\n",
    "    \n",
    "(tmp_encoder_output, tmp_encoder_outputs), tmp = test_encoder_single_sample()\n",
    "tmp\n",
    "tmp_encoder_output.size()\n",
    "tmp_encoder_outputs.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecoderRNN (\n",
       "  (emb_lin): Linear (33 -> 640)\n",
       "  (dropout): Dropout (p = 0.1)\n",
       "  (attn): Linear (1280 -> 30)\n",
       "  (attn_combine): Linear (1152 -> 640)\n",
       "  (rnn): GRU(640, 640, batch_first=True)\n",
       "  (lin_out): Linear (640 -> 33)\n",
       ")"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[torch.Size([1, 33]), torch.Size([1, 640]), torch.Size([1, 30])]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class DecoderRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, chars_encoded_size,\n",
    "                 n_layers=1, dropout_p=0.1, max_length=MAX_ATTENTION_LENGTH):\n",
    "        super(DecoderRNN, self).__init__()\n",
    "        \n",
    "        self.n_layers = n_layers\n",
    "        self.hidden_size = hidden_size\n",
    "        self.max_length = max_length\n",
    "        \n",
    "        self.emb_lin = nn.Linear(input_size, hidden_size)\n",
    "        self.dropout = nn.Dropout(dropout_p)\n",
    "        self.attn = nn.Linear(self.hidden_size+self.hidden_size, self.max_length)\n",
    "        self.attn_combine = nn.Linear(self.hidden_size+chars_encoded_size, self.hidden_size)\n",
    "        \n",
    "        #self.module_attn = torch.nn.ModuleList([self.emb_lin, self.dropout, self.attn, self.attn_combine])\n",
    "        \n",
    "        \n",
    "        self.rnn = nn.GRU(hidden_size, hidden_size, n_layers, batch_first=True, bidirectional=False)\n",
    "        self.lin_out = nn.Linear(hidden_size, input_size)\n",
    "        \n",
    "        #self.module_rnn = torch.nn.ModuleList([self.rnn, self.lin_out])\n",
    "\n",
    "    def forward(self, last_input, hidden, encoder_outputs):\n",
    "        embedded = self.emb_lin(last_input).view(1, 1, -1)\n",
    "        embedded = self.dropout(embedded)\n",
    "        embedded = embedded[0]\n",
    "                \n",
    "        attn_weights = F.softmax(self.attn(torch.cat((embedded, hidden), 1)))\n",
    "        attn_applied = torch.bmm(attn_weights.unsqueeze(0), encoder_outputs.unsqueeze(0))\n",
    "        #return embedded, attn_applied\n",
    "        \n",
    "        rnn_input = torch.cat((embedded, attn_applied[0]), 1)\n",
    "        rnn_input = self.attn_combine(rnn_input).unsqueeze(0)\n",
    "        rnn_input = F.relu(rnn_input)\n",
    "    \n",
    "        output, hidden = self.rnn(rnn_input, hidden.unsqueeze(0))\n",
    "        output = F.log_softmax(self.lin_out(output[0]))\n",
    "        \n",
    "        return output, hidden[0], attn_weights\n",
    "    \n",
    "    def init_rest_hidden(self, input_var):\n",
    "        if self.n_layers > 1:\n",
    "            hid_var = Variable(torch.zeros(self.n_layers - 1, 1, self.hidden_size)).cuda()\n",
    "            res = torch.cat((input_var, hid_var), 0)\n",
    "            return res\n",
    "        else:\n",
    "            return input_var\n",
    "        \n",
    "    def mods_split(self):\n",
    "        mods = list(decoder_rnn.modules())[1:]\n",
    "        for gru_index, mod in enumerate(mods):\n",
    "            #print(mod)\n",
    "            if type(mod) == torch.nn.modules.rnn.GRU:\n",
    "                break\n",
    "        return mods[:gru_index], mods[gru_index:]\n",
    "        \n",
    "    def mods_attn(self):\n",
    "        return self.mods_split()[0]\n",
    "        \n",
    "    def mods_gru(self):\n",
    "        return self.mods_split()[1]\n",
    "\n",
    "decoder_rnn = DecoderRNN(input_size=len(chars_after), hidden_size=tmp_encoder_output.size()[1],\n",
    "                         chars_encoded_size=tmp_encoder_outputs.size()[1], n_layers=1)\n",
    "decoder_rnn = decoder_rnn.cuda()\n",
    "decoder_rnn\n",
    "\n",
    "tmp = decoder_rnn(Variable(sos_tensor).cuda(), tmp_encoder_output, tmp_encoder_outputs)\n",
    "#tmp\n",
    "[v.size() for v in tmp]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'lr': 3, 'params': <generator object Module.parameters at 0x7f066db68150>},\n",
       " {'lr': 3, 'params': <generator object Module.parameters at 0x7f066dcf9e08>},\n",
       " {'lr': 3, 'params': <generator object Module.parameters at 0x7f066dcf9a40>},\n",
       " {'lr': 3, 'params': <generator object Module.parameters at 0x7f066dcf9ba0>},\n",
       " {'params': <generator object Module.parameters at 0x7f066dcf9200>},\n",
       " {'params': <generator object Module.parameters at 0x7f066dcf99e8>},\n",
       " {'params': <generator object Module.parameters at 0x7f066dcf94c0>}]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp = [{'params': mod.parameters(), 'lr': 3} for mod in decoder_rnn.mods_attn()]\n",
    "tmp += [{'params': mod.parameters()} for mod in decoder_rnn.mods_gru()]\n",
    "tmp.append(\n",
    "    {'params': encoder_rnn.parameters()}\n",
    ")\n",
    "tmp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training etc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('bef m tworee e derco',\n",
       " 'bef m tworee e derco',\n",
       " 'after',\n",
       " ('bef', 'after', '', ['here', 'we', 'go', 'again']))"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_model_single_sample(None, False, sample=('bef', 'after', '', 'here we go again'.split(' ')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model_single_sample(model=None, return_more=False, sample=False):\n",
    "    decoder_rnn.eval()\n",
    "    encoder_rnn.eval()\n",
    "    global encoder_output, encoder_outputs, decoded_output, char_index\n",
    "    \n",
    "    if not sample:\n",
    "        sample = get_random_sample()\n",
    "    s_bef, s_aft, s_class, s_sentence = sample\n",
    "        \n",
    "    words_t = Variable(words_to_word_vectors_tensor(s_sentence, wv_vecs, wv_idx)).cuda()\n",
    "    \n",
    "    string_t = string_to_tensor(s_bef, chars_normal_index)\n",
    "    string_t = Variable(string_t).cuda()\n",
    "    \n",
    "    encoder_output, encoder_outputs = encoder_rnn(words_t, string_t)\n",
    "    \n",
    "    decoder_input = Variable(sos_tensor).cuda()\n",
    "    decoder_hidden = encoder_output\n",
    "    \n",
    "    decoded_output = []\n",
    "    decoder_attns_arr = []\n",
    "    max_length = 50\n",
    "    for _ in range(max_length):\n",
    "        decoder_output, decoder_hidden, decoder_attns = decoder_rnn(decoder_input, decoder_hidden, encoder_outputs)\n",
    "        decoder_attns_arr.append(decoder_attns)\n",
    "        #return decoder_output\n",
    "\n",
    "        topv, topi = decoder_output.data.topk(1)\n",
    "        char_index = topi[0][0]\n",
    "        char = chars_after[char_index] # Use own prediction as next input\n",
    "                \n",
    "        if char == EOS_TOKEN:\n",
    "            break\n",
    "\n",
    "        decoded_output.append(char)\n",
    "                \n",
    "        decoder_input = torch.zeros(1, 1, len(chars_after_index))\n",
    "        decoder_input[0, 0, char_index] = 1\n",
    "        decoder_input = Variable(decoder_input).cuda()\n",
    "    \n",
    "    output = ''.join(decoded_output)\n",
    "    sample_target = s_aft\n",
    "    \n",
    "    decoder_rnn.train()\n",
    "    encoder_rnn.train()\n",
    "    \n",
    "    if return_more:\n",
    "        return output, decoded_output, decoder_attns_arr, sample\n",
    "    \n",
    "    return output, output, sample_target, sample\n",
    "    \n",
    "tmp = test_model_single_sample(None)\n",
    "tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27 January 2015 => -mrrfrfrfrfrfrfrfrfr || the twenty seventh of january twenty fifteen \n",
      "                  ['<SAMPLE>', '.']\n",
      ":              => aarfrffrffrffrffrffr || to \n",
      "                  ['chemische', 'berichte', '5', '<SAMPLE>', '399', '.']\n"
     ]
    }
   ],
   "source": [
    "def print_local_wrong_predictions(max_results=10):\n",
    "    arr = get_some_wrong_predictions(None, test_model_single_sample, max_iterations=10000, max_results=max_results)\n",
    "    for sample, predict, output in arr:\n",
    "        s_bef, s_aft, s_class, s_sentence = sample\n",
    "        print(\"{:<14} => {:<14} || {} \\n{:>17} {}\".format(s_bef, predict, s_aft, '', s_sentence, ))\n",
    "print_local_wrong_predictions(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "test_model_accuracy(encoder_rnn, test_model_single_sample, n_sample=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "collections.deque(maxlen=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train(s_bef, s_aft, s_sentence, optimizer, loss_function,\n",
    "          use_teacher_forcing, max_length=20):\n",
    "    \n",
    "    global encoder_output, encoder_outputs, decoded_output, char_index\n",
    "    \n",
    "    words_t = Variable(words_to_word_vectors_tensor(s_sentence, wv_vecs, wv_idx)).cuda() \n",
    "    \n",
    "    string_t = string_to_tensor(s_bef, chars_normal_index)\n",
    "    string_t = Variable(string_t).cuda()\n",
    "    \n",
    "    target_arr = [chars_after_index[c] for c in list(s_aft)] + [chars_after_index[EOS_TOKEN]]\n",
    "    optimizer.zero_grad()\n",
    "    loss = 0\n",
    "    \n",
    "    \n",
    "    encoder_output, encoder_outputs = encoder_rnn(words_t, string_t)\n",
    "    \n",
    "    \n",
    "    decoder_hidden = encoder_output\n",
    "    decoder_input = Variable(sos_tensor).cuda()\n",
    "\n",
    "    decoded_output = []\n",
    "    for i in range(len(target_arr)):\n",
    "        decoder_output, decoder_hidden, decoder_attns = decoder_rnn(decoder_input, decoder_hidden, encoder_outputs)\n",
    "\n",
    "        decoder_target_i = target_arr[i]\n",
    "        decoder_target_i = Variable(torch.LongTensor([decoder_target_i])).cuda()\n",
    "        loss += loss_function(decoder_output, decoder_target_i)\n",
    "        \n",
    "        topv, topi = decoder_output.data.topk(1)\n",
    "        char_index = topi[0][0]\n",
    "        char = chars_after[char_index] # Use own prediction as next input\n",
    "        decoded_output.append(char)\n",
    "        \n",
    "        if use_teacher_forcing:\n",
    "            char_index = target_arr[i] # replace input with right target\n",
    "        else:\n",
    "            # use output normally as input \n",
    "            if char == EOS_TOKEN:\n",
    "                break\n",
    "                \n",
    "        decoder_input = torch.zeros(1, 1, len(chars_after_index))\n",
    "        decoder_input[0, 0, char_index] = 1\n",
    "        decoder_input = Variable(decoder_input).cuda()\n",
    "        \n",
    "    if decoded_output[-1] == EOS_TOKEN:\n",
    "        decoded_output = decoded_output[:-1]\n",
    "\n",
    "    loss.backward()\n",
    "    \n",
    "    # https://github.com/pytorch/examples/blob/master/word_language_model/main.py\n",
    "    clip_parameters_value = False\n",
    "    clips = []\n",
    "    if clip_parameters_value:\n",
    "        for m in [decoder_rnn, encoder_rnn]:\n",
    "            clips.append(torch.nn.utils.clip_grad_norm(m.parameters(), clip_parameters_value))\n",
    "    \n",
    "    return clips\n",
    "    \n",
    "    optimizer.step()\n",
    "\n",
    "    return ''.join(decoded_output), (loss.data[0] / len(target_arr))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3.73758602142334,\n",
       " 1.2431634664535522,\n",
       " 1.3652507066726685,\n",
       " 0.4760829508304596,\n",
       " 4.131037712097168,\n",
       " 1.8706603050231934,\n",
       " 1.8490597009658813,\n",
       " 1.8010691404342651,\n",
       " 2.689138174057007,\n",
       " 0.7098698616027832,\n",
       " 4.385306358337402,\n",
       " 0.7123854160308838,\n",
       " 3.5336079597473145,\n",
       " 0.9343348145484924,\n",
       " 3.8114545345306396,\n",
       " 0.9602910280227661]"
      ]
     },
     "execution_count": 432,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters = [p for p in encoder_rnn.parameters()]\n",
    "#parameters\n",
    "tmp = [p.grad.max().data[0] for p in parameters]\n",
    "tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 430,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = 0.001\n",
    "tmp = [{'params': mod.parameters(), 'lr': (lr/10)} for mod in decoder_rnn.mods_attn()]\n",
    "tmp += [{'params': mod.parameters()} for mod in decoder_rnn.mods_gru()]\n",
    "tmp.append(\n",
    "    {'params': encoder_rnn.parameters()}\n",
    ")\n",
    "optimizer = torch.optim.Adam(tmp, lr=lr)    \n",
    "loss_function = nn.NLLLoss()\n",
    "train(s_bef, s_aft, s_sentence, optimizer, loss_function, use_teacher_forcing=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'//www.bidartourism.c'"
      ]
     },
     "execution_count": 374,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s_bef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'//www.bidartourism.com/fort.htmlhttp://www.bidartourism.com/rangeenMahal.htmlhttp://www.bidartourism.com/TarkashMahal.htmlhttp://www.bidartourism.com/GaganMahal.htmlhttp://www.bidartourism.com/Chaubara.htmlhttp://www.holidayiq.com/Solah-Khamba-Mosque-Bidar-Sightseeing-649-757.htmlhttp://www.hoparoundindia.com/karnataka/bidar-attractions/gurudwara-nanak-jhira-saheb.aspx'"
      ]
     },
     "execution_count": 267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_samples[-2]['before']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'//www'"
      ]
     },
     "execution_count": 429,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp = last_samples[-2]\n",
    "s_bef = tmp['before'][0:5]\n",
    "s_aft = tmp['after'][0:5]\n",
    "s_sentence = tmp['sentence'].split(' ')\n",
    "s_bef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_t = Variable(words_to_word_vectors_tensor(s_sentence, wv_vecs, wv_idx)).cuda() \n",
    "string_t = string_to_tensor(s_bef, chars_normal_index)\n",
    "string_t = Variable(string_t).cuda()\n",
    "target_arr = [chars_after_index[c] for c in list(s_aft)] + [chars_after_index[EOS_TOKEN]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_output, encoder_outputs = encoder_rnn(words_t, string_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       "-0.3473\n",
       "-0.5914\n",
       " 0.6090\n",
       " 0.1273\n",
       "[torch.cuda.FloatTensor of size 4 (GPU 0)]"
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_output[0,0:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       " 0.2169\n",
       "-0.2463\n",
       "-0.0235\n",
       "-0.0335\n",
       "[torch.cuda.FloatTensor of size 4 (GPU 0)]"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_outputs[0,0:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       " 0.4858\n",
       " 0.1931\n",
       " 0.7218\n",
       "[torch.cuda.FloatTensor of size 3 (GPU 0)]"
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_outputs[0,-4:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "decoder_hidden = encoder_output\n",
    "decoder_input = Variable(sos_tensor).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_output, decoder_hidden, decoder_attns = decoder_rnn(decoder_input, decoder_hidden, encoder_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topv, topi = decoder_output.data.topk(1)\n",
    "char_index = topi[0][0]\n",
    "char_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_iterations(n_iters=100000, lr=0.001, teacher_forcing_ratio=0.5,\n",
    "                     print_every=10000, plot_every=1000):\n",
    "    global optimizer\n",
    "    start = time.time()\n",
    "    \n",
    "    decoder_rnn.train()\n",
    "    encoder_rnn.train()\n",
    "\n",
    "    current_loss = 0\n",
    "    current_loss_iter = 0\n",
    "\n",
    "    tmp = [{'params': mod.parameters(), 'lr': (lr/10)} for mod in decoder_rnn.mods_attn()]\n",
    "    tmp += [{'params': mod.parameters()} for mod in decoder_rnn.mods_gru()]\n",
    "    tmp.append(\n",
    "        {'params': encoder_rnn.parameters()}\n",
    "    )\n",
    "    optimizer = torch.optim.Adam(tmp, lr=lr)\n",
    "    \n",
    "    loss_function = nn.NLLLoss()\n",
    "    \n",
    "    for iteration in range(1, n_iters + 1):\n",
    "        model_training.iterations += 1\n",
    "        \n",
    "        use_teacher_forcing = random.random() < teacher_forcing_ratio\n",
    "        \n",
    "        s_bef, s_aft, s_class, s_sentence = get_random_sample()\n",
    "        \n",
    "        result, loss = train(s_bef=s_bef, s_aft=s_aft, s_sentence=s_sentence,\n",
    "                             optimizer=optimizer,\n",
    "                             loss_function=nn.NLLLoss(), use_teacher_forcing=use_teacher_forcing,\n",
    "                             max_length=40 )\n",
    "        \n",
    "        current_loss += loss\n",
    "        current_loss_iter += 1\n",
    "\n",
    "        # Print iter number, loss, name and guess\n",
    "        if iteration % print_every == 0:\n",
    "            teacher_forcing_str = \"\"\n",
    "            if use_teacher_forcing:\n",
    "                teacher_forcing_str = \"(forcing)\"\n",
    "            correct = '✓' if result == s_aft else \"✗: {}\".format(s_aft)\n",
    "            \n",
    "            print(\"{:>6d} {:>4.0%} ({:>8}) {:>7.3f}   | {:>6.2f}: {} -> {} ({}) {}\".format(\n",
    "                      model_training.iterations, iteration/n_iters, time_since(start),\n",
    "                      current_loss/current_loss_iter, loss,\n",
    "                      s_bef, result, correct, teacher_forcing_str))\n",
    "\n",
    "        # Add current loss avg to list of losses\n",
    "        if iteration % plot_every == 0:\n",
    "            model_training.losses.append(current_loss / plot_every)\n",
    "            model_training.learning_rates.append(lr)\n",
    "            current_loss = 0\n",
    "            current_loss_iter = 0\n",
    "            \n",
    "        if model_training.iterations % 50000 == 0 or model_training.iterations == 10:\n",
    "            model_training.save_models()\n",
    "            acc = test_model_accuracy(encoder_rnn, test_model_single_sample)\n",
    "            model_training.accuracy.append(acc)\n",
    "    \n",
    "    # test_model_accuracy(model, n_sample=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Save path: data/models/whole_gen_13_1_only_chars_and_attn\n"
     ]
    }
   ],
   "source": [
    "model_training = ModelTraining(MODEL_SAVE_PATH, [encoder_rnn, decoder_rnn])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     9  18% (   0m 0s)   3.449   |   3.37: the -> eee (✗: the) \n",
      "Saved model to data/models/whole_gen_13_1_only_chars_and_attn/10_(EncoderRNN/DecoderRNN)\n",
      "Accuracy: 0.00% (       0/   10000)\n",
      "    18  36% (  3m 42s)   3.431   |   3.40: revised -> eeeeeee (✗: revised) (forcing)\n",
      "    27  54% (  3m 42s)   3.412   |   3.35: - -> ee (✗: to) \n",
      "    36  72% (  3m 42s)   3.401   |   3.20: after -> eeeee (✗: after) \n",
      "    45  90% (  3m 43s)   3.380   |   3.15: 1998 -> eeeeeeeeeeeeeeeeeeeee (✗: nineteen ninety eight) \n"
     ]
    }
   ],
   "source": [
    "train_iterations(n_iters=50, print_every=9, lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       "\n",
       "Columns 0 to 12 \n",
       "  nan   nan   nan   nan   nan   nan   nan   nan   nan   nan   nan   nan   nan\n",
       "\n",
       "Columns 13 to 25 \n",
       "  nan   nan   nan   nan   nan   nan   nan   nan   nan   nan   nan   nan   nan\n",
       "\n",
       "Columns 26 to 32 \n",
       "  nan   nan   nan   nan   nan   nan   nan\n",
       "[torch.cuda.FloatTensor of size 1x33 (GPU 0)]"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   550  53% (  0m 16s)   2.962   |   2.91: coastal -> aneeeee (✗: coastal) \n"
     ]
    }
   ],
   "source": [
    "train_iterations(n_iters=(1000-model_training.iterations), print_every=500, lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1e-05"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.0001"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer.param_groups[0]['lr']\n",
    "optimizer.param_groups[6]['lr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  2000  11% (  0m 25s)   2.627   |   2.94: flavour -> aoande (✗: flavor) \n",
      "  3000  22% (  0m 55s)   2.436   |   1.15: and -> and (✓) (forcing)\n",
      "  4000  33% (  1m 21s)   2.131   |   1.75: OS -> s s (✗: o s) (forcing)\n",
      "  5000  44% (  1m 51s)   1.969   |   1.26: 2009 -> two thennandet ne (✗: two thousand nine) (forcing)\n",
      "  6000  56% (  2m 19s)   1.827   |   0.00: a -> a (✓) \n",
      "  7000  67% (  2m 46s)   1.722   |   1.54: single -> sintte (✗: single) (forcing)\n",
      "  8000  78% (  3m 14s)   1.633   |   0.00: the -> the (✓) \n",
      "  9000  89% (  3m 44s)   1.493   |   0.00: & -> and (✓) \n",
      " 10000 100% (  4m 15s)   1.441   |   0.00: & -> and (✓) \n"
     ]
    }
   ],
   "source": [
    "train_iterations(n_iters=9000, lr=0.0001, print_every=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 20000  11% (  4m 45s)   0.355   |   0.00: st -> saint (✓) \n",
      " 30000  22% (  9m 32s)   0.291   |   0.00: Malatov -> malatov (✓) (forcing)\n",
      " 40000  33% ( 14m 18s)   0.320   |   0.00: a -> a (✓) (forcing)\n",
      " 50000  44% ( 18m 55s)   0.338   |   0.00: in -> in (✓) \n",
      "Saved model to data/models/whole_gen_13_1_only_chars_and_attn/50000_(EncoderRNN/DecoderRNN)\n",
      "Accuracy: 0.82% (      82/   10000)\n",
      " 60000  56% (  27m 7s)   0.249   |   0.00: P. -> p (✓) \n",
      " 70000  67% ( 31m 49s)   0.262   |   0.00: a -> a (✓) \n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-44-5bd73cf9ea7d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_iterations\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_iters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m90000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprint_every\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-35-b943d87a23ec>\u001b[0m in \u001b[0;36mtrain_iterations\u001b[0;34m(n_iters, lr, teacher_forcing_ratio, print_every, plot_every)\u001b[0m\n\u001b[1;32m     29\u001b[0m                              \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m                              \u001b[0mloss_function\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNLLLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_teacher_forcing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_teacher_forcing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m                              max_length=40 )\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0mcurrent_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-33-87d0105a88ed>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(s_bef, s_aft, s_sentence, optimizer, loss_function, use_teacher_forcing, max_length)\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0mdecoder_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecoder_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mdecoded_output\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mEOS_TOKEN\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0mdecoded_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecoded_output\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "train_iterations(n_iters=90000, print_every=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "balanced_data_last_sample['after']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def balanced_data_randomize_tmp():\n",
    "    global balanced_data, balanced_data_length, balanced_data_accessed_counter, balanced_data_randomize_freq\n",
    "    \n",
    "    balanced_data = sample_data[sample_data['before'].str.len() == 0]\n",
    "    balanced_data_randomize_freq = 100000\n",
    "    \n",
    "    balanced_data_length = len(balanced_data)\n",
    "    balanced_data_accessed_counter = 0\n",
    "balanced_data_randomize = balanced_data_randomize_tmp\n",
    "balanced_data_randomize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "balanced_data_sample_row()['before']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "state_dict_path = 'data/models/whole_gen_13_1_only_chars_and_attn/50000_'\n",
    "\n",
    "decoder_rnn.load_state_dict(torch.load(state_dict_path + 'DecoderRNN'))\n",
    "encoder_rnn.load_state_dict(torch.load(state_dict_path + 'EncoderRNN'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 74198  20% (   0m 0s)   4.645   |   4.64:  -> siu (✗: n a) (forcing)\n",
      " 74199  40% (   0m 0s)   5.495   |   6.35:  -> sac (✗: n a) \n",
      " 74200  60% (   0m 0s)   3.866   |   0.61:  -> s a (✗: n a) (forcing)\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-67-e2cf30f1f09e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_iterations\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_iters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprint_every\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mteacher_forcing_ratio\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.001\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-35-b943d87a23ec>\u001b[0m in \u001b[0;36mtrain_iterations\u001b[0;34m(n_iters, lr, teacher_forcing_ratio, print_every, plot_every)\u001b[0m\n\u001b[1;32m     29\u001b[0m                              \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m                              \u001b[0mloss_function\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNLLLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_teacher_forcing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_teacher_forcing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m                              max_length=40 )\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0mcurrent_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-33-87d0105a88ed>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(s_bef, s_aft, s_sentence, optimizer, loss_function, use_teacher_forcing, max_length)\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0mdecoder_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecoder_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mdecoded_output\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mEOS_TOKEN\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0mdecoded_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecoded_output\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "train_iterations(n_iters=5, print_every=1, teacher_forcing_ratio=0.5, lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 84201  33% (  4m 59s)   0.251   |   0.00: being -> being (✓) (forcing)\n",
      " 94201  67% (  9m 49s)   0.271   |   0.00: - -> to (✓) (forcing)\n",
      "Saved model to data/models/whole_gen_13_1_only_chars_and_attn/100000_(EncoderRNN/DecoderRNN)\n",
      "Accuracy: 0.99% (      99/   10000)\n",
      "104201 100% ( 17m 55s)   0.289   |   0.00: The -> the (✓) \n"
     ]
    }
   ],
   "source": [
    "train_iterations(n_iters=30000, print_every=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114201   5% (  4m 54s)   0.302   |   0.00: ST -> saint (✓) (forcing)\n",
      "124201  10% (  9m 57s)   0.274   |   0.00: frontal -> frontal (✓) \n",
      "134201  15% ( 14m 46s)   0.252   |   0.00: Book -> book (✓) \n",
      "144201  20% ( 19m 46s)   0.362   |   0.00: E. -> e (✓) (forcing)\n",
      "Saved model to data/models/whole_gen_13_1_only_chars_and_attn/150000_(EncoderRNN/DecoderRNN)\n",
      "Accuracy: 0.73% (      73/   10000)\n",
      "154201  25% ( 28m 22s)   0.322   |   0.00: vol -> volume (✓) \n",
      "164201  30% (  33m 5s)   0.310   |   0.00: & -> and (✓) \n",
      "174201  35% (  38m 4s)   0.417   |   0.00: st -> saint (✓) (forcing)\n",
      "184201  40% ( 42m 43s)   0.350   |   0.00: Magazine -> magazine (✓) \n",
      "194201  45% ( 47m 26s)   0.393   |   0.00: In -> in (✓) (forcing)\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-84-17229cbbb125>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_iterations\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_iters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprint_every\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mteacher_forcing_ratio\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.001\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-35-b943d87a23ec>\u001b[0m in \u001b[0;36mtrain_iterations\u001b[0;34m(n_iters, lr, teacher_forcing_ratio, print_every, plot_every)\u001b[0m\n\u001b[1;32m     29\u001b[0m                              \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m                              \u001b[0mloss_function\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNLLLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_teacher_forcing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_teacher_forcing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m                              max_length=40 )\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0mcurrent_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-33-87d0105a88ed>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(s_bef, s_aft, s_sentence, optimizer, loss_function, use_teacher_forcing, max_length)\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0mtopv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtopi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecoder_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtopk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0mchar_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtopi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m         \u001b[0mchar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mchars_after\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mchar_index\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m# Use own prediction as next input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m         \u001b[0mdecoded_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "train_iterations(n_iters=200000, print_every=10000, teacher_forcing_ratio=0.5, lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentence_id                                               687600\n",
       "token_id                                                       7\n",
       "class                                                      PLAIN\n",
       "before                                                         -\n",
       "after                                                         to\n",
       "class_org                                                  PLAIN\n",
       "a_word_ind                                               [57, 0]\n",
       "sentence       the grand opera house was constructed 1898 <SA...\n",
       "Name: 601296, dtype: object"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "balanced_data_last_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "state_dict_path = 'data/models/whole_gen_13_1_only_chars_and_attn/100000_'\n",
    "\n",
    "decoder_rnn.load_state_dict(torch.load(state_dict_path + 'DecoderRNN'))\n",
    "encoder_rnn.load_state_dict(torch.load(state_dict_path + 'EncoderRNN'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to data/models/whole_gen_13_1_only_chars_and_attn/200000_(EncoderRNN/DecoderRNN)\n",
      "Accuracy: 0.79% (      79/   10000)\n",
      "205635  10% (  8m 41s)   0.290   |   0.00: No -> number (✓) \n",
      "215635  20% ( 13m 39s)   0.289   |   0.46: 28,200 -> twenty eighthohousand swe hundred (✗: twenty eight thousand two hundred) (forcing)\n",
      "225635  30% ( 18m 42s)   0.271   |   0.00: currently -> currently (✓) \n",
      "235635  40% ( 23m 22s)   0.311   |   0.00: equip -> equip (✓) \n",
      "245635  50% ( 28m 18s)   0.335   |   0.00: On -> on (✓) \n",
      "Saved model to data/models/whole_gen_13_1_only_chars_and_attn/250000_(EncoderRNN/DecoderRNN)\n",
      "Accuracy: 0.82% (      82/   10000)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-132-64f00a41d86a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_iterations\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_iters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprint_every\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mteacher_forcing_ratio\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.001\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-35-b943d87a23ec>\u001b[0m in \u001b[0;36mtrain_iterations\u001b[0;34m(n_iters, lr, teacher_forcing_ratio, print_every, plot_every)\u001b[0m\n\u001b[1;32m     29\u001b[0m                              \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m                              \u001b[0mloss_function\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNLLLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_teacher_forcing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_teacher_forcing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m                              max_length=40 )\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0mcurrent_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-131-b126672171a2>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(s_bef, s_aft, s_sentence, optimizer, loss_function, use_teacher_forcing, max_length)\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0mdecoded_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecoded_output\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0;31m# https://github.com/pytorch/examples/blob/master/word_language_model/main.py\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py3_pytorch_2/lib/python3.6/site-packages/torch/autograd/variable.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, retain_variables)\u001b[0m\n\u001b[1;32m    154\u001b[0m                 \u001b[0mVariable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m         \"\"\"\n\u001b[0;32m--> 156\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py3_pytorch_2/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(variables, grad_variables, retain_graph, create_graph, retain_variables)\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[0;32m---> 98\u001b[0;31m         variables, grad_variables, retain_graph)\n\u001b[0m\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_iterations(n_iters=100000, print_every=10000, teacher_forcing_ratio=0.5, lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Updated target_arr to include eos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hell           => helleratelllerseed e || hell \n",
      "                  ['he', 'also', 'played', 'drums', 'for', 'both', 'wax', 'mannequin', 'and', 'the', 'burning', '<SAMPLE>', 'on', 'the', 'hear', 'some', 'evil', 'tour', '.']\n",
      "at             => att hundred three th || at \n",
      "                  ['he', 'also', 'worked', '<SAMPLE>', 'the', 'local', 'red', 'owl', 'supermarket', 'alongside', 'his', 'brother', '.']\n",
      "of             => ofe rscoreeterared f || of \n",
      "                  ['\"', 'severe', 'hepatotoxicity', 'following', 'ingestion', '<SAMPLE>', 'herbalife', 'nutritional', 'supplements', 'contaminated', 'with', 'bacillus', 'subtilis', '\"', '.']\n",
      "959            => nine hundred fifty n || nine hundred fifty nine \n",
      "                  ['\"', '1987', '/', '88', 'porsche', '<SAMPLE>', '\"', '.']\n",
      "the            => the r c hee hundred  || the \n",
      "                  ['security', 'forces', 'subsequently', 'reach', 'the', 'area', 'and', 'begin', 'probing', '<SAMPLE>', 'circumstances', 'surrounding', 'the', 'attack', '.']\n",
      "Barbara        => barbararardbarardber || barbara \n",
      "                  ['gloria', 'and', '<SAMPLE>', 'were', 'discovered', 'at', 'the', 'san', 'diego', 'county', 'fair', 'by', 'a', 'studio', 'official', 'from', '20th', 'century', 'fox', '.']\n",
      "-              => tolleorllsevenine ke || to \n",
      "                  ['bc', ',', 'paléorient', ',', 'volume', '33', ',', 'number', '33', '<SAMPLE>', '2', ',', 'pp', '.']\n",
      "cir            => cir r coterscertedra || circle \n",
      "                  ['1992', ')', ';', 'allegheny', 'general', 'hospital', 'v', '.', 'nlrb', ',', '608', 'f', '.', '2', 'd', '965', '(', '3', 'd', '<SAMPLE>']\n",
      "Amazon.com     => a m z z f n dot c o  || a m a z o n dot c o m \n",
      "                  ['<SAMPLE>', ',', 'inc', 'archived', 'from', 'the', 'original', 'on', '2012', '-', '04', '-', '06', '.']\n",
      "kilometres     => kilometerssmenensted || kilometers \n",
      "                  ['the', 'commune', 'has', 'a', 'land', 'area', 'of', '132', '.', '38', 'square', '<SAMPLE>', '(', '51', '.', '11', 'sq', 'mi', ')', '.']\n"
     ]
    }
   ],
   "source": [
    "print_local_wrong_predictions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "260467  20% (   5m 0s)   0.487   |   0.00: wounded -> wounded (✓) (forcing)\n",
      "270467  40% (  10m 0s)   0.566   |   3.51: www.visionzeroboston.org/Orlov -> w w w i coi oos o o o o o coo o o o o o o o o o o o coo o o o o o o o co (✗: w w w dot v i s i o n z e r o b o s t o n dot o r g s l a s h o r l o v) \n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-143-7b468a9100cc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_iterations\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_iters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprint_every\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mteacher_forcing_ratio\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.001\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-35-b943d87a23ec>\u001b[0m in \u001b[0;36mtrain_iterations\u001b[0;34m(n_iters, lr, teacher_forcing_ratio, print_every, plot_every)\u001b[0m\n\u001b[1;32m     29\u001b[0m                              \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m                              \u001b[0mloss_function\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNLLLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_teacher_forcing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_teacher_forcing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m                              max_length=40 )\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0mcurrent_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-142-4bf58e4d3d6f>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(s_bef, s_aft, s_sentence, optimizer, loss_function, use_teacher_forcing, max_length)\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0mtopv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtopi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecoder_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtopk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0mchar_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtopi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m         \u001b[0mchar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mchars_after\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mchar_index\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m# Use own prediction as next input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m         \u001b[0mdecoded_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "train_iterations(n_iters=50000, print_every=10000, teacher_forcing_ratio=0.5, lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4433358438331329401"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "char_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "state_dict_path = 'data/models/whole_gen_13_1_only_chars_and_attn/100000_'\n",
    "\n",
    "decoder_rnn.load_state_dict(torch.load(state_dict_path + 'DecoderRNN'))\n",
    "encoder_rnn.load_state_dict(torch.load(state_dict_path + 'EncoderRNN'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to data/models/whole_gen_13_1_only_chars_and_attn/200000_(EncoderRNN/DecoderRNN)\n",
      "Accuracy: 0.79% (      79/   10000)\n",
      "205635  10% (  8m 41s)   0.290   |   0.00: No -> number (✓) \n",
      "215635  20% ( 13m 39s)   0.289   |   0.46: 28,200 -> twenty eighthohousand swe hundred (✗: twenty eight thousand two hundred) (forcing)\n",
      "225635  30% ( 18m 42s)   0.271   |   0.00: currently -> currently (✓) \n",
      "235635  40% ( 23m 22s)   0.311   |   0.00: equip -> equip (✓) \n",
      "245635  50% ( 28m 18s)   0.335   |   0.00: On -> on (✓) \n",
      "Saved model to data/models/whole_gen_13_1_only_chars_and_attn/250000_(EncoderRNN/DecoderRNN)\n",
      "Accuracy: 0.82% (      82/   10000)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-132-64f00a41d86a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_iterations\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_iters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprint_every\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mteacher_forcing_ratio\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.001\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-35-b943d87a23ec>\u001b[0m in \u001b[0;36mtrain_iterations\u001b[0;34m(n_iters, lr, teacher_forcing_ratio, print_every, plot_every)\u001b[0m\n\u001b[1;32m     29\u001b[0m                              \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m                              \u001b[0mloss_function\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNLLLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_teacher_forcing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_teacher_forcing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m                              max_length=40 )\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0mcurrent_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-131-b126672171a2>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(s_bef, s_aft, s_sentence, optimizer, loss_function, use_teacher_forcing, max_length)\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0mdecoded_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecoded_output\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0;31m# https://github.com/pytorch/examples/blob/master/word_language_model/main.py\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py3_pytorch_2/lib/python3.6/site-packages/torch/autograd/variable.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, retain_variables)\u001b[0m\n\u001b[1;32m    154\u001b[0m                 \u001b[0mVariable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m         \"\"\"\n\u001b[0;32m--> 156\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py3_pytorch_2/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(variables, grad_variables, retain_graph, create_graph, retain_variables)\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[0;32m---> 98\u001b[0;31m         variables, grad_variables, retain_graph)\n\u001b[0m\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_iterations(n_iters=100000, print_every=10000, teacher_forcing_ratio=0.5, lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "state_dict_path = 'data/models/whole_gen_13_1_only_chars_and_attn/250000_'\n",
    "\n",
    "decoder_rnn.load_state_dict(torch.load(state_dict_path + 'DecoderRNN'))\n",
    "encoder_rnn.load_state_dict(torch.load(state_dict_path + 'EncoderRNN'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "285054  10% (  5m 20s)   0.439   |   0.00: ltd -> limited (✓) (forcing)\n",
      "295054  20% ( 10m 23s)   0.460   |   0.00: fire -> fire (✓) \n",
      "Saved model to data/models/whole_gen_13_1_only_chars_and_attn/300000_(EncoderRNN/DecoderRNN)\n",
      "Accuracy: 77.47% (    7747/   10000)\n",
      "305054  30% ( 16m 48s)   0.597   |   1.10: 1967 -> nineteee sex<EOS>p seven (✗: nineteen sixty seven) (forcing)\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-242-64f00a41d86a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_iterations\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_iters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprint_every\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mteacher_forcing_ratio\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.001\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-35-b943d87a23ec>\u001b[0m in \u001b[0;36mtrain_iterations\u001b[0;34m(n_iters, lr, teacher_forcing_ratio, print_every, plot_every)\u001b[0m\n\u001b[1;32m     29\u001b[0m                              \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m                              \u001b[0mloss_function\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNLLLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_teacher_forcing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_teacher_forcing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m                              max_length=40 )\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0mcurrent_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-142-4bf58e4d3d6f>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(s_bef, s_aft, s_sentence, optimizer, loss_function, use_teacher_forcing, max_length)\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0mtopv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtopi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecoder_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtopk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0mchar_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtopi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m         \u001b[0mchar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mchars_after\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mchar_index\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m# Use own prediction as next input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m         \u001b[0mdecoded_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "train_iterations(n_iters=100000, print_every=10000, teacher_forcing_ratio=0.5, lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "state_dict_path = 'data/models/whole_gen_13_1_only_chars_and_attn/300000_'\n",
    "\n",
    "decoder_rnn.load_state_dict(torch.load(state_dict_path + 'DecoderRNN'))\n",
    "encoder_rnn.load_state_dict(torch.load(state_dict_path + 'EncoderRNN'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_iterations(n_iters=100000, print_every=10000, teacher_forcing_ratio=0.5, lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print_local_wrong_predictions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_iterations(n_iters=100000, print_every=10000, teacher_forcing_ratio=0.1, lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print_local_wrong_predictions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'retrieved june 17 , 2012 from <SAMPLE> noise on imdb miller .'"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_samples[-2]['sentence']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_iterations(n_iters=200000, print_every=10000, teacher_forcing_ratio=0.1, lr=0.0005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print_local_wrong_predictions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_iterations(n_iters=300000, print_every=10000, teacher_forcing_ratio=0.1, lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print_local_wrong_predictions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_iterations(n_iters=300000, print_every=10000, teacher_forcing_ratio=0, lr=0.0005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print_local_wrong_predictions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_iterations(n_iters=200000, print_every=10000, teacher_forcing_ratio=0.2, lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print_local_wrong_predictions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_iterations(n_iters=500000, print_every=10000, teacher_forcing_ratio=0, lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print_local_wrong_predictions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_iterations(n_iters=500000, print_every=10000, teacher_forcing_ratio=0, lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print_local_wrong_predictions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_iterations(n_iters=400000, print_every=10000, teacher_forcing_ratio=0, lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_iterations(n_iters=10000, lr=0.001, print_every=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print_local_wrong_predictions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_iterations(n_iters=200000, print_every=10000, teacher_forcing_ratio=0.3, lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "state_dict_path = 'data/models/whole_gen_13_only_chars_and_attn/10_'\n",
    "#state_dict_path = 'data/models/whole_gen_13_only_chars_and_attn/250000_'\n",
    "\n",
    "decoder_rnn.load_state_dict(torch.load(state_dict_path + 'DecoderRNN'))\n",
    "encoder_rnn.load_state_dict(torch.load(state_dict_path + 'EncoderRNN'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "balanced_data.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "balanced_data.groupby('class')['class'].count()\n",
    "len(balanced_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def balanced_data_randomize_long():\n",
    "    global balanced_data, balanced_data_length, balanced_data_accessed_counter, balanced_data_randomize_freq\n",
    "    \n",
    "    bal_data = pd.concat([v.sample(min(2000, len(v))) for k, v in balanced_data_classes_select])\n",
    "    long_data = sample_data[sample_data['before'].str.len()>8].sample(4000)\n",
    "    elec_data = sample_data[sample_data['class']=='ELECTRONIC']\n",
    "    let_long_data = sample_data[(sample_data['class'] == 'LETTERS') & (sample_data['before'].str.len() > 5)]\n",
    "    balanced_data = pd.concat([bal_data, long_data, elec_data, let_long_data])#.drop_duplicates()\n",
    "    balanced_data = balanced_data[~balanced_data.index.duplicated(keep='first')]\n",
    "    \n",
    "    balanced_data_length = len(balanced_data)\n",
    "    balanced_data_randomize_freq = balanced_data_length * 0.5\n",
    "    balanced_data_accessed_counter = 0\n",
    "\n",
    "balanced_data_randomize = balanced_data_randomize_long\n",
    "balanced_data_randomize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def debug_show_attention(input_sentence, output_words, attentions):\n",
    "    # Set up figure with colorbar\n",
    "    fig = plt.figure(figsize=(15,6))\n",
    "    ax = fig.add_subplot(111)\n",
    "    #cax = ax.matshow(attentions.numpy(), cmap='bone')\n",
    "    cax = ax.matshow(attentions, cmap='bone')\n",
    "    fig.colorbar(cax)\n",
    "    # Set up axes\n",
    "    #ax.set_xticklabels([''] + input_sentence.split(' ') + ['<EOS>'], rotation=90)\n",
    "    #ax.set_xticklabels([''] + input_sentence + ['<EOS>'], rotation=90)\n",
    "    ax.set_yticklabels([''] + output_words)\n",
    "    \n",
    "    input_sentence = input_sentence + ['<EOS>']\n",
    "    #inp_arr = [\"{}\\n{}\".format(input_sentence[i], input_sentence[-1-i]) for i in range(len(input_sentence))]\n",
    "    inp_arr = input_sentence\n",
    "    ax.set_xticklabels([''] + inp_arr, rotation=0)\n",
    "\n",
    "    # Show label at every tick\n",
    "    ax.xaxis.set_major_locator(matplotlib.ticker.MultipleLocator(1))\n",
    "    ax.yaxis.set_major_locator(matplotlib.ticker.MultipleLocator(1))\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "def debug_eval_sample_show_attention():\n",
    "    \n",
    "    sample_row = balanced_data_sample_row()\n",
    "    #sample_row = balanced_data[balanced_data['before'].str.len()>15].sample(1).iloc[0]\n",
    "    sample = sample_row['before'], sample_row['a_word_ind'], sample_row['class'], sample_row['sentence'].split(' ')\n",
    "\n",
    "    output, decoded_output, decoder_attns_arr, sample = test_model_single_sample(None, \n",
    "                                                            return_more=True, sample=sample)\n",
    "    print('input:  ', sample[0])\n",
    "    print('output: ', decoded_output)\n",
    "    print('target:   ', ' '.join([words_after_common[w] for w in sample[1][:-1]]))\n",
    "\n",
    "    attns = np.array([arr.data[0].cpu().numpy() for arr in decoder_attns_arr])\n",
    "\n",
    "    debug_show_attention(list(sample[0]), decoded_output, attns)\n",
    "    #plt.matshow(attns)\n",
    "\n",
    "debug_eval_sample_show_attention()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "balanced_data.groupby('class')['class'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test_in_categories(iter_len = 1000):\n",
    "    wrong_preds = {}\n",
    "    for cat in categories_all:\n",
    "        tmp_data = sample_data[sample_data['class'] == cat].sample(iter_len)\n",
    "        correct_n = 0\n",
    "        wrong_preds_arr = []\n",
    "\n",
    "        for _ in range(iter_len):\n",
    "            sample_row = tmp_data.iloc[_]\n",
    "            sample = sample_row['before'], sample_row['a_word_ind'], sample_row['class'], sample_row['sentence']\n",
    "\n",
    "            output, t1, sample_target, t2 = test_model_single_sample(None, sample=sample)\n",
    "            if output == sample_target:\n",
    "                correct_n += 1\n",
    "            else:\n",
    "                wrong_preds_arr.append([sample_target, output])\n",
    "\n",
    "        print(\"{:>10}: {:>5d}/{:>5d} ({:>4.0%})\".format(cat, correct_n, iter_len, correct_n/iter_len))\n",
    "        wrong_preds[cat] = wrong_preds_arr\n",
    "    return wrong_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wrong_preds = test_in_categories(3000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wrong_preds['LETTERS']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# With training longer words\n",
    "wrong_preds = test_in_categories()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:py3_pytorch_2]",
   "language": "python",
   "name": "conda-env-py3_pytorch_2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
