{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pytorch utils oh: pytorch_utils_oh_1.py\n",
      "Pytorch: 0.2.0_4\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import importlib\n",
    "from pytorch_utils_oh_1 import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MODEL_SAVE_PATH = 'letters_1'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import pytorch_utils_oh_1; importlib.reload(pytorch_utils_oh_1); from pytorch_utils_oh_1 import *;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_data = pickle.load(open(\"data/en_train_not_changed_verb_fix_2.pkl\", \"rb\" ))\n",
    "all_data_sentence_index = all_data.set_index('sentence_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "letters_data = all_data[all_data['class']=='LETTERS']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>token_id</th>\n",
       "      <th>class</th>\n",
       "      <th>before</th>\n",
       "      <th>after</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6909787</th>\n",
       "      <td>524750</td>\n",
       "      <td>9</td>\n",
       "      <td>LETTERS</td>\n",
       "      <td>D.C.'s</td>\n",
       "      <td>d c's</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3847166</th>\n",
       "      <td>295812</td>\n",
       "      <td>13</td>\n",
       "      <td>LETTERS</td>\n",
       "      <td>PDF</td>\n",
       "      <td>p d f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2422233</th>\n",
       "      <td>188158</td>\n",
       "      <td>3</td>\n",
       "      <td>LETTERS</td>\n",
       "      <td>cnn</td>\n",
       "      <td>c n n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8657415</th>\n",
       "      <td>654804</td>\n",
       "      <td>6</td>\n",
       "      <td>LETTERS</td>\n",
       "      <td>Ph</td>\n",
       "      <td>p h</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6896852</th>\n",
       "      <td>523780</td>\n",
       "      <td>12</td>\n",
       "      <td>LETTERS</td>\n",
       "      <td>U.S.</td>\n",
       "      <td>u s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1242585</th>\n",
       "      <td>97936</td>\n",
       "      <td>7</td>\n",
       "      <td>LETTERS</td>\n",
       "      <td>US</td>\n",
       "      <td>u s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1934541</th>\n",
       "      <td>150902</td>\n",
       "      <td>7</td>\n",
       "      <td>LETTERS</td>\n",
       "      <td>FM</td>\n",
       "      <td>f m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8449318</th>\n",
       "      <td>639418</td>\n",
       "      <td>15</td>\n",
       "      <td>LETTERS</td>\n",
       "      <td>XVIIe</td>\n",
       "      <td>x v i i e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2495561</th>\n",
       "      <td>193732</td>\n",
       "      <td>13</td>\n",
       "      <td>LETTERS</td>\n",
       "      <td>U.K.</td>\n",
       "      <td>u k</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6745899</th>\n",
       "      <td>512597</td>\n",
       "      <td>18</td>\n",
       "      <td>LETTERS</td>\n",
       "      <td>P.</td>\n",
       "      <td>p</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         sentence_id  token_id    class  before      after\n",
       "6909787       524750         9  LETTERS  D.C.'s      d c's\n",
       "3847166       295812        13  LETTERS     PDF      p d f\n",
       "2422233       188158         3  LETTERS     cnn      c n n\n",
       "8657415       654804         6  LETTERS      Ph        p h\n",
       "6896852       523780        12  LETTERS    U.S.        u s\n",
       "1242585        97936         7  LETTERS      US        u s\n",
       "1934541       150902         7  LETTERS      FM        f m\n",
       "8449318       639418        15  LETTERS   XVIIe  x v i i e\n",
       "2495561       193732        13  LETTERS    U.K.        u k\n",
       "6745899       512597        18  LETTERS      P.          p"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "letters_data.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "letters_match_re = re.compile(r\"[a-zA-Z]\") \n",
    "def letters_transform_baseline(string):\n",
    "    global letters_before_after_last_string\n",
    "    letters_before_after_last_string = string\n",
    "    arr = []\n",
    "    if string == \"'s\":\n",
    "        return string\n",
    "    for i, c in enumerate(string):\n",
    "        if letters_match_re.match(c):\n",
    "            arr.append(c)\n",
    "        elif c == '&':\n",
    "            arr.append('and')\n",
    "        elif len(string) > 1 and i==len(string)-2 and string[-1] == 's':\n",
    "            arr[-1] = arr[-1] + \"'s\"\n",
    "            break\n",
    "        elif len(string) > 2 and i==len(string)-3 and string[-2:] == 's':\n",
    "            arr[-1] = arr[-1] + \"'s\"\n",
    "        elif c == 'é':\n",
    "            arr.append('e')\n",
    "            arr.append('acute')\n",
    "            \n",
    "    return ' '.join(arr).lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"a e's\""
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "letters_transform_baseline(\"AE's\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_baseline(n_sample=20, print_wrongs=True):\n",
    "    n_correct = 0 \n",
    "    for _ in range(n_sample):\n",
    "        row = letters_data.iloc[random.randint(1, len(letters_data)-1)]\n",
    "        tmp=row\n",
    "        s_bef = row['before']\n",
    "        s_aft = row['after']\n",
    "        result = letters_transform_baseline(s_bef)\n",
    "        if result == s_aft:\n",
    "            n_correct += 1\n",
    "            # print(\"YAY: {} => {}\".format(s_bef, s_aft))\n",
    "        elif print_wrongs:\n",
    "            print(\"NOO: {} => {} ({})\".format(s_bef, result, s_aft))\n",
    "    print(\"Accuracy: {:>4.2%} ({:>8d}/{:>8d})\".format(n_correct/n_sample, n_correct, n_sample))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOO: CDs => c d s (c d's)\n",
      "NOO: GCSEs => g c s e s (g c s e's)\n",
      "NOO: Ulus => u l u s (u l u's)\n",
      "NOO: Thos => t h o s (t h o's)\n",
      "NOO: NOCs => n o c s (n o c's)\n",
      "NOO: ATVs => a t v s (a t v's)\n",
      "NOO: Québécois => q u e acute b e acute c o i s (q u e acute b e acute c o i's)\n",
      "NOO: Tas => t a s (t a's)\n",
      "NOO: Ves => v e s (v e's)\n",
      "NOO: SDKs => s d k s (s d k's)\n",
      "NOO: OKs => o k s (o k's)\n",
      "NOO: Mes => m e s (m e's)\n",
      "Accuracy: 98.80% (     988/    1000)\n"
     ]
    }
   ],
   "source": [
    "eval_baseline(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 98.59% (   98589/  100000)\n"
     ]
    }
   ],
   "source": [
    "eval_baseline(100000, print_wrongs=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>token_id</th>\n",
       "      <th>class</th>\n",
       "      <th>before</th>\n",
       "      <th>after</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7459959</th>\n",
       "      <td>565730</td>\n",
       "      <td>6</td>\n",
       "      <td>NOT_CHANGED</td>\n",
       "      <td>,</td>\n",
       "      <td>,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4751479</th>\n",
       "      <td>363745</td>\n",
       "      <td>3</td>\n",
       "      <td>NOT_CHANGED</td>\n",
       "      <td>Hispanic</td>\n",
       "      <td>Hispanic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2165066</th>\n",
       "      <td>168526</td>\n",
       "      <td>16</td>\n",
       "      <td>NOT_CHANGED</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6848805</th>\n",
       "      <td>520203</td>\n",
       "      <td>1</td>\n",
       "      <td>NOT_CHANGED</td>\n",
       "      <td>applications</td>\n",
       "      <td>applications</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5290088</th>\n",
       "      <td>404069</td>\n",
       "      <td>4</td>\n",
       "      <td>NOT_CHANGED</td>\n",
       "      <td>Cup</td>\n",
       "      <td>Cup</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         sentence_id  token_id        class        before         after\n",
       "7459959       565730         6  NOT_CHANGED             ,             ,\n",
       "4751479       363745         3  NOT_CHANGED      Hispanic      Hispanic\n",
       "2165066       168526        16  NOT_CHANGED             .             .\n",
       "6848805       520203         1  NOT_CHANGED  applications  applications\n",
       "5290088       404069         4  NOT_CHANGED           Cup           Cup"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['NOT_CHANGED' 'NUMBERS' 'LETTERS' 'PLAIN' 'VERBATIM' 'ELECTRONIC']\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "categories_all = all_data[\"class\"].unique()\n",
    "print(categories_all)\n",
    "print(len(categories_all))\n",
    "categories_index = dict((c, i) for i, c in enumerate(categories_all))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Letters all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<EOS><SOS> !\"#$%&'()+,-./0123456789:;?ABCDEFGHIJKLMNOPQRSTUVWXYZ[]_abcdefghijklmnopqrstuvwxyz|~¡£¥ª«²³µº»¼½¾¿éɒʻˈΩμ—€⅓⅔⅛⅝⅞☒\n",
      "115\n"
     ]
    }
   ],
   "source": [
    "tmp = sorted(list(set(''.join(all_data['before']))))\n",
    "characters_all = ['<EOS>', '<SOS>'] + sorted(list(set(tmp)))\n",
    "characters_all_index = dict((c, i) for i, c in enumerate(characters_all))\n",
    "print(''.join(characters_all))\n",
    "print(len(characters_all))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Common words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7380"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "common_words = pickle.load(open(\"data/en_train_words_before_over_100.pk\", \"rb\" ))\n",
    "common_words = [EOS_TOKEN, SOS_TOKEN, UNKNOWN_WORD_TOKEN, NUMBER_WORD_TOKEN] + common_words\n",
    "common_words_index = dict((c, i) for i, c in enumerate(common_words))\n",
    "len(common_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### More balanced sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "class\n",
       "ELECTRONIC        4964\n",
       "LETTERS         144364\n",
       "NOT_CHANGED    9218584\n",
       "NUMBERS         448151\n",
       "PLAIN            36472\n",
       "VERBATIM         65855\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data.groupby(\"class\")[\"class\"].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "balanced_data_classes_select = list(all_data.groupby('class'))\n",
    "balanced_data_accessed_counter = 0 \n",
    "balanced_data_length = 0\n",
    "def balanced_data_randomize(max_len=20000):\n",
    "    global balanced_data, balanced_data_length, balanced_data_accessed_counter\n",
    "    balanced_data = pd.concat([v.sample(min(max_len, len(v))) for k, v in balanced_data_classes_select])\n",
    "    balanced_data_length = len(balanced_data)\n",
    "    balanced_data_accessed_counter = 0\n",
    "\n",
    "def balanced_data_sample_row():\n",
    "    global balanced_data_accessed_counter\n",
    "    balanced_data_accessed_counter += 1\n",
    "    if balanced_data_accessed_counter/balanced_data_length > 0.2:\n",
    "        balanced_data_randomize()\n",
    "    return balanced_data.iloc[random.randint(1, balanced_data_length-1)]\n",
    "    \n",
    "balanced_data_randomize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "class\n",
       "ELECTRONIC      4964\n",
       "LETTERS        20000\n",
       "NOT_CHANGED    20000\n",
       "NUMBERS        20000\n",
       "PLAIN          20000\n",
       "VERBATIM       20000\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "balanced_data.groupby(\"class\")[\"class\"].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ELECTRONIC : Catholic-Hierarchy.org -> c a t h o l i c d a s h h i e r a r c h y dot o r g\n",
      "\" Bishop Giuseppe Pamphilj ( Panfili ) , O.S.A. \" <SAMPLE> .\n",
      "['\"', 'Bishop', 'Giuseppe', 'Pamphilj', '(', 'Panfili', ')', ',', 'O.S.A.', '\"', '<SAMPLE>', '.']\n",
      "torch.Size([1, 13, 7380])\n",
      "torch.Size([1, 23, 115])\n"
     ]
    }
   ],
   "source": [
    "def get_random_sample():\n",
    "    sample_row = balanced_data_sample_row()\n",
    "    sentence_id = sample_row['class']\n",
    "\n",
    "    rows = all_data_sentence_index.loc[sample_row['sentence_id']]\n",
    "    befores = list(rows.before)\n",
    "        \n",
    "    token_id_idx = list(rows['token_id']).index(sample_row['token_id'])\n",
    "    befores[token_id_idx] = SAMPLE_WORD_TOKEN\n",
    "    \n",
    "    return sample_row['before'], sample_row['after'], sample_row['class'], befores\n",
    "            \n",
    "def tmp():\n",
    "    s_bef, s_aft, s_class, s_sentence = get_random_sample()\n",
    "    print(s_class, ':', s_bef, '->', s_aft)\n",
    "    print(' '.join(s_sentence))\n",
    "    print(s_sentence)\n",
    "    print(words_to_tensor(list(s_sentence), common_words_index).shape)\n",
    "    print(string_to_tensor(s_bef, characters_all_index).shape)\n",
    "tmp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:py3_pytorch_2]",
   "language": "python",
   "name": "conda-env-py3_pytorch_2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
